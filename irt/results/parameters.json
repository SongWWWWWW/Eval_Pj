{"ability": [2.4018726348876953, 2.329103708267212, 2.3264341354370117, 2.3218472003936768, 2.235281467437744, 2.2089908123016357, 2.1927340030670166, 2.1563525199890137, 2.069796323776245, 2.134772300720215, 2.0637152194976807, 2.0120179653167725, 1.9016363620758057, 2.006091594696045, 1.963613748550415, 1.8987712860107422, 1.8476264476776123, 1.7398755550384521, 1.7235966920852661, 1.685867428779602, 1.6939491033554077, 1.6863685846328735, 1.7371591329574585, 1.6925349235534668, 1.6544526815414429, 1.6366097927093506, 1.6419498920440674, 1.6396126747131348, 1.583674669265747, 1.63006591796875, 1.60049569606781, 1.5930521488189697, 1.592613935470581, 1.5784050226211548, 1.5600309371948242, 1.5992865562438965, 1.5441958904266357, 1.5165778398513794, 1.4697504043579102, 1.436922550201416, 1.4573171138763428, 1.4735283851623535, 1.4231157302856445, 1.412319540977478, 1.404105544090271, 1.4036625623703003, 1.4423011541366577, 1.3658865690231323, 1.3419052362442017, 1.3647085428237915, 1.4479737281799316, 1.3250559568405151, 1.3063969612121582, 1.3022993803024292, 1.3199009895324707, 1.3055106401443481, 1.3020950555801392, 1.3046115636825562, 1.3039346933364868, 1.2492597103118896, 1.3750271797180176, 1.2728389501571655, 1.3061299324035645, 1.2961480617523193, 1.2702863216400146, 1.2574208974838257, 1.2664172649383545, 1.2850663661956787, 1.1791925430297852, 1.239660382270813, 1.2349834442138672, 1.3310531377792358, 1.2470901012420654, 1.299087405204773, 1.3092589378356934, 1.2517690658569336, 1.328075885772705, 1.3365468978881836, 1.3562809228897095, 1.277413249015808, 1.3041573762893677, 1.3413456678390503, 1.3341814279556274, 1.219375491142273, 1.2032231092453003, 1.2157025337219238, 1.3203585147857666, 1.2810478210449219, 1.2915279865264893, 1.2909353971481323, 1.3559083938598633, 1.2374495267868042, 1.2049355506896973, 1.2206004858016968, 1.3408231735229492, 1.2096773386001587, 1.3028349876403809, 1.3165363073349, 1.210836410522461, 1.3222930431365967, 1.2174241542816162, 1.310380220413208, 1.1851086616516113, 1.1934126615524292, 1.300166368484497, 1.2108612060546875, 1.3264203071594238, 1.1860034465789795, 1.2964009046554565, 1.211451530456543, 1.300125002861023, 1.2027002573013306, 1.2033395767211914, 1.1523094177246094, 1.3274388313293457, 1.309150218963623, 1.2595622539520264, 1.3205504417419434, 1.3094302415847778, 1.2016708850860596, 1.290452241897583, 1.203163504600525, 1.2922433614730835, 1.1837210655212402, 1.1964958906173706, 1.2505301237106323, 1.2918304204940796, 1.3366135358810425, 1.2408905029296875, 1.1558932065963745, 1.1639044284820557, 1.1729687452316284, 1.1579859256744385, 1.2542439699172974, 1.1877459287643433, 1.1823683977127075, 1.1780474185943604, 1.1722428798675537, 1.1409058570861816, 1.2544186115264893, 1.221624493598938, 1.2018612623214722, 1.2648648023605347, 1.2629295587539673, 1.2609076499938965, 1.2846379280090332, 1.1261729001998901, 1.2694995403289795, 1.2760581970214844, 1.2681071758270264, 1.2312681674957275, 1.2808454036712646, 1.1565169095993042, 1.2905046939849854, 1.2906736135482788, 1.2468839883804321, 1.2008774280548096, 1.2104663848876953, 1.1905514001846313, 1.142722487449646, 1.2803360223770142, 1.2534619569778442, 1.273619532585144, 1.1657534837722778, 1.2716481685638428, 1.210323691368103, 1.1437392234802246, 1.2485988140106201, 1.153130292892456, 1.153183937072754, 1.2281910181045532, 1.2754408121109009, 1.2915679216384888, 1.2853776216506958, 1.145243525505066, 1.1551777124404907, 1.1612297296524048, 1.1587051153182983, 1.2471972703933716, 1.2498692274093628, 1.1576570272445679, 1.130121111869812, 1.1743690967559814, 1.1232966184616089, 1.2443652153015137, 1.1532862186431885, 1.2280539274215698, 1.2222416400909424, 1.233289361000061, 1.2225780487060547, 1.233986735343933, 1.274549961090088, 1.2286300659179688, 1.2615050077438354, 1.288045048713684, 1.2344528436660767, 1.2425885200500488, 1.2256457805633545, 1.2687817811965942, 1.1268606185913086, 1.1298779249191284, 1.1513994932174683, 1.127712607383728, 1.2890321016311646, 1.1342906951904297, 1.2652229070663452, 1.2680644989013672, 1.1471138000488281, 1.234621524810791, 1.2863534688949585, 1.2049421072006226, 1.1999026536941528, 1.140978455543518, 1.209539771080017, 1.2766308784484863, 1.2530794143676758, 1.273639440536499, 1.1197832822799683, 1.2890156507492065, 1.1175297498703003, 1.2746429443359375, 1.2902384996414185, 1.2598488330841064, 1.289634346961975, 1.2265243530273438, 1.2208991050720215, 1.2132182121276855, 1.2393569946289062, 1.225154161453247, 1.2028108835220337, 1.2682572603225708, 1.2626820802688599, 1.1343698501586914, 1.205942153930664, 1.2506564855575562, 1.1343252658843994, 1.2274134159088135, 1.1363075971603394, 1.1507751941680908, 1.2058757543563843, 1.258023738861084, 1.2064905166625977, 1.1726828813552856, 1.2212064266204834, 1.0929172039031982, 1.212027668952942, 1.1975973844528198, 1.237227439880371, 1.2287381887435913, 1.2475337982177734, 1.1322364807128906, 1.0831148624420166, 1.2149320840835571, 1.228638768196106, 1.1174113750457764, 1.1280211210250854, 1.2532172203063965, 1.1988697052001953, 1.108215093612671, 1.254907250404358, 1.234703540802002, 1.0899677276611328, 1.190626859664917, 1.262631893157959, 1.1501657962799072, 1.2094008922576904, 1.2697004079818726, 1.23201584815979, 1.2504388093948364, 1.2125029563903809, 1.087990641593933, 1.255176305770874, 1.0672649145126343, 1.24875807762146, 1.2075388431549072, 1.205857515335083, 1.0978169441223145, 1.1900222301483154, 1.2392799854278564, 1.2536791563034058, 1.2167751789093018, 1.2357358932495117, 1.1559075117111206, 1.090159296989441, 1.1766051054000854, 1.2526109218597412, 1.2142283916473389, 1.2353510856628418, 1.2357192039489746, 1.2081377506256104, 1.1233443021774292, 1.2466716766357422, 1.247467279434204, 1.1005311012268066, 1.1857492923736572, 1.1900089979171753, 1.1785824298858643, 1.1975805759429932, 1.2382627725601196, 1.079538345336914, 1.231858253479004, 1.1945446729660034, 1.2001186609268188, 1.2250043153762817, 1.2249019145965576, 1.2242770195007324, 1.2198220491409302, 1.1787351369857788, 1.255037784576416, 1.1044347286224365, 1.1159231662750244, 1.2343007326126099, 1.2416977882385254, 1.2355566024780273, 1.1952027082443237, 1.1271576881408691, 1.2365055084228516, 1.2239148616790771, 1.0908164978027344, 1.1030420064926147, 1.2188056707382202, 1.0906388759613037, 1.1851016283035278, 1.2178826332092285, 1.2480390071868896, 1.2303671836853027, 1.2244867086410522, 1.1544932126998901, 1.0960211753845215, 1.1295509338378906, 1.2241958379745483, 1.1595284938812256, 1.212141990661621, 1.2270303964614868, 1.1980409622192383, 1.223258137702942, 1.2300970554351807, 1.233715534210205, 1.160091757774353, 1.0988997220993042, 1.092260479927063, 1.1957255601882935, 1.2217786312103271, 1.197951316833496, 1.0980019569396973, 1.056290626525879, 1.2292118072509766, 1.1946719884872437, 1.2306101322174072, 1.0626684427261353, 1.2239603996276855, 1.0973930358886719, 1.228545069694519, 1.168250322341919, 1.2227894067764282, 1.0727583169937134, 1.054868221282959, 1.1804025173187256, 1.1714929342269897, 1.2286871671676636, 1.1961246728897095, 1.141097068786621, 1.2062880992889404, 1.1202609539031982, 1.225682020187378, 1.15444016456604, 1.2210967540740967, 1.221397876739502, 1.180275797843933, 1.0711476802825928, 1.0811560153961182, 1.0735703706741333, 1.0496151447296143, 1.1836576461791992, 1.1295006275177002, 1.0886521339416504, 1.216468095779419, 1.225925087928772, 1.2078845500946045, 1.0571035146713257, 1.079331398010254, 1.2291244268417358, 1.2252445220947266, 1.205852746963501, 1.2141607999801636, 1.224229097366333, 1.2136887311935425, 1.0568723678588867, 1.0665771961212158, 1.1702321767807007, 1.216213345527649, 1.2016171216964722, 1.0885400772094727, 1.178831696510315, 1.106154203414917, 1.1982855796813965, 1.025865912437439, 1.1060023307800293, 1.0093505382537842, 1.2096613645553589, 1.2040457725524902, 1.0591051578521729, 1.1267595291137695, 1.2042725086212158, 1.052811622619629, 1.1988165378570557, 1.1743491888046265, 1.106420636177063, 1.198715329170227, 1.0613654851913452, 1.2099096775054932, 1.187229037284851, 1.1573407649993896, 1.1983224153518677, 1.07090163230896, 1.1570700407028198, 1.2165096998214722, 1.1952648162841797, 1.2121751308441162, 1.0690327882766724, 1.1568890810012817, 1.1921066045761108, 1.1963645219802856, 1.2123855352401733, 1.1993645429611206, 1.1953651905059814, 1.1914142370224, 1.2072851657867432, 1.0852018594741821, 1.1880393028259277, 1.053576111793518, 1.208033561706543, 1.2033262252807617, 1.182905673980713, 1.2029975652694702, 1.2108246088027954, 1.1956570148468018, 1.1772359609603882, 1.167270541191101, 1.1991298198699951, 1.1546988487243652, 1.0522609949111938, 1.1872042417526245, 1.1893292665481567, 1.1950300931930542, 1.1921647787094116, 1.1893978118896484, 1.1909458637237549, 1.1777530908584595, 1.1816010475158691, 1.2129614353179932, 1.0953301191329956, 1.1962939500808716, 1.2068809270858765, 1.0190696716308594, 1.1364904642105103, 1.1912281513214111, 1.002015471458435, 1.1917855739593506, 1.202275276184082, 1.1996492147445679, 1.0777182579040527, 1.1984487771987915, 1.2063792943954468, 1.1854380369186401, 1.0186679363250732, 1.1456085443496704, 1.2066259384155273, 1.0548125505447388, 1.1918835639953613, 1.0681034326553345, 1.1847724914550781, 1.1800990104675293, 1.130678415298462, 1.1953785419464111, 1.0677745342254639, 1.1623584032058716, 1.1938127279281616, 1.1564093828201294, 1.181733250617981, 1.0572481155395508, 1.1331181526184082, 1.1694458723068237, 1.1993837356567383, 1.1345398426055908, 1.1829203367233276, 1.150191068649292, 1.199587106704712, 1.1614315509796143, 1.048746943473816, 1.198627233505249, 1.1912857294082642, 1.1885910034179688, 1.1849504709243774, 1.19123375415802, 1.1902902126312256, 1.189624309539795, 1.1590564250946045, 1.2007983922958374, 1.1825320720672607, 1.1834558248519897, 1.1034516096115112, 1.1881390810012817, 1.1432769298553467, 1.196934700012207, 1.1772950887680054, 1.1853107213974, 1.1949963569641113, 1.161009430885315, 1.1427855491638184, 1.1959285736083984, 1.1846208572387695, 1.1697561740875244, 1.1603822708129883, 1.1888052225112915, 1.1721290349960327, 1.187880039215088, 1.1526247262954712, 1.024337649345398, 1.1797816753387451, 1.1797477006912231, 1.1102569103240967, 1.1324844360351562, 1.1789212226867676, 1.1903971433639526, 1.1857103109359741, 1.1636435985565186, 1.0741164684295654, 1.1695992946624756, 1.1918468475341797, 1.1797685623168945, 1.0326510667800903, 1.1384059190750122, 1.164565086364746, 1.185656189918518, 1.1018306016921997, 1.1782035827636719, 1.1744985580444336, 1.140176773071289, 1.1579089164733887, 1.1281335353851318, 1.176923394203186, 1.18025803565979, 1.176121473312378, 1.2031354904174805, 1.1893627643585205, 1.0771944522857666, 1.1314209699630737, 1.1757457256317139, 1.166279911994934, 1.0456868410110474, 1.1764723062515259, 1.1765475273132324, 1.0226035118103027, 1.03316330909729, 1.1512306928634644, 1.18112313747406, 1.1711806058883667, 1.175912618637085, 1.1212677955627441, 1.1864514350891113, 1.0497676134109497, 1.1752244234085083, 1.164903998374939, 1.1115384101867676, 1.0239531993865967, 1.0274739265441895, 1.1226582527160645, 1.1781740188598633, 1.0336614847183228, 1.1603646278381348, 1.1564176082611084, 1.1700857877731323, 1.1462956666946411, 1.148698091506958, 1.1710383892059326, 1.0247684717178345, 1.1608555316925049, 0.9845753312110901, 1.132562279701233, 1.1819452047348022, 1.1037497520446777, 1.1791064739227295, 1.158737063407898, 1.175513505935669, 1.1257457733154297, 1.179523229598999, 1.1653472185134888, 1.179909110069275, 1.048332929611206, 1.1556867361068726, 1.167356014251709, 1.163812518119812, 1.1741396188735962, 1.1869409084320068, 1.1509915590286255, 1.1616227626800537, 1.0423002243041992, 1.0053540468215942, 1.165537714958191, 1.156851887702942, 1.1588634252548218, 1.163353681564331, 1.1007130146026611, 1.174368143081665, 1.1196784973144531, 1.1709271669387817, 1.127332329750061, 1.1543936729431152, 1.107923150062561, 1.1561574935913086, 1.1600183248519897, 1.0309323072433472, 1.133987307548523, 1.1656432151794434, 1.171844720840454, 1.0918773412704468, 1.1671935319900513, 1.011683464050293, 1.0516685247421265, 1.1405413150787354, 1.0758455991744995, 1.1672146320343018, 1.1703108549118042, 0.9860245585441589, 1.0499624013900757, 1.0357855558395386, 1.165838599205017, 1.021950602531433, 1.1607681512832642, 1.146454095840454, 0.993583619594574, 1.1530038118362427, 1.1683558225631714, 1.164015293121338, 1.1099016666412354, 1.1192562580108643, 1.0935739278793335, 1.1298311948776245, 1.0276556015014648, 1.078963279724121, 1.14598548412323, 1.1755468845367432, 1.0466731786727905, 1.1334480047225952, 1.15189790725708, 1.1695899963378906, 1.1600341796875, 1.1140353679656982, 1.0143647193908691, 0.9912883043289185, 1.1550893783569336, 1.162157416343689, 1.0059207677841187, 1.1497210264205933, 1.1439107656478882, 1.1585400104522705, 1.122468113899231, 1.157150149345398, 1.1050339937210083, 1.1361528635025024, 1.1521106958389282, 1.1386362314224243, 1.1244914531707764, 1.0286420583724976, 1.0908769369125366, 1.1380919218063354, 1.1528146266937256, 1.1459869146347046, 1.1189838647842407, 1.1454641819000244, 0.9649626016616821, 1.1474531888961792, 1.0791422128677368, 1.0326547622680664, 1.1357215642929077, 1.153403878211975, 1.1091506481170654, 1.1233477592468262, 1.1458120346069336, 1.105759620666504, 1.1088932752609253, 0.9648507237434387, 0.9751847982406616, 1.1010571718215942, 1.1249678134918213, 0.9761145710945129, 1.1338233947753906, 1.0958927869796753, 1.1423312425613403, 1.0591806173324585, 1.1338146924972534, 1.107287049293518, 1.116668462753296, 0.9964421391487122, 1.1478910446166992, 1.1182414293289185, 1.1511530876159668, 0.9820597767829895, 1.144879698753357, 1.1338368654251099, 1.145588755607605, 1.1324690580368042, 1.1480787992477417, 1.144575595855713, 1.1395879983901978, 1.0902388095855713, 1.0936392545700073, 0.978941023349762, 1.1282926797866821, 1.1388142108917236, 1.1465814113616943, 0.9876247644424438, 1.1305524110794067, 1.1186662912368774, 0.9926789402961731, 1.0011727809906006, 1.1451653242111206, 1.1420888900756836, 1.1192409992218018, 0.9816769957542419, 0.9877156019210815, 1.0156452655792236, 1.1156548261642456, 1.143825650215149, 0.9936365485191345, 1.1342010498046875, 1.139155626296997, 1.011966586112976, 0.9859118461608887, 1.13081693649292, 1.1348180770874023, 1.1163920164108276, 1.1273084878921509, 1.1497323513031006, 1.089552402496338, 0.9822803735733032, 1.1155136823654175, 1.1181727647781372, 1.140053629875183, 1.119997262954712, 0.9855246543884277, 1.1204988956451416, 1.0885968208312988, 1.1204837560653687, 0.9868516325950623, 0.9833431839942932, 1.1217008829116821, 0.9734516143798828, 1.1332075595855713, 1.0086466073989868, 1.143967866897583, 1.1215473413467407, 0.9410613775253296, 1.025699257850647, 1.1208772659301758, 1.1264452934265137, 0.9980294704437256, 1.1239378452301025, 1.1185014247894287, 1.1066776514053345, 1.13692045211792, 0.9383405447006226, 1.1370832920074463, 1.1264870166778564, 0.9707099199295044, 1.1254777908325195, 1.1204967498779297, 1.1003583669662476, 1.002913475036621, 1.1298869848251343, 1.1257431507110596, 1.1340268850326538, 1.1160335540771484, 1.135953664779663, 1.0879735946655273, 1.1168397665023804, 1.0037238597869873, 0.9679924845695496, 0.9881139993667603, 1.1222736835479736, 0.979598879814148, 1.1143593788146973, 1.0930900573730469, 0.9689304232597351, 1.1101361513137817, 1.0114836692810059, 0.965925395488739, 1.0788350105285645, 0.900549054145813, 1.1272953748703003, 1.1177061796188354, 1.0320879220962524, 1.0946379899978638, 1.0993788242340088, 1.0111768245697021, 0.9338878989219666, 1.0884276628494263, 1.1015461683273315, 1.1246955394744873, 1.0773000717163086, 1.0988242626190186, 1.1057451963424683, 1.03557288646698, 1.0969332456588745, 1.0101165771484375, 1.1226969957351685, 0.9589799642562866, 0.9627383351325989, 1.1155861616134644, 1.0810142755508423, 1.096531629562378, 1.0686722993850708, 1.1130677461624146, 1.0394407510757446, 0.9738859534263611, 1.1092617511749268, 1.103025197982788, 1.054752230644226, 1.1096539497375488, 1.036162257194519, 1.0305659770965576, 1.120850920677185, 1.002174735069275, 0.923413872718811, 1.109519124031067, 1.0217430591583252, 1.1093122959136963, 1.0994004011154175, 1.114615559577942, 1.1167584657669067, 0.9614114165306091, 0.9481977820396423, 1.1291090250015259, 1.0785534381866455, 1.1011115312576294, 1.0751206874847412, 1.1021977663040161, 0.9676864743232727, 1.0496948957443237, 1.1001598834991455, 1.1043727397918701, 1.105470061302185, 1.0064985752105713, 1.1005831956863403, 1.10006844997406, 0.9871909618377686, 1.0196624994277954, 1.103326439857483, 1.09019136428833, 1.100002408027649, 0.9331808686256409, 0.9833890795707703, 1.1220828294754028, 1.0747175216674805, 0.9746719598770142, 1.0978379249572754, 0.9749956130981445, 0.9576409459114075, 1.0948950052261353, 1.0950733423233032, 1.0813266038894653, 1.0628581047058105, 1.0510139465332031, 1.1039873361587524, 1.0830742120742798, 1.056431531906128, 1.0980808734893799, 1.097265362739563, 0.9802096486091614, 1.084355354309082, 1.0465055704116821, 1.043028473854065, 0.9563973546028137, 1.0953011512756348, 1.0084573030471802, 0.9286691546440125, 0.9526088833808899, 1.083801507949829, 1.0081353187561035, 0.9344175457954407, 0.9560998678207397, 1.0303995609283447, 1.068831443786621, 0.9524134397506714, 0.9564244151115417, 1.0080387592315674, 1.0555472373962402, 1.094709038734436, 1.0786359310150146, 0.9557945728302002, 0.93098384141922, 0.9003919959068298, 1.0658384561538696, 1.056692361831665, 1.0281318426132202, 1.0827723741531372, 1.0731559991836548, 1.0085276365280151, 1.0540521144866943, 1.0885626077651978, 1.0305356979370117, 1.064400315284729, 0.9807478785514832, 0.9932388067245483, 1.0317591428756714, 0.9089499711990356, 1.0893882513046265, 1.0688430070877075, 1.067206621170044, 1.028477668762207, 0.961452841758728, 1.0681836605072021, 1.0178418159484863, 0.9954785704612732, 1.0633323192596436, 1.0692567825317383, 1.063433051109314, 0.8780825138092041, 1.0390042066574097, 1.0010921955108643, 0.9434376358985901, 1.0017081499099731, 0.9097829461097717, 1.05144202709198, 1.0247182846069336, 0.9516303539276123, 0.8975684642791748, 1.0428738594055176, 1.070250153541565, 1.046497106552124, 0.9655961990356445, 1.0699357986450195, 1.0466861724853516, 0.9585627913475037, 1.0697933435440063, 1.0111602544784546, 1.0349116325378418, 0.8906997442245483, 1.0410218238830566, 0.9289728999137878, 0.9528384804725647, 0.9298197627067566, 0.9664902091026306, 0.9741865396499634, 1.0712357759475708, 1.0467149019241333, 1.078805685043335, 0.979246199131012, 1.0727519989013672, 0.9172059893608093, 1.081703782081604, 1.050087332725525, 0.9623344540596008, 0.9520168304443359, 0.9899674654006958, 0.9236266613006592, 0.9252796173095703, 1.045216679573059, 0.9143929481506348, 1.069394826889038, 0.902328372001648, 1.0745418071746826, 0.9857708811759949, 1.0589243173599243, 1.0690817832946777, 0.9192798137664795, 1.049193263053894, 0.9234771132469177, 1.0565664768218994, 0.9409453868865967, 1.0277369022369385, 0.9857975840568542, 1.0537883043289185, 1.013786792755127, 0.9136796593666077, 0.9467055201530457, 0.9459680318832397, 0.9462689161300659, 1.0193978548049927, 0.9512662887573242, 0.9346495866775513, 0.9318845868110657, 0.9773855209350586, 0.9244635105133057, 1.0339956283569336, 0.8875161409378052, 1.060422420501709, 1.03721022605896, 1.0439599752426147, 1.0199302434921265, 0.9069724678993225, 0.907768189907074, 1.0648093223571777, 1.048054575920105, 1.026926875114441, 1.0400512218475342, 1.0309442281723022, 1.0315213203430176, 0.8819422125816345, 0.8831249475479126, 0.9865514039993286, 1.020350456237793, 0.9195296764373779, 0.9131584763526917, 1.0230005979537964, 0.9180437922477722, 0.9177807569503784, 1.0380393266677856, 0.9134294390678406, 1.0159283876419067, 0.9815222024917603, 0.9803615808486938, 0.9330264925956726, 1.0278712511062622, 1.0187186002731323, 0.9027670621871948, 1.0254565477371216, 0.972953736782074, 1.0237715244293213, 0.9283314943313599, 0.9426337480545044, 0.8732107281684875, 0.9158799052238464, 0.9793857932090759, 0.9979351758956909, 1.0105466842651367, 0.8833786249160767, 1.043372392654419, 0.975703239440918, 1.0101956129074097, 1.026958703994751, 0.9100661873817444, 1.0165847539901733, 0.8690475225448608, 0.8865687847137451, 1.0195108652114868, 1.008238434791565, 0.948145866394043, 0.9735286235809326, 0.8950285315513611, 0.9678770303726196, 0.8717763423919678, 1.0314692258834839, 1.0075125694274902, 1.0202829837799072, 0.8398449420928955, 0.9921249151229858, 0.9268653988838196, 0.9392254948616028, 1.0180912017822266, 0.8914798498153687, 0.9296526312828064, 1.0242048501968384, 0.8597821593284607, 1.0353847742080688, 0.8539441823959351, 1.017439842224121, 1.025794506072998, 1.0020416975021362, 0.9305247068405151, 0.9852315783500671, 0.90204918384552, 1.0250011682510376, 1.0013766288757324, 1.0111497640609741, 0.9629616737365723, 0.9838744401931763, 0.8541632890701294, 1.0237263441085815, 0.945928692817688, 1.0301916599273682, 0.890301525592804, 1.011171817779541, 0.8637476563453674, 0.8475611805915833, 0.9153127670288086, 0.9965850114822388, 0.9683371186256409, 0.8640817403793335, 0.8732107877731323, 0.8881081342697144, 1.0154480934143066, 0.872912585735321, 0.8635494112968445, 1.0182265043258667, 0.9760712385177612, 0.9675262570381165, 0.89869225025177, 1.0045382976531982, 1.0048729181289673, 1.0063685178756714, 0.8835243582725525, 0.9487269520759583, 0.8993712067604065, 0.8209169507026672, 1.0066742897033691, 0.8686753511428833, 0.8399122953414917, 0.8686457276344299, 0.9462743997573853, 0.8259580135345459, 0.9847476482391357, 0.8869050741195679, 0.8958110213279724, 1.011718988418579, 0.84958815574646, 0.897766649723053, 0.849936306476593, 0.8801208138465881, 0.9469969272613525, 0.8431997895240784, 0.9938619136810303, 0.9190322160720825, 0.8273730278015137, 0.8739475011825562, 0.8434974551200867, 0.9915127754211426, 0.9318629503250122, 0.8503375053405762, 0.9524994492530823, 0.9935858845710754, 0.8503823280334473, 0.8445560932159424, 0.9790093302726746, 0.8883036375045776, 0.8337818384170532, 0.9503311514854431, 0.9282240867614746, 0.8926250338554382, 0.9208175539970398, 0.9974581003189087, 0.9594757556915283, 0.8644617795944214, 0.860585629940033, 0.8918745517730713, 0.8719104528427124, 0.8565019965171814, 0.9354042410850525, 0.9610913991928101, 0.8445693850517273, 0.8107402920722961, 0.8554977178573608, 0.8495060801506042, 0.8832235336303711, 0.899840772151947, 0.8292656540870667, 0.8107717037200928, 0.8556886911392212, 0.9313355088233948, 0.8555543422698975, 0.8453143835067749, 0.9310246706008911, 0.9216919541358948, 0.9519728422164917, 0.9361686706542969, 0.9844056963920593, 0.9646537899971008, 0.9265313148498535, 0.916940450668335, 0.8581051826477051, 0.8442392349243164, 0.8293436765670776, 0.822941780090332, 0.9013840556144714, 0.8322784900665283, 0.8436863422393799, 0.8445371985435486, 0.9261478185653687, 0.8639643788337708, 0.830845296382904, 0.9253253936767578, 0.952229917049408, 0.8010281920433044, 0.8894892930984497, 0.9226064085960388, 0.957450807094574, 0.9509764313697815, 0.8982874155044556, 0.9376952052116394, 0.9631862044334412, 0.9286848306655884, 0.9349793791770935, 0.830383837223053, 0.9192313551902771, 0.8956186771392822, 0.8371466398239136, 0.9304414987564087, 0.8463821411132812, 0.8554517030715942, 0.9152125120162964, 0.9606958031654358, 0.8397386074066162, 0.9429453611373901, 0.8486555218696594, 0.9199989438056946, 0.8174528479576111, 0.8146733045578003, 0.8467080593109131, 0.7826958298683167, 0.9485629200935364, 0.9574987292289734, 0.9309179782867432, 0.8014418482780457, 0.9589710831642151, 0.8329142928123474, 0.8372595310211182, 0.8130480051040649, 0.852469265460968, 0.9464620351791382, 0.9079734683036804, 0.8289854526519775, 0.9400110840797424, 0.9195743799209595, 0.8264035582542419, 0.8039234280586243, 0.9340349435806274, 0.9208505749702454, 0.8894913792610168, 0.9505662322044373, 0.933426022529602, 0.8019823431968689, 0.9494845271110535, 0.9400254487991333, 0.8913718461990356, 0.9496371746063232, 0.7635769248008728, 0.8113095760345459, 0.9067636132240295, 0.9211059212684631, 0.8935139775276184, 0.7928332090377808, 0.9395629167556763, 0.9301098585128784, 0.8574332594871521, 0.8912030458450317, 0.8484683036804199, 0.9417346119880676, 0.8111854791641235, 0.911627471446991, 0.8385814428329468, 0.8775001168251038, 0.7505254149436951, 0.826727569103241, 0.8422430753707886, 0.8380655646324158, 0.8969444632530212, 0.8274508714675903, 0.8053420782089233, 0.8653681874275208, 0.9305465221405029, 0.897679328918457, 0.7782020568847656, 0.7782560586929321, 0.9247915744781494, 0.7725578546524048, 0.8567630052566528, 0.8967949748039246, 0.7911108732223511, 0.8524981737136841, 0.8110523819923401, 0.897928774356842, 0.8674074411392212, 0.8557822704315186, 0.755326509475708, 0.8839846849441528, 0.9143484234809875, 0.8830581307411194, 0.9029701352119446, 0.8437655568122864, 0.8044763207435608, 0.7789133191108704, 0.895822286605835, 0.7584741711616516, 0.7590211033821106, 0.7899678349494934, 0.7684769630432129, 0.8011190295219421, 0.7835685610771179, 0.751922070980072, 0.8548575043678284, 0.8405897617340088, 0.787055492401123, 0.8086991906166077, 0.8787224292755127, 0.8918590545654297, 0.7206004858016968, 0.7717790603637695, 0.7723217010498047, 0.7539049983024597, 0.8543291687965393, 0.7868683934211731, 0.9033242464065552, 0.9053141474723816, 0.8189169764518738, 0.8871415853500366, 0.9011568427085876, 0.7424203753471375, 0.7358486652374268, 0.7913671135902405, 0.8992549777030945, 0.8971298336982727, 0.7363759279251099, 0.8738421201705933, 0.8799970149993896, 0.8804698586463928, 0.8098567724227905, 0.8590149283409119, 0.7531540989875793, 0.7964512705802917, 0.8733009696006775, 0.8171336650848389, 0.7587305903434753, 0.8411726355552673, 0.8237108588218689, 0.8785457611083984, 0.7804834842681885, 0.7605944275856018, 0.7660417556762695, 0.686672031879425, 0.8120970129966736, 0.7310227155685425, 0.8864985108375549, 0.7915298938751221, 0.8038930296897888, 0.8527568578720093, 0.8269855976104736, 0.7664881944656372, 0.7334694862365723, 0.7769370675086975, 0.8033514022827148, 0.8348644375801086, 0.8808538317680359, 0.7345088124275208, 0.7325725555419922, 0.778703510761261, 0.7331308722496033, 0.8783866167068481, 0.8108410239219666, 0.7765055298805237, 0.7716023325920105, 0.8855803608894348, 0.7796519994735718, 0.7728623747825623, 0.8716104030609131, 0.7161768674850464, 0.7231390476226807, 0.8457822203636169, 0.8109365105628967, 0.7758168578147888, 0.7468922734260559, 0.7453440427780151, 0.8607398271560669, 0.7727394700050354, 0.7542503476142883, 0.8588582873344421, 0.7666813731193542, 0.7613900899887085, 0.7617539763450623, 0.770529568195343, 0.7549958825111389, 0.7719675898551941, 0.8724943995475769, 0.76680588722229, 0.7224412560462952, 0.7052836418151855, 0.7658738493919373, 0.7550897598266602, 0.754738450050354, 0.7659360766410828, 0.7982997894287109, 0.7060948610305786, 0.770358681678772, 0.8673517107963562, 0.7564555406570435, 0.7483724355697632, 0.7392854690551758, 0.8553361296653748, 0.8442009091377258, 0.758163571357727, 0.7700725793838501, 0.6983110308647156, 0.7500994205474854, 0.7362030744552612, 0.8388013243675232, 0.6988375782966614, 0.7020717263221741, 0.7648906111717224, 0.7682462334632874, 0.7714517116546631, 0.7083522081375122, 0.7865666747093201, 0.7417301535606384, 0.7538190484046936, 0.7788748741149902, 0.8131817579269409, 0.696032702922821, 0.7538714408874512, 0.7390367984771729, 0.7454560995101929, 0.7495124340057373, 0.7981957197189331, 0.7136173844337463, 0.7140184044837952, 0.7408039569854736, 0.7110546231269836, 0.7523084878921509, 0.7395516037940979, 0.7195714116096497, 0.8187584280967712, 0.7241004705429077, 0.7863714098930359, 0.6965786218643188, 0.7758054733276367, 0.7415750622749329, 0.7366405725479126, 0.7888981699943542, 0.7189955711364746, 0.7080929279327393, 0.7957698702812195, 0.709543764591217, 0.7377732396125793, 0.7047131061553955, 0.718378484249115, 0.6854950785636902, 0.756847620010376, 0.8141865134239197, 0.7101186513900757, 0.7254952192306519, 0.8547720313072205, 0.7169594764709473, 0.7429674863815308, 0.8420346975326538, 0.829176127910614, 0.8323097229003906, 0.6939502358436584, 0.8146177530288696, 0.7191740870475769, 0.7171334624290466, 0.6794936656951904, 0.7185046076774597, 0.7185049653053284, 0.726519763469696, 0.7229980826377869, 0.7243454456329346, 0.7019820809364319, 0.7178129553794861, 0.7484473586082458, 0.7025845050811768, 0.7076945304870605, 0.7087605595588684, 0.7632960081100464, 0.6595087647438049, 0.7186416983604431, 0.7434361577033997, 0.7773596048355103, 0.692173957824707, 0.6960446238517761, 0.6905348300933838, 0.6849536299705505, 0.7731117606163025, 0.8300305008888245, 0.7148517966270447, 0.7066551446914673, 0.7773100137710571, 0.716887891292572, 0.7026691436767578, 0.7286879420280457, 0.7210221886634827, 0.6914874911308289, 0.702799916267395, 0.7301114201545715, 0.7550767064094543, 0.7540283799171448, 0.7825837135314941, 0.7238574028015137, 0.7645388841629028, 0.662243127822876, 0.7821797728538513, 0.8067228198051453, 0.6950405240058899, 0.6557014584541321, 0.6918459534645081, 0.7146143317222595, 0.6893113851547241, 0.7345634698867798, 0.7567651271820068, 0.6896558403968811, 0.7110669612884521, 0.7811155319213867, 0.79944908618927, 0.7473296523094177, 0.6999789476394653, 0.6527771353721619, 0.6939154863357544, 0.6850242018699646, 0.7044869661331177, 0.6990821957588196, 0.7908655405044556, 0.6682409048080444, 0.6602580547332764, 0.6854957938194275, 0.70010906457901, 0.741550624370575, 0.7213509678840637, 0.7757779359817505, 0.6749128103256226, 0.701803982257843, 0.7570571303367615, 0.7413036823272705, 0.6815329790115356, 0.6867523193359375, 0.6331834197044373, 0.7711594104766846, 0.7427962422370911, 0.6466380953788757, 0.7239357233047485, 0.6572203636169434, 0.6905964612960815, 0.7605128288269043, 0.6715638637542725, 0.7232218980789185, 0.7644346952438354, 0.7324928045272827, 0.6698427796363831, 0.742965817451477, 0.7319058179855347, 0.6233158111572266, 0.676508367061615, 0.6439739465713501, 0.6442261934280396, 0.7449347972869873, 0.7173942923545837, 0.6471841931343079, 0.7997502684593201, 0.7452349066734314, 0.728365957736969, 0.6451629996299744, 0.6804965734481812, 0.6397855877876282, 0.7276396155357361, 0.6813821196556091, 0.6671940684318542, 0.7014136910438538, 0.6965400576591492, 0.7113046050071716, 0.6755198240280151, 0.6679675579071045, 0.688327968120575, 0.7151005268096924, 0.6610975861549377, 0.6509364247322083, 0.7358695864677429, 0.6494178175926208, 0.6517443656921387, 0.702785849571228, 0.7131406664848328, 0.6289669275283813, 0.685440719127655, 0.6935593485832214, 0.6345793008804321, 0.7102367877960205, 0.7264904379844666, 0.6452713012695312, 0.6182990074157715, 0.6760941743850708, 0.710746705532074, 0.7371420860290527, 0.6311241984367371, 0.7473810315132141, 0.7207135558128357, 0.6338862180709839, 0.6168370246887207, 0.6503705382347107, 0.6984710693359375, 0.6639750003814697, 0.6892492771148682, 0.5982856154441833, 0.7277776002883911, 0.6062259674072266, 0.6064210534095764, 0.620800793170929, 0.5947115421295166, 0.7391646504402161, 0.6743611097335815, 0.7115307450294495, 0.6309998035430908, 0.6204054355621338, 0.6016733050346375, 0.6028060913085938, 0.6721500754356384, 0.6415351033210754, 0.6263718008995056, 0.693053126335144, 0.6250742673873901, 0.635219931602478, 0.7005855441093445, 0.6982255578041077, 0.6692749857902527, 0.6352710127830505, 0.6354677081108093, 0.5661938190460205, 0.5977209210395813, 0.5656561851501465, 0.6268224716186523, 0.605157732963562, 0.5721203684806824, 0.6680271625518799, 0.6530712842941284, 0.6217058300971985, 0.5861761569976807, 0.5826622843742371, 0.610512375831604, 0.5821825861930847, 0.6187071204185486, 0.6499500274658203, 0.6041806936264038, 0.6235828995704651, 0.6305508017539978, 0.6882044076919556, 0.6235283613204956, 0.5761982202529907, 0.673041820526123, 0.6524755954742432, 0.652357816696167, 0.6061878800392151, 0.609950602054596, 0.6492888927459717, 0.5687351822853088, 0.5492168068885803, 0.6316089034080505, 0.6352207660675049, 0.5801876187324524, 0.6569132804870605, 0.6244770884513855, 0.6310232281684875, 0.5645923018455505, 0.5930756330490112, 0.562038779258728, 0.6790361404418945, 0.6005647778511047, 0.6285748481750488, 0.6128667593002319, 0.552855372428894, 0.6225689649581909, 0.6238238215446472, 0.5794861316680908, 0.5557396411895752, 0.6249323487281799, 0.6019161343574524, 0.524476945400238, 0.667613685131073, 0.6029731035232544, 0.5597025156021118, 0.5961016416549683, 0.675329864025116, 0.6219083666801453, 0.5717431902885437, 0.5460008382797241, 0.684451162815094, 0.5443031191825867, 0.6247841119766235, 0.594244658946991, 0.61467444896698, 0.6215741038322449, 0.5554980039596558, 0.6210061311721802, 0.6068610548973083, 0.6067177057266235, 0.6377962231636047, 0.6005890369415283, 0.5512402653694153, 0.6072481274604797, 0.6538625955581665, 0.5579777359962463, 0.6327822804450989, 0.6560286283493042, 0.544223427772522, 0.6320736408233643, 0.5543118119239807, 0.615391731262207, 0.5473511219024658, 0.577154278755188, 0.5701006054878235, 0.5074425935745239, 0.5173739194869995, 0.6133400797843933, 0.5135464668273926, 0.6660102605819702, 0.6277080774307251, 0.5714136958122253, 0.6066581606864929, 0.5289705991744995, 0.5609205365180969, 0.5390262007713318, 0.5751755833625793, 0.578656792640686, 0.6001771092414856, 0.6247631311416626, 0.5859497785568237, 0.5247429013252258, 0.5352287292480469, 0.5647294521331787, 0.5562775731086731, 0.6013025641441345, 0.5010533928871155, 0.5393843054771423, 0.5153456926345825, 0.5311757922172546, 0.5272442102432251, 0.5333650708198547, 0.5566902756690979, 0.5191686153411865, 0.597385048866272, 0.5820341110229492, 0.569887101650238, 0.6035148501396179, 0.5373029112815857, 0.5995576977729797, 0.5660682320594788, 0.5454209446907043, 0.5754363536834717, 0.5151481032371521, 0.540306568145752, 0.5394879579544067, 0.5842115879058838, 0.50702965259552, 0.6328088045120239, 0.5764837265014648, 0.5163207650184631, 0.5515746474266052, 0.5185023546218872, 0.5720964074134827, 0.5392009615898132, 0.5334329009056091, 0.5202555656433105, 0.5326223373413086, 0.5476623177528381, 0.5926666259765625, 0.5335854887962341, 0.5560380816459656, 0.5280399918556213, 0.5197556614875793, 0.540050208568573, 0.5384082794189453, 0.5798493027687073, 0.5377581119537354, 0.6205569505691528, 0.5465875864028931, 0.5000248551368713, 0.580553412437439, 0.5908686518669128, 0.5754739046096802, 0.4996813237667084, 0.47918760776519775, 0.504158616065979, 0.6671736836433411, 0.5694414377212524, 0.5480303168296814, 0.4970094561576843, 0.5289042592048645, 0.5068874955177307, 0.524117648601532, 0.5787220597267151, 0.5406229496002197, 0.5069069266319275, 0.5326068997383118, 0.5558978319168091, 0.5946484208106995, 0.49014344811439514, 0.4931167960166931, 0.5256727337837219, 0.49035027623176575, 0.5832525491714478, 0.5845775604248047, 0.5237835049629211, 0.5085415244102478, 0.49029502272605896, 0.49086615443229675, 0.5305367112159729, 0.5260379314422607, 0.5610065460205078, 0.5616729855537415, 0.5152333974838257, 0.5953050255775452, 0.5701338648796082, 0.5183770656585693, 0.5214048027992249, 0.5237828493118286, 0.47318026423454285, 0.478406697511673, 0.5560658574104309, 0.568895161151886, 0.48265987634658813, 0.4917562007904053, 0.5402677059173584, 0.5140417814254761, 0.5015549659729004, 0.5236541628837585, 0.5625582933425903, 0.5959539413452148, 0.544893205165863, 0.4578520655632019, 0.4692254662513733, 0.5205243229866028, 0.46920114755630493, 0.54696124792099, 0.4660126864910126, 0.4805677533149719, 0.4907282590866089, 0.455690860748291, 0.4941937029361725, 0.48652026057243347, 0.4943360984325409, 0.46936550736427307, 0.5467113256454468, 0.49050894379615784, 0.5420652031898499, 0.5295777916908264, 0.5937830805778503, 0.49132850766181946, 0.5479894280433655, 0.4997482895851135, 0.5118454694747925, 0.5532616376876831, 0.5419762134552002, 0.5140600800514221, 0.5499531030654907, 0.4488922655582428, 0.4706425964832306, 0.4442666172981262, 0.4395761489868164, 0.5397539138793945, 0.5571872591972351, 0.4578474164009094, 0.4670822322368622, 0.45422306656837463, 0.45840007066726685, 0.536833643913269, 0.44041118025779724, 0.395260751247406, 0.44511574506759644, 0.5266509652137756, 0.48205864429473877, 0.48592740297317505, 0.515282928943634, 0.46497249603271484, 0.5077222585678101, 0.4505138099193573, 0.44984570145606995, 0.4582754075527191, 0.49811989068984985, 0.49247556924819946, 0.4390724301338196, 0.47739723324775696, 0.48601260781288147, 0.4283541738986969, 0.47494566440582275, 0.47311991453170776, 0.4533674418926239, 0.4548454284667969, 0.4408656358718872, 0.42012447118759155, 0.45710188150405884, 0.4878527820110321, 0.427447110414505, 0.4519255459308624, 0.4693578779697418, 0.45164725184440613, 0.4410969018936157, 0.469308465719223, 0.4748442471027374, 0.4733988046646118, 0.49358952045440674, 0.481906533241272, 0.4624606668949127, 0.4537619948387146, 0.4567737281322479, 0.5247097015380859, 0.5310655832290649, 0.5105265974998474, 0.4246556758880615, 0.4945032596588135, 0.5257387757301331, 0.4715823829174042, 0.47475433349609375, 0.5133174061775208, 0.47496551275253296, 0.5073783993721008, 0.4318239688873291, 0.456229567527771, 0.5046451687812805, 0.5025239586830139, 0.4726124703884125, 0.43066298961639404, 0.45000889897346497, 0.44395995140075684, 0.45545846223831177, 0.48754817247390747, 0.4712330400943756, 0.46114110946655273, 0.44105064868927, 0.4126197397708893, 0.38520851731300354, 0.3931517004966736, 0.44203856587409973, 0.5415377616882324, 0.4493814706802368, 0.42275550961494446, 0.42454516887664795, 0.4427236318588257, 0.4771941900253296, 0.41573795676231384, 0.4528157114982605, 0.485247403383255, 0.4519895017147064, 0.5043097138404846, 0.47976991534233093, 0.4696078598499298, 0.3806499242782593, 0.3808356523513794, 0.4382643401622772, 0.3882567584514618, 0.42842939496040344, 0.4681476950645447, 0.39051517844200134, 0.4247455596923828, 0.4425123333930969, 0.3920898735523224, 0.535324215888977, 0.40479061007499695, 0.42305251955986023, 0.4321410059928894, 0.4388040602207184, 0.4135783612728119, 0.4512832760810852, 0.4396234452724457, 0.41307640075683594, 0.4047325849533081, 0.39580029249191284, 0.38418886065483093, 0.4040365517139435, 0.47112563252449036, 0.4125377833843231, 0.4081755578517914, 0.5173700451850891, 0.4692186415195465, 0.44473952054977417, 0.3709322512149811, 0.38904643058776855, 0.42202049493789673, 0.4134801924228668, 0.4420310854911804, 0.39818140864372253, 0.4442276656627655, 0.3296339213848114, 0.4021460711956024, 0.39646393060684204, 0.3849240243434906, 0.3928896486759186, 0.4260229468345642, 0.39956268668174744, 0.4252036213874817, 0.3966260552406311, 0.3957020938396454, 0.41671016812324524, 0.37332478165626526, 0.390731543302536, 0.39768728613853455, 0.41670820116996765, 0.39379891753196716, 0.41432175040245056, 0.33751174807548523, 0.39173004031181335, 0.42646944522857666, 0.45169737935066223, 0.46666863560676575, 0.40606144070625305, 0.37283262610435486, 0.4061796963214874, 0.39513805508613586, 0.44571730494499207, 0.4176478385925293, 0.38009655475616455, 0.36870822310447693, 0.39404988288879395, 0.3964756429195404, 0.4696274697780609, 0.35636284947395325, 0.3605039417743683, 0.411674827337265, 0.3939116895198822, 0.3903864920139313, 0.3838649392127991, 0.33983752131462097, 0.3512343764305115, 0.42838552594184875, 0.36411580443382263, 0.3785884976387024, 0.4142224192619324, 0.3536067605018616, 0.3749242126941681, 0.382711797952652, 0.3632272481918335, 0.380704790353775, 0.40292099118232727, 0.3543475866317749, 0.3556106388568878, 0.36211711168289185, 0.3788194954395294, 0.4027349352836609, 0.4365689158439636, 0.3355088531970978, 0.3278917968273163, 0.37927907705307007, 0.3401023745536804, 0.35467633605003357, 0.33536863327026367, 0.46446406841278076, 0.39488503336906433, 0.3950517177581787, 0.4010249078273773, 0.31390610337257385, 0.42448267340660095, 0.352658748626709, 0.36317315697669983, 0.39406803250312805, 0.3761374056339264, 0.43775254487991333, 0.32631614804267883, 0.3911242187023163, 0.31443434953689575, 0.4106951057910919, 0.2972217798233032, 0.34096530079841614, 0.2853359282016754, 0.3313318192958832, 0.35420796275138855, 0.39009374380111694, 0.3493940234184265, 0.33304065465927124, 0.3633362650871277, 0.3925500214099884, 0.35176193714141846, 0.4240659773349762, 0.3278917372226715, 0.32157063484191895, 0.3727332353591919, 0.34562698006629944, 0.3186637759208679, 0.30180472135543823, 0.3497157096862793, 0.31522229313850403, 0.31680038571357727, 0.32699134945869446, 0.30928856134414673, 0.342199444770813, 0.3192022144794464, 0.37818220257759094, 0.2769547402858734, 0.3222612142562866, 0.2885545492172241, 0.2910853922367096, 0.30520614981651306, 0.32591986656188965, 0.27720752358436584, 0.352783203125, 0.3113056719303131, 0.3034476339817047, 0.320523738861084, 0.3213518559932709, 0.3215709626674652, 0.3125702738761902, 0.28911635279655457, 0.35461199283599854, 0.30787983536720276, 0.2811223566532135, 0.3046022057533264, 0.35435301065444946, 0.2693610191345215, 0.3054540157318115, 0.3977392911911011, 0.2972466051578522, 0.2820308804512024, 0.26552870869636536, 0.30919745564460754, 0.3178621530532837, 0.28859609365463257, 0.2909783124923706, 0.3660697340965271, 0.2496555745601654, 0.3093950152397156, 0.32581472396850586, 0.27662456035614014, 0.3209006190299988, 0.26250767707824707, 0.3716678321361542, 0.34475263953208923, 0.271650493144989, 0.3348061442375183, 0.29848194122314453, 0.280825674533844, 0.31261780858039856, 0.2989276945590973, 0.3123722970485687, 0.26034706830978394, 0.2102593034505844, 0.35236623883247375, 0.2549229860305786, 0.29694899916648865, 0.3266878128051758, 0.28921210765838623, 0.3132295608520508, 0.28762078285217285, 0.31898781657218933, 0.23527613282203674, 0.26825448870658875, 0.260616272687912, 0.2985725998878479, 0.2695468068122864, 0.2766339182853699, 0.32129284739494324, 0.28097251057624817, 0.30700406432151794, 0.2664829194545746, 0.2433452010154724, 0.23363909125328064, 0.28448614478111267, 0.26964619755744934, 0.3393911123275757, 0.24814021587371826, 0.26007071137428284, 0.2705519199371338, 0.29868510365486145, 0.3026493787765503, 0.2962758541107178, 0.2912347912788391, 0.2331511527299881, 0.23307643830776215, 0.22056454420089722, 0.23579257726669312, 0.23802465200424194, 0.30915507674217224, 0.26587608456611633, 0.2525024116039276, 0.26670804619789124, 0.2245088666677475, 0.2782999873161316, 0.24740274250507355, 0.2481623739004135, 0.26451730728149414, 0.23711198568344116, 0.22862684726715088, 0.2560425400733948, 0.24050664901733398, 0.29162052273750305, 0.26456791162490845, 0.2644594609737396, 0.22323502600193024, 0.27004948258399963, 0.262440949678421, 0.215873122215271, 0.28773584961891174, 0.22821739315986633, 0.2171570360660553, 0.2474783957004547, 0.25030145049095154, 0.29133275151252747, 0.2851021885871887, 0.3060918152332306, 0.22695668041706085, 0.24160321056842804, 0.2656542658805847, 0.20691247284412384, 0.241108238697052, 0.2947680354118347, 0.21647395193576813, 0.29153069853782654, 0.2440032958984375, 0.24227601289749146, 0.2145686000585556, 0.21658450365066528, 0.2342294603586197, 0.2509414553642273, 0.26216137409210205, 0.2829156219959259, 0.20931726694107056, 0.19350875914096832, 0.2336796373128891, 0.20073340833187103, 0.2266339659690857, 0.21211951971054077, 0.20819173753261566, 0.25774824619293213, 0.22871077060699463, 0.2140766829252243, 0.20247484743595123, 0.20037716627120972, 0.2615632116794586, 0.22541357576847076, 0.24608707427978516, 0.23375624418258667, 0.1894049197435379, 0.19982163608074188, 0.22370050847530365, 0.17445917427539825, 0.1790781468153, 0.276741087436676, 0.25413084030151367, 0.2300340235233307, 0.21383243799209595, 0.18210159242153168, 0.26445871591567993, 0.21567019820213318, 0.2128334641456604, 0.2159326672554016, 0.2160881906747818, 0.2907310128211975, 0.18418334424495697, 0.24202705919742584, 0.2192317247390747, 0.2062249481678009, 0.21887774765491486, 0.19749082624912262, 0.20848140120506287, 0.21523745357990265, 0.2493661791086197, 0.18326957523822784, 0.16608469188213348, 0.16483475267887115, 0.23011502623558044, 0.1891602873802185, 0.22445546090602875, 0.16599877178668976, 0.19088436663150787, 0.1914856880903244, 0.1402685046195984, 0.18825286626815796, 0.21589702367782593, 0.1507139950990677, 0.17810015380382538, 0.1560838222503662, 0.14865826070308685, 0.22717049717903137, 0.1657165139913559, 0.17840509116649628, 0.18477462232112885, 0.17869973182678223, 0.20926639437675476, 0.18798425793647766, 0.18973137438297272, 0.22415125370025635, 0.2267429232597351, 0.15002378821372986, 0.17029792070388794, 0.15687185525894165, 0.2008240669965744, 0.16504499316215515, 0.14265932142734528, 0.12377531081438065, 0.18926537036895752, 0.17700469493865967, 0.20818117260932922, 0.13705725967884064, 0.18904231488704681, 0.23582468926906586, 0.17773431539535522, 0.16237783432006836, 0.1765488237142563, 0.18275268375873566, 0.1616034209728241, 0.21363195776939392, 0.22863267362117767, 0.15091829001903534, 0.1601746529340744, 0.17665177583694458, 0.15898172557353973, 0.10178150236606598, 0.15049834549427032, 0.18279363214969635, 0.16584093868732452, 0.23663292825222015, 0.1905760020017624, 0.164244145154953, 0.1265084445476532, 0.1533549427986145, 0.1796400249004364, 0.1303240805864334, 0.13525983691215515, 0.17083041369915009, 0.13998664915561676, 0.10938291996717453, 0.17956559360027313, 0.15194383263587952, 0.2082606703042984, 0.12702563405036926, 0.11294534057378769, 0.11479127407073975, 0.168380469083786, 0.17125669121742249, 0.19447273015975952, 0.15237241983413696, 0.1373952031135559, 0.19027340412139893, 0.13969556987285614, 0.15370792150497437, 0.08702342212200165, 0.18920443952083588, 0.1620994508266449, 0.19639092683792114, 0.1546601504087448, 0.15671810507774353, 0.1707361489534378, 0.13508769869804382, 0.10718245804309845, 0.1702263057231903, 0.14260655641555786, 0.14325018227100372, 0.1544356346130371, 0.14104063808918, 0.1566447913646698, 0.19370093941688538, 0.15535570681095123, 0.15269243717193604, 0.12906983494758606, 0.15185540914535522, 0.1766606718301773, 0.159947007894516, 0.16519272327423096, 0.1111140176653862, 0.18349997699260712, 0.10012690722942352, 0.10049331188201904, 0.17565907537937164, 0.0734325647354126, 0.14902053773403168, 0.14318539202213287, 0.09723979234695435, 0.11033296585083008, 0.0964665338397026, 0.10821302980184555, 0.14169606566429138, 0.1242087185382843, 0.11284013837575912, 0.12744422256946564, 0.11110395938158035, 0.16664567589759827, 0.12024685740470886, 0.11871686577796936, 0.04585253819823265, 0.11867150664329529, 0.1587141901254654, 0.15750283002853394, 0.10729813575744629, 0.1251872330904007, 0.16044194996356964, 0.10493983328342438, 0.139746755361557, 0.11024391651153564, 0.13793067634105682, 0.08238177746534348, 0.08517646789550781, 0.08305080980062485, 0.04791645333170891, 0.04822662100195885, 0.11284676939249039, 0.12211786210536957, 0.07399294525384903, 0.11159629374742508, 0.081875741481781, 0.06308868527412415, 0.13610433042049408, 0.09970198571681976, 0.06761043518781662, 0.17048457264900208, 0.11115451157093048, 0.0736403837800026, 0.07479198276996613, 0.06228091940283775, 0.0640423521399498, 0.0614420585334301, 0.11979199945926666, 0.07642359286546707, 0.09866553544998169, 0.13651911914348602, 0.08464377373456955, 0.03566952794790268, 0.1262863427400589, 0.07070054858922958, 0.025898940861225128, 0.12964095175266266, 0.06842964887619019, 0.10237541049718857, 0.05246762931346893, 0.059401676058769226, 0.051896076649427414, 0.11705465614795685, 0.14665216207504272, 0.07794039696455002, 0.08666380494832993, 0.07469106465578079, 0.09921572357416153, 0.0391024686396122, 0.03719942271709442, 0.034490808844566345, 0.026284893974661827, 0.06069624051451683, 0.0199546217918396, 0.06926682591438293, 0.13029681146144867, 0.038264986127614975, 0.0893825814127922, 0.026611678302288055, 0.09903998672962189, 0.02924400009214878, 0.08575936406850815, 0.08383620530366898, 0.06252152472734451, 0.11618853360414505, -0.004340168088674545, 0.11679811030626297, 0.01519858743995428, 0.04713422432541847, 0.03141029179096222, 0.018773000687360764, 0.08790158480405807, 0.036819830536842346, 0.06698409467935562, 0.06250695884227753, -0.00033156253630295396, 0.04568463936448097, 0.04220891743898392, 0.03783716261386871, -0.012059957720339298, 0.050705887377262115, 0.06302746385335922, 0.024008363485336304, 0.08711332082748413, 0.0022208429872989655, 0.05730598792433739, 0.043271906673908234, 0.02846224419772625, -0.004251718986779451, 0.010281823575496674, 0.017673159018158913, 0.02339279279112816, 0.024772925302386284, 0.018872834742069244, 0.017527051270008087, 0.0008162501617334783, 0.0469779409468174, 0.032445069402456284, -0.03139454126358032, 0.05062597990036011, 0.04954905062913895, 0.016989195719361305, 0.057173456996679306, 0.03197573870420456, 0.03849562257528305, 0.013324870727956295, 0.02178335376083851, 0.00777325127273798, 0.043564699590206146, 0.024221112951636314, -0.004815054591745138, 0.03836803883314133, -0.04204384982585907, -0.04920823499560356, -0.012195970863103867, 0.007303088903427124, -0.03145909309387207, 0.01651221700012684, -0.04374493286013603, -0.052280448377132416, 0.04984647408127785, -0.004347422160208225, -0.03714153915643692, 0.01914057694375515, 0.014817331917583942, -0.01944623328745365, -0.014401139691472054, -0.033016953617334366, -0.04801229387521744, -0.011053066700696945, -0.05589711666107178, -0.04876349866390228, -0.02268543653190136, 0.0472082681953907, -0.056974347680807114, -0.02407633699476719, -0.044172316789627075, 5.8145607908954844e-05, 0.014686780981719494, 0.03477990999817848, -0.06623292714357376, -0.019829116761684418, -0.019618278369307518, -0.0677991583943367, 0.03361892327666283, -0.08047079294919968, -0.023399516940116882, 0.006803399417549372, -0.0421307310461998, -0.08875590562820435, -0.03171562775969505, -0.06257796287536621, -0.08017467707395554, -0.09145402908325195, 0.006625577807426453, 0.004402205813676119, -0.04924725741147995, -0.01132121030241251, -0.052781347185373306, -0.02624966949224472, 0.003713899292051792, -0.0038999514654278755, -0.027693189680576324, -0.08384440094232559, -0.07442491501569748, -0.032943133264780045, -0.14194124937057495, -0.06188651919364929, -0.07484866678714752, -0.0356840156018734, -0.054148782044649124, -0.02818145416676998, -0.09937950223684311, -0.04267675429582596, -0.08215991407632828, -0.12721113860607147, -0.08583956211805344, -0.10174034535884857, -0.12673279643058777, -0.09294599294662476, -0.07730170339345932, -0.09564787149429321, -0.1221751868724823, -0.06337187439203262, -0.10868117958307266, -0.10763949900865555, -0.11540474742650986, -0.06848198920488358, -0.10796532034873962, -0.16860654950141907, -0.02584805339574814, -0.0906621664762497, -0.15383140742778778, -0.12369150668382645, -0.10421346873044968, -0.11215218901634216, -0.09913818538188934, -0.05630277097225189, -0.07857464253902435, -0.07194757461547852, -0.09358036518096924, -0.025209156796336174, -0.11878278106451035, -0.0982426255941391, -0.10813263058662415, -0.13244162499904633, -0.11184032261371613, -0.12206455320119858, -0.11333932727575302, -0.14046256244182587, -0.13582953810691833, -0.0855356827378273, -0.10388317704200745, -0.11735554039478302, -0.12270139157772064, -0.09972160309553146, -0.15002574026584625, -0.12049400806427002, -0.10113593935966492, -0.14282073080539703, -0.12796330451965332, -0.13948160409927368, -0.11744192987680435, -0.12337887287139893, -0.1168740838766098, -0.14876024425029755, -0.1365019679069519, -0.10555139929056168, -0.14367002248764038, -0.13644802570343018, -0.11675017327070236, -0.1625991016626358, -0.09305457025766373, -0.10507679730653763, -0.053760431706905365, -0.12593646347522736, -0.12736967206001282, -0.16090406477451324, -0.12906992435455322, -0.14057807624340057, -0.07576270401477814, -0.16579848527908325, -0.15389731526374817, -0.1604900360107422, -0.10416534543037415, -0.12059032171964645, -0.17059843242168427, -0.17347143590450287, -0.11351297795772552, -0.0886424109339714, -0.15328538417816162, -0.138184055685997, -0.12353196740150452, -0.13061952590942383, -0.14803455770015717, -0.1438085436820984, -0.17021554708480835, -0.13848066329956055, -0.18164537847042084, -0.16163107752799988, -0.13807925581932068, -0.15756773948669434, -0.18405264616012573, -0.16478407382965088, -0.180698424577713, -0.14146259427070618, -0.14774470031261444, -0.1720341145992279, -0.14158935844898224, -0.19701528549194336, -0.15575145184993744, -0.1720981001853943, -0.20774312317371368, -0.18057818710803986, -0.21207226812839508, -0.16227348148822784, -0.1493859589099884, -0.1546991914510727, -0.19390378892421722, -0.17985084652900696, -0.18508309125900269, -0.15550026297569275, -0.15349498391151428, -0.18610158562660217, -0.18101909756660461, -0.18019254505634308, -0.17300915718078613, -0.22508324682712555, -0.1389797329902649, -0.24492810666561127, -0.20703916251659393, -0.17839425802230835, -0.16674397885799408, -0.16340549290180206, -0.19885438680648804, -0.16998343169689178, -0.16201329231262207, -0.1977611780166626, -0.22322311997413635, -0.2200136035680771, -0.18361222743988037, -0.1947869062423706, -0.1899852454662323, -0.19018632173538208, -0.18695208430290222, -0.17471419274806976, -0.24237897992134094, -0.252441942691803, -0.2719012200832367, -0.20962369441986084, -0.22969821095466614, -0.21865838766098022, -0.20748072862625122, -0.2243443727493286, -0.21778573095798492, -0.21507196128368378, -0.20463034510612488, -0.28205305337905884, -0.1930263638496399, -0.19302867352962494, -0.23649489879608154, -0.19835995137691498, -0.21578793227672577, -0.1870063990354538, -0.2755207419395447, -0.2097347229719162, -0.2219286561012268, -0.19398806989192963, -0.3209954500198364, -0.1935630887746811, -0.2809133231639862, -0.2571301758289337, -0.22601641714572906, -0.2161492556333542, -0.2104017585515976, -0.18201255798339844, -0.21997080743312836, -0.23633648455142975, -0.21579334139823914, -0.25689923763275146, -0.2400633990764618, -0.2810671031475067, -0.27341586351394653, -0.24960851669311523, -0.23804450035095215, -0.21442289650440216, -0.260131299495697, -0.27661558985710144, -0.2716100215911865, -0.22900329530239105, -0.27299943566322327, -0.26725077629089355, -0.28573569655418396, -0.2774876356124878, -0.2534167468547821, -0.23955753445625305, -0.2753588557243347, -0.24877578020095825, -0.31097784638404846, -0.2872949540615082, -0.2640436589717865, -0.2762223184108734, -0.22945210337638855, -0.20763790607452393, -0.2592935264110565, -0.2615327537059784, -0.30126041173934937, -0.22909100353717804, -0.27118104696273804, -0.30346593260765076, -0.29224497079849243, -0.31037190556526184, -0.3448803722858429, -0.27197080850601196, -0.27587243914604187, -0.3214629292488098, -0.22418339550495148, -0.3450113534927368, -0.24821223318576813, -0.2490633726119995, -0.29343855381011963, -0.22518965601921082, -0.34325259923934937, -0.35178443789482117, -0.3078157305717468, -0.31238695979118347, -0.2646702527999878, -0.2744048535823822, -0.31260788440704346, -0.3161596655845642, -0.28401705622673035, -0.22859767079353333, -0.31118419766426086, -0.3162825107574463, -0.2679775357246399, -0.30010655522346497, -0.310298353433609, -0.31484049558639526, -0.39814019203186035, -0.3315357565879822, -0.3185020089149475, -0.3222275972366333, -0.27203622460365295, -0.3178696632385254, -0.2776539623737335, -0.29374831914901733, -0.3218154013156891, -0.29403844475746155, -0.27840864658355713, -0.32546958327293396, -0.30999091267585754, -0.26325297355651855, -0.23391497135162354, -0.28231415152549744, -0.30595290660858154, -0.3103232681751251, -0.3035707175731659, -0.3339252769947052, -0.31786075234413147, -0.2815314829349518, -0.2771807610988617, -0.29096704721450806, -0.34281429648399353, -0.32517579197883606, -0.3593694567680359, -0.3600892126560211, -0.23457185924053192, -0.31785622239112854, -0.32374072074890137, -0.3127099275588989, -0.3210102319717407, -0.33092373609542847, -0.308084636926651, -0.3456547260284424, -0.3662436902523041, -0.3312767744064331, -0.32002776861190796, -0.3570621907711029, -0.29623299837112427, -0.34725460410118103, -0.3750230073928833, -0.3707825839519501, -0.3008263111114502, -0.3032449185848236, -0.33869513869285583, -0.3247857689857483, -0.3418330252170563, -0.30789363384246826, -0.33042314648628235, -0.30734142661094666, -0.31140294671058655, -0.3072904050350189, -0.350475549697876, -0.3314369320869446, -0.31258609890937805, -0.3608371317386627, -0.3499954342842102, -0.3138817846775055, -0.31642067432403564, -0.337313175201416, -0.36883240938186646, -0.3741919994354248, -0.37387946248054504, -0.320194274187088, -0.43969324231147766, -0.3091306984424591, -0.34033557772636414, -0.3734963536262512, -0.3528224229812622, -0.3578229546546936, -0.3551274538040161, -0.3133906424045563, -0.3140319585800171, -0.334921270608902, -0.375097393989563, -0.3711751699447632, -0.37544021010398865, -0.4056733250617981, -0.35409706830978394, -0.4076353907585144, -0.39371827244758606, -0.32339343428611755, -0.35648012161254883, -0.35529661178588867, -0.36953186988830566, -0.4014224708080292, -0.37518608570098877, -0.3020554184913635, -0.3887731432914734, -0.3722379207611084, -0.4018605947494507, -0.3441462516784668, -0.40872058272361755, -0.4529237747192383, -0.377128005027771, -0.4350268840789795, -0.3492791950702667, -0.32394760847091675, -0.3717886805534363, -0.437531054019928, -0.3959697186946869, -0.3828321397304535, -0.390560507774353, -0.38180679082870483, -0.37426578998565674, -0.4229130446910858, -0.4020150601863861, -0.3966309726238251, -0.42754966020584106, -0.35959187150001526, -0.42804211378097534, -0.3939509391784668, -0.4383106529712677, -0.41283997893333435, -0.35833585262298584, -0.39359262585639954, -0.38400891423225403, -0.4573836922645569, -0.3769921064376831, -0.40161728858947754, -0.3978029787540436, -0.4451790750026703, -0.44582968950271606, -0.45378535985946655, -0.37466612458229065, -0.39224401116371155, -0.42824506759643555, -0.419071763753891, -0.466913640499115, -0.3936716914176941, -0.4143678545951843, -0.4151439666748047, -0.46633240580558777, -0.384988009929657, -0.39945027232170105, -0.42960166931152344, -0.48245275020599365, -0.452634334564209, -0.44995376467704773, -0.4336521625518799, -0.4340408444404602, -0.4784833788871765, -0.3910725712776184, -0.4890368580818176, -0.4466123878955841, -0.463227778673172, -0.4686833322048187, -0.4204484522342682, -0.44383639097213745, -0.4764452278614044, -0.4615640640258789, -0.4620536267757416, -0.4700106680393219, -0.47255367040634155, -0.42282891273498535, -0.42886146903038025, -0.42877790331840515, -0.4444330632686615, -0.4540594518184662, -0.4831339120864868, -0.4693630635738373, -0.4648865759372711, -0.49558931589126587, -0.42348623275756836, -0.4591401219367981, -0.45266616344451904, -0.47472113370895386, -0.503591775894165, -0.45859336853027344, -0.47128620743751526, -0.47940582036972046, -0.48583853244781494, -0.45263105630874634, -0.5035896897315979, -0.45240646600723267, -0.4664231538772583, -0.5153708457946777, -0.5170462131500244, -0.46102091670036316, -0.4872961640357971, -0.4896819591522217, -0.5017219185829163, -0.5216009020805359, -0.50788813829422, -0.5196142792701721, -0.5264409184455872, -0.5203274488449097, -0.5259891152381897, -0.44311198592185974, -0.5190218091011047, -0.49242618680000305, -0.4657820761203766, -0.4654734134674072, -0.4638248383998871, -0.4878118932247162, -0.5399039387702942, -0.5259315967559814, -0.5171329975128174, -0.5080623030662537, -0.47317394614219666, -0.4870460629463196, -0.5155478715896606, -0.48388412594795227, -0.4890676438808441, -0.4701991677284241, -0.48807284235954285, -0.4872509241104126, -0.41865795850753784, -0.5067910552024841, -0.5180574655532837, -0.5291754007339478, -0.4897923767566681, -0.5030325651168823, -0.5142821073532104, -0.4876554608345032, -0.5169104933738708, -0.5142809152603149, -0.4905148148536682, -0.5343451499938965, -0.48152250051498413, -0.489801824092865, -0.4876933991909027, -0.4873965084552765, -0.5427913665771484, -0.4912739098072052, -0.5306592583656311, -0.5207200050354004, -0.5000450611114502, -0.4671204090118408, -0.5084086656570435, -0.5263083577156067, -0.47164028882980347, -0.507337749004364, -0.5171630382537842, -0.556541383266449, -0.5069671273231506, -0.5098873972892761, -0.4831584393978119, -0.5218560695648193, -0.5350349545478821, -0.5273705124855042, -0.5219929218292236, -0.5127990245819092, -0.5102589130401611, -0.46641671657562256, -0.5135552287101746, -0.4998973608016968, -0.5393788814544678, -0.50909823179245, -0.5141719579696655, -0.47707274556159973, -0.5250943899154663, -0.4956957995891571, -0.5406064987182617, -0.5254508852958679, -0.5315870642662048, -0.5254548192024231, -0.5114350318908691, -0.525631308555603, -0.5678234100341797, -0.5036094784736633, -0.5462481379508972, -0.542275071144104, -0.5071419477462769, -0.5750798583030701, -0.5252909064292908, -0.5134327411651611, -0.5545722246170044, -0.5176689624786377, -0.5015933513641357, -0.5638478398323059, -0.5268623232841492, -0.5679241418838501, -0.5267139673233032, -0.48996731638908386, -0.5296584367752075, -0.5307775735855103, -0.5112195014953613, -0.5188822150230408, -0.5509160161018372, -0.56181800365448, -0.5444241762161255, -0.5356649160385132, -0.5525201559066772, -0.5369017720222473, -0.5206476449966431, -0.5338466763496399, -0.5369173884391785, -0.5617536902427673, -0.5065689086914062, -0.5570803880691528, -0.5546878576278687, -0.5593607425689697, -0.5385452508926392, -0.5594139695167542, -0.5162071585655212, -0.5211670398712158, -0.5418611764907837, -0.5637293457984924, -0.5312931537628174, -0.5305811166763306, -0.5580569505691528, -0.5509318709373474, -0.5468898415565491, -0.5610995292663574, -0.5715698599815369, -0.5550980567932129, -0.5862287282943726, -0.5494785308837891, -0.5510712265968323, -0.5397554636001587, -0.5450101494789124, -0.5702786445617676, -0.5613283514976501, -0.6023831367492676, -0.6213371157646179, -0.5654107332229614, -0.5297713875770569, -0.54239821434021, -0.5511171221733093, -0.5638259649276733, -0.5379628539085388, -0.5463019609451294, -0.5681168437004089, -0.5247915387153625, -0.5106071829795837, -0.5622042417526245, -0.5597803592681885, -0.5430961847305298, -0.5856360793113708, -0.5532472133636475, -0.5257473587989807, -0.5977497696876526, -0.5388352870941162, -0.5752918720245361, -0.6158768534660339, -0.5753979682922363, -0.552023708820343, -0.6151303648948669, -0.5499081015586853, -0.5817807912826538, -0.5874143838882446, -0.619019627571106, -0.5860847234725952, -0.5998094081878662, -0.5759087800979614, -0.5639382004737854, -0.6039668917655945, -0.633795440196991, -0.583137035369873, -0.5812456607818604, -0.6046777367591858, -0.5722334384918213, -0.5633302330970764, -0.6017816662788391, -0.5922321677207947, -0.6294074654579163, -0.5925257802009583, -0.6020976305007935, -0.6467660665512085, -0.60872483253479, -0.6083875298500061, -0.6029778718948364, -0.6093889474868774, -0.6260992288589478, -0.6279103755950928, -0.5777655243873596, -0.6057265400886536, -0.6575321555137634, -0.657126247882843, -0.6567094922065735, -0.6573364734649658, -0.6172626614570618, -0.6244856119155884, -0.625555157661438, -0.6275975108146667, -0.6381316781044006, -0.612223744392395, -0.6672655940055847, -0.6373448371887207, -0.6671017408370972, -0.6187366843223572, -0.6399288773536682, -0.6295926570892334, -0.6417244076728821, -0.6291013360023499, -0.6451122164726257, -0.6267943978309631, -0.6338219046592712, -0.6497572064399719, -0.5928710103034973, -0.6253257989883423, -0.6178080439567566, -0.6786419749259949, -0.642558217048645, -0.6477563977241516, -0.6501770615577698, -0.6445558071136475, -0.6383050084114075, -0.6857065558433533, -0.6637226343154907, -0.6787692308425903, -0.6233084797859192, -0.6333428621292114, -0.6897369027137756, -0.6577705144882202, -0.7080827951431274, -0.6612548828125, -0.6921476721763611, -0.5907171368598938, -0.6536737680435181, -0.6604268550872803, -0.6413712501525879, -0.6435540914535522, -0.6712567806243896, -0.6964537501335144, -0.6567788124084473, -0.7021435499191284, -0.694241464138031, -0.6595826745033264, -0.694222629070282, -0.6982300281524658, -0.6546983122825623, -0.6943974494934082, -0.6669490933418274, -0.6447594165802002, -0.6396290063858032, -0.6291393041610718, -0.6900472640991211, -0.7107612490653992, -0.6373451352119446, -0.6935849189758301, -0.7063270807266235, -0.6958100199699402, -0.6769230961799622, -0.6857213377952576, -0.6524245738983154, -0.6767022609710693, -0.6277858018875122, -0.6947206854820251, -0.6824650168418884, -0.6202130913734436, -0.6202623248100281, -0.6900901198387146, -0.6797953248023987, -0.6741676926612854, -0.7039762735366821, -0.6764929294586182, -0.6492615938186646, -0.7175489068031311, -0.706131637096405, -0.6912217140197754, -0.71244877576828, -0.6695829033851624, -0.708696186542511, -0.6841418147087097, -0.6679643988609314, -0.6735169291496277, -0.6880380511283875, -0.6302892565727234, -0.732622504234314, -0.646480917930603, -0.7321463823318481, -0.7337597608566284, -0.721225917339325, -0.683908998966217, -0.6879165172576904, -0.65336012840271, -0.7130588889122009, -0.7211790084838867, -0.6881094574928284, -0.6846150755882263, -0.7116118669509888, -0.7531845569610596, -0.7101777195930481, -0.786335289478302, -0.7301140427589417, -0.721630334854126, -0.7134787440299988, -0.6794666647911072, -0.664555549621582, -0.6395730972290039, -0.7237290740013123, -0.6701754927635193, -0.7157098054885864, -0.6874231100082397, -0.6678553223609924, -0.7753236293792725, -0.7177315950393677, -0.7021549344062805, -0.7043830156326294, -0.737937331199646, -0.7396921515464783, -0.6997785568237305, -0.7252923250198364, -0.8185195326805115, -0.7258351445198059, -0.8260112404823303, -0.7021730542182922, -0.762884795665741, -0.772062361240387, -0.739225447177887, -0.7516636848449707, -0.7006972432136536, -0.7401891946792603, -0.7469261884689331, -0.7426066398620605, -0.724538266658783, -0.7380217909812927, -0.7657727599143982, -0.777965247631073, -0.7526990175247192, -0.7389628887176514, -0.7627153396606445, -0.7763959169387817, -0.7266390323638916, -0.7754361629486084, -0.7751672267913818, -0.7517374157905579, -0.7785895466804504, -0.7138184309005737, -0.7366230487823486, -0.7599285840988159, -0.7556331157684326, -0.7486781477928162, -0.7888423204421997, -0.7615528106689453, -0.8164268732070923, -0.7579077482223511, -0.7523853778839111, -0.7591866850852966, -0.7699140906333923, -0.7837857007980347, -0.7855523824691772, -0.7854271531105042, -0.7853752374649048, -0.784697949886322, -0.8741702437400818, -0.8749403357505798, -0.8512206673622131, -0.7823207378387451, -0.7907863259315491, -0.7867850065231323, -0.7491599321365356, -0.8199055790901184, -0.828400194644928, -0.8285471796989441, -0.7694756984710693, -0.7743761539459229, -0.8655791282653809, -0.79649817943573, -0.7946000695228577, -0.7863210439682007, -0.7943316698074341, -0.763316810131073, -0.7370001673698425, -0.8013945817947388, -0.7997761368751526, -0.79728102684021, -0.7845485806465149, -0.7693287134170532, -0.73127281665802, -0.7748993039131165, -0.8121814131736755, -0.7901989221572876, -0.823050320148468, -0.8787662386894226, -0.7711964249610901, -0.7617164850234985, -0.7784086465835571, -0.7841529846191406, -0.8082113862037659, -0.814967155456543, -0.8095372319221497, -0.8089591264724731, -0.8822196125984192, -0.7790423631668091, -0.7805919051170349, -0.8245095610618591, -0.8212665319442749, -0.8179401159286499, -0.7596792578697205, -0.7912712693214417, -0.8899268507957458, -0.7967515587806702, -0.8212026357650757, -0.7923464179039001, -0.8428248167037964, -0.810448169708252, -0.7843922972679138, -0.8093485236167908, -0.8948948979377747, -0.83039391040802, -0.8058699369430542, -0.8220760226249695, -0.7993459105491638, -0.8042279481887817, -0.785200834274292, -0.8468403816223145, -0.8422378897666931, -0.8276758790016174, -0.8472922444343567, -0.803528368473053, -0.7896308302879333, -0.8421772122383118, -0.8347136378288269, -0.8070777058601379, -0.8452494740486145, -0.8360570073127747, -0.8319337964057922, -0.8160924911499023, -0.8366871476173401, -0.839031457901001, -0.851143479347229, -0.8375310301780701, -0.8646519780158997, -0.8305953741073608, -0.7833284139633179, -0.8560618758201599, -0.8166346549987793, -0.9287317991256714, -0.8572293519973755, -0.8327076435089111, -0.8562613129615784, -0.8731089234352112, -0.8206766247749329, -0.8688526749610901, -0.8205599188804626, -0.9491879343986511, -0.8599041104316711, -0.8751393556594849, -0.8521996736526489, -0.8392441272735596, -0.8371448516845703, -0.8148794770240784, -0.8732480406761169, -0.8485235571861267, -0.8361025452613831, -0.8556786179542542, -0.8197990655899048, -0.8654102087020874, -0.9521526098251343, -0.9417860507965088, -0.814605712890625, -0.8705397248268127, -0.8686167597770691, -0.8708470463752747, -0.8702919483184814, -0.8660120964050293, -0.8776647448539734, -0.8725834488868713, -0.8851770162582397, -0.867026686668396, -0.8824851512908936, -0.8801940679550171, -0.9662076830863953, -0.8804193139076233, -0.8922368288040161, -0.8884004950523376, -0.9802772998809814, -0.8750944137573242, -0.8844190239906311, -0.9537131190299988, -0.8846293091773987, -0.9022031426429749, -0.9015840291976929, -0.954034149646759, -0.8787488341331482, -0.8951510190963745, -0.9240822792053223, -0.887814998626709, -0.9846746921539307, -0.8423197269439697, -0.9403228163719177, -0.917454719543457, -0.9129594564437866, -0.8682020306587219, -0.9728249907493591, -0.9827495217323303, -0.848820686340332, -1.011505126953125, -0.9143531322479248, -0.9050348401069641, -0.9032860994338989, -0.9020203351974487, -0.9055766463279724, -0.922813355922699, -0.8879151344299316, -0.9079697728157043, -1.0616421699523926, -0.9236196875572205, -1.0085004568099976, -0.9168382287025452, -0.8983890414237976, -0.9251704216003418, -0.953074038028717, -0.9134384989738464, -1.049309492111206, -1.0018219947814941, -0.9180297255516052, -0.9388145804405212, -0.9175552725791931, -0.9084619283676147, -0.9218818545341492, -0.9519188404083252, -0.8906442523002625, -0.9484769701957703, -0.9214297533035278, -0.9511430859565735, -0.9567828178405762, -0.9523998498916626, -0.9138007760047913, -0.9565575122833252, -0.9191728830337524, -0.9289112091064453, -0.9166443943977356, -0.9327824115753174, -1.0268652439117432, -1.0068401098251343, -0.9449233412742615, -0.9152142405509949, -0.9678459167480469, -0.9962764978408813, -1.0246543884277344, -0.9413791298866272, -0.9480903744697571, -0.9284923672676086, -0.9395102262496948, -0.8953870534896851, -0.9606307744979858, -0.9485554695129395, -0.9372808933258057, -0.9917449355125427, -0.9618977308273315, -0.9624047875404358, -0.939555823802948, -0.9400314688682556, -1.0455418825149536, -0.9537294507026672, -1.0483250617980957, -1.0923620462417603, -1.0839542150497437, -0.9616007804870605, -0.9694692492485046, -0.9721694588661194, -0.9398270845413208, -0.9269315600395203, -1.0864156484603882, -0.9849047660827637, -0.9516839385032654, -0.9794514775276184, -0.9785997271537781, -0.9615246057510376, -0.9831162095069885, -0.9707971811294556, -1.0880776643753052, -0.9639546871185303, -1.0539675951004028, -0.9932156801223755, -0.9839119911193848, -0.9705036282539368, -0.97019362449646, -1.1155263185501099, -1.0785284042358398, -0.9704945087432861, -0.9826363921165466, -0.9872725009918213, -1.001267433166504, -0.9835324883460999, -0.9519652128219604, -1.0848972797393799, -0.9969258308410645, -0.9772841930389404, -0.9827851057052612, -0.9994048476219177, -0.9862932562828064, -1.1371588706970215, -1.0885326862335205, -0.978096067905426, -1.0186046361923218, -1.0991848707199097, -1.099037528038025, -1.0988106727600098, -1.099099040031433, -0.9991677403450012, -1.099039077758789, -1.0018121004104614, -1.0172319412231445, -1.0484366416931152, -1.023049235343933, -1.015235424041748, -1.0089783668518066, -0.9455788135528564, -1.0225646495819092, -1.016482949256897, -1.024016261100769, -1.040298581123352, -1.0010672807693481, -1.016589641571045, -0.994642972946167, -1.0216500759124756, -1.0219274759292603, -1.0251264572143555, -1.0246702432632446, -0.998788058757782, -1.047014594078064, -1.1039984226226807, -1.0170800685882568, -1.1078542470932007, -1.0418180227279663, -1.0309336185455322, -1.0376739501953125, -1.0437524318695068, -1.042015790939331, -1.0297415256500244, -1.0424792766571045, -1.0882033109664917, -1.0182875394821167, -1.0723848342895508, -1.0542490482330322, -1.1390608549118042, -1.0276882648468018, -1.055403470993042, -1.0198981761932373, -1.0679264068603516, -1.0554324388504028, -1.034961462020874, -1.0816336870193481, -1.1404067277908325, -1.1068789958953857, -1.1050046682357788, -1.142313003540039, -1.0891644954681396, -1.0453784465789795, -1.063370704650879, -1.0592000484466553, -1.0414115190505981, -1.1405978202819824, -1.0798388719558716, -1.0672518014907837, -1.0818880796432495, -1.0746744871139526, -1.1892004013061523, -1.062216877937317, -1.049390196800232, -1.07148015499115, -1.0642272233963013, -1.0629324913024902, -1.1355986595153809, -1.0901689529418945, -1.0262094736099243, -1.0585641860961914, -1.0679020881652832, -1.0847607851028442, -1.0969347953796387, -1.0543510913848877, -1.0765869617462158, -1.1511671543121338, -1.068747639656067, -1.071458101272583, -1.097032070159912, -1.0978959798812866, -1.0336909294128418, -1.159001111984253, -1.159013032913208, -1.1620715856552124, -1.0732558965682983, -1.0735985040664673, -1.0900905132293701, -1.090393304824829, -1.108734130859375, -1.0885266065597534, -1.1820627450942993, -1.15277898311615, -1.0824462175369263, -1.076590657234192, -1.0823019742965698, -1.0886447429656982, -1.1000783443450928, -1.122436761856079, -1.116700530052185, -1.0905601978302002, -1.0610246658325195, -1.0605671405792236, -1.1325145959854126, -1.1992030143737793, -1.0664796829223633, -1.1155380010604858, -1.124377727508545, -1.1122814416885376, -1.0848097801208496, -1.1073131561279297, -1.175106167793274, -1.1375333070755005, -1.13241708278656, -1.1113953590393066, -1.127335786819458, -1.1006711721420288, -1.1320862770080566, -1.2031726837158203, -1.1323360204696655, -1.2594962120056152, -1.0873322486877441, -1.141684889793396, -1.1579939126968384, -1.1365820169448853, -1.1021275520324707, -1.1315642595291138, -1.1500301361083984, -1.2190001010894775, -1.1635477542877197, -1.1705238819122314, -1.1757251024246216, -1.1655274629592896, -1.1375820636749268, -1.2170730829238892, -1.159700632095337, -1.1689680814743042, -1.133151888847351, -1.164581060409546, -1.1291027069091797, -1.2934513092041016, -1.1492538452148438, -1.1333584785461426, -1.2422993183135986, -1.177366852760315, -1.254675269126892, -1.2548236846923828, -1.1421358585357666, -1.2315921783447266, -1.1736080646514893, -1.2506605386734009, -1.1185308694839478, -1.1486375331878662, -1.2010059356689453, -1.1726428270339966, -1.1704926490783691, -1.1687248945236206, -1.1320658922195435, -1.1917921304702759, -1.153196096420288, -1.18424391746521, -1.2449095249176025, -1.2057965993881226, -1.1534069776535034, -1.2012571096420288, -1.167534351348877, -1.201033115386963, -1.218666911125183, -1.1810351610183716, -1.2886707782745361, -1.184383749961853, -1.1693841218948364, -1.187475323677063, -1.190847396850586, -1.1920320987701416, -1.2222038507461548, -1.222080111503601, -1.1732065677642822, -1.2063770294189453, -1.1708444356918335, -1.2081658840179443, -1.2226759195327759, -1.1793830394744873, -1.1751302480697632, -1.2350045442581177, -1.1980395317077637, -1.1492433547973633, -1.2351553440093994, -1.1998668909072876, -1.227924108505249, -1.2167185544967651, -1.2462637424468994, -1.285823106765747, -1.2026644945144653, -1.2160723209381104, -1.2166134119033813, -1.256241798400879, -1.2019915580749512, -1.2472655773162842, -1.2678947448730469, -1.2843362092971802, -1.2398947477340698, -1.2276920080184937, -1.246229648590088, -1.2140851020812988, -1.243456482887268, -1.263130784034729, -1.2472583055496216, -1.2016078233718872, -1.2701932191848755, -1.263630747795105, -1.3011386394500732, -1.2678276300430298, -1.335815668106079, -1.2370353937149048, -1.2540594339370728, -1.243549108505249, -1.2729408740997314, -1.2688148021697998, -1.3596843481063843, -1.2885339260101318, -1.3071221113204956, -1.3194983005523682, -1.3019423484802246, -1.2246272563934326, -1.254739761352539, -1.3775092363357544, -1.2806751728057861, -1.2692465782165527, -1.3261082172393799, -1.2655038833618164, -1.2943345308303833, -1.290516972541809, -1.4364683628082275, -1.320573329925537, -1.2322169542312622, -1.3195266723632812, -1.433232069015503, -1.363891363143921, -1.2872682809829712, -1.2950595617294312, -1.372910976409912, -1.2703288793563843, -1.3120129108428955, -1.349762201309204, -1.33992600440979, -1.3068100214004517, -1.294285535812378, -1.3055649995803833, -1.297662377357483, -1.3663619756698608, -1.3401576280593872, -1.3659080266952515, -1.3031115531921387, -1.2892241477966309, -1.30520761013031, -1.3310340642929077, -1.3516708612442017, -1.3347722291946411, -1.3713016510009766, -1.4804599285125732, -1.3229150772094727, -1.3487646579742432, -1.3285261392593384, -1.3390058279037476, -1.3300063610076904, -1.306898832321167, -1.3881947994232178, -1.397748351097107, -1.3283932209014893, -1.3253086805343628, -1.4120163917541504, -1.3540372848510742, -1.3423945903778076, -1.4001706838607788, -1.3715687990188599, -1.3624814748764038, -1.3787139654159546, -1.3466461896896362, -1.394955039024353, -1.3536262512207031, -1.4082740545272827, -1.381317377090454, -1.350682258605957, -1.3459595441818237, -1.374991774559021, -1.3630553483963013, -1.3722416162490845, -1.4239009618759155, -1.4027183055877686, -1.4014195203781128, -1.3538548946380615, -1.4143726825714111, -1.3517402410507202, -1.419369101524353, -1.4163258075714111, -1.3864010572433472, -1.4155608415603638, -1.3924596309661865, -1.3682832717895508, -1.3570151329040527, -1.3870899677276611, -1.434335708618164, -1.436224341392517, -1.4246412515640259, -1.4224449396133423, -1.4249908924102783, -1.3968549966812134, -1.3891701698303223, -1.536842703819275, -1.3914997577667236, -1.3922260999679565, -1.3989346027374268, -1.4557644128799438, -1.452498197555542, -1.4727418422698975, -1.446324348449707, -1.406259536743164, -1.4260953664779663, -1.4154726266860962, -1.4461172819137573, -1.4268604516983032, -1.3866971731185913, -1.4052011966705322, -1.4280874729156494, -1.4329711198806763, -1.447688102722168, -1.4542229175567627, -1.45169198513031, -1.501235842704773, -1.4517852067947388, -1.4700615406036377, -1.4032453298568726, -1.4367245435714722, -1.4428932666778564, -1.4360707998275757, -1.4469767808914185, -1.4659031629562378, -1.4966070652008057, -1.500983715057373, -1.4515596628189087, -1.4547981023788452, -1.460842251777649, -1.4804056882858276, -1.4267791509628296, -1.4808307886123657, -1.4993616342544556, -1.4704868793487549, -1.5215169191360474, -1.4845249652862549, -1.5083506107330322, -1.4917224645614624, -1.4986770153045654, -1.4871456623077393, -1.495298147201538, -1.5371509790420532, -1.458191156387329, -1.5309429168701172, -1.5115398168563843, -1.4761861562728882, -1.5305572748184204, -1.4841418266296387, -1.5270060300827026, -1.497200608253479, -1.4901145696640015, -1.5121175050735474, -1.5225706100463867, -1.475046992301941, -1.5536609888076782, -1.5658658742904663, -1.5277715921401978, -1.5104389190673828, -1.5046952962875366, -1.50778329372406, -1.5336781740188599, -1.475725769996643, -1.539823293685913, -1.4796125888824463, -1.4753508567810059, -1.5120365619659424, -1.5301321744918823, -1.49501633644104, -1.5154880285263062, -1.5507110357284546, -1.5485568046569824, -1.496475100517273, -1.5166715383529663, -1.473218560218811, -1.549267292022705, -1.566686749458313, -1.5376379489898682, -1.580284833908081, -1.5869364738464355, -1.5453366041183472, -1.5046172142028809, -1.5524598360061646, -1.5541685819625854, -1.5472902059555054, -1.5628869533538818, -1.5303219556808472, -1.5254509449005127, -1.6829932928085327, -1.5556904077529907, -1.566238522529602, -1.5022703409194946, -1.6171892881393433, -1.5543549060821533, -1.5678114891052246, -1.5554453134536743, -1.5381335020065308, -1.5746582746505737, -1.5588045120239258, -1.5567009449005127, -1.5907270908355713, -1.5832157135009766, -1.6036617755889893, -1.5763342380523682, -1.5810949802398682, -1.5807751417160034, -1.5897226333618164, -1.6147435903549194, -1.6018067598342896, -1.5627837181091309, -1.5600206851959229, -1.565169334411621, -1.5869117975234985, -1.581404685974121, -1.600976824760437, -1.5981922149658203, -1.5959793329238892, -1.5993798971176147, -1.5693819522857666, -1.618782877922058, -1.631911039352417, -1.5836782455444336, -1.583656907081604, -1.6040703058242798, -1.6023811101913452, -1.6074044704437256, -1.5996034145355225, -1.583370566368103, -1.6520895957946777, -1.5833309888839722, -1.609065055847168, -1.7301033735275269, -1.6247975826263428, -1.6275140047073364, -1.5999304056167603, -1.607925534248352, -1.6074575185775757, -1.605672836303711, -1.593575358390808, -1.606977939605713, -1.6386879682540894, -1.6006325483322144, -1.6303231716156006, -1.7645535469055176, -1.6129225492477417, -1.7590465545654297, -1.642915964126587, -1.6188609600067139, -1.6060383319854736, -1.5944459438323975, -1.6762771606445312, -1.6038869619369507, -1.622266411781311, -1.6304062604904175, -1.6263153553009033, -1.6719077825546265, -1.641845703125, -1.6086982488632202, -1.6059094667434692, -1.726064920425415, -1.607886552810669, -1.6291903257369995, -1.646312952041626, -1.632394552230835, -1.625769853591919, -1.6379666328430176, -1.6228914260864258, -1.6309021711349487, -1.780175805091858, -1.685755968093872, -1.6281001567840576, -1.6473853588104248, -1.6454510688781738, -1.678798794746399, -1.6953669786453247, -1.6860620975494385, -1.7127492427825928, -1.6925128698349, -1.6929224729537964, -1.6669539213180542, -1.7517883777618408, -1.658634066581726, -1.6896897554397583, -1.7173364162445068, -1.6658153533935547, -1.6988354921340942, -1.6829575300216675, -1.795289158821106, -1.674424409866333, -1.6694436073303223, -1.8052223920822144, -1.6707565784454346, -1.6825544834136963, -1.6763663291931152, -1.640741229057312, -1.6832854747772217, -1.6917486190795898, -1.8111279010772705, -1.6907793283462524, -1.7104809284210205, -1.7158246040344238, -1.6963683366775513, -1.702004313468933, -1.687759518623352, -1.7035796642303467, -1.74136221408844, -1.739566445350647, -1.6708214282989502, -1.680647611618042, -1.7099876403808594, -1.7265982627868652, -1.6841679811477661, -1.734269380569458, -1.7519338130950928, -1.6880515813827515, -1.7259176969528198, -1.7230035066604614, -1.6566356420516968, -1.7141225337982178, -1.7310727834701538, -1.68047297000885, -1.7280067205429077, -1.6846109628677368, -1.724472165107727, -1.6843165159225464, -1.7621219158172607, -1.7463937997817993, -1.743383526802063, -1.6940600872039795, -1.7081583738327026, -1.7603085041046143, -1.7514160871505737, -1.7294583320617676, -1.7021288871765137, -1.771877646446228, -1.7568167448043823, -1.7170183658599854, -1.7105967998504639, -1.754074215888977, -1.7449671030044556, -1.72403883934021, -1.7041178941726685, -1.7816139459609985, -1.7187069654464722, -1.7203717231750488, -1.7151482105255127, -1.7514879703521729, -1.7556906938552856, -1.7564847469329834, -1.7520718574523926, -1.7659939527511597, -1.7718077898025513, -1.8844767808914185, -1.7737003564834595, -1.7034322023391724, -1.7421852350234985, -1.8910595178604126, -1.7589566707611084, -1.80024254322052, -1.7630066871643066, -1.7764378786087036, -1.759634017944336, -1.7473641633987427, -1.767844319343567, -1.7706607580184937, -1.7898238897323608, -1.8347628116607666, -1.9013867378234863, -1.8122862577438354, -1.7951761484146118, -1.76594078540802, -1.7670857906341553, -1.7518086433410645, -1.917013168334961, -1.932049036026001, -1.783521056175232, -1.8136250972747803, -1.786363959312439, -1.7879414558410645, -1.7902729511260986, -1.753002643585205, -1.8100441694259644, -1.8174277544021606, -1.780686378479004, -1.897646188735962, -1.9284052848815918, -1.8073230981826782, -1.7949553728103638, -1.810841679573059, -1.8058892488479614, -1.8383146524429321, -1.848353624343872, -1.9226480722427368, -1.923087477684021, -1.8078992366790771, -1.9571242332458496, -1.788417100906372, -1.805321455001831, -1.861339807510376, -1.7801547050476074, -1.9647778272628784, -1.8095767498016357, -1.8526053428649902, -1.827721357345581, -1.8237006664276123, -1.8235946893692017, -1.8298174142837524, -1.8382267951965332, -1.9584141969680786, -1.9489142894744873, -1.9828764200210571, -1.9387935400009155, -1.7973129749298096, -1.7981207370758057, -1.8098269701004028, -1.7975647449493408, -1.8005764484405518, -1.8111178874969482, -1.85320246219635, -1.8201055526733398, -1.851460576057434, -1.877646803855896, -1.8772337436676025, -1.992812156677246, -1.9455198049545288, -1.85960054397583, -1.9898359775543213, -1.8400294780731201, -1.8426463603973389, -1.8447496891021729, -1.8399041891098022, -1.8332195281982422, -1.8018866777420044, -1.8281055688858032, -1.974640965461731, -2.0010335445404053, -2.0013482570648193, -2.001004934310913, -1.8519513607025146, -1.8901638984680176, -1.8485678434371948, -2.0018601417541504, -1.8605440855026245, -1.9985331296920776, -1.8373664617538452, -1.869001030921936, -1.8440234661102295, -2.024015188217163, -1.8323278427124023, -1.882488489151001, -1.8903095722198486, -1.8633304834365845, -1.8949389457702637, -1.909496545791626, -1.891235589981079, -1.862207055091858, -1.8977540731430054, -1.8709967136383057, -1.8933252096176147, -1.8969632387161255, -1.9037686586380005, -1.85513174533844, -2.003957986831665, -2.0041327476501465, -1.936309576034546, -2.04228138923645, -1.9365248680114746, -1.9903995990753174, -1.992616057395935, -1.8904048204421997, -1.8906320333480835, -1.9364526271820068, -1.9066510200500488, -2.0453040599823, -1.9123679399490356, -1.8869704008102417, -1.9119089841842651, -1.939238429069519, -1.9960086345672607, -1.8865454196929932, -1.9455134868621826, -1.879398226737976, -1.9984946250915527, -2.0298025608062744, -1.9442062377929688, -1.9117658138275146, -2.0521156787872314, -2.0620343685150146, -2.063277006149292, -2.0653607845306396, -1.9234634637832642, -2.0397942066192627, -2.0252387523651123, -1.9069757461547852, -1.9410942792892456, -1.9327425956726074, -1.941978931427002, -1.939374566078186, -1.9451509714126587, -2.0305655002593994, -2.0350182056427, -1.929397702217102, -2.0607876777648926, -1.9359580278396606, -2.0602123737335205, -1.880387306213379, -1.9137464761734009, -1.959221601486206, -2.0634751319885254, -2.082573175430298, -1.9680345058441162, -2.0715649127960205, -1.9516792297363281, -2.0686638355255127, -1.9280519485473633, -2.080104112625122, -2.0692453384399414, -1.96122407913208, -1.93825101852417, -1.916396141052246, -2.06899356842041, -1.9182032346725464, -1.9450502395629883, -1.9078198671340942, -2.1080336570739746, -1.9491639137268066, -1.9767835140228271, -2.124115228652954, -2.0817437171936035, -2.077181339263916, -2.0706982612609863, -2.096123456954956, -2.080695390701294, -2.101499557495117, -2.1073036193847656, -2.1329617500305176, -1.9386301040649414, -2.082590103149414, -2.099299430847168, -2.0891153812408447, -2.0964548587799072, -1.9954850673675537, -1.9957340955734253, -2.1123881340026855, -2.101865291595459, -2.061629056930542, -1.900577425956726, -2.1090874671936035, -2.0105831623077393, -2.030641555786133, -2.118440866470337, -2.025381326675415, -2.1041650772094727, -2.135671377182007, -2.134946346282959, -2.102360963821411, -2.104545831680298, -1.9861632585525513, -2.1533913612365723, -1.9611883163452148, -2.0084211826324463, -1.9959373474121094, -2.133666753768921, -2.0906081199645996, -1.9947173595428467, -2.12078857421875, -2.145235776901245, -2.1530332565307617, -2.039496421813965, -2.125886917114258, -2.1610991954803467, -2.0546300411224365, -2.1279027462005615, -2.012526750564575, -2.0862109661102295, -2.172454595565796, -2.1573259830474854, -2.0194473266601562, -2.1614654064178467, -1.9773898124694824, -2.1764066219329834, -2.157588005065918, -2.0445187091827393, -1.9939424991607666, -2.127136468887329, -2.0222742557525635, -2.158801555633545, -2.15804386138916, -2.192458152770996, -2.0193774700164795, -2.160710573196411, -2.1704869270324707, -2.148228645324707, -2.169816017150879, -2.169811725616455, -2.174445390701294, -2.0809199810028076, -2.1559035778045654, -2.0349836349487305, -2.1749448776245117, -2.174147367477417, -1.9983241558074951, -2.0420567989349365, -2.0519046783447266, -2.1857595443725586, -2.053640127182007, -2.0233964920043945, -2.0693747997283936, -2.1753602027893066, -2.0830209255218506, -2.191234588623047, -2.1750247478485107, -2.1677403450012207, -2.1852571964263916, -2.1914989948272705, -2.0272200107574463, -2.1675851345062256, -2.0767288208007812, -2.188746452331543, -2.2202308177948, -2.2129428386688232, -2.0603110790252686, -2.195364475250244, -2.0690970420837402, -2.18839430809021, -2.2131638526916504, -2.1946184635162354, -2.2031662464141846, -2.0869832038879395, -2.220036029815674, -2.2123215198516846, -2.207221746444702, -2.1906771659851074, -2.080101251602173, -2.1029489040374756, -2.0798590183258057, -2.2050180435180664, -2.1610193252563477, -2.0513126850128174, -2.2404749393463135, -2.1938581466674805, -2.2028260231018066, -2.2289185523986816, -2.0953736305236816, -2.2044382095336914, -2.1733334064483643, -2.2054812908172607, -2.2154040336608887, -2.220294237136841, -2.22653865814209, -2.1836419105529785, -2.0958547592163086, -2.1949121952056885, -2.124767303466797, -2.129369020462036, -2.2280189990997314, -2.208038568496704, -2.078455924987793, -2.223446846008301, -2.124709129333496, -2.2030484676361084, -2.079561471939087, -2.0872814655303955, -2.079232931137085, -2.2354886531829834, -2.229478120803833, -2.145739793777466, -2.2031033039093018, -2.254251480102539, -2.1067371368408203, -2.2511346340179443, -2.2287063598632812, -2.1145877838134766, -2.138026475906372, -2.2441797256469727, -2.0996148586273193, -2.2451651096343994, -2.1234612464904785, -2.2636704444885254, -2.1348445415496826, -2.2161991596221924, -2.225945234298706, -2.2295329570770264, -2.1146676540374756, -2.125623941421509, -2.228238105773926, -2.127903938293457, -2.2606613636016846, -2.2516136169433594, -2.2574045658111572, -2.2451229095458984, -2.2314302921295166, -2.1976912021636963, -2.2375216484069824, -2.218259811401367, -2.2509469985961914, -2.090609073638916, -2.256028413772583, -2.2658467292785645, -2.264479398727417, -2.2111308574676514, -2.27744460105896, -2.260368824005127, -2.0670082569122314, -2.169175386428833, -2.172173500061035, -2.25469708442688, -2.172544479370117, -2.2892730236053467, -2.116713762283325, -2.128303289413452, -2.106217384338379, -2.156405448913574, -2.280242443084717, -2.1648051738739014, -2.2811782360076904, -2.281402111053467, -2.159304618835449, -2.273662567138672, -2.160536289215088, -2.221151351928711, -2.2765822410583496, -2.2028965950012207, -2.273639440536499, -2.1580309867858887, -2.2648768424987793, -2.132465362548828, -2.1328258514404297, -2.1956377029418945, -2.320147752761841, -2.3299081325531006, -2.1809191703796387, -2.3049545288085938, -2.193756580352783, -2.185994863510132, -2.3228938579559326, -2.236551284790039, -2.2867212295532227, -2.320692300796509, -2.323406457901001, -2.2877516746520996, -2.097585439682007, -2.1360061168670654, -2.3037872314453125, -2.31034517288208, -2.3217077255249023, -2.290137529373169, -2.2956185340881348, -2.15347957611084, -2.33394455909729, -2.315601348876953, -2.258545160293579, -2.211914539337158, -2.194967746734619, -2.2962236404418945, -2.2376248836517334, -2.300910234451294, -2.3256092071533203, -2.2734248638153076, -2.338667154312134, -2.1954803466796875, -2.3347504138946533, -2.1759190559387207, -2.183624267578125, -2.189706802368164, -2.319321393966675, -2.306295156478882, -2.3406689167022705, -2.3113670349121094, -2.328625202178955, -2.3330585956573486, -2.3555073738098145, -2.3487000465393066, -2.3447701930999756, -2.2032485008239746, -2.209137201309204, -2.325941801071167, -2.2894022464752197, -2.1955149173736572, -2.3220298290252686, -2.3203542232513428, -2.331047773361206, -2.3085718154907227, -2.2949471473693848, -2.300596237182617, -2.2176806926727295, -2.3315834999084473, -2.2679479122161865, -2.3445680141448975, -2.3436996936798096, -2.351653814315796, -2.2197201251983643, -2.352017879486084, -2.3516016006469727, -2.2015621662139893, -2.344731330871582, -2.230757713317871, -2.350985050201416, -2.1910674571990967, -2.330357074737549, -2.3526206016540527, -2.3100929260253906, -2.2268311977386475, -2.3543314933776855, -2.2457895278930664, -2.3575594425201416, -2.358245611190796, -2.378065347671509, -2.2129087448120117, -2.3626747131347656, -2.3492486476898193, -2.3888564109802246, -2.2478761672973633, -2.2243964672088623, -2.3683788776397705, -2.2332780361175537, -2.374401569366455, -2.3086025714874268, -2.240915536880493, -2.2434566020965576, -2.394998550415039, -2.246443271636963, -2.325124979019165, -2.410979747772217, -2.3857815265655518, -2.2745656967163086, -2.246081829071045, -2.361987829208374, -2.3456079959869385, -2.4033756256103516, -2.3846209049224854, -2.265488624572754, -2.3386082649230957, -2.4392690658569336, -2.316143274307251, -2.3722474575042725, -2.2944583892822266, -2.374499797821045, -2.2794721126556396, -2.2732670307159424, -2.2860634326934814, -2.2729692459106445, -2.299062728881836, -2.300741672515869, -2.2805464267730713, -2.4075067043304443, -2.2965340614318848, -2.439753293991089, -2.391242742538452, -2.2825703620910645, -2.4007883071899414, -2.432466983795166, -2.4054689407348633, -2.447256565093994, -2.364288091659546, -2.373814582824707, -2.4188790321350098, -2.412564516067505, -2.3766870498657227, -2.34609055519104, -2.3091940879821777, -2.297231912612915, -2.382944345474243, -2.442214012145996, -2.307281732559204, -2.331707000732422, -2.443941354751587, -2.339454174041748, -2.3127281665802, -2.4527387619018555, -2.2985501289367676, -2.451802968978882, -2.3530595302581787, -2.3609883785247803, -2.410170793533325, -2.442324638366699, -2.4085240364074707, -2.3118250370025635, -2.4567208290100098, -2.438767433166504, -2.3369364738464355, -2.34222412109375, -2.427231788635254, -2.422788619995117, -2.414705514907837, -2.3445322513580322, -2.4402246475219727, -2.341838836669922, -2.460148334503174, -2.4655203819274902, -2.4610626697540283, -2.508526086807251, -2.3409528732299805, -2.3515264987945557, -2.432217836380005, -2.455015182495117, -2.349548101425171, -2.3892412185668945, -2.3317742347717285, -2.3357512950897217, -2.455893039703369, -2.491767168045044, -2.441110134124756, -2.4700191020965576, -2.337008476257324, -2.4462528228759766, -2.3342180252075195, -2.3724446296691895, -2.3685524463653564, -2.396801233291626, -2.485490560531616, -2.309138298034668, -2.33634877204895, -2.4907565116882324, -2.3680577278137207, -2.351250171661377, -2.4691696166992188, -2.4913830757141113, -2.4649319648742676, -2.321922779083252, -2.4966559410095215, -2.4745843410491943, -2.381732702255249, -2.485517978668213, -2.368924617767334, -2.3587534427642822, -2.4633450508117676, -2.3986051082611084, -2.473360776901245, -2.4916257858276367, -2.4146885871887207, -2.482853412628174, -2.4144067764282227, -2.540337085723877, -2.3518452644348145, -2.5172855854034424, -2.4800589084625244, -2.539440155029297, -2.5401296615600586, -2.386371374130249, -2.3524038791656494, -2.513807535171509, -2.377655506134033, -2.528219223022461, -2.5231573581695557, -2.5158817768096924, -2.3889920711517334, -2.515174627304077, -2.495011568069458, -2.513367176055908, -2.4713456630706787, -2.4908621311187744, -2.5549051761627197, -2.5240657329559326, -2.5415098667144775, -2.4045863151550293, -2.428450107574463, -2.543851613998413, -2.4462625980377197, -2.531183958053589, -2.547731876373291, -2.5231194496154785, -2.4928231239318848, -2.409189462661743, -2.526970624923706, -2.4178051948547363, -2.547198534011841, -2.5618412494659424, -2.502265453338623, -2.5061542987823486, -2.5393118858337402, -2.580880880355835, -2.507983922958374, -2.5499067306518555, -2.534128189086914, -2.440028429031372, -2.4313902854919434, -2.5087218284606934, -2.5254290103912354, -2.5552918910980225, -2.4404351711273193, -2.503354072570801, -2.546823740005493, -2.562908887863159, -2.5499513149261475, -2.5969290733337402, -2.5627589225769043, -2.587273359298706, -2.596733570098877, -2.604218006134033, -2.5565500259399414, -2.5966241359710693, -2.5966813564300537, -2.5974817276000977, -2.4666829109191895, -2.4424784183502197, -2.451305866241455, -2.5971052646636963, -2.6043591499328613, -2.5692591667175293, -2.522151470184326, -2.5966029167175293, -2.4515221118927, -2.560326337814331, -2.5977632999420166, -2.5674099922180176, -2.4501993656158447, -2.5796966552734375, -2.5881128311157227, -2.487433671951294, -2.554917097091675, -2.5699846744537354, -2.5935757160186768, -2.5829670429229736, -2.5832951068878174, -2.559164524078369, -2.4712438583374023, -2.6275627613067627, -2.585362434387207, -2.572908401489258, -2.6182861328125, -2.5501739978790283, -2.5451583862304688, -2.4204230308532715, -2.552081823348999, -2.58620285987854, -2.585325002670288, -2.613933563232422, -2.4696106910705566, -2.4782919883728027, -2.580974817276001, -2.500913381576538, -2.608297109603882, -2.4884281158447266, -2.580037832260132, -2.5669503211975098, -2.4995129108428955, -2.4992711544036865, -2.586758613586426, -2.498542070388794, -2.5732481479644775, -2.635361433029175, -2.5150692462921143, -2.4771604537963867, -2.6079535484313965, -2.6027212142944336, -2.6106560230255127, -2.470959424972534, -2.5733954906463623, -2.5105481147766113, -2.6321613788604736, -2.621521234512329, -2.5526351928710938, -2.598493814468384, -2.6449077129364014, -2.6396923065185547, -2.591846466064453, -2.6008286476135254, -2.610029458999634, -2.508676052093506, -2.5851802825927734, -2.5292961597442627, -2.6466574668884277, -2.650608777999878, -2.6367123126983643, -2.6388354301452637, -2.6221325397491455, -2.609949827194214, -2.6533942222595215, -2.6612019538879395, -2.588076114654541, -2.6761622428894043, -2.5490732192993164, -2.6232047080993652, -2.628545045852661, -2.700840473175049, -2.67582106590271, -2.648904800415039, -2.525505781173706, -2.6312577724456787, -2.5573842525482178, -2.603519916534424, -2.6592342853546143, -2.6426150798797607, -2.656226396560669, -2.5603060722351074, -2.635939598083496, -2.6545188426971436, -2.6689159870147705, -2.6545121669769287, -2.572052478790283, -2.642045497894287, -2.653151750564575, -2.6801869869232178, -2.6546523571014404, -2.6151018142700195, -2.63635516166687, -2.6312789916992188, -2.662601947784424, -2.6897222995758057, -2.6547043323516846, -2.693118095397949, -2.655890464782715, -2.6952192783355713, -2.6436405181884766, -2.652384042739868, -2.5418965816497803, -2.715644598007202, -2.549194574356079, -2.6788058280944824, -2.664065361022949, -2.5606961250305176, -2.685464382171631, -2.742753267288208, -2.696030378341675, -2.6853182315826416, -2.6501357555389404, -2.6831789016723633, -2.58933687210083, -2.7066874504089355, -2.5587902069091797, -2.5488603115081787, -2.659552812576294, -2.736854076385498, -2.5924675464630127, -2.6983120441436768, -2.7237801551818848, -2.7048885822296143, -2.724442481994629, -2.5635037422180176, -2.689018726348877, -2.7316932678222656, -2.592766284942627, -2.7133424282073975, -2.549934148788452, -2.707761764526367, -2.5816752910614014, -2.5896520614624023, -2.717529058456421, -2.7113449573516846, -2.732982635498047, -2.7241122722625732, -2.626458168029785, -2.7319271564483643, -2.739380121231079, -2.7312428951263428, -2.761343479156494, -2.757871627807617, -2.723684310913086, -2.7428793907165527, -2.7097973823547363, -2.748983144760132, -2.745422601699829, -2.738434076309204, -2.778979539871216, -2.7332215309143066, -2.6723873615264893, -2.737290382385254, -2.77252459526062, -2.8016536235809326, -2.801666259765625, -2.8006021976470947, -2.7803122997283936, -2.8015222549438477, -2.631976366043091, -2.723392963409424, -2.780130386352539, -2.7729947566986084, -2.800403594970703, -2.801460027694702, -2.791173219680786, -2.763329029083252, -2.7574801445007324, -2.660616874694824, -2.7809031009674072, -2.7997043132781982, -2.6576459407806396, -2.7529525756835938, -2.7759499549865723, -2.6576271057128906, -2.661752223968506, -2.637382984161377, -2.790440082550049, -2.7216169834136963, -2.769544839859009, -2.7752082347869873, -2.7118639945983887, -2.7963459491729736, -2.801326036453247, -2.7792136669158936, -2.6639938354492188, -2.8226327896118164, -2.7871479988098145, -2.8054473400115967, -2.7755067348480225, -2.8164103031158447, -2.6820638179779053, -2.8018641471862793, -2.7898917198181152, -2.826932907104492, -2.7470955848693848, -2.797438144683838, -2.636662244796753, -2.784571647644043, -2.7661118507385254, -2.7973415851593018, -2.7914388179779053, -2.7016897201538086, -2.8020260334014893, -2.812941789627075, -2.8032541275024414, -2.731619119644165, -2.713251829147339, -2.834000587463379, -2.8623502254486084, -2.8549885749816895, -2.762934446334839, -2.8824470043182373, -2.7641050815582275, -2.833853006362915, -2.722342014312744, -2.764472484588623, -2.8416287899017334, -2.7324795722961426, -2.836973190307617, -2.8237435817718506, -2.889132261276245, -2.879725694656372, -2.85221791267395, -2.7406482696533203, -2.8837149143218994, -2.793764591217041, -2.8629372119903564, -2.918473482131958, -2.798908233642578, -2.8897523880004883, -2.7385666370391846, -2.788808584213257, -2.8979506492614746, -2.880793571472168, -2.834477663040161, -2.9162449836730957, -2.903613328933716, -2.8314099311828613, -2.8272433280944824, -2.7368998527526855, -2.893533706665039, -2.908691644668579, -2.7989189624786377, -2.915316343307495, -2.737706422805786, -2.8420422077178955, -2.769598960876465, -2.7817299365997314, -2.918992519378662, -2.9478886127471924, -2.881817102432251, -2.896733045578003, -2.929931640625, -2.9371533393859863, -2.9170238971710205, -2.9200029373168945, -2.908083915710449, -2.8011739253997803, -2.817094326019287, -2.794605255126953, -2.893653631210327, -2.8118224143981934, -2.9182300567626953, -2.9664721488952637, -2.799940347671509, -2.848680257797241, -2.802821636199951, -2.8292477130889893, -2.947906017303467, -2.936380624771118, -2.930220127105713, -2.848691463470459, -2.9541077613830566, -2.9732983112335205, -2.9604082107543945, -2.9720776081085205, -2.797229528427124, -2.903404474258423, -2.926215648651123, -2.825639486312866, -2.8766977787017822, -2.8381099700927734, -2.971201181411743, -2.9495956897735596, -2.907235860824585, -2.8382604122161865, -2.86297869682312, -2.8564205169677734, -2.8445277214050293, -3.017491579055786, -2.95116925239563, -2.897719144821167, -3.0167837142944336, -2.870204210281372, -3.017138719558716, -2.9206297397613525, -2.7950375080108643, -2.8616816997528076, -3.0079517364501953, -2.8517303466796875, -2.841733455657959, -2.9872257709503174, -2.8923277854919434, -3.017725944519043, -2.8676624298095703, -2.898517370223999, -2.851141929626465, -2.874394655227661, -2.871523857116699, -2.9740705490112305, -2.8945932388305664, -3.0238397121429443, -2.9062094688415527, -2.9051427841186523, -3.0171761512756348, -2.9337077140808105, -2.895646095275879, -2.9884066581726074, -2.874777317047119, -2.8854780197143555, -2.8956167697906494, -2.9974989891052246, -2.8930716514587402, -3.014169454574585, -2.9583730697631836, -2.8928158283233643, -2.8933520317077637, -2.9107680320739746, -2.9104480743408203, -3.02170729637146, -2.9293222427368164, -3.018127918243408, -3.0061516761779785, -3.0340254306793213, -2.9314630031585693, -2.953566789627075, -3.0064399242401123, -2.9348490238189697, -3.0455760955810547, -2.9548137187957764, -2.969316244125366, -3.0835230350494385, -3.070981502532959, -2.9804482460021973, -3.0485801696777344, -3.0931921005249023, -3.0787525177001953, -3.1345150470733643, -3.0712640285491943, -3.1109588146209717, -3.00821852684021, -3.0695035457611084, -3.0885422229766846, -2.936699628829956, -3.008021354675293, -3.0850751399993896, -3.060943126678467, -2.986806869506836, -3.0561347007751465, -2.9634079933166504, -3.1428213119506836, -3.1229827404022217, -2.99332857131958, -2.98809552192688, -3.0932631492614746, -3.0573501586914062, -2.9852190017700195, -3.0587856769561768, -3.0404698848724365, -2.962008476257324, -3.0394747257232666, -3.135185956954956, -3.1297953128814697, -3.137697458267212, -3.128692150115967, -3.0247764587402344, -3.0777626037597656, -3.1383116245269775, -3.045227527618408, -3.137786388397217, -3.1453053951263428, -3.1820120811462402, -3.003627061843872, -3.137174129486084, -3.082583427429199, -3.081587314605713, -3.1370043754577637, -3.1849985122680664, -3.113720417022705, -3.1937129497528076, -3.231916904449463, -3.0803136825561523, -3.1939306259155273, -3.196601390838623, -3.170567512512207, -3.0355629920959473, -3.0810046195983887, -3.1695117950439453, -3.1633195877075195, -3.1448721885681152, -3.1544291973114014, -3.0588505268096924, -3.2440762519836426, -3.167978048324585, -3.072197198867798, -3.1404755115509033, -3.183631420135498, -3.1029865741729736, -3.190707206726074, -3.187901020050049, -3.1309497356414795, -3.2497987747192383, -3.2082114219665527, -3.14432954788208, -3.220818281173706, -3.0528085231781006, -3.1898069381713867, -3.100304365158081, -3.1212568283081055, -3.2185118198394775, -3.2039785385131836, -3.2577009201049805, -3.2817065715789795, -3.22487211227417, -3.220083713531494, -3.2386646270751953, -3.1773617267608643, -3.224482774734497, -3.3374433517456055, -3.1265575885772705, -3.264777183532715, -3.2104954719543457, -3.2501332759857178, -3.1913633346557617, -3.2499544620513916, -3.1405131816864014, -3.279644250869751, -3.1858725547790527, -3.1860592365264893, -3.12443208694458, -3.218834638595581, -3.156806230545044, -3.3105690479278564, -3.267879009246826, -3.1418955326080322, -3.18685245513916, -3.2093074321746826, -3.2474191188812256, -3.305891513824463, -3.2759857177734375, -3.2463037967681885, -3.2559542655944824, -3.208803415298462, -3.2950046062469482, -3.300097703933716, -3.2760956287384033, -3.220660448074341, -3.223027229309082, -3.309568166732788, -3.2585339546203613, -3.2576916217803955, -3.301481008529663, -3.2211215496063232, -3.260503053665161, -3.226710557937622, -3.258333206176758, -3.2581939697265625, -3.3225924968719482, -3.3675425052642822, -3.3142664432525635, -3.280393362045288, -3.3352348804473877, -3.2159435749053955, -3.3873467445373535, -3.418374538421631, -3.3440935611724854, -3.4192349910736084, -3.212914228439331, -3.2961597442626953, -3.4171576499938965, -3.386322259902954, -3.3498659133911133, -3.2506165504455566, -3.283780097961426, -3.327174186706543, -3.3325448036193848, -3.2759206295013428, -3.457641839981079, -3.3050241470336914, -3.3448705673217773, -3.219452381134033, -3.4408957958221436, -3.333373785018921, -3.4559154510498047, -3.3225045204162598, -3.3319902420043945, -3.413670301437378, -3.3524091243743896, -3.3276290893554688, -3.4009931087493896, -3.32358980178833, -3.428776502609253, -3.394340753555298, -3.46281361579895, -3.4407403469085693, -3.4848926067352295, -3.381542444229126, -3.390150547027588, -3.443618059158325, -3.5051965713500977, -3.4687490463256836, -3.390995502471924, -3.4212441444396973, -3.4679689407348633, -3.4781606197357178, -3.4114108085632324, -3.3727073669433594, -3.4084253311157227, -3.448770523071289, -3.493042469024658, -3.5001561641693115, -3.422285318374634, -3.4857988357543945, -3.530644655227661, -3.498671054840088, -3.466378688812256, -3.532271385192871, -3.479156255722046, -3.5038585662841797, -3.4371249675750732, -3.470268487930298, -3.486661195755005, -3.600029468536377, -3.5754878520965576, -3.497805118560791, -3.517996072769165, -3.4772446155548096, -3.5275254249572754, -3.5248897075653076, -3.44366455078125, -3.5088231563568115, -3.544053554534912, -3.468289852142334, -3.503150701522827, -3.541459083557129, -3.551816701889038, -3.528134822845459, -3.5450897216796875, -3.5250842571258545, -3.4900641441345215, -3.495525598526001, -3.4922947883605957, -3.5855259895324707, -3.5758559703826904, -3.567842960357666, -3.5723729133605957, -3.666966438293457, -3.5768253803253174, -3.541809320449829, -3.56557035446167, -3.5743589401245117, -3.523244857788086, -3.6543819904327393, -3.5802903175354004, -3.529578685760498, -3.5560832023620605, -3.597726583480835, -3.5305705070495605, -3.59419584274292, -3.5795905590057373, -3.6413795948028564, -3.553252696990967, -3.562191963195801, -3.570050001144409, -3.586829900741577, -3.6356585025787354, -3.614439010620117, -3.6911563873291016, -3.6075515747070312, -3.520932912826538, -3.6903889179229736, -3.699437141418457, -3.6040704250335693, -3.6912341117858887, -3.544548511505127, -3.5738322734832764, -3.575038433074951, -3.668346881866455, -3.644123077392578, -3.709383010864258, -3.5968809127807617, -3.556892156600952, -3.733175039291382, -3.6861765384674072, -3.733214855194092, -3.725132703781128, -3.7361671924591064, -3.6302621364593506, -3.7191319465637207, -3.6363942623138428, -3.72805118560791, -3.784487724304199, -3.7619433403015137, -3.742335081100464, -3.7204864025115967, -3.66668963432312, -3.734804153442383, -3.7357585430145264, -3.750488519668579, -3.6621809005737305, -3.7611358165740967, -3.745271682739258, -3.806027412414551, -3.6797521114349365, -3.759267807006836, -3.7666118144989014, -3.6387057304382324, -3.728372812271118, -3.7181553840637207, -3.667151927947998, -3.719266176223755, -3.77170729637146, -3.704807758331299, -3.800377130508423, -3.738586902618408, -3.8202388286590576, -3.8446836471557617, -3.7844560146331787, -3.772465229034424, -3.8017091751098633, -3.7883174419403076, -3.7525203227996826, -3.7486841678619385, -3.683668613433838, -3.663090229034424, -3.806149482727051, -3.7336292266845703, -3.723510503768921, -3.702275514602661, -3.712320566177368, -3.7541890144348145, -3.685669183731079, -3.8178791999816895, -3.8111767768859863, -3.832162618637085, -3.6967058181762695, -3.797991991043091, -3.748295783996582, -3.7002241611480713, -3.859468460083008, -3.835394859313965, -3.78381085395813, -3.864121675491333, -3.7634854316711426, -3.7749624252319336, -3.7485222816467285, -3.689890146255493, -3.8593602180480957, -3.7267489433288574, -3.82045841217041, -3.897901773452759, -3.872647285461426, -3.8414852619171143, -3.8765311241149902, -3.8459932804107666, -3.8591036796569824, -3.870241641998291, -3.864755868911743, -3.8443212509155273, -3.766740322113037, -3.8471381664276123, -3.7892467975616455, -3.9429421424865723, -3.8016862869262695, -3.845524549484253, -3.7689833641052246, -3.8667984008789062, -3.82978892326355, -3.856435537338257, -3.8953123092651367, -3.9352340698242188, -3.841456651687622, -3.9397149085998535, -3.887781858444214, -3.8421506881713867, -3.8562376499176025, -3.8348379135131836, -3.8238461017608643, -3.8946030139923096, -3.9234025478363037, -3.846273183822632, -3.801419496536255, -3.8879027366638184, -3.874264717102051, -3.8937888145446777, -3.7594077587127686, -3.936234474182129, -3.9475271701812744, -3.9026520252227783, -3.8628921508789062, -3.783109188079834, -3.9604218006134033, -3.860179901123047, -3.862797975540161, -3.8915014266967773, -3.885234832763672, -3.9179494380950928, -3.7600815296173096, -3.876333475112915, -3.965841770172119, -3.963754415512085, -3.8586368560791016, -3.9742558002471924, -3.9314117431640625, -3.9800562858581543, -3.9350266456604004, -3.9349875450134277, -4.01841926574707, -3.9836106300354004, -3.9441072940826416, -4.032495498657227, -3.8911049365997314, -3.907989025115967, -3.976736545562744, -3.95625638961792, -3.9556987285614014, -4.007893085479736, -3.9193668365478516, -4.00875997543335, -3.9579453468322754, -4.015627861022949, -3.9181134700775146, -4.009638786315918, -3.9847285747528076, -3.9531166553497314, -3.9185292720794678, -3.9428861141204834, -3.9330027103424072, -4.055111408233643, -3.855320453643799, -4.055356979370117, -3.9938361644744873, -4.015051364898682, -3.890929698944092, -3.946018934249878, -3.954373598098755, -4.011205673217773, -3.931588888168335, -4.031304359436035, -3.9669535160064697, -4.001969814300537, -3.982173442840576, -3.994572401046753, -4.108007907867432, -3.972400665283203, -4.013116836547852, -4.024900913238525, -3.988191604614258, -4.004251480102539, -3.9886209964752197, -3.987410545349121, -3.9898242950439453, -4.039348125457764, -4.017098903656006, -3.897569179534912, -4.049071311950684, -3.9732298851013184, -4.031373023986816, -4.0513014793396, -4.047091484069824, -4.068958282470703, -4.0198211669921875, -4.063008785247803, -3.9840452671051025, -3.9719793796539307, -4.074545860290527, -4.152235984802246, -3.948350667953491, -4.078457355499268, -4.031270503997803, -4.068591594696045, -4.047211170196533, -3.901454448699951, -4.021878242492676, -4.1295881271362305, -4.0952558517456055, -3.9715566635131836, -4.047966003417969, -4.080957412719727, -4.118539333343506, -4.084219932556152, -4.064154148101807, -4.143938064575195, -4.019826412200928, -4.014070510864258, -4.0964436531066895, -4.127867698669434, -4.089052200317383, -4.127015590667725, -4.028489112854004, -4.089325428009033, -4.120757579803467, -3.993953227996826, -4.159849166870117, -4.125884532928467, -3.9930243492126465, -4.061980247497559, -4.042015075683594, -4.150242328643799, -4.054927349090576, -4.067046165466309, -4.149754047393799, -4.126800060272217, -3.9909186363220215, -4.139000415802002, -4.088148593902588, -4.152303218841553, -4.072286128997803, -4.1516194343566895, -4.001059532165527, -4.131443500518799, -4.154754638671875, -4.092154026031494, -4.202968120574951, -4.073386192321777, -4.143305778503418, -4.091416358947754, -4.078316688537598, -4.111156463623047, -4.05666971206665, -4.064276695251465, -4.046461582183838, -4.121253490447998, -4.228459358215332, -4.132434844970703, -4.033896446228027, -4.084048748016357, -4.1591339111328125, -4.126996040344238, -4.231230735778809, -4.19367790222168, -4.195600509643555, -4.179080009460449, -4.202775478363037, -4.190116882324219, -4.256673336029053, -4.193490982055664, -4.170888423919678, -4.249060153961182, -4.228755950927734, -4.185633659362793, -4.169418811798096, -4.145779132843018, -4.1689348220825195, -4.171364784240723, -4.128566741943359, -4.12822151184082, -4.172508716583252, -4.162758827209473, -4.12234354019165, -4.139791011810303, -4.154625415802002, -4.172816276550293, -4.276272773742676, -4.209015846252441, -4.132084369659424, -4.12645149230957, -4.252818584442139, -4.230090618133545, -4.250422954559326, -4.229637622833252, -4.308762073516846, -4.2365336418151855, -4.271681308746338, -4.164820194244385, -4.205624103546143, -4.1920390129089355, -4.250507354736328, -4.189484596252441, -4.208621501922607, -4.209784030914307, -4.216716766357422, -4.20241117477417, -4.233368396759033, -4.195446491241455, -4.266482353210449, -4.110729694366455, -4.249692440032959, -4.233084678649902, -4.281765460968018, -4.322434902191162, -4.314059734344482, -4.1541523933410645, -4.310442924499512, -4.311466217041016, -4.270949363708496, -4.230452537536621, -4.236536026000977, -4.326504230499268, -4.247498989105225, -4.2483601570129395, -4.390431880950928, -4.296854496002197, -4.263784885406494, -4.26876974105835, -4.329273223876953, -4.282297134399414, -4.233180522918701, -4.29163122177124, -4.241682052612305, -4.270510673522949, -4.336315631866455, -4.353647232055664, -4.374650001525879, -4.266662120819092, -4.435703277587891, -4.258353233337402, -4.361152648925781, -4.237591743469238, -4.34208869934082, -4.370738983154297, -4.389142990112305, -4.497488021850586, -4.411225318908691, -4.380148410797119, -4.324168682098389, -4.379319190979004, -4.375997066497803, -4.258159160614014, -4.3884806632995605, -4.4132819175720215, -4.396089553833008, -4.379899978637695, -4.319366931915283, -4.459479331970215, -4.397663116455078, -4.455548286437988, -4.38388204574585, -4.347787380218506, -4.240428924560547, -4.446263313293457, -4.373705863952637, -4.369748592376709, -4.376984119415283, -4.3048295974731445, -4.36314582824707, -4.428389072418213, -4.41272497177124, -4.3536858558654785, -4.366325378417969, -4.312591552734375, -4.403887748718262, -4.471578121185303, -4.383785724639893, -4.333183288574219, -4.37925386428833, -4.4113593101501465, -4.392664432525635, -4.411668300628662, -4.433239936828613, -4.557375907897949, -4.501857757568359, -4.444730281829834, -4.365516185760498, -4.440763473510742, -4.398971080780029, -4.49501371383667, -4.458960056304932, -4.446761608123779, -4.489135265350342, -4.443595886230469, -4.461639404296875, -4.472260475158691, -4.394376277923584, -4.537909030914307, -4.4923834800720215, -4.458329677581787, -4.397349834442139, -4.548202037811279, -4.477991580963135, -4.410017967224121, -4.518402099609375, -4.565262317657471, -4.379425048828125, -4.367122650146484, -4.366128921508789, -4.538368225097656, -4.491620063781738, -4.575833320617676, -4.452805995941162, -4.530157089233398, -4.533738136291504, -4.499207019805908, -4.642316818237305, -4.6081862449646, -4.651927471160889, -4.6086907386779785, -4.555321216583252, -4.547183990478516, -4.538921356201172, -4.5090250968933105, -4.49267053604126, -4.543761253356934, -4.53855037689209, -4.671329021453857, -4.511105537414551, -4.545913219451904, -4.509579658508301, -4.606517314910889, -4.5905680656433105, -4.572803974151611, -4.444540023803711, -4.5366902351379395, -4.501551151275635, -4.599553108215332, -4.483149528503418, -4.551865100860596, -4.534296035766602, -4.534339427947998, -4.658445358276367, -4.563388824462891, -4.554585933685303, -4.616541862487793, -4.533888339996338, -4.670790195465088, -4.583616256713867, -4.719947338104248, -4.675384998321533, -4.5644683837890625, -4.608798980712891, -4.7485527992248535, -4.637032985687256, -4.600856781005859, -4.777756690979004, -4.647611141204834, -4.655378818511963, -4.730813980102539, -4.637909412384033, -4.593723297119141, -4.6171441078186035, -4.6475911140441895, -4.596688747406006, -4.584383964538574, -4.596837520599365, -4.663025856018066, -4.641294956207275, -4.637714862823486, -4.668263912200928, -4.568375110626221, -4.546034336090088, -4.606827259063721, -4.533766746520996, -4.77935791015625, -4.618093967437744, -4.733554840087891, -4.684632301330566, -4.712120532989502, -4.629308223724365, -4.706863880157471, -4.763115882873535, -4.614925384521484, -4.70669412612915, -4.735836029052734, -4.65949821472168, -4.627643585205078, -4.638702392578125, -4.83594274520874, -4.768925189971924, -4.650353908538818, -4.746437072753906, -4.610091209411621, -4.63640022277832, -4.627189636230469, -4.740753650665283, -4.672001361846924, -4.6476616859436035, -4.733946800231934, -4.902565956115723, -4.763201713562012, -4.726808547973633, -4.7748494148254395, -4.738747596740723, -4.79356575012207, -4.8776445388793945, -4.738158702850342, -4.848182201385498, -4.80224084854126, -4.799961090087891, -4.761693954467773, -4.769667625427246, -4.794584274291992, -4.7926025390625, -4.831348896026611, -4.877959728240967, -4.794405460357666, -4.7955169677734375, -4.806267738342285, -4.703596115112305, -4.7269368171691895, -4.797825813293457, -4.897303581237793, -4.758233547210693, -4.78169584274292, -4.920384883880615, -4.686183452606201, -4.702024459838867, -4.816792964935303, -4.743170738220215, -4.760916709899902, -4.719007968902588, -4.663517951965332, -4.741528511047363, -4.834982395172119, -4.774744987487793, -4.826874256134033, -4.934133052825928, -4.834003925323486, -4.870131015777588, -4.824013710021973, -4.854702949523926, -4.794954299926758, -4.945372581481934, -5.015411853790283, -5.0342116355896, -4.897390365600586, -4.887285232543945, -4.8013763427734375, -4.851131439208984, -4.738129615783691, -4.83821964263916, -4.832879543304443, -4.766488075256348, -4.779018402099609, -4.962740421295166, -4.856207847595215, -4.873333930969238, -4.856578826904297, -4.919099807739258, -5.016909122467041, -4.958411693572998, -4.9963860511779785, -5.0282440185546875, -4.948172569274902, -4.962190628051758, -5.0611982345581055, -4.975892066955566, -4.980862617492676, -4.904462814331055, -5.125449180603027, -4.984933853149414, -4.828708171844482, -4.927608489990234, -4.92867374420166, -5.0219831466674805, -4.908167362213135, -5.081856727600098, -4.9373297691345215, -5.03900146484375, -4.9339165687561035, -4.869856834411621, -4.967012882232666, -5.009586334228516, -4.888878345489502, -4.908726692199707, -4.938065052032471, -5.037988662719727, -4.88395881652832, -4.889392852783203, -4.882386207580566, -4.979742050170898, -5.011787414550781, -5.040534019470215, -5.03507137298584, -5.0211873054504395, -5.0108962059021, -5.087104320526123, -5.007800579071045, -4.982643127441406, -5.062705039978027, -5.096253395080566, -5.162671089172363, -5.059063911437988, -5.101612091064453, -5.038489818572998, -5.069905757904053, -5.127086639404297, -5.0331549644470215, -5.243690490722656, -5.049609661102295, -5.096328258514404, -5.1304144859313965, -5.105547904968262, -4.975425720214844, -5.152871131896973, -5.019482135772705, -5.090306758880615, -5.0707573890686035, -5.0252766609191895, -5.028102397918701, -5.147542953491211, -5.160080909729004, -5.047447204589844, -5.0152812004089355, -5.078928470611572, -5.080995559692383, -5.093349456787109, -5.107676029205322, -5.082388401031494, -5.163617134094238, -4.979701042175293, -5.02100133895874, -4.955078125, -5.250151634216309, -5.1367411613464355, -5.222997188568115, -5.217131614685059, -5.139101028442383, -5.139194488525391, -5.265554428100586, -5.238369941711426, -5.1399054527282715, -5.084654808044434, -5.101941108703613, -5.1421284675598145, -5.143322467803955, -5.218658924102783, -5.213104724884033, -5.148193359375, -5.120700359344482, -5.1945390701293945, -5.144787311553955, -5.195803642272949, -5.082250118255615, -5.240123271942139, -5.11268949508667, -5.203487873077393, -5.132230758666992, -5.164064884185791, -5.186558246612549, -5.093414783477783, -5.205580711364746, -5.101559638977051, -5.204680919647217, -5.118184566497803, -5.211151123046875, -5.114634037017822, -5.148394584655762, -5.128498077392578, -5.259740829467773, -5.197689056396484, -5.166110038757324, -5.205374240875244, -5.089782238006592, -5.168854713439941, -5.163749694824219, -5.212025165557861, -5.08799934387207, -5.225230693817139, -5.123998165130615, -5.310674667358398, -5.259495735168457, -5.252442359924316, -5.295093536376953, -5.351861000061035, -5.261597156524658, -5.3832688331604, -5.252447128295898, -5.401541709899902, -5.183469295501709, -5.2510528564453125, -5.229020118713379, -5.2273969650268555, -5.290566444396973, -5.321665287017822, -5.303874969482422, -5.286954879760742, -5.321350574493408, -5.2304301261901855, -5.399051189422607, -5.284394264221191, -5.307088851928711, -5.285764694213867, -5.3825154304504395, -5.396103858947754, -5.249726295471191, -5.335207462310791, -5.2835235595703125, -5.27698278427124, -5.270701885223389, -5.387796401977539, -5.224053859710693, -5.271442413330078, -5.244244575500488, -5.329229831695557, -5.284593105316162, -5.2726240158081055, -5.243574619293213, -5.324069499969482, -5.292353630065918, -5.316931247711182, -5.379141807556152, -5.426323890686035, -5.42506742477417, -5.38814115524292, -5.384732246398926, -5.42546272277832, -5.440369129180908, -5.460069179534912, -5.503548622131348, -5.382277965545654, -5.451993465423584, -5.407489776611328, -5.404661655426025, -5.507126808166504, -5.495861053466797, -5.42780876159668, -5.437150478363037, -5.413195610046387, -5.530627250671387, -5.458888053894043, -5.426304340362549, -5.414347171783447, -5.414431095123291, -5.424903869628906, -5.418692111968994, -5.425728797912598, -5.491387844085693, -5.514769554138184, -5.524354934692383, -5.517120838165283, -5.421879291534424, -5.422028064727783, -5.423675060272217, -5.43447208404541, -5.413616180419922, -5.565581798553467, -5.34534215927124, -5.526416301727295, -5.482621669769287, -5.415162563323975, -5.486237049102783, -5.442535400390625, -5.381829261779785, -5.3855695724487305, -5.497642517089844, -5.397634506225586, -5.409755706787109, -5.375817775726318, -5.522220134735107], "diff": [1.1836421489715576, -1.2181127071380615, 0.6324918866157532, 0.1952376365661621, 0.5660392045974731, -0.4912452697753906, -1.0411603450775146, -0.730818510055542, 1.092630386352539, -2.007810354232788, -1.6079634428024292, -1.1820818185806274, 2.2425131797790527, -0.44734054803848267, -0.9527162313461304, -1.0679395198822021, -0.2719135284423828, -0.4929710924625397, -1.825595736503601, -1.578752040863037, 0.6241580843925476, -0.6020707488059998, 1.7340940237045288, -0.32744142413139343, -0.35434654355049133, -1.2967923879623413, 2.028024673461914, 0.1608530879020691, -0.6290100812911987, 0.15442273020744324, 0.40332290530204773, 0.6059308052062988, -0.15290699899196625, -0.8850709199905396, 0.7777448892593384, 0.2685128450393677, -0.028757460415363312, -1.0719630718231201, 1.753734827041626, -0.6886651515960693, -1.9899561405181885, -2.6950581073760986, -2.5861663818359375, 1.9743303060531616, 1.9688612222671509, -0.21774820983409882, 2.201077938079834, 2.0247929096221924, -1.7853636741638184, -0.22904783487319946, 0.5031977295875549, -0.018310092389583588, 0.6613760590553284, 0.9716097712516785, 0.6287531852722168, 0.9155320525169373, -0.044143326580524445, -0.04910490661859512, 0.000877958838827908, 1.9960405826568604, -0.9197070002555847, -1.5493453741073608, 0.1219821348786354, -0.667837917804718, -0.5536343455314636, -0.0979718491435051, 0.012671513482928276, -0.28212499618530273, 1.8151051998138428, 0.4949335753917694, -0.6986748576164246, -1.2321699857711792, -3.0922110080718994, 0.3403696119785309, 1.2789188623428345, -0.19045864045619965, 1.2914748191833496, 0.3290981948375702, -0.3024035692214966, 1.8859617710113525, -0.1671861708164215, -0.2888437807559967, -0.6685161590576172, -2.8112356662750244, 1.1165332794189453, 1.9150043725967407, -1.1004173755645752, 1.5639539957046509, -0.12224756181240082, 0.6242241263389587, 1.793933391571045, 1.6120134592056274, -1.7711294889450073, 2.042235851287842, -1.120897650718689, 0.09756677597761154, 0.6439216732978821, -1.6733418703079224, 1.9467369318008423, 0.6380141973495483, -0.6000120639801025, 2.3519086837768555, -1.1897642612457275, 0.26962825655937195, 0.9594765901565552, -1.3009188175201416, 1.1247527599334717, -2.3419556617736816, 0.604341447353363, -0.6082495450973511, 2.182164192199707, 2.1354904174804688, -0.24729785323143005, -1.6471433639526367, -1.1164562702178955, 0.4593317210674286, -1.1434327363967896, -0.23103050887584686, 1.0847324132919312, -0.833130955696106, -0.18097591400146484, -2.267247438430786, 2.3367950916290283, -2.033808708190918, 0.12129227817058563, -0.004733312409371138, -1.2831166982650757, -0.5904203653335571, -0.8318279981613159, -0.7676546573638916, 2.1272714138031006, 0.43994221091270447, 0.26138871908187866, 0.21350769698619843, 0.49338048696517944, -0.1383306235074997, -1.9584161043167114, -0.41323941946029663, -1.119337558746338, 0.6395821571350098, 0.9386286735534668, -1.2090078592300415, -0.4794943928718567, -1.0586576461791992, -1.1948106288909912, -0.4034425914287567, -1.891318917274475, 1.5271008014678955, 0.43095114827156067, -1.8234773874282837, 0.7793307304382324, -2.837310314178467, 0.41243061423301697, 2.139946937561035, 0.6406506299972534, -2.016575813293457, -2.3134734630584717, 0.2754109501838684, 1.7777915000915527, -0.912360429763794, -0.322568416595459, -1.0035717487335205, -1.4433799982070923, -0.46606916189193726, -1.5885334014892578, -0.4066213369369507, -1.7479747533798218, 0.5933836102485657, -0.7055968642234802, -0.36549699306488037, -0.9788134098052979, -1.9131453037261963, 0.30054569244384766, -0.580919623374939, 0.5837177038192749, -0.48034030199050903, 0.9274427890777588, -1.0487005710601807, -1.6313393115997314, -0.5303826928138733, 1.2646498680114746, 0.8939976692199707, -1.5261670351028442, 0.9316509962081909, -1.1498185396194458, -0.9300442337989807, -0.5415314435958862, 0.6255404353141785, 0.8849181532859802, -1.4148669242858887, 1.3076621294021606, -0.5637432932853699, 0.0816916823387146, 1.061697244644165, -1.0887970924377441, 0.2674325406551361, 0.9230037331581116, 2.409494161605835, -1.1902737617492676, -1.2124439477920532, 0.05783061310648918, 2.050595283508301, -2.493255615234375, 0.09304950386285782, 2.289752244949341, 0.10351451486349106, -1.3196450471878052, -0.7247143983840942, -0.8818626999855042, 0.7327703833580017, 2.1252806186676025, 0.23544928431510925, -0.15455664694309235, -0.2087099403142929, 2.1353793144226074, -1.5308712720870972, -0.12346690893173218, 0.19793181121349335, 2.0828843116760254, 2.0951950550079346, 0.12041617184877396, 1.8082528114318848, 1.9646354913711548, 2.275292158126831, -0.1392291933298111, -2.2260541915893555, 2.081522226333618, 1.7007235288619995, -1.0321216583251953, -0.8568857908248901, 1.6893202066421509, 1.5609041452407837, -0.6910675168037415, -1.1273759603500366, -1.42947256565094, -1.019364833831787, -0.9177102446556091, -0.7520319223403931, -2.1498491764068604, 2.345991849899292, 1.9873310327529907, 1.1603379249572754, 1.4920427799224854, -1.0881948471069336, 2.2958076000213623, -0.7387859225273132, 1.1341447830200195, 2.363813638687134, -1.123544454574585, -0.7964356541633606, -2.5824968814849854, 0.35101354122161865, -1.7943609952926636, 0.5214948654174805, -0.22722093760967255, 1.8545031547546387, 0.09751372039318085, -2.3049259185791016, -1.057279109954834, 1.7041990756988525, -1.3972219228744507, -0.12437555193901062, 2.023237705230713, -0.5016000866889954, 1.5028201341629028, 0.7860248684883118, 0.08805283904075623, 1.1427501440048218, 1.537407636642456, -1.3759897947311401, 0.6667345762252808, 1.002405047416687, -0.8189127445220947, 2.3646273612976074, 1.1344858407974243, 2.2650036811828613, 0.21700212359428406, 1.2277650833129883, -0.34352782368659973, -0.7487662434577942, 1.4150937795639038, -0.7974691987037659, 1.1409293413162231, 1.439507007598877, -2.4311177730560303, 1.5372788906097412, -0.3936161696910858, -0.8125416040420532, 0.06235780939459801, -0.47471654415130615, 1.380237102508545, 0.1308087855577469, -0.7332475185394287, -0.1491539031267166, -1.579024076461792, -0.4927043318748474, 0.701443612575531, 2.0171499252319336, 0.14928342401981354, 1.6913713216781616, -0.4257930815219879, -0.9369926452636719, -0.10799816995859146, 0.014965337701141834, -0.7803740501403809, 1.4394783973693848, -0.770401656627655, 0.7512782216072083, 0.13573448359966278, 1.7969863414764404, -0.801327645778656, -0.7577460408210754, 2.0752406120300293, -0.7503024935722351, -0.7692132592201233, 2.226536512374878, -1.5291311740875244, 1.2349398136138916, 0.7019155025482178, -0.5878651142120361, 1.5391401052474976, -0.2930464744567871, 2.6137845516204834, -0.09830381721258163, 2.099247455596924, -0.6041597723960876, 1.9914567470550537, -2.0281481742858887, -1.1533883810043335, -1.3728224039077759, 1.1181437969207764, 1.1869444847106934, -1.104981780052185, -0.03658689558506012, 0.7936906218528748, 1.0163941383361816, -1.7175875902175903, -0.5061568021774292, -1.1273183822631836, 0.18791712820529938, 2.018126964569092, -0.8907609581947327, -0.3724563717842102, 0.6599013805389404, -1.167085886001587, -1.4105966091156006, 1.0952656269073486, -1.3659358024597168, -0.9337720274925232, -1.4638482332229614, -1.1724250316619873, 0.9491974711418152, 2.344435453414917, 0.14466460049152374, 2.190739870071411, -1.0980908870697021, -1.3362003564834595, -1.1699659824371338, 1.0708123445510864, 1.9514394998550415, 0.18198160827159882, -1.3281962871551514, 1.9910825490951538, 2.2072267532348633, 1.3781601190567017, 0.03567104786634445, -1.1898893117904663, -0.5504109263420105, 0.5203706622123718, -0.7204223275184631, -1.5051963329315186, 1.419959306716919, 0.757583498954773, 0.3006206750869751, -1.9946461915969849, 1.708863377571106, 2.0167765617370605, -1.725037932395935, -0.6936426162719727, -1.75966215133667, 1.9440916776657104, -0.4820176661014557, -1.1020092964172363, -0.5477899312973022, -0.5655293464660645, -0.5287119150161743, 1.3242403268814087, -1.195774793624878, -0.6048367023468018, 2.269066572189331, -0.5190086364746094, -0.863830029964447, 1.8595951795578003, 0.47746071219444275, 1.249834656715393, 0.38156944513320923, 1.2011314630508423, 0.2862367630004883, -0.2510833144187927, -0.5737804174423218, 0.08235979080200195, -0.7645757794380188, -1.1233587265014648, 1.455090045928955, -0.7670894265174866, -1.7746835947036743, -0.6442432999610901, 0.10841275751590729, 0.30553075671195984, -1.6089855432510376, 1.9162819385528564, 0.2696177065372467, -1.251460075378418, 1.5774364471435547, -0.708197295665741, 0.6796929240226746, -0.5416358113288879, 2.1663548946380615, -0.13107411563396454, -0.28104597330093384, 1.1700184345245361, 0.4512767493724823, 1.12649405002594, 0.39499276876449585, 0.8388289213180542, 1.979960560798645, -2.532503604888916, 0.27693626284599304, -0.2687366008758545, -0.6374666690826416, 0.2082107812166214, -1.4646034240722656, 0.29704827070236206, 2.029092788696289, 0.15433797240257263, 2.3362345695495605, -0.14719440042972565, -0.8245545625686646, -0.26252618432044983, 2.068181037902832, -1.6626907587051392, -1.4621318578720093, -0.5823869109153748, 0.5266607403755188, 1.631538987159729, -0.3407113552093506, 2.592348575592041, 0.6718863248825073, -0.8609330654144287, 2.3080148696899414, -0.27259594202041626, -1.860772967338562, 1.7146649360656738, 1.1764614582061768, -0.3497828245162964, -1.4712209701538086, -0.611441433429718, -0.9094711542129517, -0.784648060798645, -1.1679484844207764, -1.8029673099517822, 1.7278741598129272, 0.3649280071258545, 2.1314709186553955, -1.1276580095291138, 1.9279885292053223, 0.04873111844062805, 2.1049344539642334, -1.8156909942626953, -0.48492738604545593, 1.2464302778244019, -0.5225515961647034, -0.20204393565654755, -0.01647914946079254, -0.8069272637367249, -1.1526767015457153, 0.8618646860122681, 1.8278898000717163, 1.8081059455871582, -0.21315082907676697, 1.1118947267532349, 0.43606483936309814, -1.3978692293167114, 1.2609529495239258, -0.9957290291786194, 2.2968740463256836, -0.9188060760498047, 2.2163729667663574, -0.07878211885690689, -1.7756946086883545, 0.17174850404262543, 0.9898690581321716, 1.4981679916381836, -0.42216789722442627, -2.2533681392669678, 0.8344668745994568, 1.6320815086364746, -0.1880803406238556, -2.2743215560913086, -0.3638405501842499, -0.8512594699859619, -0.9991040229797363, -1.7447528839111328, 1.529639720916748, -2.3524158000946045, -0.8726266026496887, 2.411726236343384, -0.9497160315513611, -1.2361100912094116, 1.2185983657836914, 0.9166490435600281, -0.7234255075454712, -1.2754194736480713, 0.6846434473991394, 2.1502416133880615, -1.502551794052124, -0.4767816364765167, -0.046367231756448746, -0.8023812770843506, 0.5353302955627441, -0.8199443221092224, -0.7460463643074036, -1.2877639532089233, 0.16601870954036713, -0.96486896276474, -0.2081219106912613, -1.130599856376648, 0.3798799216747284, -0.8957574367523193, 0.44306454062461853, -0.6101903319358826, 0.7400016784667969, -0.5092595815658569, -0.1368480920791626, 0.6231911182403564, -1.4095603227615356, 0.19340546429157257, 0.3992862403392792, -0.5749459266662598, 0.4199807941913605, 0.924212634563446, 1.0863182544708252, -0.7071619629859924, -1.3372918367385864, -0.5583487749099731, -1.0425747632980347, 0.32675981521606445, -1.4578510522842407, 1.70107102394104, -0.39457282423973083, -0.8129695057868958, 0.06655704975128174, 0.2100987583398819, -1.9519193172454834, 1.4190056324005127, 0.7333219051361084, -1.4021100997924805, -0.8504471182823181, -0.9586123824119568, 2.222153425216675, 0.767342209815979, -0.30064451694488525, 2.243607997894287, 0.05539252236485481, -0.14015215635299683, -0.6912723183631897, -0.9761686325073242, 0.20127293467521667, -1.2136926651000977, -0.9489092230796814, 0.9601854681968689, -1.804999589920044, -1.6366292238235474, -0.6304457783699036, -0.8766614198684692, -1.3854085206985474, -0.5877419710159302, 2.3124046325683594, 2.353017807006836, 1.4643272161483765, -0.2964165508747101, -0.32890987396240234, -1.2175688743591309, 0.1895873248577118, 1.763338327407837, -0.6804661154747009, -0.12039298564195633, -0.3396017253398895, 0.9457725882530212, 1.5773547887802124, -0.5292555093765259, -0.9646711349487305, 0.8702623844146729, 0.6286221146583557, -0.8148604035377502, -1.1313660144805908, -0.158647820353508, 0.6601232886314392, 0.8904243111610413, 0.9198009967803955, -0.5139775276184082, 0.06409311294555664, -0.5197349190711975, 0.24365234375, 0.003968818578869104, 0.49002131819725037, 0.33230534195899963, -0.14422236382961273, -1.3088371753692627, -0.8541275858879089, -0.8384525775909424, 0.13478326797485352, -0.021251307800412178, 0.3425924479961395, 1.3283990621566772, 0.374468058347702, -1.2256476879119873, -0.5457096099853516, 1.7631139755249023, -1.278130054473877, 0.7731764912605286, 0.769916296005249, 1.4252068996429443, -1.5939418077468872, -1.4216629266738892, 0.27580970525741577, 1.6533453464508057, 1.8816349506378174, 2.163809061050415, -0.3169890344142914, -1.6011897325515747, -0.8559792637825012, -1.1259480714797974, -0.9828647375106812, -1.5975310802459717, -0.6896865367889404, -1.3393667936325073, -1.586284875869751, 0.07354830205440521, -1.1948316097259521, 2.0897538661956787, 0.5946588516235352, -0.24710382521152496, 1.7135008573532104, -0.9173942804336548, -1.7985291481018066, -1.2366596460342407, -0.13600631058216095, 1.2524094581604004, -0.6579712629318237, -1.4243050813674927, 0.4575045704841614, 0.7806903123855591, 0.058162711560726166, 0.7136971354484558, -0.45195186138153076, 1.5651957988739014, 0.5740364193916321, 1.4547309875488281, -0.03842825070023537, 0.48295116424560547, 0.5141916275024414, 0.07612335681915283, 1.9675402641296387, -1.3766369819641113, -0.012730621732771397, -0.09024321287870407, -0.3229994773864746, -0.49022728204727173, 0.14297999441623688, -0.7306923866271973, 1.9053471088409424, 2.402306318283081, -1.4606248140335083, -1.3365813493728638, -0.38167452812194824, -1.1406428813934326, -0.0474129393696785, -0.299155592918396, -1.7367161512374878, 0.01570979692041874, -1.0176349878311157, -2.060662031173706, 1.9078795909881592, -0.4300658702850342, 0.6331087946891785, 2.126474142074585, 0.5140619277954102, -0.34134650230407715, -0.9751505255699158, -0.7545760273933411, 1.9366644620895386, -1.0993620157241821, -0.3516220450401306, 2.068563222885132, 0.3299197256565094, -0.18677589297294617, 0.1912284791469574, 0.5448580384254456, -0.14689777791500092, 0.15266475081443787, 0.4814242720603943, -0.3750724494457245, -0.07714314758777618, 1.2200977802276611, 0.9383131265640259, 1.0781716108322144, -0.3243531584739685, 0.8451367616653442, -1.218105673789978, 1.093115210533142, 1.6492745876312256, 0.3664810061454773, 2.2625315189361572, 1.6616907119750977, -0.4771907329559326, -1.3338125944137573, 0.4176942706108093, 0.5234125256538391, 1.315087914466858, 0.3319239616394043, -0.17831872403621674, -1.0623639822006226, -0.5066378712654114, -0.24290406703948975, 2.1897199153900146, 0.6833935379981995, 1.491180658340454, -0.31482964754104614, -1.0635522603988647, 0.536284327507019, 2.3437108993530273, 0.3055874705314636, -1.2197833061218262, -0.9291061758995056, 1.8398133516311646, -1.8126193284988403, -1.2501250505447388, 2.2835869789123535, 0.268810510635376, -0.22155435383319855, 1.2934596538543701, 0.10184644907712936, 1.7019392251968384, 0.9235804677009583, -0.9780705571174622, -0.5017655491828918, -0.3622913360595703, -0.27488887310028076, -1.3142515420913696, 0.921153724193573, 0.013648834079504013, 0.8520633578300476, -0.6362768411636353, -1.011879563331604, 1.97359037399292, 0.2649250626564026, 0.6863009333610535, -0.03099399246275425, 1.7042714357376099, -1.88033926486969, 2.064804792404175, 0.2055998295545578, 0.6412587761878967, -1.0021390914916992, -1.5211873054504395, -2.0326757431030273, -0.6695630550384521, 2.0347766876220703, 2.2265408039093018, 1.5685440301895142, 0.9257397651672363, -0.6772080063819885, -1.5146960020065308, -0.5683983564376831, 1.8550410270690918, 0.010073076002299786, -0.15174177289009094, 1.645889163017273, -1.2747318744659424, -1.9601773023605347, 0.4836532175540924, 0.02168526127934456, -0.588864803314209, -0.03819219768047333, -1.0361919403076172, -0.2649862766265869, 1.1925091743469238, -2.073035478591919, -0.562663733959198, -1.4692760705947876, -0.7101300954818726, 2.2316091060638428, -1.7073780298233032, -0.010821624659001827, 0.8263437151908875, 1.9027684926986694, -0.36650457978248596, -1.4867912530899048, 0.27863991260528564, 0.7180823683738708, -0.14468203485012054, 1.4094303846359253, -0.23500283062458038, -0.6968647241592407, 0.1826370805501938, -1.0650919675827026, -0.3133372366428375, -1.177117109298706, 0.4488379955291748, -0.7214616537094116, 1.5822463035583496, -0.3853283226490021, -0.7869358062744141, 1.320330262184143, 1.5749653577804565, 1.937389612197876, 2.191025972366333, -0.9838501214981079, 1.2192515134811401, -0.8428680896759033, 0.4648296535015106, -0.35055068135261536, 1.6797078847885132, -1.303524136543274, -0.11803596466779709, -1.4608402252197266, -1.4568352699279785, -0.37242457270622253, 1.853471279144287, 0.10582996159791946, 2.1811745166778564, 0.6881304383277893, -0.43547627329826355, -0.6743918061256409, -0.09581320732831955, 1.125407338142395, 2.1297707557678223, 0.1225418969988823, 0.055948443710803986, 0.7031928896903992, 0.08391746133565903, -1.6967896223068237, 2.3841068744659424, -0.3374727666378021, 0.734772264957428, 2.1590263843536377, -0.018941665068268776, 0.32111623883247375, -2.2230124473571777, -1.9308271408081055, -0.6313621401786804, 0.21012276411056519, -0.43885794281959534, 2.327538251876831, 1.240857481956482, 1.9635509252548218, -1.3874926567077637, 2.310945749282837, 0.6964162588119507, -1.1520824432373047, -0.13381372392177582, -0.7784262895584106, -1.1382479667663574, -1.5743436813354492, 1.07712721824646, 0.7951704263687134, 1.251278281211853, 0.5954515933990479, -0.9444500803947449, -0.7701579928398132, 1.5025845766067505, -0.20405830442905426, 1.5839259624481201, -0.4995187222957611, 2.2572453022003174, 1.1502705812454224, -0.9842239022254944, -0.9473145604133606, 1.1593692302703857, -0.6897276043891907, -0.347141832113266, -1.2770670652389526, 2.390544891357422, 0.5803624987602234, -0.3728443384170532, 2.282386541366577, 0.340663343667984, 1.1012452840805054, -1.3811131715774536, -1.3575619459152222, -0.11132080107927322, 1.108894944190979, -1.3901937007904053, -1.6697288751602173, 1.685951828956604, 2.121134042739868, -1.4639755487442017, 0.09397975355386734, -0.8574520349502563, 1.5759613513946533, -0.1439734697341919, -2.673733711242676, 0.4340918958187103, 1.0234246253967285, 0.002424519741907716, -1.2661142349243164, -0.78513503074646, 2.304018259048462, -1.124175786972046, 0.7253589034080505, 1.9835655689239502, 0.36719202995300293, -0.7599018812179565, 0.9903659224510193, -0.8414178490638733, 1.2032030820846558, 0.5707628726959229, 0.5351496934890747, -1.308823823928833, 0.5913764834403992, -0.2029864639043808, 1.3212881088256836, 0.19698430597782135, -1.5001804828643799, -1.6163572072982788, -0.8448494076728821, 1.2801177501678467, -1.1467386484146118, -0.7489997148513794, 0.7975230813026428, -1.2092268466949463, 0.6603445410728455, -0.8926641345024109, -0.6685956716537476, 1.9037672281265259, -0.3456783890724182, -1.2695554494857788, 0.4998372793197632, 2.0479509830474854, 1.110522985458374, -0.23929761350154877, 0.7039348483085632, 1.5908149480819702, -1.3282698392868042, 0.6004431843757629, 1.4229490756988525, -1.3852263689041138, 1.0146085023880005, 0.6135626435279846, 1.277374029159546, -0.12423642724752426, 0.20974816381931305, 2.198345899581909, 0.1183561161160469, 0.18662191927433014, 0.7059800028800964, -0.8924757838249207, 0.5211669206619263, 0.19408753514289856, 1.008811354637146, -0.3296002149581909, -1.3607395887374878, -1.4198895692825317, 0.5521072745323181, -0.8409280776977539, -0.6799591779708862, 0.07973107695579529, 0.03339938819408417, -0.6400073170661926, 0.32091623544692993, 0.16592073440551758, -1.2610224485397339, 0.986865758895874, 0.6245823502540588, -0.7903746962547302, -0.44533771276474, -1.37198805809021, 0.149821475148201, 1.216338872909546, -0.82817542552948, -0.24949316680431366, -0.5969055891036987, 1.2945936918258667, -0.3873797059059143, 1.3003277778625488, 2.2501919269561768, 0.2609773576259613, -0.10940680652856827, -0.984027087688446, 0.24341744184494019, -0.630321204662323, -2.014512538909912, -0.696861207485199, -0.5337031483650208, 0.5227044224739075, 0.6671838760375977, -0.36753934621810913, -1.3161964416503906, 1.8276447057724, 0.23647689819335938, 0.850396454334259, -0.4982891380786896, 2.07768177986145, 0.6709237694740295, -1.160719871520996, -0.7284975647926331, 0.37091895937919617, 0.4130339026451111, 0.35987308621406555, 1.8505641222000122, -0.6849043965339661, 0.1906239092350006, 2.1367785930633545, 0.3327116072177887, -1.0145331621170044, 1.3098013401031494, -1.0795596837997437, -1.4075775146484375, -1.0124506950378418, 0.8283559083938599, 0.3144735097885132, -1.538948655128479, -0.7799041271209717, 1.7650082111358643, -0.5173869729042053, 1.0016475915908813, 0.09652472287416458, -0.954829752445221, 0.6088814735412598, 2.040572166442871, -0.9376884698867798, -1.326100468635559, 1.1709785461425781, -1.061915636062622, 1.381358027458191, 0.8294287323951721, 2.1294474601745605, 2.2099781036376953, 1.1686495542526245, 1.4065123796463013, 1.56352698802948, 1.799095869064331, -1.5621944665908813, 0.11868500709533691, 2.1047921180725098, 2.1075360774993896, 1.761784553527832, -1.9144178628921509, -1.3329004049301147, 1.1214441061019897, -0.073236383497715, 1.9037871360778809, 1.8276618719100952, -0.5693860054016113, -1.3495591878890991, 0.3132518231868744, -1.6415741443634033, -1.1456488370895386, -1.083789348602295, 2.042100429534912, 0.11065087467432022, -2.616909980773926, -0.48682230710983276, -0.47731614112854004, 2.051342725753784, -1.1387845277786255, -1.7950376272201538, 0.43801698088645935, 0.07737202197313309, -2.5007073879241943, -1.950446605682373, 0.8509281277656555, -1.5817662477493286, -1.726812481880188, 1.1616127490997314, -1.6606605052947998, -0.046924807131290436, 0.6458770632743835, -0.8006429076194763, -0.5650795698165894, 1.6015602350234985, -0.16849608719348907, -1.2833199501037598, 0.2982356548309326, -1.0955411195755005, 1.5294922590255737, 1.0141838788986206, -0.49725669622421265, 0.4633176922798157, -0.48427465558052063, -1.9256244897842407, 0.4726720154285431, 2.150571823120117, -0.2111983448266983, 1.1355847120285034, 0.48233312368392944, 0.06784083694219589, -0.8114598393440247, -0.2674978971481323, 1.0863243341445923, -0.2070121318101883, 0.8633905053138733, -0.5502755045890808, -0.1895720213651657, 1.7503058910369873, -1.2223867177963257, -0.04138224571943283, -1.346166968345642, -0.19103692471981049, 0.18119090795516968, 0.7185288667678833, 0.7446675896644592, -1.368987798690796, -0.31922757625579834, -0.0405111238360405, 0.8019731044769287, -0.5741881728172302, 1.6526869535446167, 0.3190997540950775, -2.1763148307800293, -0.6168052554130554, -0.7299207448959351, -0.37252089381217957, -0.44071274995803833, 0.9287104606628418, 1.414351463317871, -2.102398633956909, -0.35571691393852234, 0.11363811790943146, -0.21363380551338196, 1.324841022491455, -0.099101722240448, 0.46096137166023254, 0.4542127251625061, -0.28879401087760925, 0.8244690895080566, -0.2232983112335205, 0.4521830081939697, -1.7195829153060913, 1.802304744720459, -0.5654624104499817, 1.2126641273498535, -0.6461716294288635, 1.8041741847991943, 2.0208194255828857, 1.7082982063293457, -1.137062668800354, -2.066506862640381, 0.33825182914733887, -0.9038017988204956, -0.5624262094497681, 2.087660312652588, 0.5134724974632263, -0.48098224401474, -0.8314679861068726, 2.0428881645202637, -1.3109220266342163, 0.90787672996521, -0.16538465023040771, 1.2029067277908325, 0.03376864641904831, -1.056895136833191, 2.350306749343872, -0.5289779901504517, 1.634071707725525, -1.2398624420166016, -0.6551117897033691, 2.2920453548431396, -0.4161684215068817, -1.6795698404312134, -0.3177209794521332, 0.09922090172767639, 1.328808069229126, 1.1679059267044067, 0.04685314744710922, -0.41991809010505676, -1.191510558128357, 0.08423199504613876, 1.482576847076416, 1.1816844940185547, -0.011138852685689926, 0.195098415017128, 2.2769017219543457, 0.048008449375629425, -0.55301833152771, -0.5597268342971802, -1.521165132522583, 0.0686393454670906, 1.5336506366729736, -2.635664701461792, -1.391372799873352, 1.3800721168518066, -0.8135781288146973, -1.608899712562561, -0.5340137481689453, -1.7404696941375732, -0.9698600172996521, -1.5650863647460938, 2.3604512214660645, 0.9267682433128357, 0.26127341389656067, -1.8355891704559326, 0.3389602601528168, 0.01945238746702671, 1.8458362817764282, -0.06305232644081116, -0.016502894461154938, 0.14334146678447723, -0.6044058799743652, 0.08552790433168411, 0.8444589376449585, -2.6293046474456787, -1.4669735431671143, 2.199023485183716, -0.7862783670425415, 0.7861136198043823, -1.1581087112426758, -1.3943918943405151, -2.1344542503356934, 0.48234060406684875, -1.455845832824707, -0.2138596922159195, -0.5639976263046265, -2.1301801204681396, 2.0298964977264404, -0.22048978507518768, 2.0662357807159424, 0.10502507537603378, -1.2845412492752075, 2.234340190887451, 0.002149739535525441, 0.37678974866867065, -0.4196971356868744, 2.0326147079467773, -0.7070649862289429, -0.037063032388687134, -1.0356254577636719, 0.6762533783912659, -0.6553733944892883, 1.6912697553634644, 0.3081398904323578, -0.8584409952163696, -0.5702335238456726, -1.5866079330444336, 1.502447247505188, -1.0289009809494019, 1.5240697860717773, 1.0350433588027954, -1.6156977415084839, 0.36043962836265564, 0.34037381410598755, 0.1390731930732727, -0.7641996741294861, -1.320327639579773, -0.15665777027606964, -0.06039879471063614, -0.9162766337394714, 2.2463371753692627, -1.5101162195205688, -1.4198378324508667, -0.25201621651649475, 2.3585007190704346, 0.9342872500419617, -0.2679886519908905, -0.12346938252449036, 1.811844825744629, -0.23849523067474365, 0.5689970850944519, -1.0324798822402954, 1.239446759223938, 1.1967557668685913, -0.7308064699172974, -1.0370235443115234, 0.454283207654953, -0.39916515350341797, 1.2182884216308594, 2.199054718017578, -0.7236002683639526, -1.2842097282409668, -0.42904797196388245, 0.3499598503112793, -1.0647833347320557, 1.7612686157226562, 0.7653924822807312, -0.8953737020492554, -0.2775033414363861, -0.25468748807907104, -1.63034987449646, -1.4929906129837036, -0.009981514886021614, -0.8846583962440491, -0.16034966707229614, -0.08407939225435257, -0.2793087661266327, 0.3663312792778015, -1.0719668865203857, -1.0558680295944214, 1.8187602758407593, 1.8034954071044922, -1.1037832498550415, -2.0990660190582275, 0.24904823303222656, 0.06740936636924744, -0.5533081293106079, 1.6180044412612915], "disc": [0.7197628021240234, 1.2272562980651855, 1.1416518688201904, 1.0902692079544067, 1.5975062847137451, 1.5128965377807617, 1.4468895196914673, 0.7416270971298218, 0.6793668866157532, 1.5517674684524536, 1.5244759321212769, 1.3453477621078491, 1.4484103918075562, 1.3657207489013672, 1.0957698822021484, 1.500828742980957, 1.4993892908096313, 1.3395901918411255, 1.007988691329956, 1.6024143695831299, 0.7492361068725586, 1.310597538948059, 1.0345520973205566, 1.1452934741973877, 1.28611159324646, 1.5340830087661743, 1.4617987871170044, 1.6662122011184692, 1.724371075630188, 1.2043687105178833, 1.883668065071106, 1.2942949533462524, 0.9970366358757019, 1.32607901096344, 0.4990442991256714, 1.8226912021636963, 0.6993163228034973, 1.3700034618377686, 0.8429427742958069, 1.3700016736984253, 1.2301931381225586, 1.3759922981262207, 1.2734384536743164, 1.4388483762741089, 1.1771769523620605, 0.7833925485610962, 1.3150140047073364, 0.8677912354469299, 1.4869663715362549, 1.2449991703033447, 1.8129431009292603, 0.9246227741241455, 1.1388942003250122, 0.5838028192520142, 0.9630001187324524, 0.9521998763084412, 1.3297892808914185, 0.3747795522212982, 1.5564110279083252, 1.4695665836334229, 1.2619163990020752, 1.235390305519104, 1.3660966157913208, 1.3347643613815308, 1.1826329231262207, 1.6112881898880005, 1.4075992107391357, 1.356128215789795, 1.0831260681152344, 1.2088006734848022, 1.0401456356048584, 1.7070655822753906, 1.2409871816635132, 1.3494794368743896, 0.9264318346977234, 0.9270211458206177, 1.1563173532485962, 1.3114229440689087, 1.0267771482467651, 1.4792442321777344, 1.8152084350585938, 1.3675874471664429, 1.4761009216308594, 1.3109898567199707, 1.1821504831314087, 1.1155123710632324, 1.6965105533599854, 0.880021870136261, 0.4389841556549072, 1.2128081321716309, 1.1279863119125366, 1.2516896724700928, 1.065686583518982, 1.4147766828536987, 1.452174425125122, 1.0395241975784302, 0.9668415784835815, 1.0950535535812378, 0.9652636647224426, 1.1545233726501465, 1.3104417324066162, 1.8140515089035034, 1.1728729009628296, 1.2670602798461914, 1.4928034543991089, 1.651258111000061, 1.6661945581436157, 1.1977558135986328, 1.3354649543762207, 1.6619746685028076, 1.1815913915634155, 1.2767693996429443, 1.436531901359558, 1.3616441488265991, 1.2845326662063599, 0.9659994840621948, 1.3606303930282593, 1.6407557725906372, 0.9945096969604492, 1.127882957458496, 0.7835836410522461, 1.1577359437942505, 1.66654634475708, 1.197107195854187, 1.5430660247802734, 1.143553376197815, 1.5564955472946167, 1.3144696950912476, 1.4924710988998413, 1.1459523439407349, 1.4644169807434082, 1.7732617855072021, 0.9610549211502075, 1.2927143573760986, 0.7596976161003113, 1.9484776258468628, 1.2382205724716187, 1.4655293226242065, 1.1987777948379517, 1.338708758354187, 1.691677451133728, 1.53556489944458, 1.4024537801742554, 1.4850670099258423, 1.1543607711791992, 1.9109963178634644, 0.9935517907142639, 0.9913710951805115, 0.8791693449020386, 1.6890352964401245, 0.9829884171485901, 1.4365947246551514, 1.0498499870300293, 1.14267897605896, 1.1224429607391357, 1.2017436027526855, 1.388786792755127, 1.152069330215454, 0.6034206748008728, 1.1980904340744019, 1.4281975030899048, 1.53962242603302, 1.6143555641174316, 1.027292251586914, 1.2464476823806763, 1.4228649139404297, 0.9160686135292053, 0.9341113567352295, 1.51227605342865, 1.319290280342102, 1.2464512586593628, 1.1272672414779663, 0.7958735823631287, 1.793397307395935, 0.859994113445282, 1.2827651500701904, 1.0527931451797485, 1.3824737071990967, 1.3388879299163818, 1.566136360168457, 0.7550963759422302, 0.9562585353851318, 1.6460113525390625, 1.2389312982559204, 1.3449702262878418, 1.6051980257034302, 1.3246747255325317, 1.332100510597229, 1.01347815990448, 1.7459951639175415, 0.8982893228530884, 1.7080280780792236, 1.7462066411972046, 1.408539891242981, 0.9843576550483704, 1.3662315607070923, 1.1221896409988403, 1.7602927684783936, 1.2273231744766235, 1.2265995740890503, 1.3391894102096558, 0.7684996128082275, 1.124551773071289, 1.3018755912780762, 1.2888940572738647, 0.8096404075622559, 1.6134674549102783, 1.3925613164901733, 1.401829481124878, 0.5986143946647644, 1.1646069288253784, 1.426391363143921, 1.0798757076263428, 1.568952202796936, 1.4177806377410889, 1.6191755533218384, 1.2473478317260742, 1.130879521369934, 1.3054372072219849, 0.9444239139556885, 1.8615639209747314, 1.0411189794540405, 0.9157315492630005, 1.626593828201294, 1.4688668251037598, 1.2161126136779785, 1.0088716745376587, 1.2879208326339722, 1.197479248046875, 1.868196725845337, 1.198845386505127, 1.077105164527893, 1.4878252744674683, 1.2626579999923706, 1.0443742275238037, 0.9869633316993713, 1.0637115240097046, 1.5947048664093018, 1.1887104511260986, 1.6644973754882812, 1.6348191499710083, 0.6874008178710938, 1.2484184503555298, 1.167132019996643, 1.6052271127700806, 0.9653909206390381, 0.9341028332710266, 1.8002636432647705, 1.4503902196884155, 1.255013108253479, 1.2520524263381958, 1.843241810798645, 1.2703895568847656, 0.83589768409729, 0.8272435069084167, 1.1831634044647217, 1.1668962240219116, 1.3118387460708618, 1.4974321126937866, 1.4718974828720093, 1.6768211126327515, 0.945813000202179, 1.3007006645202637, 1.4194316864013672, 1.278448462486267, 1.2140051126480103, 1.6465513706207275, 0.45797500014305115, 0.6881622672080994, 1.8376264572143555, 1.1855738162994385, 1.0227597951889038, 1.6010491847991943, 1.2255769968032837, 1.0979419946670532, 1.6508339643478394, 0.9602052569389343, 0.7004822492599487, 1.7173649072647095, 1.2993882894515991, 0.9310210943222046, 1.8576953411102295, 0.9972995519638062, 1.3965204954147339, 1.3356860876083374, 1.068729281425476, 1.8378400802612305, 1.1750731468200684, 1.4842642545700073, 1.1560841798782349, 0.562950611114502, 1.1409329175949097, 1.381989598274231, 1.0721293687820435, 1.433129906654358, 0.9479377269744873, 1.5195276737213135, 1.342458963394165, 1.726199984550476, 1.098694920539856, 1.252943754196167, 1.3829975128173828, 1.1819154024124146, 0.8333621621131897, 1.2627536058425903, 0.8242684602737427, 1.2729557752609253, 0.9039324522018433, 1.4031440019607544, 1.476546049118042, 1.4838043451309204, 1.1702847480773926, 0.9612872004508972, 0.9976940155029297, 0.8194192051887512, 1.591735601425171, 1.036778450012207, 0.8256083726882935, 1.0105725526809692, 1.3524106740951538, 0.8083828091621399, 1.5339295864105225, 1.1591731309890747, 0.6129770278930664, 0.9051397442817688, 1.4484251737594604, 1.120377779006958, 1.1797248125076294, 1.655853509902954, 1.5717413425445557, 1.7052973508834839, 1.1747828722000122, 1.5206102132797241, 1.3003178834915161, 1.107265830039978, 1.0195894241333008, 1.2754440307617188, 0.9295968413352966, 1.3565477132797241, 1.1841843128204346, 1.4619569778442383, 1.416430115699768, 1.2005611658096313, 1.4366132020950317, 1.3272814750671387, 1.212205410003662, 0.9180682897567749, 0.8575568199157715, 1.0901319980621338, 1.6752346754074097, 1.6704317331314087, 0.6309999227523804, 1.7442594766616821, 1.438796877861023, 1.2289586067199707, 1.1230915784835815, 1.4157899618148804, 1.3834080696105957, 1.3447980880737305, 1.2932369709014893, 0.7992798089981079, 1.200315237045288, 1.1659595966339111, 1.4453505277633667, 0.8630411028862, 1.048111915588379, 1.0218135118484497, 0.8258800506591797, 0.8945122361183167, 1.2409892082214355, 1.520063042640686, 1.1592384576797485, 0.7909577488899231, 1.1698368787765503, 1.3208826780319214, 1.3915497064590454, 1.1894400119781494, 1.740309476852417, 0.7941081523895264, 1.7314828634262085, 0.8799203634262085, 0.9397882223129272, 1.6653541326522827, 1.6890103816986084, 0.8480702042579651, 1.477266550064087, 1.0185455083847046, 1.2719471454620361, 1.1565378904342651, 1.4828320741653442, 1.3618510961532593, 1.290696382522583, 0.9653182029724121, 1.295996069908142, 0.5302844047546387, 1.1298984289169312, 0.8452485203742981, 0.8807060718536377, 1.0869807004928589, 0.8635239601135254, 1.3210941553115845, 1.2593591213226318, 1.1266686916351318, 1.0582095384597778, 1.3876837491989136, 1.307408332824707, 0.8194904327392578, 1.4001274108886719, 1.465417742729187, 1.3581531047821045, 1.5397595167160034, 1.2909234762191772, 1.631515622138977, 0.9188383221626282, 1.1285321712493896, 0.8290629982948303, 0.9936230182647705, 1.4756553173065186, 1.4718807935714722, 0.8473291397094727, 0.7310503721237183, 0.9944233298301697, 0.5302554368972778, 1.0393486022949219, 1.2847697734832764, 1.5046223402023315, 1.293525218963623, 1.3720158338546753, 1.2748452425003052, 0.7572622299194336, 0.6938499808311462, 0.9894199967384338, 1.5486173629760742, 1.0821270942687988, 1.0753251314163208, 1.7425856590270996, 1.593851089477539, 1.5166003704071045, 1.4439350366592407, 1.2962132692337036, 1.1109590530395508, 1.2917968034744263, 1.1081174612045288, 1.3955141305923462, 1.1027073860168457, 1.0129222869873047, 1.3342101573944092, 1.3954124450683594, 1.6854664087295532, 1.7236568927764893, 1.3523290157318115, 1.2421120405197144, 1.4171950817108154, 0.8908610343933105, 1.4133594036102295, 1.1970903873443604, 1.4735503196716309, 0.6007905602455139, 1.4925650358200073, 1.405838131904602, 1.3416675329208374, 0.9090819358825684, 0.642678439617157, 1.337319254875183, 1.4743372201919556, 1.022762656211853, 1.4522324800491333, 1.4100524187088013, 1.12998628616333, 1.768814206123352, 1.022253394126892, 0.7919209599494934, 0.7936422824859619, 1.3621407747268677, 1.5210673809051514, 1.0097784996032715, 1.119100570678711, 1.2632828950881958, 0.6749961972236633, 1.1957932710647583, 0.9728655815124512, 1.2080059051513672, 1.697248935699463, 1.4151936769485474, 1.127507209777832, 1.700123906135559, 1.2761249542236328, 0.9347231388092041, 1.6882963180541992, 1.187471628189087, 1.212996244430542, 1.1133302450180054, 1.0206032991409302, 1.7139036655426025, 1.1820168495178223, 0.7360121011734009, 0.9893339276313782, 1.1098065376281738, 1.3837498426437378, 1.7717368602752686, 1.2758406400680542, 1.605826497077942, 1.0198664665222168, 0.6238173842430115, 1.0186703205108643, 1.423473834991455, 1.7955317497253418, 1.1536146402359009, 1.659568190574646, 0.6367232203483582, 0.7804673314094543, 1.191154956817627, 1.2701797485351562, 1.3995050191879272, 1.3179444074630737, 1.4804949760437012, 1.5129599571228027, 0.9081346988677979, 1.509187936782837, 0.7894771695137024, 1.1478677988052368, 1.3311198949813843, 1.688141942024231, 0.9545096755027771, 1.5543406009674072, 1.2249680757522583, 1.5951154232025146, 1.3232444524765015, 1.365098237991333, 0.7918165326118469, 1.3569891452789307, 0.9766833186149597, 1.420143485069275, 0.8116691708564758, 1.4848181009292603, 1.4624886512756348, 1.456176996231079, 1.881766438484192, 1.2535680532455444, 0.9619234204292297, 1.0442358255386353, 0.9901440143585205, 1.4259275197982788, 1.0569660663604736, 1.291783332824707, 1.4347302913665771, 1.7282344102859497, 1.447713851928711, 0.7688827514648438, 1.059332013130188, 1.00114905834198, 1.2316880226135254, 1.816638708114624, 1.2160379886627197, 1.3048988580703735, 1.5913877487182617, 1.2716727256774902, 1.4242509603500366, 1.4840550422668457, 1.6789324283599854, 1.443005084991455, 1.6944479942321777, 1.7421795129776, 1.3634475469589233, 0.9754727482795715, 1.132834792137146, 1.194920539855957, 1.295634150505066, 1.5970063209533691, 1.487412929534912, 1.1110895872116089, 1.324187994003296, 1.0865646600723267, 1.2450958490371704, 1.2971547842025757, 1.5829284191131592, 1.5923014879226685, 1.169873833656311, 1.4201685190200806, 1.334588646888733, 1.325824499130249, 1.0487332344055176, 1.585427165031433, 1.225167155265808, 0.9555396437644958, 1.3149091005325317, 1.8186030387878418, 1.0218099355697632, 0.6938925981521606, 1.0823750495910645, 1.6116069555282593, 0.9957374930381775, 0.776246964931488, 1.1100220680236816, 1.003305435180664, 1.4321619272232056, 1.4910889863967896, 1.2567483186721802, 1.3555755615234375, 1.010754942893982, 1.262523889541626, 0.7625998854637146, 1.3719978332519531, 1.3499858379364014, 1.227882981300354, 1.209685206413269, 0.9820821285247803, 1.5005359649658203, 1.5504733324050903, 1.076306700706482, 1.5763119459152222, 1.6437276601791382, 1.108585238456726, 0.9717326164245605, 0.8068147301673889, 1.2772709131240845, 1.4219599962234497, 1.299235463142395, 1.1030250787734985, 1.8235129117965698, 1.340556263923645, 1.0813775062561035, 1.3154972791671753, 0.9411535263061523, 1.2785701751708984, 1.072348952293396, 0.6612274050712585, 1.2720732688903809, 1.1590900421142578, 1.3872904777526855, 1.7635835409164429, 1.544803261756897, 0.9765190482139587, 1.7461081743240356, 0.9163923263549805, 1.2985414266586304, 1.079210877418518, 1.633935570716858, 1.4374436140060425, 1.300093650817871, 1.3813470602035522, 1.1946598291397095, 1.0572577714920044, 0.9883270859718323, 1.4189757108688354, 1.0468944311141968, 0.9591172337532043, 1.2246720790863037, 1.1280157566070557, 1.07269287109375, 1.5214029550552368, 1.4528007507324219, 1.216023325920105, 0.8728366494178772, 1.0972568988800049, 1.228102207183838, 1.274957537651062, 0.7955008149147034, 0.8482177257537842, 0.7936150431632996, 1.1888784170150757, 1.198564052581787, 1.4993553161621094, 1.0718283653259277, 1.2294058799743652, 1.0220032930374146, 0.9264005422592163, 1.2007708549499512, 1.6185147762298584, 1.5570954084396362, 1.6426317691802979, 0.9041081666946411, 1.768972396850586, 1.0387672185897827, 0.9177579879760742, 1.3532806634902954, 1.1191761493682861, 1.7356823682785034, 1.5084688663482666, 1.432153344154358, 1.2766033411026, 0.7332765460014343, 1.1220412254333496, 1.1379214525222778, 1.832312822341919, 1.517293930053711, 1.466456413269043, 1.5903862714767456, 1.3420318365097046, 1.1187117099761963, 1.2814995050430298, 1.1186004877090454, 1.2137073278427124, 1.5254087448120117, 1.394598126411438, 0.9215301871299744, 1.3771543502807617, 1.024184226989746, 0.6339552998542786, 1.4665430784225464, 0.9048402905464172, 0.9996995329856873, 1.2263705730438232, 1.5164525508880615, 1.363279104232788, 1.1734484434127808, 1.1673160791397095, 1.0354670286178589, 0.9368261694908142, 1.5098680257797241, 1.141711711883545, 1.3679816722869873, 1.3618289232254028, 1.0855072736740112, 1.403960943222046, 1.2598838806152344, 1.4645769596099854, 0.49625512957572937, 1.3238153457641602, 0.7834399938583374, 1.5564860105514526, 1.212111473083496, 1.1415504217147827, 1.3883146047592163, 1.425792932510376, 1.5122708082199097, 1.0910496711730957, 1.020691990852356, 1.3576626777648926, 1.206701636314392, 0.9819353222846985, 1.673892855644226, 1.0325974225997925, 1.8167879581451416, 1.4174668788909912, 1.159218430519104, 1.273390531539917, 0.7880256175994873, 1.5880094766616821, 1.5407466888427734, 1.0993459224700928, 1.194654107093811, 1.6401147842407227, 0.7058462500572205, 1.3579655885696411, 1.3235249519348145, 1.7073278427124023, 1.5993754863739014, 1.6412919759750366, 1.5587260723114014, 0.9650787115097046, 1.2873635292053223, 0.9806151390075684, 1.7532707452774048, 1.152413249015808, 0.9564410448074341, 0.9073564410209656, 1.3736212253570557, 1.1433199644088745, 0.9992569088935852, 1.3781967163085938, 1.03325355052948, 0.6149985790252686, 0.9198459386825562, 0.9510190486907959, 1.512543797492981, 0.9807971119880676, 0.9967347383499146, 1.503621220588684, 1.591196060180664, 1.278228759765625, 1.173365831375122, 1.5099915266036987, 1.298421025276184, 1.0719345808029175, 1.2011682987213135, 1.6842398643493652, 1.027618646621704, 0.724515974521637, 1.343677282333374, 1.171505093574524, 0.9501768946647644, 1.7043060064315796, 1.1713356971740723, 1.5410631895065308, 1.5015218257904053, 0.9913457632064819, 0.6326534152030945, 1.0980967283248901, 1.1753259897232056, 1.1890798807144165, 1.5805567502975464, 1.5278888940811157, 1.220585584640503, 1.4284133911132812, 1.0542484521865845, 0.7659631371498108, 1.1133701801300049, 1.6088217496871948, 0.7604139447212219, 0.5237689018249512, 1.4447517395019531, 1.5006576776504517, 1.1680208444595337, 1.300058126449585, 0.9704398512840271, 1.4610400199890137, 1.041664719581604, 1.8558329343795776, 1.284766674041748, 1.4213470220565796, 0.7804937958717346, 0.8922937512397766, 1.4240621328353882, 1.4902971982955933, 1.123070240020752, 1.121444582939148, 1.3323642015457153, 1.7608612775802612, 0.9172235131263733, 0.8825485110282898, 1.0784142017364502, 1.4141110181808472, 0.9898533821105957, 1.2543630599975586, 1.076256513595581, 1.5120186805725098, 1.179778814315796, 1.1066232919692993, 1.4788320064544678, 0.8632208108901978, 1.4467377662658691, 1.248958945274353, 1.647842288017273, 0.9621709585189819, 1.1302341222763062, 1.6812270879745483, 1.5906708240509033, 1.195191740989685, 0.7871399521827698, 1.3538575172424316, 1.2140097618103027, 1.1821153163909912, 1.769575595855713, 1.8111705780029297, 0.8271895051002502, 1.4875741004943848, 1.027730107307434, 0.814387857913971, 1.4910260438919067, 0.9868977069854736, 1.3600763082504272, 0.6873641014099121, 1.0671733617782593, 1.4946736097335815, 0.945195198059082, 1.1755837202072144, 0.8409640192985535, 1.6280169486999512, 0.605433464050293, 1.8042681217193604, 1.2852883338928223, 1.1845542192459106, 1.430050253868103, 1.794952154159546, 1.2615073919296265, 0.7443099617958069, 1.121819019317627, 1.1116225719451904, 1.0495327711105347, 1.0029240846633911, 1.3583886623382568, 1.3757872581481934, 0.8647271990776062, 1.5818283557891846, 1.6116844415664673, 1.2419657707214355, 1.6304810047149658, 1.034211277961731, 1.455486536026001, 1.5122538805007935, 1.428337574005127, 1.8450851440429688, 1.7876789569854736, 1.4709906578063965, 1.620590090751648, 1.5857045650482178, 1.4853326082229614, 1.2477834224700928, 1.6391077041625977, 1.5310553312301636, 0.5905384421348572, 1.220456600189209, 1.5716919898986816, 1.6470043659210205, 0.6633120179176331, 1.2467862367630005, 1.264549732208252, 1.3982508182525635, 1.289637565612793, 0.7842234969139099, 1.269385576248169, 1.4891098737716675, 1.1576958894729614, 0.8047245144844055, 0.851574182510376, 1.440565586090088, 1.5209012031555176, 1.7325071096420288, 1.5547124147415161, 1.4828133583068848, 1.0355225801467896, 1.3270514011383057, 1.2917789220809937, 0.8949478268623352, 0.9549042582511902, 1.09343683719635, 1.0013868808746338, 1.5426445007324219, 1.8262766599655151, 1.019570231437683, 1.7790240049362183, 0.7705875039100647, 0.7237184047698975, 1.196892499923706, 1.1692538261413574, 1.1367976665496826, 0.8522721529006958, 1.0011026859283447, 0.6696430444717407, 1.0608785152435303, 1.1442705392837524, 0.8437814116477966, 1.4497950077056885, 1.0625462532043457, 1.380305528640747, 0.8635909557342529, 1.6924591064453125, 0.682863712310791, 1.3430445194244385, 1.1688849925994873, 1.2294336557388306, 1.0089194774627686, 1.1217466592788696, 1.5007622241973877, 1.465210199356079, 0.9711599946022034, 1.528551459312439, 1.5154999494552612, 0.989605188369751, 1.0277366638183594, 1.0922911167144775, 1.440703272819519, 1.1012669801712036, 1.1639177799224854, 1.5994062423706055, 1.5293288230895996, 1.4088921546936035, 1.3388502597808838, 0.9217314720153809, 1.5264798402786255, 1.4469940662384033, 1.904594898223877, 1.3324681520462036, 0.7018634080886841, 1.4022531509399414, 1.2651039361953735, 0.3770522475242615, 0.9132546782493591, 1.5309861898422241, 1.3089969158172607, 0.9292653799057007, 0.9277924299240112, 0.4011114537715912, 0.864493191242218, 1.3607244491577148, 1.0031473636627197, 1.5937610864639282, 0.9254574179649353, 1.3105392456054688, 1.5403958559036255, 1.4829730987548828, 1.0975592136383057, 0.983575701713562, 1.9423071146011353, 0.8640525937080383, 1.7481226921081543, 1.3176281452178955, 1.2185399532318115, 1.4046902656555176, 1.1211645603179932, 1.2381680011749268, 1.2848132848739624, 1.2818692922592163, 0.9236699342727661, 0.9175088405609131, 1.1404688358306885, 1.2195274829864502, 1.400910496711731, 1.1187433004379272, 0.9992424249649048, 1.2396965026855469, 1.084468960762024, 1.207654595375061, 1.1807669401168823, 0.7834930419921875, 0.9705448150634766, 1.3042330741882324, 1.3805657625198364, 1.1508959531784058, 1.4622715711593628, 1.585152506828308, 1.544661045074463, 0.9072709679603577, 1.4195390939712524, 0.90793377161026, 1.080181360244751, 1.178085207939148, 0.9024062156677246, 1.3797787427902222, 1.181872010231018, 0.6763342022895813, 0.8894846439361572, 1.7658326625823975, 0.8861544728279114, 0.7456437349319458, 1.545240044593811, 1.5994760990142822, 1.628088116645813, 1.1155964136123657, 1.2053074836730957, 1.4092955589294434, 1.3551442623138428, 0.9538300037384033, 0.9296910166740417, 0.9666955471038818, 0.5361372828483582, 1.310766339302063, 1.2716178894042969, 1.365061640739441, 1.2497000694274902, 1.560025691986084, 1.198818564414978, 1.5328655242919922, 0.9660760760307312, 1.307030439376831, 1.453700065612793, 1.079925537109375, 1.0868949890136719, 0.7626500725746155, 1.1088131666183472, 1.2750087976455688, 0.9772449731826782, 1.209401249885559, 0.7862952947616577, 1.446994662284851, 1.1505825519561768, 1.4495770931243896, 1.2281399965286255, 1.6580331325531006, 1.107052206993103, 1.18645441532135, 1.3776801824569702, 0.9564502835273743, 1.3020501136779785, 0.7320888638496399, 1.6377097368240356, 1.1030482053756714, 1.2257513999938965, 0.9861340522766113, 1.2705187797546387, 1.3800190687179565, 1.4009140729904175, 1.6087287664413452, 1.6638169288635254, 0.7832148671150208, 1.2458888292312622, 0.7041980624198914, 1.1163526773452759, 1.3275632858276367, 1.2117493152618408, 1.0551882982254028, 1.4947423934936523, 1.534035563468933, 1.642220139503479, 1.2775403261184692, 0.5373129844665527, 1.1746292114257812, 1.09715735912323, 1.2735244035720825, 1.2357150316238403, 1.3435789346694946, 1.3035523891448975, 1.465196132659912, 1.0396788120269775, 0.7268549203872681, 1.4095040559768677, 0.9221966862678528, 1.577789306640625, 0.697509765625, 1.3551490306854248, 1.245803952217102, 1.673811674118042, 1.6403385400772095, 0.9267618060112, 1.3333197832107544, 1.3801467418670654, 1.428339958190918, 1.8017711639404297, 1.3628023862838745, 0.9315736293792725, 1.0471961498260498, 1.2627019882202148, 1.54251229763031, 1.3667306900024414, 1.3079136610031128, 1.0124554634094238, 1.4542624950408936, 1.057654619216919, 1.6465591192245483, 1.1403714418411255, 1.2785402536392212, 1.0906559228897095, 1.1149471998214722, 1.132755994796753, 1.0037232637405396, 1.040473461151123, 1.3164000511169434, 1.6696860790252686, 1.1412039995193481, 1.1553916931152344, 0.8105127811431885, 1.3423036336898804, 1.5396578311920166, 1.237295150756836, 1.320899486541748, 1.442244052886963, 1.251127004623413, 0.8035494685173035, 1.9423000812530518, 0.8327771425247192, 1.4118636846542358, 0.8494922518730164, 0.8036966919898987, 1.0831587314605713, 1.2967761754989624, 1.1090117692947388, 1.3043445348739624, 1.2173465490341187, 1.1525728702545166, 1.2357501983642578, 1.484830617904663, 1.3117555379867554, 0.9617774486541748, 0.9811390042304993, 1.3830143213272095, 1.4765781164169312, 1.3785979747772217, 1.0942965745925903, 1.3241267204284668, 0.8009698987007141, 1.2019307613372803, 1.5487537384033203, 1.7869822978973389, 1.4406976699829102, 0.9791814088821411, 1.5252878665924072, 1.4807946681976318, 1.1004767417907715, 1.5150901079177856, 1.4218617677688599, 1.3655506372451782, 0.980381965637207, 1.240486741065979, 1.2887675762176514, 1.7662583589553833, 0.9707443118095398, 1.61506986618042, 1.3066446781158447, 0.6272947788238525, 1.5079693794250488, 1.4056754112243652, 0.9458672404289246, 0.8748914003372192, 0.976563036441803, 0.9412963390350342, 1.0817298889160156, 1.7049646377563477, 1.6762102842330933, 1.2353496551513672, 1.247333288192749, 1.2375906705856323, 1.4176385402679443, 0.8046188354492188, 0.9889227747917175, 1.2157243490219116, 0.9206249713897705, 1.487332820892334, 1.4974790811538696, 1.6820333003997803, 0.9165275692939758, 0.786107063293457, 1.3515530824661255, 1.6622130870819092, 1.5323106050491333, 1.1334853172302246, 1.068847417831421, 1.1522642374038696, 1.4409602880477905, 1.1869268417358398, 1.3345379829406738, 1.275571584701538, 1.2481926679611206, 1.2728512287139893, 1.0495141744613647, 1.6896449327468872, 0.7827873229980469, 1.5292757749557495, 1.4103868007659912, 1.3176331520080566, 0.9974302649497986, 1.5318044424057007, 1.5923033952713013, 1.349719524383545, 1.2126702070236206, 1.3341038227081299, 1.161474347114563, 1.3817951679229736, 1.1114057302474976, 1.3250232934951782, 1.3241959810256958, 1.6529332399368286, 1.101516842842102, 1.2708845138549805, 1.044880747795105, 1.6043803691864014, 1.3261487483978271, 1.0733113288879395, 1.0142524242401123, 1.467864990234375, 1.2560096979141235, 1.0112648010253906, 1.3118549585342407, 1.0456007719039917, 1.1766833066940308, 0.7877753376960754, 0.8623181581497192, 0.5461394190788269, 0.8142622113227844, 0.6853674650192261, 1.391353964805603, 1.0258903503417969, 1.067525863647461, 1.3301619291305542, 1.4006664752960205, 1.3432193994522095, 1.2415896654129028, 1.4725078344345093, 1.0556347370147705, 1.3310593366622925, 0.9685887694358826, 1.362257719039917, 1.7036007642745972, 1.2798285484313965, 1.0249617099761963, 1.1120030879974365, 1.1298478841781616, 0.7755576372146606, 1.1236116886138916, 1.6522685289382935, 1.440932035446167, 1.2497358322143555, 1.4820733070373535, 1.4304226636886597, 1.8502589464187622, 1.5943289995193481, 1.0880917310714722, 1.6180853843688965, 1.2703648805618286, 1.427521824836731, 1.2637150287628174, 0.8136737942695618, 1.6677281856536865, 1.0613082647323608, 0.7920898199081421, 1.1025519371032715, 1.7145140171051025, 1.17125403881073, 1.618358850479126, 0.8655268549919128, 0.28243446350097656, 0.8726511597633362, 1.1566227674484253, 1.2683693170547485, 1.6034678220748901, 0.9718301892280579, 1.8648245334625244, 0.5331270694732666, 1.3742351531982422, 0.6783624291419983, 1.3209854364395142, 1.1710819005966187, 1.3667887449264526, 1.5838836431503296, 1.235006332397461, 1.3025119304656982], "irt_model": "2pl", "item_ids": {"0": "q_0", "1": "q_1", "2": "q_2", "3": "q_3", "4": "q_4", "5": "q_5", "6": "q_6", "7": "q_7", "8": "q_8", "9": "q_9", "10": "q_10", "11": "q_11", "12": "q_12", "13": "q_13", "14": "q_14", "15": "q_15", "16": "q_16", "17": "q_17", "18": "q_18", "19": "q_19", "20": "q_20", "21": "q_21", "22": "q_22", "23": "q_23", "24": "q_24", "25": "q_25", "26": "q_26", "27": "q_27", "28": "q_28", "29": "q_29", "30": "q_30", "31": "q_31", "32": "q_32", "33": "q_33", "34": "q_34", "35": "q_35", "36": "q_36", "37": "q_37", "38": "q_38", "39": "q_39", "40": "q_40", "41": "q_41", "42": "q_43", "43": "q_44", "44": "q_45", "45": "q_46", "46": "q_47", "47": "q_48", "48": "q_49", "49": "q_50", "50": "q_51", "51": "q_52", "52": "q_53", "53": "q_54", "54": "q_55", "55": "q_56", "56": "q_57", "57": "q_58", "58": "q_59", "59": "q_60", "60": "q_61", "61": "q_62", "62": "q_63", "63": "q_64", "64": "q_65", "65": "q_66", "66": "q_67", "67": "q_68", "68": "q_69", "69": "q_70", "70": "q_71", "71": "q_72", "72": "q_73", "73": "q_74", "74": "q_75", "75": "q_76", "76": "q_77", "77": "q_78", "78": "q_79", "79": "q_80", "80": "q_81", "81": "q_82", "82": "q_83", "83": "q_84", "84": "q_85", "85": "q_86", "86": "q_87", "87": "q_88", "88": "q_89", "89": "q_90", "90": "q_91", "91": "q_92", "92": "q_93", "93": "q_94", "94": "q_95", "95": "q_96", "96": "q_97", "97": "q_98", "98": "q_99", "99": "q_100", "100": "q_101", "101": "q_102", "102": "q_103", "103": "q_104", "104": "q_105", "105": "q_106", "106": "q_107", "107": "q_108", "108": "q_109", "109": "q_110", "110": "q_111", "111": "q_112", "112": "q_113", "113": "q_114", "114": "q_115", "115": "q_116", "116": "q_117", "117": "q_118", "118": "q_119", "119": "q_120", "120": "q_122", "121": "q_123", "122": "q_124", "123": "q_125", "124": "q_126", "125": "q_127", "126": "q_128", "127": "q_129", "128": "q_130", "129": "q_131", "130": "q_132", "131": "q_133", "132": "q_134", "133": "q_135", "134": "q_136", "135": "q_137", "136": "q_138", "137": "q_139", "138": "q_140", "139": "q_141", "140": "q_142", "141": "q_143", "142": "q_144", "143": "q_145", "144": "q_146", "145": "q_147", "146": "q_148", "147": "q_149", "148": "q_150", "149": "q_151", "150": "q_152", "151": "q_153", "152": "q_154", "153": "q_155", "154": "q_156", "155": "q_157", "156": "q_158", "157": "q_159", "158": "q_160", "159": "q_161", "160": "q_162", "161": "q_163", "162": "q_164", "163": "q_165", "164": "q_166", "165": "q_167", "166": "q_168", "167": "q_169", "168": "q_170", "169": "q_171", "170": "q_173", "171": "q_174", "172": "q_175", "173": "q_176", "174": "q_177", "175": "q_178", "176": "q_179", "177": "q_180", "178": "q_181", "179": "q_182", "180": "q_183", "181": "q_184", "182": "q_185", "183": "q_186", "184": "q_187", "185": "q_188", "186": "q_189", "187": "q_190", "188": "q_191", "189": "q_192", "190": "q_193", "191": "q_194", "192": "q_195", "193": "q_196", "194": "q_197", "195": "q_198", "196": "q_199", "197": "q_200", "198": "q_201", "199": "q_202", "200": "q_203", "201": "q_204", "202": "q_205", "203": "q_206", "204": "q_207", "205": "q_208", "206": "q_209", "207": "q_210", "208": "q_211", "209": "q_212", "210": "q_213", "211": "q_214", "212": "q_215", "213": "q_216", "214": "q_217", "215": "q_218", "216": "q_219", "217": "q_220", "218": "q_221", "219": "q_222", "220": "q_224", "221": "q_225", "222": "q_226", "223": "q_227", "224": "q_228", "225": "q_229", "226": "q_230", "227": "q_231", "228": "q_232", "229": "q_233", "230": "q_234", "231": "q_235", "232": "q_236", "233": "q_237", "234": "q_238", "235": "q_239", "236": "q_240", "237": "q_241", "238": "q_242", "239": "q_243", "240": "q_244", "241": "q_245", "242": "q_246", "243": "q_247", "244": "q_248", "245": "q_249", "246": "q_250", "247": "q_251", "248": "q_252", "249": "q_253", "250": "q_254", "251": "q_255", "252": "q_256", "253": "q_257", "254": "q_258", "255": "q_259", "256": "q_260", "257": "q_261", "258": "q_262", "259": "q_263", "260": "q_264", "261": "q_265", "262": "q_266", "263": "q_267", "264": "q_268", "265": "q_269", "266": "q_270", "267": "q_271", "268": "q_272", "269": "q_273", "270": "q_274", "271": "q_275", "272": "q_276", "273": "q_277", "274": "q_278", "275": "q_279", "276": "q_280", "277": "q_281", "278": "q_282", "279": "q_283", "280": "q_284", "281": "q_285", "282": "q_286", "283": "q_287", "284": "q_288", "285": "q_289", "286": "q_290", "287": "q_291", "288": "q_292", "289": "q_293", "290": "q_294", "291": "q_295", "292": "q_296", "293": "q_297", "294": "q_298", "295": "q_299", "296": "q_300", "297": "q_301", "298": "q_302", "299": "q_303", "300": "q_304", "301": "q_305", "302": "q_306", "303": "q_307", "304": "q_308", "305": "q_309", "306": "q_310", "307": "q_311", "308": "q_312", "309": "q_313", "310": "q_314", "311": "q_315", "312": "q_316", "313": "q_317", "314": "q_318", "315": "q_319", "316": "q_320", "317": "q_321", "318": "q_322", "319": "q_323", "320": "q_324", "321": "q_325", "322": "q_326", "323": "q_327", "324": "q_328", "325": "q_329", "326": "q_330", "327": "q_331", "328": "q_332", "329": "q_333", "330": "q_334", "331": "q_335", "332": "q_336", "333": "q_337", "334": "q_338", "335": "q_339", "336": "q_340", "337": "q_341", "338": "q_342", "339": "q_343", "340": "q_345", "341": "q_346", "342": "q_347", "343": "q_348", "344": "q_349", "345": "q_350", "346": "q_351", "347": "q_352", "348": "q_353", "349": "q_354", "350": "q_355", "351": "q_356", "352": "q_357", "353": "q_358", "354": "q_359", "355": "q_360", "356": "q_361", "357": "q_362", "358": "q_363", "359": "q_364", "360": "q_365", "361": "q_366", "362": "q_367", "363": "q_368", "364": "q_369", "365": "q_370", "366": "q_371", "367": "q_372", "368": "q_373", "369": "q_374", "370": "q_375", "371": "q_376", "372": "q_377", "373": "q_378", "374": "q_379", "375": "q_380", "376": "q_381", "377": "q_382", "378": "q_383", "379": "q_384", "380": "q_385", "381": "q_386", "382": "q_387", "383": "q_388", "384": "q_389", "385": "q_391", "386": "q_392", "387": "q_393", "388": "q_394", "389": "q_395", "390": "q_396", "391": "q_397", "392": "q_398", "393": "q_399", "394": "q_400", "395": "q_401", "396": "q_402", "397": "q_403", "398": "q_404", "399": "q_405", "400": "q_406", "401": "q_407", "402": "q_408", "403": "q_409", "404": "q_410", "405": "q_411", "406": "q_412", "407": "q_413", "408": "q_414", "409": "q_415", "410": "q_416", "411": "q_417", "412": "q_418", "413": "q_419", "414": "q_420", "415": "q_421", "416": "q_422", "417": "q_423", "418": "q_424", "419": "q_425", "420": "q_426", "421": "q_427", "422": "q_428", "423": "q_429", "424": "q_430", "425": "q_431", "426": "q_432", "427": "q_433", "428": "q_434", "429": "q_435", "430": "q_436", "431": "q_437", "432": "q_438", "433": "q_439", "434": "q_440", "435": "q_441", "436": "q_442", "437": "q_443", "438": "q_444", "439": "q_445", "440": "q_446", "441": "q_447", "442": "q_448", "443": "q_449", "444": "q_450", "445": "q_451", "446": "q_452", "447": "q_453", "448": "q_454", "449": "q_455", "450": "q_456", "451": "q_457", "452": "q_458", "453": "q_459", "454": "q_460", "455": "q_461", "456": "q_462", "457": "q_463", "458": "q_464", "459": "q_465", "460": "q_466", "461": "q_467", "462": "q_468", "463": "q_469", "464": "q_470", "465": "q_471", "466": "q_472", "467": "q_473", "468": "q_474", "469": "q_475", "470": "q_476", "471": "q_477", "472": "q_478", "473": "q_479", "474": "q_480", "475": "q_481", "476": "q_482", "477": "q_483", "478": "q_484", "479": "q_485", "480": "q_486", "481": "q_487", "482": "q_488", "483": "q_489", "484": "q_490", "485": "q_491", "486": "q_492", "487": "q_493", "488": "q_494", "489": "q_495", "490": "q_496", "491": "q_497", "492": "q_498", "493": "q_499", "494": "q_500", "495": "q_501", "496": "q_502", "497": "q_503", "498": "q_504", "499": "q_505", "500": "q_506", "501": "q_507", "502": "q_508", "503": "q_509", "504": "q_510", "505": "q_511", "506": "q_512", "507": "q_513", "508": "q_514", "509": "q_515", "510": "q_516", "511": "q_517", "512": "q_518", "513": "q_519", "514": "q_520", "515": "q_521", "516": "q_522", "517": "q_523", "518": "q_524", "519": "q_525", "520": "q_526", "521": "q_527", "522": "q_528", "523": "q_529", "524": "q_531", "525": "q_532", "526": "q_533", "527": "q_534", "528": "q_535", "529": "q_536", "530": "q_537", "531": "q_538", "532": "q_539", "533": "q_540", "534": "q_541", "535": "q_542", "536": "q_543", "537": "q_544", "538": "q_545", "539": "q_546", "540": "q_547", "541": "q_548", "542": "q_549", "543": "q_550", "544": "q_551", "545": "q_552", "546": "q_553", "547": "q_554", "548": "q_555", "549": "q_556", "550": "q_557", "551": "q_558", "552": "q_559", "553": "q_560", "554": "q_561", "555": "q_562", "556": "q_563", "557": "q_564", "558": "q_565", "559": "q_566", "560": "q_567", "561": "q_568", "562": "q_569", "563": "q_571", "564": "q_572", "565": "q_573", "566": "q_574", "567": "q_575", "568": "q_576", "569": "q_577", "570": "q_578", "571": "q_579", "572": "q_580", "573": "q_581", "574": "q_582", "575": "q_583", "576": "q_584", "577": "q_585", "578": "q_586", "579": "q_587", "580": "q_589", "581": "q_590", "582": "q_591", "583": "q_592", "584": "q_593", "585": "q_594", "586": "q_595", "587": "q_596", "588": "q_597", "589": "q_598", "590": "q_599", "591": "q_600", "592": "q_601", "593": "q_602", "594": "q_603", "595": "q_604", "596": "q_605", "597": "q_606", "598": "q_607", "599": "q_608", "600": "q_609", "601": "q_610", "602": "q_611", "603": "q_612", "604": "q_613", "605": "q_614", "606": "q_615", "607": "q_616", "608": "q_617", "609": "q_618", "610": "q_619", "611": "q_620", "612": "q_621", "613": "q_622", "614": "q_624", "615": "q_625", "616": "q_626", "617": "q_627", "618": "q_628", "619": "q_629", "620": "q_630", "621": "q_631", "622": "q_632", "623": "q_633", "624": "q_634", "625": "q_635", "626": "q_636", "627": "q_637", "628": "q_638", "629": "q_639", "630": "q_640", "631": "q_641", "632": "q_642", "633": "q_643", "634": "q_644", "635": "q_645", "636": "q_646", "637": "q_647", "638": "q_648", "639": "q_649", "640": "q_650", "641": "q_651", "642": "q_652", "643": "q_653", "644": "q_654", "645": "q_655", "646": "q_656", "647": "q_657", "648": "q_658", "649": "q_659", "650": "q_660", "651": "q_661", "652": "q_662", "653": "q_663", "654": "q_664", "655": "q_665", "656": "q_666", "657": "q_667", "658": "q_668", "659": "q_669", "660": "q_670", "661": "q_671", "662": "q_672", "663": "q_673", "664": "q_674", "665": "q_675", "666": "q_676", "667": "q_677", "668": "q_678", "669": "q_679", "670": "q_680", "671": "q_681", "672": "q_682", "673": "q_683", "674": "q_684", "675": "q_685", "676": "q_686", "677": "q_687", "678": "q_688", "679": "q_689", "680": "q_690", "681": "q_691", "682": "q_692", "683": "q_693", "684": "q_694", "685": "q_695", "686": "q_696", "687": "q_697", "688": "q_698", "689": "q_699", "690": "q_701", "691": "q_702", "692": "q_703", "693": "q_704", "694": "q_705", "695": "q_706", "696": "q_707", "697": "q_708", "698": "q_709", "699": "q_710", "700": "q_711", "701": "q_712", "702": "q_713", "703": "q_714", "704": "q_715", "705": "q_716", "706": "q_717", "707": "q_718", "708": "q_719", "709": "q_720", "710": "q_721", "711": "q_722", "712": "q_723", "713": "q_724", "714": "q_725", "715": "q_726", "716": "q_727", "717": "q_728", "718": "q_729", "719": "q_730", "720": "q_731", "721": "q_732", "722": "q_733", "723": "q_734", "724": "q_735", "725": "q_736", "726": "q_737", "727": "q_738", "728": "q_739", "729": "q_740", "730": "q_741", "731": "q_742", "732": "q_743", "733": "q_744", "734": "q_745", "735": "q_746", "736": "q_747", "737": "q_748", "738": "q_749", "739": "q_750", "740": "q_751", "741": "q_752", "742": "q_753", "743": "q_754", "744": "q_755", "745": "q_756", "746": "q_757", "747": "q_758", "748": "q_759", "749": "q_760", "750": "q_761", "751": "q_762", "752": "q_763", "753": "q_764", "754": "q_765", "755": "q_766", "756": "q_767", "757": "q_768", "758": "q_769", "759": "q_770", "760": "q_771", "761": "q_772", "762": "q_773", "763": "q_774", "764": "q_775", "765": "q_776", "766": "q_777", "767": "q_778", "768": "q_779", "769": "q_780", "770": "q_781", "771": "q_782", "772": "q_783", "773": "q_784", "774": "q_785", "775": "q_786", "776": "q_787", "777": "q_788", "778": "q_789", "779": "q_790", "780": "q_791", "781": "q_792", "782": "q_793", "783": "q_794", "784": "q_795", "785": "q_796", "786": "q_797", "787": "q_798", "788": "q_799", "789": "q_800", "790": "q_801", "791": "q_802", "792": "q_803", "793": "q_804", "794": "q_805", "795": "q_806", "796": "q_807", "797": "q_808", "798": "q_809", "799": "q_810", "800": "q_811", "801": "q_812", "802": "q_813", "803": "q_814", "804": "q_815", "805": "q_816", "806": "q_817", "807": "q_818", "808": "q_819", "809": "q_820", "810": "q_821", "811": "q_822", "812": "q_823", "813": "q_824", "814": "q_825", "815": "q_826", "816": "q_827", "817": "q_828", "818": "q_829", "819": "q_830", "820": "q_831", "821": "q_833", "822": "q_834", "823": "q_835", "824": "q_836", "825": "q_837", "826": "q_838", "827": "q_839", "828": "q_840", "829": "q_841", "830": "q_842", "831": "q_843", "832": "q_844", "833": "q_845", "834": "q_846", "835": "q_847", "836": "q_848", "837": "q_849", "838": "q_850", "839": "q_851", "840": "q_852", "841": "q_853", "842": "q_854", "843": "q_855", "844": "q_856", "845": "q_857", "846": "q_858", "847": "q_859", "848": "q_860", "849": "q_861", "850": "q_862", "851": "q_863", "852": "q_864", "853": "q_865", "854": "q_866", "855": "q_867", "856": "q_868", "857": "q_869", "858": "q_870", "859": "q_871", "860": "q_872", "861": "q_873", "862": "q_874", "863": "q_875", "864": "q_876", "865": "q_877", "866": "q_878", "867": "q_879", "868": "q_880", "869": "q_881", "870": "q_882", "871": "q_883", "872": "q_884", "873": "q_885", "874": "q_886", "875": "q_887", "876": "q_888", "877": "q_889", "878": "q_890", "879": "q_891", "880": "q_892", "881": "q_893", "882": "q_894", "883": "q_895", "884": "q_896", "885": "q_897", "886": "q_898", "887": "q_899", "888": "q_900", "889": "q_901", "890": "q_902", "891": "q_903", "892": "q_904", "893": "q_905", "894": "q_906", "895": "q_907", "896": "q_908", "897": "q_909", "898": "q_910", "899": "q_911", "900": "q_912", "901": "q_913", "902": "q_914", "903": "q_915", "904": "q_916", "905": "q_917", "906": "q_918", "907": "q_919", "908": "q_920", "909": "q_921", "910": "q_922", "911": "q_923", "912": "q_924", "913": "q_925", "914": "q_926", "915": "q_927", "916": "q_928", "917": "q_929", "918": "q_930", "919": "q_931", "920": "q_932", "921": "q_933", "922": "q_934", "923": "q_935", "924": "q_936", "925": "q_937", "926": "q_938", "927": "q_939", "928": "q_940", "929": "q_941", "930": "q_942", "931": "q_943", "932": "q_944", "933": "q_945", "934": "q_946", "935": "q_947", "936": "q_948", "937": "q_949", "938": "q_950", "939": "q_951", "940": "q_952", "941": "q_953", "942": "q_954", "943": "q_955", "944": "q_956", "945": "q_957", "946": "q_958", "947": "q_959", "948": "q_960", "949": "q_961", "950": "q_962", "951": "q_963", "952": "q_964", "953": "q_965", "954": "q_966", "955": "q_967", "956": "q_968", "957": "q_969", "958": "q_970", "959": "q_971", "960": "q_972", "961": "q_973", "962": "q_974", "963": "q_975", "964": "q_976", "965": "q_977", "966": "q_978", "967": "q_979", "968": "q_980", "969": "q_981", "970": "q_982", "971": "q_983", "972": "q_984", "973": "q_985", "974": "q_986", "975": "q_987", "976": "q_988", "977": "q_989", "978": "q_990", "979": "q_991", "980": "q_992", "981": "q_993", "982": "q_994", "983": "q_995", "984": "q_996", "985": "q_997", "986": "q_998", "987": "q_999", "988": "q_1000", "989": "q_1001", "990": "q_1002", "991": "q_1003", "992": "q_1004", "993": "q_1005", "994": "q_1006", "995": "q_1007", "996": "q_1008", "997": "q_1009", "998": "q_1010", "999": "q_1011", "1000": "q_1012", "1001": "q_1013", "1002": "q_1014", "1003": "q_1015", "1004": "q_1016", "1005": "q_1017", "1006": "q_1018", "1007": "q_1019", "1008": "q_1020", "1009": "q_1021", "1010": "q_1022", "1011": "q_1023", "1012": "q_1024", "1013": "q_1025", "1014": "q_1026", "1015": "q_1027", "1016": "q_1028", "1017": "q_1029", "1018": "q_1030", "1019": "q_1031", "1020": "q_1032", "1021": "q_1033", "1022": "q_1034", "1023": "q_1035", "1024": "q_1036", "1025": "q_1037", "1026": "q_1038", "1027": "q_1039", "1028": "q_1040", "1029": "q_1041", "1030": "q_1042", "1031": "q_1043", "1032": "q_1044", "1033": "q_1045", "1034": "q_1046", "1035": "q_1047", "1036": "q_1048", "1037": "q_1049", "1038": "q_1050", "1039": "q_1051", "1040": "q_1052", "1041": "q_1053", "1042": "q_1054", "1043": "q_1055", "1044": "q_1056", "1045": "q_1058", "1046": "q_1059", "1047": "q_1060", "1048": "q_1061", "1049": "q_1062", "1050": "q_1063", "1051": "q_1064", "1052": "q_1065", "1053": "q_1066", "1054": "q_1067", "1055": "q_1068", "1056": "q_1069", "1057": "q_1070", "1058": "q_1071", "1059": "q_1072", "1060": "q_1073", "1061": "q_1074", "1062": "q_1075", "1063": "q_1076", "1064": "q_1077", "1065": "q_1078", "1066": "q_1079", "1067": "q_1080", "1068": "q_1081", "1069": "q_1082", "1070": "q_1083", "1071": "q_1084", "1072": "q_1085", "1073": "q_1086", "1074": "q_1087", "1075": "q_1088", "1076": "q_1089", "1077": "q_1090", "1078": "q_1091", "1079": "q_1092", "1080": "q_1093", "1081": "q_1094", "1082": "q_1095", "1083": "q_1096", "1084": "q_1097", "1085": "q_1098", "1086": "q_1099", "1087": "q_1100", "1088": "q_1101", "1089": "q_1102", "1090": "q_1103", "1091": "q_1104", "1092": "q_1105", "1093": "q_1106", "1094": "q_1107", "1095": "q_1108", "1096": "q_1109", "1097": "q_1110", "1098": "q_1111", "1099": "q_1112", "1100": "q_1113", "1101": "q_1114", "1102": "q_1115", "1103": "q_1116", "1104": "q_1117", "1105": "q_1118", "1106": "q_1119", "1107": "q_1120", "1108": "q_1121", "1109": "q_1122", "1110": "q_1123", "1111": "q_1124", "1112": "q_1125", "1113": "q_1126", "1114": "q_1127", "1115": "q_1128", "1116": "q_1129", "1117": "q_1130", "1118": "q_1131", "1119": "q_1132", "1120": "q_1133", "1121": "q_1134", "1122": "q_1135", "1123": "q_1136", "1124": "q_1137", "1125": "q_1138", "1126": "q_1139", "1127": "q_1140", "1128": "q_1141", "1129": "q_1142", "1130": "q_1143", "1131": "q_1144", "1132": "q_1145", "1133": "q_1146", "1134": "q_1147", "1135": "q_1148", "1136": "q_1149", "1137": "q_1150", "1138": "q_1151", "1139": "q_1152", "1140": "q_1153", "1141": "q_1154", "1142": "q_1155", "1143": "q_1156", "1144": "q_1157", "1145": "q_1158", "1146": "q_1159", "1147": "q_1160", "1148": "q_1161", "1149": "q_1162", "1150": "q_1163", "1151": "q_1164", "1152": "q_1165", "1153": "q_1166", "1154": "q_1167", "1155": "q_1168", "1156": "q_1169", "1157": "q_1170", "1158": "q_1171", "1159": "q_1172", "1160": "q_1173", "1161": "q_1174", "1162": "q_1175", "1163": "q_1176", "1164": "q_1177", "1165": "q_1178", "1166": "q_1179", "1167": "q_1180", "1168": "q_1181", "1169": "q_1182", "1170": "q_1183", "1171": "q_1184", "1172": "q_1185", "1173": "q_1186", "1174": "q_1187", "1175": "q_1188", "1176": "q_1189", "1177": "q_1190", "1178": "q_1191", "1179": "q_1192", "1180": "q_1193", "1181": "q_1194", "1182": "q_1195", "1183": "q_1196", "1184": "q_1197", "1185": "q_1198", "1186": "q_1199", "1187": "q_1200", "1188": "q_1201", "1189": "q_1202", "1190": "q_1203", "1191": "q_1204", "1192": "q_1205", "1193": "q_1206", "1194": "q_1207", "1195": "q_1208", "1196": "q_1209", "1197": "q_1210", "1198": "q_1211", "1199": "q_1212", "1200": "q_1213", "1201": "q_1214", "1202": "q_1215", "1203": "q_1216", "1204": "q_1217", "1205": "q_1218", "1206": "q_1219", "1207": "q_1220", "1208": "q_1221", "1209": "q_1222", "1210": "q_1223", "1211": "q_1224", "1212": "q_1225", "1213": "q_1226", "1214": "q_1227", "1215": "q_1228", "1216": "q_1229", "1217": "q_1230", "1218": "q_1231", "1219": "q_1232", "1220": "q_1233", "1221": "q_1234", "1222": "q_1235", "1223": "q_1236", "1224": "q_1237", "1225": "q_1238", "1226": "q_1239", "1227": "q_1240", "1228": "q_1241", "1229": "q_1242", "1230": "q_1243", "1231": "q_1244", "1232": "q_1245", "1233": "q_1246", "1234": "q_1247", "1235": "q_1248", "1236": "q_1249", "1237": "q_1250", "1238": "q_1251", "1239": "q_1252", "1240": "q_1253", "1241": "q_1254", "1242": "q_1255", "1243": "q_1256", "1244": "q_1257", "1245": "q_1258", "1246": "q_1259", "1247": "q_1260", "1248": "q_1261", "1249": "q_1262", "1250": "q_1263", "1251": "q_1264", "1252": "q_1265", "1253": "q_1266", "1254": "q_1267", "1255": "q_1268", "1256": "q_1269", "1257": "q_1270", "1258": "q_1271", "1259": "q_1272", "1260": "q_1273", "1261": "q_1274", "1262": "q_1275", "1263": "q_1276", "1264": "q_1277", "1265": "q_1278", "1266": "q_1279", "1267": "q_1280", "1268": "q_1281", "1269": "q_1282", "1270": "q_1283", "1271": "q_1284", "1272": "q_1285", "1273": "q_1286", "1274": "q_1287", "1275": "q_1288", "1276": "q_1289", "1277": "q_1290", "1278": "q_1291", "1279": "q_1292", "1280": "q_1293", "1281": "q_1294", "1282": "q_1295", "1283": "q_1296", "1284": "q_1297", "1285": "q_1298", "1286": "q_1299", "1287": "q_1300", "1288": "q_1301", "1289": "q_1302", "1290": "q_1303", "1291": "q_1304", "1292": "q_1305", "1293": "q_1306", "1294": "q_1307", "1295": "q_1308", "1296": "q_1309", "1297": "q_1310", "1298": "q_1311", "1299": "q_1312", "1300": "q_1313", "1301": "q_1314", "1302": "q_1315", "1303": "q_1316", "1304": "q_1317", "1305": "q_1318"}, "subject_ids": {"0": "Llama-3-70B-Instruct-DPO-v0.2", "1": "Llama-3-70B-japanese-suzume-vector-v0.1", "2": "Llama-3-70B-Instruct-DPO-v0.4", "3": "Llama-3-70B-Instruct-DPO-v0.3", "4": "Llama3-TenyxChat-70B", "5": "Llama-3-70B-Instruct-DPO-v0.1", "6": "autotrain-llama3-70b-orpo-v1", "7": "Meta-Llama-3-70B-Instruct", "8": "Qwen2-72B", "9": "llama-3-70B-Instruct-abliterated", "10": "autotrain-llama3-70b-orpo-v2", "11": "autotrain-llama3-oh-sft-v0-2", "12": "tigerbot-70b-chat-v4-4k", "13": "Llama3-70B-Fireplace", "14": "Llama3-70B-Chinese-Chat", "15": "Llama-3-Giraffe-70B-Instruct", "16": "Mixtral-8x22B-Instruct-v0.1", "17": "Qwen1.5-110B", "18": "Phi-3-medium-128k-instruct", "19": "Phi-3-Medium-Llamaish", "20": "Llama-3-70B-Instruct-Gradient-262k", "21": "Phi-3-medium-4k-instruct", "22": "Llama-3-Lumimaid-70B-v0.1-alt", "23": "Rhea-72b-v0.3", "24": "TW3-JRGL-v1", "25": "Ein-72B-v0.1", "26": "Ein-72B-v0.13", "27": "Ein-72B-v0.12", "28": "Llama-3-70B-Instruct-Gradient-524k", "29": "Llama-3-Lumimaid-70B-v0.1", "30": "Ein-72B-v0.11", "31": "Smaug-72B-v0.1", "32": "Smaug-70B-v0.1", "33": "Rhea-72b-v0.4", "34": "MoMo-72B-lora-1.8.7-DPO", "35": "Rhea-72b-v0.2", "36": "sft_model_test1", "37": "alpaca-dragon-72b-v1", "38": "Tess-72B-v1.5b", "39": "Meta-Llama-3-70B", "40": "MoMo-70B-lora-1.8.6-DPO", "41": "MultiVerse_70B", "42": "Llama-3-70B-Orpo-v0.1", "43": "Rhea-72b-v0.5", "44": "free-evo-qwen72b-v0.8-re", "45": "free-evo-qwen72b-v0.8", "46": "YiSM-34B-0rn", "47": "Yi-34Bx2-MoE-60B", "48": "Luminex-72B-v0.1", "49": "Ein-70B-v2", "50": "NeuralMaths-Experiment-7b", "51": "Phi-3-mini-mango-1", "52": "Phi-3-mini-mango-1-llamafied", "53": "Tess-2.0-Llama-3-70B", "54": "Mixtral_34Bx2_MoE_60B", "55": "C0325-L", "56": "Phi-3-mini-4k-instruct-v0.3", "57": "35b-beta-long", "58": "TomGrc_FusionNet_34Bx2_MoE_v0.1_DPO_f16", "59": "phi-3-22b", "60": "NeuralBeagleOpenChat", "61": "SeaLLM-7B-v2.5", "62": "MoMo-70B-lora-1.8.5-DPO", "63": "Truthful_DPO_cloudyu_Mixtral_34Bx2_MoE_60B", "64": "AnFeng_v3_Avocet", "65": "Phi-3-mini-4k-instruct", "66": "Yi-34Bx2-MoE-60B-DPO", "67": "airoboros-70b-3.3", "68": "Mixtral-8x22B-v0.1", "69": "phi-3-mini-4k-instruct-llamafied", "70": "Liberated-Qwen1.5-72B", "71": "StarMonarch-7B", "72": "Phi-3-mini-4k-instruct-v0.2", "73": "M-LChat-7b", "74": "Pearl-7B-slerp", "75": "Daredevil-8B", "76": "MonarchPipe-7B-slerp", "77": "Neural4gsm8k", "78": "TheTop-5x7B-Instruct-S4-v0.1", "79": "The-Trinity-Coder-7B", "80": "Mayo", "81": "FernandoGPT-v1", "82": "WestSeverus-7B-DPO", "83": "SauerkrautLM-14b-MoE-LaserChat", "84": "Yi-1.5-34B", "85": "OrcaHermes-Mistral-70B-miqu", "86": "Cygnus-7B", "87": "NeuralPearlBeagle", "88": "Marcoroni-neural-chat-7B-v2", "89": "Mistral-T5-7B-v1", "90": "NeuralDaredevil-7B", "91": "Daredevil-8B-abliterated", "92": "Nous-Hermes-2-SUS-Chat-2x34B", "93": "Neural-SOVLish-Devil-8B-L3", "94": "WestSeverusJaskier", "95": "Tess-2.0-Llama-3-70B-v0.2", "96": "CatMacaroni-Slerp", "97": "CatMarcoro14-7B-slerp", "98": "ChimeraLlama-3-8B-v2", "99": "Maxine-7B-0401-ties", "100": "FusionNet_34Bx2_MoE_v0.1", "101": "mistral-7b-merged-dare", "102": "xDAN-L2-moe-2x-v1", "103": "Qwen2-7B", "104": "StarEmpress-3x7B", "105": "Mahou-1.3-llama3-8B", "106": "Daredevil-7B", "107": "NeuralLLaMa-3-8b-ORPO-v0.3", "108": "OpenCM-14", "109": "TomGrc_FusionNet_34Bx2_MoE_v0.1_full_linear_DPO", "110": "Lumina-3", "111": "Yi-34Bx3-MoE-90B", "112": "Nous-Hermes-2-SUS-Chat-34B-Slerp", "113": "openchat-3.5-0106-gemma", "114": "MoEv4Config-TestWeightedTIES-7b", "115": "NeuralWestSeverus-7B-slerp", "116": "billie", "117": "StrangeMerges_45-7B-dare_ties", "118": "LaserPipe-7B-SLERP", "119": "Proteus-8B", "120": "Slerp-CM-mist-dpo", "121": "Cognitron-8B", "122": "Severus-7B", "123": "Halu-8B-Llama3-v0.3", "124": "Yi-34Bx2-MOE-200K", "125": "Mathral", "126": "Calme-7B-Instruct-v0.4", "127": "StrangeMerges_53-7B-model_stock", "128": "flux-7b-v0.2", "129": "Mahou-1.0-llama3-8B", "130": "llama-3-NeuralMahou", "131": "phillama-3.8b-v0.1", "132": "Llama-3-15B-Instruct-ft-v2", "133": "MultiverseMath-12B-MoE", "134": "SOVLish-Devil-8B-L3", "135": "Luminex-34B-v0.1", "136": "Maverick-8B", "137": "UNA-SimpleSmaug-34b-v1beta", "138": "llama-3-sauce-v2-8B", "139": "Neuralmaath-12B-MoE", "140": "flux-7b-v0.1", "141": "badger-l3-instruct-32k", "142": "CatunaMayo", "143": "Marcoroni-7B-v3", "144": "CatMacaroni14", "145": "Neural-Cosmic-Boy-7B-slerp", "146": "Deita-32b", "147": "UltraCatunaMayo", "148": "StrangeMerges_3-7B-slerp", "149": "StrangeMerges_52-7B-dare_ties", "150": "Dream-7B-slerp", "151": "Mistral-7b-instruct-v0.2-private-edw2", "152": "Wilbur-30B", "153": "Neural-4-Maths-7b", "154": "RasGullaINEX12-7B-slerp", "155": "mistral-ft-optimized-1218", "156": "Helion-4x34B", "157": "openchat-3.5-1210-Seraph-Slerp", "158": "Cosmosis-3x34B", "159": "MM-OV-bagel-DPO-34b-c1000-250", "160": "StrangeMerges_44-7B-dare_ties", "161": "supermario-v2", "162": "CM-14", "163": "Phi-3-mini-4k-instruct-v0.1", "164": "BurningBruce-003", "165": "stealth-v1.2", "166": "MM-Orc-Vic-bagel-34b-c1000", "167": "Oot-v2_lll", "168": "Smaugv0.1", "169": "Smaug-34B-v0.1", "170": "Mixtral_7Bx5_MoE_30B", "171": "CatunaLaserPi", "172": "MDBX-7B", "173": "StrangeMerges_20-7B-slerp", "174": "SUS-Chat-34B", "175": "MetaMath-Bagel-DPO-34B", "176": "yi-9b-may-ortho-baukit-13fail-3000total-bf16", "177": "Maxine-34B-stock", "178": "Harmony-4x7B-bf16", "179": "supermario-slerp", "180": "llama-3-bophades-v2-8B", "181": "Deita-20b", "182": "Merged-OpenLlama3-8B", "183": "72B-preview", "184": "Blur-7B-slerp-v0.1", "185": "Nous-Hermes-2-SUS-Chat-34B-Linear", "186": "TheTop-5x7B-Instruct-S2-v0.1", "187": "ipo-test", "188": "piccolo-8x7b", "189": "Seraph-openchat-3.5-1210-Slerp", "190": "TheTop-5x7B-Instruct-S3-v0.1", "191": "kellemar-DPO-Orca-Distilled-7B-SLERP", "192": "Eukaryote-8x7B-bf16", "193": "Starling_Monarch_Westlake_Garten-7B-v0.1", "194": "Calme-7B-Instruct-v0.5", "195": "7Bx4_DPO", "196": "MarcMistral-7B", "197": "Proctora", "198": "jaLLAbi2-7b", "199": "Mahou-1.2-llama3-8B", "200": "Smaug-Mixtral-v0.1", "201": "ChimeraLlama-3-8B-v3", "202": "Luminex-34B-v0.2", "203": "LexiLumin-7B", "204": "Phi-3-medium-4k-instruct-abliterated-v3", "205": "merge_7B_state_2", "206": "BeagleMist-7B", "207": "Yi-1.5-9B-Chat", "208": "Scorpio-7B", "209": "WestBeagle-7B", "210": "Seraph-7B", "211": "multimaster-7b-v2", "212": "Daredevil-8B-abliterated-dpomix", "213": "Marcoroni-v3-neural-chat-v3-3-Slerp", "214": "Capricorn-7B", "215": "jaskier-7b-dpo-v2", "216": "MarcDareBeagle-7B", "217": "openchat-3.6-8b-20240522", "218": "BeagSake-7B", "219": "merge_model_test_v2", "220": "NeoCortex-7B-slerp", "221": "M7-7b", "222": "Topxtral-4x7B-v0.1", "223": "Multiverse-Experiment-slerp-7b", "224": "Marcoroni-8x7B-v3-MoE", "225": "threebird-7B", "226": "RasGulla1-7b", "227": "SamirGPT-v1", "228": "Beyonder-4x7B-v2", "229": "OpenHermes-2.5-neural-chat-v3-3-openchat-3.5-1210-Slerp", "230": "JupiterINEX12-12B-MoE", "231": "TheTop-5x7B-Instruct-D-v0.1", "232": "Llama-3-MahouDevil-8B", "233": "Pulsar_7B", "234": "SevereNeuralBeagleTrix-7B", "235": "Nous-Hermes-2-Mixtral-8x7B-DPO", "236": "LogoS-7Bx2-MoE-13B-v0.1", "237": "Yi-1.5-34B-Chat", "238": "Astralis-4x34B", "239": "Calmesmol-7B-slerp", "240": "Mayoroya", "241": "trinity-v1", "242": "stealth-v1.3", "243": "LogoS-7Bx2-MoE-13B-v0.2", "244": "72B-preview-llamafied-qwen-llamafy", "245": "multimaster-7b-v3", "246": "Dare-k-7B-ties", "247": "mhm-8x7B-FrankenMoE-v1.0", "248": "kellemar-KrishnaHercules-0.1-7b-slerp", "249": "v1olet_marcoroni-go-bruins-merge-7B", "250": "L3-8B-Stheno-v3.1", "251": "gemma-ko-7b-instruct-v0.62", "252": "WestSeverus-7B-DPO-v2", "253": "Macaroni-7b-Tied", "254": "Llama-3-15B-Instruct-zeroed-ft", "255": "llama-3-stella-8B", "256": "DareBeagle-7B", "257": "MetaMath-Cybertron-Starling", "258": "llama-3-stella-truthy-dpo-8B", "259": "sixtyoneeighty-FNCARL-7B-slerp", "260": "BurningBruce-005", "261": "Llama-3-Giraffe-70B", "262": "StrangeMerges_15-7B-slerp", "263": "NeuralStockFusion-7b", "264": "megatron_1.1_MoE_2x7B", "265": "QuantumBruins-7B-slerp", "266": "Blur-7b-slerp-v1.41", "267": "Beagle14-7B", "268": "flammen10-mistral-7B", "269": "pmmpk-EinstainMorcoro14KrishnaHercules-7b-slerp", "270": "Llama-3-8B-Instruct-abliterated-v2", "271": "supermario_v2", "272": "Barcenas-3.8b", "273": "flammen15-gutenberg-DPO-v1-7B", "274": "7Bx4_DPO_2e", "275": "Neurallaymons-7B-slerp", "276": "Llama-3-8B-Instruct-v0.5", "277": "caTUNABeagle", "278": "MixtureofMerges-MoE-4x7b-v4", "279": "NeuralKuke-4-All-7b", "280": "neurotic-crown-clown-7b-ties", "281": "mistral-7b-merged-dare_6x7", "282": "mistral-ft-optimized-1227", "283": "Senku-70B-Full", "284": "Valkyrie-V1", "285": "multi_verse_model", "286": "Mixtral_7Bx6_MoE_35B", "287": "MBX-7B", "288": "CognitiveFusion2-4x7B-BF16", "289": "go-bruins-v2.1.1", "290": "badger-zeta-l3-4x8b", "291": "NeuralSirKrishna-7b", "292": "Multimerge-Neurallaymons-12B-MoE", "293": "SmartLlama-3-8B-MS-v0.1", "294": "Mistral-7b-instruct-v0.2-summ-sft-ed2", "295": "Mistral-7B-Merge-14-v0.5", "296": "openmixtral-4x7b-merged", "297": "BruinHermes", "298": "MarcBeagle-7B", "299": "4bit_quant_TomGrc_FusionNet_34Bx2_MoE_v0.1_DPO", "300": "Mistroll-7B-v2.2", "301": "Bianca-7b", "302": "LeoScorpius-GreenNode-7B-v1", "303": "distilabeled-Marcoro14-7B-slerp", "304": "MergeTrix-7B", "305": "binarized-ingotrix-slerp-7b", "306": "Kaltsit-16x7B-bf16", "307": "LelaStarling-7B", "308": "StrangeMerges_21-7B-slerp", "309": "Taiwan-LLM-8x7B-DPO", "310": "Mahou-1.2a-llama3-8B", "311": "MistralTrix-SLERP", "312": "Ognoexperiment27Multi_verse_model-7B", "313": "Calme-4x7B-MoE-v0.1", "314": "MixTAO-7Bx2-MoE-v8.1", "315": "MAmmoTH2-7B-Plus", "316": "kuno-dogwalker-7b", "317": "Mayonnaise-4in1-02", "318": "SOLAR-math-2x10.7b", "319": "_model_llama_3_8B_Instruct_fine_tuned_xMR_1e", "320": "Calme-4x7B-MoE-v0.2", "321": "Llama-3-8B-Instruct-DPO-v0.4", "322": "LeoScorpius-GreenNode-Alpaca-7B-v1", "323": "Konstanta-7B", "324": "NeuralSynthesis-7b-v0.4-slerp", "325": "Mergerix-7b-v0.3", "326": "MultiverseEx26-7B-slerp", "327": "Darewin-7B", "328": "Quyen-Pro-v0.1", "329": "MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp", "330": "Fasciculus-Arcuatus-7B-slerp", "331": "NeuralMonarchCoderPearlBeagle-T3Q-Mistral-Orca-Math-DPO-7b", "332": "Mayonnaise-4in1-01", "333": "J4RVIZ-v6.0", "334": "mindy-7b-v2", "335": "NeuralOmniBeagleMBX-v3-7B", "336": "Meliodas-7b-dare", "337": "NeuralKrishna-7B-v3", "338": "Starling-dolphin-E26-7B", "339": "Llama-3-8B-Instruct-v0.2", "340": "SmaugDolphin-60B", "341": "grindin", "342": "NeuDist-Ro-7B", "343": "pee", "344": "TARS-8B", "345": "NeuralLLaMa-3-8b-DT-v0.1", "346": "NeuralSynthesis-7B-v0.3", "347": "Marcoro14-7B-ties", "348": "NeuralKrishnaMath-7B-slerp", "349": "Truthful_DPO_TomGrc_FusionNet_34Bx2_MoE", "350": "pikus-pikantny-7B-dare", "351": "NeuralMiLLaMa-8B-slerp", "352": "Percival_01-7b-slerp", "353": "mistral-7b-dpo-v6", "354": "WildMBXMarconi-SLERP-7B", "355": "Llama-3-8B-Ultra-Instruct-SaltSprinkle", "356": "FusionNet_34Bx2_MoE", "357": "StrangeMerges_11-7B-slerp", "358": "mistral-7b-dpo-merge-v1.1", "359": "NeuralSynthesis-7B-v0.1", "360": "dzakwan-MoE-4x7b-Beta", "361": "CatPPT", "362": "kuno-royale-v3-7b", "363": "Mistral-7B-Merge-14-v0.4", "364": "NeuralArjuna-7B-DT", "365": "Lelantos-7B", "366": "MixTAO-7Bx2-MoE-Instruct-v2.0", "367": "Neuraljack-12B-MoE", "368": "quantum-dpo-v0.1", "369": "MetaMath-bagel-34b-v0.2-c1500", "370": "Llama-3-8B-Instruct-DPO-v0.2", "371": "Tess-70B-v1.6", "372": "CCK_Asura_v3.0", "373": "TheTop-5x7B-Instruct-S5-v0.1", "374": "Valor_Macaroni_moe", "375": "Llama-3-15B-Instruct-zeroed", "376": "B3E3-SLM-7b-v3.0", "377": "TurdusDareBeagle-7B", "378": "bruphin-lambda", "379": "Meta-Llama-3-8B-Instruct-abliterated-v3", "380": "Llama-3-8B-Instruct-v0.1", "381": "Versatile-7B", "382": "PercivalMelodias-7B-slerp", "383": "metis-chat-instruct-7b", "384": "SuperFlammen-4x7B", "385": "T3QM7", "386": "JupiterMerge-7B-slerp", "387": "AbL3In-15B", "388": "MAmmoTH2-8B-Plus", "389": "GreenNodeLM-v3olet-7B", "390": "Jason1903_SLERP", "391": "NeuralMarcoro14-7B", "392": "nil_Llama-3-8B-Instruct_v0.1.0", "393": "StrangeMerges_16-7B-slerp", "394": "Chicka-Mistral-4x7b", "395": "FusionNet_7Bx2_MoE_14B", "396": "internlm2-20b-llama", "397": "Chicka-Mixtral-3x7b", "398": "Goku-8x22B-v0.1", "399": "Maxine-7B-0401-stock", "400": "WestOrcaNeural-V2-DARETIES-7B", "401": "blossom-v5-32b", "402": "CatPPT-base", "403": "StrangeMerges_32-7B-slerp", "404": "Mahou-1.1-llama3-8B", "405": "distilabeled-Marcoro14-7B-slerp-full", "406": "Pearl-7B-0211-ties", "407": "Chicka-Mistral-3x7b", "408": "SuperBruphin-3x7B", "409": "L3-test-2", "410": "megatron_2.1_MoE_2x7B", "411": "Einstein-4d-Marcoro14-nddmpk-KrishnaHercules-7b-slerp", "412": "mistral-7b-dpo-v5", "413": "Apollo-7B-0529-M-5", "414": "Llama-3-8B-Instruct-DPO-v0.3", "415": "StrangeMerges_9-7B-dare_ties", "416": "Multimerge-12B-MoE", "417": "Beyonder-4x7B-v3", "418": "T3QM7XP", "419": "Configurable-Yi-1.5-9B-Chat", "420": "dec10", "421": "BurningBruce-004", "422": "NeuralDareBeagle-7B-slerp", "423": "Mistral-7B-orca-dpo-2h", "424": "Beast-Soul", "425": "aegolius-acadicus-v1-30b", "426": "MultiCalm-7B-slerp", "427": "YamshadowExperiment28-7B", "428": "MetaMath-Cybertron", "429": "NeuralGanesha-7b", "430": "Halu-8B-Llama3-Blackroot", "431": "Omningotex-7b-slerp", "432": "Kinship-Exp-2", "433": "DareBeagel-2x7B", "434": "limyClown-7B-slerp", "435": "Jupiter-k-7B-slerp", "436": "OmniCorso-7B", "437": "Experiment26Yamshadow-7B", "438": "Mayonnaise-4in1-022", "439": "Mistral-7B-Instruct-adapt-v0.2", "440": "Severusectum-7B-DPO", "441": "PiVoT-SUS-RP", "442": "OmniTrixAI", "443": "Eris-Lelanacles-7b", "444": "MBX-7B-v2", "445": "J4RVIZ-v5.0", "446": "bruphin-epsilon", "447": "aegolius-acadicus-30b", "448": "haLLawa4-7b", "449": "kuno-dogpark-7b", "450": "NeuralSynthesis-7B-v0.2", "451": "MetaMath-Tulpar-7b-v2-Slerp", "452": "StrangeMerges_25-7B-dare_ties", "453": "test2_4", "454": "autotrain-cei9g-ag3pe", "455": "go-bruins-v2.1", "456": "blockchainlabs_joe_bez_seminar", "457": "Qwen-72B", "458": "experiment26-truthy-iter-1", "459": "MeliodasPercival_01_Experiment26T3q", "460": "experiment26-truthy-iter-2", "461": "Hermes-2-Theta-Llama-3-8B", "462": "Mutliverse_model_official", "463": "blockchainlabs_7B_merged_test2_4", "464": "Experiment26-7B", "465": "autotrain-mixtral7x8b-math", "466": "smol_bruin-7b", "467": "test3_sft_16bit", "468": "llama-3-spicy-abliterated-stella-8B", "469": "Calmex26merge-12B-MoE", "470": "35b-beta", "471": "experiment26-truthy-iter-0", "472": "Flammen-Bophades-7B", "473": "MixTAO-7Bx2-MoE-DPO", "474": "Cognito-2x7B-bf16", "475": "C0318-G", "476": "multimaster-7b-v6", "477": "INEX16-7b", "478": "NexoNimbus-7B", "479": "SilverMaiden-7B-slerp", "480": "Llama-3-8B-Ultra-Instruct", "481": "StarlingMaths-12B-MoE", "482": "neurotic-crown-clown-7b-tak-stack-dpo", "483": "Mistral-7B-sumz-dpo-3h", "484": "MergeM-7B", "485": "TripleMerge2-7B-Ties", "486": "blockchainlabs_test3_seminar", "487": "Neural-Krishna-Multiverse-7b-v3", "488": "jaskier-7b-dpo", "489": "L3-krai-test", "490": "NeuralContamination-7B-ties", "491": "LimmyAutomerge-7B-slerp", "492": "ladybird-base-7B-v8", "493": "FusionNet_7Bx2_MoE_v0.1", "494": "T3Q-Mistral-Orca-Math-DPO", "495": "shadow-clown-7B-slerp", "496": "MBX-7B-v3", "497": "BillyTheKid1803", "498": "ShadowM7EXP-7B", "499": "CombinaTrix-7B", "500": "RandomMergeNoNormWEIGHTED-7B-DARETIES", "501": "NeuralMathChat-7B-V0.2", "502": "WildMarcoroni-Variant1-7B", "503": "quantum-v0.01", "504": "AutoLimmy-7B-slerp", "505": "MyModelsMerge-7b", "506": "JARVIS-v2.0", "507": "StrangeMerges_23-7B-slerp", "508": "NeuralBeagle14-7B", "509": "Capricorn-7B-DPO", "510": "AlloyIngotNeoY", "511": "Myriad-7B-Slerp", "512": "TurdusTrixBeagle-DARETIES-7B", "513": "experiment26-SPIN-iter-0", "514": "Neural-Krishna-Multiverse-7b-v2", "515": "INEX4-7b", "516": "Mistral-7B-Instruct-adapt-v0.21", "517": "YamShadow-7B", "518": "Halu-8B-Llama3-CR-v0.45", "519": "Mistral-7B-summ-privatev1", "520": "Mistral-7B-Instruct-adapt-v0.23", "521": "Strangecoven-7B-slerp", "522": "Kindred-7B-slerp", "523": "Mistral-7B-Instruct-exp-e2", "524": "Ramakrishna-7b-v3", "525": "Experimentmultiverse-7B-slerp", "526": "StrangeMerges_50-7B-slerp", "527": "MoMo-70B-LoRA-V1.4", "528": "kuno-royale-v2-7b", "529": "StrangeMerges_30-7B-slerp", "530": "Mistral-7B-Instruct-adapt-v0.22", "531": "Configurable-Llama-3-8B-v0.2", "532": "quantum-trinity-v0.1", "533": "CatunaMayo-DPO", "534": "INEX12-7b", "535": "StrangeMerges_51-7B-dare_ties", "536": "Pegasus-7b-slerp", "537": "StrangeMonarch-7B-slerp", "538": "NeuralKukedlc-7B-Labonned", "539": "Hippy-AAI-7B", "540": "piccolo-math-2x7b", "541": "SuperThetaMaven", "542": "NeuralKrishna-7B-slerp", "543": "CalmExperiment-7B-slerp", "544": "OGNO-7B", "545": "StrangeMerges_43-7B-dare_ties", "546": "MetaMath-Chupacabra-7B-v2.01-Slerp", "547": "StrangeMerges_10-7B-slerp", "548": "WestOrcaNeuralMarco-DPO-v2-DARETIES-7B", "549": "NeuralMergeTest-001", "550": "Llama-3-LizardCoder-8B", "551": "supermario_v4", "552": "T3Q-Merge-Mistral7B", "553": "L3-krai-test-2", "554": "aqua-smaug-0.3-8B", "555": "Inex12Yamshadow-7B", "556": "slerp-test-turdus-beagle", "557": "StrangeMerges_42-7B-dare_ties", "558": "Kinship-Exp-1", "559": "Sectumsempra-7B-DPO", "560": "TurdusBeagle-7B", "561": "llama-3-8b-okay", "562": "Mergerix-7b-v0.4", "563": "WildWest-Variant3-7B", "564": "StarlingMaxLimmy-7B-slerp", "565": "ai-medical-model-32bit", "566": "Nous-Hermes-2-Yi-34B", "567": "openchat-3.5-0106-128k-DPO_dpo-binarized-NeuralTrix-7B", "568": "Calme-7B-Instruct-v0.2", "569": "a", "570": "OgnoMonarch-7B", "571": "OmniBeagle-7B", "572": "flammen15X-mistral-7B", "573": "KuTrix-7b", "574": "Westgate", "575": "NeuralBeagleJaskier", "576": "Llama-3-8B-Instruct-v0.3", "577": "Strangemerges_32Yamshadow-7B", "578": "llama-3-gutenberg-8B", "579": "supermario-slerp-v3", "580": "JARVIS-v3.0", "581": "CultriX-MoE-BF16", "582": "Padma-SLM-7b-v1.0", "583": "flammen13-mistral-7B", "584": "merge_7B_state_1", "585": "Pearl-7B-0210-ties", "586": "T3QM7X", "587": "StrangeMerges_26-7B-dare_ties", "588": "TW3CESCO.V2", "589": "neural-chat-7b-v3-3-Slerp", "590": "Nanashi-2x7B-bf16", "591": "StrangeMerges_31-7B-slerp", "592": "Calme-7B-Instruct-v0.9", "593": "B3E3-SLM-7b-v2.0", "594": "ChatMarc-YesAnotherMerge-7B", "595": "ShadowYamshadow-7B", "596": "Mayonnaise-4in1-03", "597": "MoMo-72B-LoRA-V1.4", "598": "Configurable-Llama-3-8B-v0.3", "599": "M7merge-7B-slerp", "600": "NeuralExperiment-7b-dare-ties", "601": "OmniBeagleSquaredMBX-v3-7B-v2", "602": "jaskier-7b-dpo-v7.1", "603": "Konstanta-Alpha-V2-7B", "604": "Zebrafish-7B", "605": "ThetaMaven5", "606": "Padma-SLM-7b-v3.0", "607": "go-bruins", "608": "Blurred-Beagle-7b-slerp", "609": "Neuralcoven-7B-slerp", "610": "kuno-royale-7b", "611": "yam-jom-7B-slerp", "612": "llama-3-nectar-dpo-8B", "613": "Buttercup-4x7B-bf16", "614": "NeuralFusion-7b-Dare-Ties", "615": "AlloyIngotNeoX", "616": "DistilabelCerberus-7B-slerp", "617": "Azathoth-16x7B-bf16", "618": "Llama-3-8B-Instruct-v0.7", "619": "MetaMath-neural-chat-7b-v3-2-Slerp", "620": "flammen5-mistral-7B", "621": "Marcoroni-neural-chat-7B-v2_gsm8k_merged_s", "622": "Experiment26Yam_Ognoexperiment27Multi_verse_model", "623": "yam-jom-7B-dare", "624": "ARC1", "625": "MetaMath-NeuralHermes-2.5-Mistral-7B-Linear", "626": "neural-chat-v3-3-8x7b-MoE", "627": "LeeMerge-7B-slerp", "628": "HaluAnjir-8B-L3-DD", "629": "pastiche-crown-clown-7b-dare", "630": "WestKunai-X-7b", "631": "Phoenix_DPO_60B", "632": "FusionNet_7Bx2_MoE_Ko_DPO_Adapter_Attach", "633": "Solutus-3x7B", "634": "Beast-Soul-new", "635": "ShadowNeural-7B-v1", "636": "Neuralmultiverse-7B-slerp", "637": "laserxtral", "638": "Test-7B", "639": "llama-3-stinky-v2-8B", "640": "MergeTest-7B-slerp", "641": "B3E3-SLM-7b-v1.0", "642": "StrangeMerges_22-7B-slerp", "643": "openchat-nectar-0.6", "644": "WestSeverus-7B", "645": "MixtureofMerges-MoE-4x7b-v5", "646": "mergekit-slerp-zplzqvn", "647": "Calme-7B-Instruct-v0.3", "648": "Pigris-7b-v0.3", "649": "Llama-3-8B-Instruct-abliterated-dpomix", "650": "Phi-3-mini-128k-instruct-HumanChoice-4.6k-DPO", "651": "Experiment26Yamshadow_Ognoexperiment27Multi_verse_model", "652": "TripleMerge-7B-Ties", "653": "llama3-8b_sa_v0.1", "654": "TW3CESCO.V3", "655": "stealth-v2", "656": "Blur-7b-slerp-v1.46", "657": "multimaster-7b-v4", "658": "NeuralsirkrishnaExperiment26-7B", "659": "go-bruins-v2", "660": "flammen3", "661": "jaskier-7b-dpo-v5.6", "662": "MBX-7B-v3-DPO", "663": "bophades-mistral-7B", "664": "openchat-nectar-0.1", "665": "WestMaid_HermesMonarchv0.1", "666": "flammen17-mistral-7B", "667": "ParrotOgno-7B", "668": "Wernicke-7B-v1", "669": "StrangeMerges_49-7B-dare_ties", "670": "shadow-clown-7B-dare", "671": "phi_3", "672": "YamshadowInex12_Multi_verse_modelExperiment28", "673": "Mistral-7B-Merge-14-v0.1", "674": "llama-3-slerp-kraut-dragon-8B", "675": "yam-jom-7B-ties", "676": "yam-jom-7B", "677": "Einstein-4D-MoE-2x7b-test", "678": "Lumina-RP", "679": "Experiment30-7B", "680": "WestLakeX-7B-EvoMerge", "681": "Mistral-7B-privatemix-ia1", "682": "Phi-3-Mini-4K-Boost", "683": "firefly-qwen1.5-en-14b-dpo-v0.1", "684": "Blur-7b-v1.21", "685": "Prokaryote-8x7B-bf16", "686": "Phi-3-mini-128k-instruct", "687": "flammen8-mistral-7B", "688": "NeuralPipe-7B-ties", "689": "YamshadowInex12_Experiment26T3q", "690": "Truthful_DPO_TomGrc_FusionNet_7Bx2_MoE_13B", "691": "ogno-monarch-jaskier-merge-7b-OH-PREF-DPO-v2", "692": "MultiVerse_LASER", "693": "Severus-7B-DPO", "694": "Configurable-Llama-3-8B-v0.1", "695": "YamshadowStrangemerges_32_Experiment24Ognoexperiment27", "696": "NeuralJaskier-7b-dpo", "697": "Mistral-7B-sumz-dpo-4h", "698": "Nous-Hermes-2-MoE-2x34B", "699": "Neural-Krishna-Multiverse-7b", "700": "Mistral-7B-orca-dpo-4h", "701": "M7Yamshadowexperiment28_Experiment26T3q", "702": "flammen11-mistral-7B", "703": "M7Yamshadowexperiment28_Strangemerges_30Experiment26", "704": "CalmeRity-stock", "705": "T3qm7xNeuralsirkrishna-7B", "706": "flammen6-mistral-7B", "707": "Open-StarLake-Swap-7B", "708": "Phi-3-mini-128k-instruct-LinearBunkaScore-4.6k-DPO", "709": "ogno-monarch-jaskier-merge-7b-OH-PREF-DPO", "710": "AlloyIngotNeo", "711": "jaskier-7b-dpo-v6.1", "712": "Nous-Hermes-2-SOLAR-10.7B", "713": "ogno-monarch-jaskier-merge-7b", "714": "Harpy-7B-Model_Stock", "715": "Llama-3-DARE-v3-8B", "716": "L3-SnowStorm-v1.15-4x8B-B", "717": "MixTAO-7Bx2-MoE-Instruct-v5.0", "718": "Franken-MoE-18B-v0.1", "719": "MixTAO-7Bx2-MoE-Instruct-v1.0", "720": "Llama-3-8B-Instruct-v0.4", "721": "llama-3-sqrt-crocodile-v0.0A", "722": "L-MChat-7b", "723": "Eris_PrimeV3.05-Vision-7B", "724": "bophades-mistral-math-DPO-7B", "725": "whattest", "726": "dpo-binarized-NeutrixOmnibe-7B", "727": "HeroBophades-2x7B", "728": "Eclipse-13B-dpo", "729": "Llama-3-11.5B-Instruct-v2", "730": "Experiment28Yam-7B", "731": "Mixtral_AI_Cyber_3.m1", "732": "Wernicke-7B-v8", "733": "Mergerix-7b-v0.5", "734": "Multiparadigm_7B", "735": "garten2-7b", "736": "llama-3-stinky-8B", "737": "Experiment27Pastiche-7B", "738": "bruphin-kappa", "739": "TheMayonnaise", "740": "bophades-mistral-truthy-DPO-7B", "741": "Meta-Llama-3-8B-Instruct", "742": "MixtureofMerges-MoE-2x7b-v6", "743": "MonarchCoder-MoE-2x7B", "744": "Experiment27Neuralsirkrishna-7B", "745": "llama-3-dragonmaid-8B-v2", "746": "MetaMath-NeuralHermes-2.5-Mistral-7B-Ties", "747": "ogno-monarch-jaskier-merge-7b-v2", "748": "Meta-Llama-3-8B-Instruct-LessResistant", "749": "Neural-4-ARC-7b", "750": "Calme-7B-Instruct-v0.1", "751": "OmniBeagleMBX-v3-7B", "752": "Prima-LelantaclesV7-experimental-7b", "753": "SUS-Bagel-200K-DARE-Test", "754": "oswald-7b", "755": "Experiment29Pastiche-7B", "756": "CatunaLaserPi-DPO", "757": "Llama-3-8B-Instruct-DPO-v0.1", "758": "NeuralLake-Variant1-7B", "759": "Experiment28-7B", "760": "Wernicke-7B-v9", "761": "BenchmarkEngineering-F2-7B-slerp", "762": "MiquMaid-v1-70B", "763": "Cyrax-7B", "764": "NeuralMarioMonarch-7B-slerp", "765": "Phi-SoSerious-Mini-V1", "766": "BenchmarkEngineering-7B-slerp", "767": "MixtureofMerges-MoE-2x7b-SLERPv0.9", "768": "flammen13X-mistral-7B", "769": "openchat-nectar-0.14", "770": "supermario_v3", "771": "UltraMerge-7B", "772": "slerp-bophades-truthy-math-mistral-7B", "773": "PasticheAlloyingotneoy-7B", "774": "DPOB-INMTOB-7B", "775": "SuperMente-7B-v4", "776": "ogno-monarch-jaskier-merge-7b-OH-PREF-DPO-v3", "777": "MetaMath-una-cybertron-v2-bf16-Ties", "778": "openbuddy-deepseek-67b-v18.1-4k", "779": "MetaMath-Mistral-2x7B", "780": "OmniBeagleSquaredMBX-v3-7B", "781": "Nous-Hermes-2-SOLAR-10.7B-MISALIGNED", "782": "NeuTrixOmniBe-7B-model-remix", "783": "Valor-7B-v0.1", "784": "Fewshot-Metamath-OrcaVicuna-Mistral", "785": "Calme-7B-Instruct-v0.1.1", "786": "Rose-2x7B", "787": "llama-3-merged-linear", "788": "MoeLovely-13B", "789": "contaminated_proof_7b_v1.0_safetensor", "790": "bophades-v2-mistral-7B", "791": "flammen18X-mistral-7B", "792": "Pigris-7b-v0.4", "793": "MixTAO-7Bx2-MoE-Instruct-v7.0", "794": "MergeTrix-7B-v2", "795": "NeuralKrishnaMathWizard-7B", "796": "ECE-TW3-JRGL-V1", "797": "SeverusWestLake-7B-DPO", "798": "Lelanta-lake-7b", "799": "AlloyIngot", "800": "WestKunai-Hermes-7b", "801": "Ogno-Monarch-Neurotic-7B-Dare-Ties", "802": "Monarch-7B", "803": "LeoScorpius-7B-Chat-DPO", "804": "Experiment31-7B", "805": "shqiponja-15b-v1", "806": "MixtureofMerges-MoE-2x7b-v7", "807": "Poppy_Porpoise-0.85-L3-8B", "808": "KingNish-Llama3-8b", "809": "AiMaven-Prometheus", "810": "NeuralPizza-WestSeverus-7B-Merge-slerp", "811": "jaskier-7b-dpo-v4.3", "812": "MBA-7B", "813": "ShadowYam-7B", "814": "NeuralTrix-7B-dpo-laser", "815": "Meta-Llama-3-8B-Uninstruct-function-calling-json-mode-model_stock-v0.1", "816": "NMTOB-7B", "817": "DPOB-NMTOB-7B", "818": "mistral-7b-merged-ties", "819": "JaskierMistral-7B-slerp", "820": "MarcoHermes", "821": "StarlingMaxLimmy2-7B-slerp", "822": "OGNO-7b-dpo-truthful", "823": "MedleyMD", "824": "CCK_Asura_v2.1", "825": "Suppe-v1-7B", "826": "Apollo-7b-orpo-Experimental", "827": "MixTAO-7Bx2-MoE-Instruct-v4.0", "828": "Mistral-7b-instruct-v0.2-summ-sft-dpo-e2", "829": "Neurotic-Jomainotrik-7b-slerp", "830": "INEX8-7B", "831": "Nous-Hermes-2-SOLAR-10.7B-x2-MoE", "832": "orthorus-125b-v2", "833": "StrangeMerges_24-7B-slerp", "834": "Blur-4x7b-MOE-v0.1", "835": "Buttercup-7b-dpo-slerp", "836": "pastiche-crown-clown-7b-dare-dpo", "837": "MixTAO-7Bx2-MoE-Instruct-v6.0", "838": "Aura_L3_8B", "839": "yam-sam-7B", "840": "MonaTrix-v4-7B-DPO", "841": "Mistral-7B-privatemix-ia2", "842": "merged-dpo-binarized-NeutrixOmnibe-7B", "843": "openchat-3.5-0106-laser", "844": "Buttercup-7b-dpo-ties", "845": "MonaTrix-7B-DPOv2", "846": "0.0005_llama_4iters_bs128_5551lr_iter_1", "847": "FNCARLplus-7b", "848": "MonaTrix-v4", "849": "StrangeMerges_27-7B-dare_ties", "850": "StrangeMerges_5-7B-ties", "851": "openbuddy-mistral-22b-v21.1-32k", "852": "SauerkrautLM-7b-LaserChat", "853": "Confinus-2x7B", "854": "Eris_Remix_DPO_7B", "855": "Tiamat-8b-1.2-Llama-3-DPO", "856": "ogno-monarch-jaskier-merge-7b-OH-PREF-DPO-v4-test", "857": "MetaMath-Mistral-7B", "858": "Halu-8B-Llama3-DT", "859": "SmartToxic-7B", "860": "GoldenMaiden-7B-model_stock", "861": "AiMaven-Merkaba-7b", "862": "MavenWest", "863": "Spaetzle-v69-7b", "864": "Merkaba-Maven-0.1", "865": "NeuralCeptrix-7B-slerp", "866": "TextBase-v0.2", "867": "MaidFlameSoup-7B", "868": "strange_3236-7B", "869": "Starling-LM-7B-beta-LaserRMT-v1", "870": "Experiment29-7B", "871": "ShadowNeural-7B-ORPO", "872": "NeuralDareDMistralPro-7b-slerp", "873": "Boundary-Meta-Llama-3-2x8B-MoE", "874": "Marengoli_7B_SLERP", "875": "Marcoro14-7B-slerp", "876": "llama3s-merged-linear", "877": "Umbra-v2.1-MoE-4x10.7", "878": "StrangeMerges_29-7B-dare_ties", "879": "ROGERphi-7B-slerp", "880": "Bagel-Hermes-2x34b", "881": "SeaLLM-7B-v2", "882": "CapybaraMarcoroni-7B", "883": "Eris_Remix_7B", "884": "llamaster-8B-v0.1", "885": "Llama-3-Unholy-8B", "886": "InnerILLM-7B-slerp", "887": "neuronal-7b-Mlab", "888": "PasticheInex12-7B", "889": "MixtureofMerges-MoE-v2", "890": "Sina-Thor-7b-Merge", "891": "Halu-OAS-8B-Llama3", "892": "Grafted-Wind-Elementals-2x70B", "893": "Neural-4-QA-7b", "894": "Excalibur-7B", "895": "MixSwap", "896": "Brocae-Area-7B-slerp", "897": "CeptrixBeagle-12B-MoE", "898": "NeuralPizza-7B-V0.2", "899": "openmixtral-6x7b-v2", "900": "OgnoExperiment27-7B", "901": "GreenNodeLM-7B-v4leo", "902": "macaroni-7b", "903": "openchat-nectar-0.4", "904": "StrangeMerges_4-7B-slerp", "905": "Dolphin-2.8-slerp", "906": "QuartetAnemoi-70B-t0.0001", "907": "Mistral-7B-sumz-dpo-5h", "908": "Buttercup-V2-bf16", "909": "StrangeMerges_36-7B-slerp", "910": "LHK_DPO_v1", "911": "Llama-3-8B-Instruct-ortho-baukit-toxic-n128-v3", "912": "UltraCatunaMayo-DPO", "913": "EmertonOmniBeagle-7B-dpo", "914": "NeuralDolphin-7B-slerp", "915": "Patronum-7B", "916": "iWillChangeTheNameLater", "917": "West-Hermes-7B", "918": "dbrx-base", "919": "newmerge", "920": "mistral-7b-merged-slerp", "921": "Configurable-Hermes-2-Pro-Llama-3-8B", "922": "MistralHermesPipe-7B-slerp", "923": "CCK_Asura_v1.1.0", "924": "NeuralTrixlaser-bf16", "925": "Einstein-4D-Marcoro14-7b-full-slerp", "926": "Llama-3-8B-Instruct-v0.8", "927": "O0128", "928": "Loyal-Macaroni-Maid-7B", "929": "Prima-LelantaclesV6.69-7b", "930": "WestlakeMaziyar-7B-slerp", "931": "openchat-nectar-0.11", "932": "TriFusionNexus-7b", "933": "complect-7B-slerp", "934": "Llama-3-LewdPlay-8B-evo", "935": "Experiment24-7B", "936": "Lelantos-DPO-7B", "937": "Chimera-7B-slerp", "938": "kiqu-70b", "939": "Mixtral_7Bx2_MoE", "940": "Llama-3-8B-Lexi-Uncensored", "941": "Monarch-7B-SFT", "942": "Lexi-Llama-3-8B-Uncensored", "943": "coven_7b_128k_orpo_alpha", "944": "flippa-exp26-v3-7b", "945": "NeuTrixOmniBe-DPO", "946": "Montebello_7B_SLERP", "947": "MonarchLake-7B", "948": "fiona-7B-v0.2", "949": "crown-clown-7b-slerp", "950": "Fewshot-Metamath-Mistral", "951": "jaskier-7b-dpo-v4.1", "952": "WestLakeX-7B-EvoMerge-Variant2", "953": "CreativeSmart-2x7B", "954": "Llama-3-8B-Instruct-ortho-baukit-toxic-v2", "955": "Lotus-7B", "956": "LuminariX-8B", "957": "MetaMath-neural-chat-7b-v3-2-Ties", "958": "WestLake-7B-v2-laser", "959": "llama3_ruozhiba_8b", "960": "supermario_v1", "961": "CosmicBun-8B", "962": "HeroBophades-3x7B", "963": "Mistral-Passthrough-8L-10B", "964": "T3Q-DPO-Mistral-7B", "965": "MixtureofMerges-MoE-4x7b-v3", "966": "llama3-8b-instruct-align-test1-kto", "967": "LadybirdPercival-7B-slerp", "968": "llama-3-merge-pp-instruct-8B", "969": "WONMSeverusDevil-TIES-7B", "970": "Orca-SOLAR-4x10.7b", "971": "Clown-DPO-Extended", "972": "NeuralTrix-7B-dpo-relaser", "973": "StrangeMerges_28-7B-dare_ties", "974": "Sphinx-7B-Model_Stock", "975": "llama3-8b-instruct-align-test2-kto", "976": "openchat-3.5-0106-32k", "977": "openchat-3.5-0106", "978": "openchat-3.5-0106-mod-gpt5", "979": "WestLake-7B-v2-laser-truthy-dpo", "980": "openchat-nectar-0.5", "981": "Unsafe-Llama-3-8B", "982": "0.0_llama_nodpo_3iters_bs128_531lr_iter_1", "983": "Spaetzle-v8-7b", "984": "Code-Mistral-7B", "985": "T3Q-EN-DPO-Mistral-7B", "986": "CCK_Asura_v1", "987": "NeuralKrishna-7B-V2-DPO", "988": "Experiment27-7B", "989": "EmertonMonarch-7B-slerp", "990": "Buttercup-V2-laser", "991": "llama-3-wissenschaft-8B", "992": "yi-9b-may-ortho-baukit-30fail-3000total-bf16", "993": "Beagle_Turdus", "994": "CeramicMaiden-7B-Slerp", "995": "NeuralTrix-7B-dpo", "996": "WestLakeMultiverse-12B-MoE", "997": "multimaster-7b-v5", "998": "dpo-binarized-NeuralTrix-7B", "999": "Miqu-MS-70B", "1000": "Llama-Phi-3_DoRA", "1001": "Mistral-7B-private-spef", "1002": "StrangeMerges_40-7B-dare_ties", "1003": "Yi-1.5-34B-Chat-16K", "1004": "MasherAI-v6.1-7B-checkpoint3", "1005": "T3Q-Mistral-UB-DPO-v1.0", "1006": "0.0005_llama_nodpo_3iters_bs128_531lr_iter_1", "1007": "0.001_llama-3_nodpo_3iters_bs128_531lr_iter_1", "1008": "Mistral-7B-adaptv0.9", "1009": "Hermes-2-Pro-Llama-3-8B", "1010": "Lumina-3.5", "1011": "LuminRP-7B", "1012": "LuminRP-7B-128k-v0.2", "1013": "Starling-LM-7B-beta-laser-dpo", "1014": "Griffon-7B-Model_Stock", "1015": "Direct-sm-private-e1", "1016": "test_dataset_Codellama-3-8B", "1017": "TextBase-7B-v0.1", "1018": "NinjaDolphin-7B", "1019": "jaskier-7b-dpo-v3.3", "1020": "openchat-nectar-0.7", "1021": "MathDolphin-7B", "1022": "miiqu-f16", "1023": "L3-RP_io", "1024": "Saul-Instruct-Clown-7b", "1025": "Experiment25-7B", "1026": "Blurdus-7b-v0.1", "1027": "Lamma3merge2-15B-MoE", "1028": "MonaTrix-v6", "1029": "Eris_PrimeV4-Vision-7B", "1030": "West-Dare-7B", "1031": "Bophades-BruinsMaid-7B", "1032": "Anjir-8B-L3", "1033": "NeuralMaxime-7B-slerp", "1034": "blossom-v5-14b", "1035": "stealth-rag-v1.1", "1036": "NeuralMonarch-7B", "1037": "bruphin-iota", "1038": "OpenHermes-2.5-neural-chat-v3-3-Slerp", "1039": "una-cybertron-7b-v3-OMA", "1040": "orca_mini_v5_8b_dpo", "1041": "Oxide-F1-7B-slerp", "1042": "Defne_llama3_2x8B", "1043": "flammen16-mistral-7B", "1044": "Eris_PrimeV3-Vision-7B", "1045": "Eris-Floramix-7b", "1046": "SOLAR-10.7B-NahIdWin", "1047": "FrankenDPO-4x7B-bf16", "1048": "openchat-nectar-0.8", "1049": "MiaAffogato-Indo-Mistral-7b", "1050": "Eris-Daturamix-7b", "1051": "Olethros-8B", "1052": "openchat-nectar-0.3", "1053": "MoE-StrangeMerges-2x7B", "1054": "miqu-1-70b-sf", "1055": "Turdus", "1056": "Qwen2-beta-14B", "1057": "Mistral-7b-instruct-v0.2-summ-dpo-ed2", "1058": "Marcoroni-7b-DPO-Merge", "1059": "WestMonarchLasers-7B-slerp", "1060": "OpenMia-Indo-Mistral-7b-v3", "1061": "Wernicke-7B-dpo", "1062": "llama-3-merge-avalon-8B", "1063": "PrometheusLaser-7B-slerp", "1064": "connate-7B-slerp", "1065": "WestLake-7B-v2", "1066": "MoE_13B_DPO", "1067": "Yuna-7b-Merge", "1068": "Qwen1.5-14B", "1069": "TW3CESCO.V4", "1070": "DARE_TIES_13B", "1071": "Samlagast-7B-bf16", "1072": "orca_mini_v5_8b", "1073": "Eris_Floramix_DPO_7B", "1074": "ChimeraLlama-3-8B", "1075": "Miqu-70B-Alpaca-DPO", "1076": "ChatHercules-2.5-Mistral-7B-DPO", "1077": "Prima-LelantaclesV6-7b", "1078": "RoyalMaid-7B-slerp", "1079": "Chimera-8B", "1080": "Test2_SLIDE", "1081": "dolphin-2.9.1-mixtral-1x22b", "1082": "Mistral-7b-instruct-v0.2-summ-dpo-ed3", "1083": "penny5-dolphin-einstein-llama3-dare-ties-chatml", "1084": "Pearl-34B-ties", "1085": "test3_sft_16bit_dpo2", "1086": "flammen27-mistral-7B", "1087": "Cognate-7B-slerp", "1088": "WizardMath-7B-V1.1", "1089": "Mistral-7B-orca-dpo-8h", "1090": "NeuralMona_MoE-4x7B", "1091": "flammen3X", "1092": "CosmicNoodle-7B", "1093": "Beyonder-4x7B-random-lora", "1094": "Trillama-8B", "1095": "BoreanGale-70B", "1096": "NeuralTurdusVariant1-7B", "1097": "nil_Llama-3-8B-Instruct_v0.1.1", "1098": "llama-3-lumimaid-habib-v3", "1099": "Llama-3-8B-Instruct-Coder", "1100": "Distilled-HermesChat-7B", "1101": "dbrx-instruct", "1102": "Faraday-7B", "1103": "meta-llama-3-8b-instruct-hf-ortho-baukit-2fail-128total", "1104": "openchat-3.5-0106-128k-DPO", "1105": "StrangeMerges_8-7B-slerp", "1106": "orca_mini_v4_8b", "1107": "Mistral-7B-Merge-02-v0", "1108": "SFR-Iterative-DPO-LLaMA-3-8B-R", "1109": "SOVL-Mega-Mash-L3-8B", "1110": "StrangeMerges_7-7B-slerp", "1111": "Llama3-8B-Chinese-Chat-v2-nightly", "1112": "NeuralTrix-bf16", "1113": "ScaleDown-7B-slerp-v0.1", "1114": "llama-3-lumimaid-habib-v7", "1115": "Orthocopter_8B", "1116": "openbuddy-deepseek-67b-v15.3-4k", "1117": "MonaCeption-7B-SLERP-DPO", "1118": "BetterSaul-7B-slerp", "1119": "Llama3-8B-Chinese-Chat", "1120": "e.star.7b", "1121": "MoNeuTrix-7B-v1", "1122": "Llama3-8B-Chinese-Chat-v2-nightly-v2", "1123": "Bombus_3x8B_v2", "1124": "Westlake-7B", "1125": "WestSeverusJaskier-OpenOrca", "1126": "A0120", "1127": "NarumashiRTS-V2", "1128": "13B_MATH_DPO", "1129": "Yi-1.5-6B-Chat", "1130": "GreenNodeLM-7B-v2leo", "1131": "NeuralTrix-7B-v1", "1132": "flammen22-mistral-7B", "1133": "llama3-8b-spaetzle-v13", "1134": "openchat-3.5-1210-starling-slerp", "1135": "NeuralMonarchCoderPearlBeagle", "1136": "Bald-Eagle-7B", "1137": "llama3-8b-spaetzle-v20", "1138": "flammen29-mistral-7B", "1139": "Kunoichi-7B", "1140": "60B_MoE_Coder_v3", "1141": "final_model_test_v2", "1142": "CarbonBeagle-11B", "1143": "openbuddy-deepseek-67b-v15.1", "1144": "Evangelion-7B", "1145": "Magistral-7B-v0.1", "1146": "HelpingAI-8B", "1147": "luxia-21.4b-alignment-v1.2", "1148": "openbuddy-deepseek-67b-v15.2", "1149": "v1olet_merged_dpo_7B_v3", "1150": "0.0005_llama_nodpo_3iters_bs128_531lr_iter_2", "1151": "Fimbulvetr-Kuro-Lotus-10.7B", "1152": "GreenNodeLM-7B-v1olet", "1153": "Asherah_7B", "1154": "BrurryDog-7b-v0.1", "1155": "Lowke-2x7B-v1", "1156": "Paradigm_7B", "1157": "Mistral-7b-instruct-v0.2-summ-sft-dpo-e1", "1158": "flammen21X-mistral-7B", "1159": "DonutLM-v1", "1160": "SOVL-Mega-Mash-V2-L3-8B", "1161": "Llama-3-Neurona-8b", "1162": "Gigi-Llama3-8B-Chinese-zh", "1163": "Draco-8x7B", "1164": "Lelantos-low-tune", "1165": "Kaiju-11B", "1166": "Nimue-7B", "1167": "meta-llama-3-8b-instruct-hf-ortho-baukit-10fail-1000total", "1168": "WestSeverus-ORPO-7B", "1169": "MasherAI-v6.1-7B-checkpoint6-pro", "1170": "Test-Instruct-Solar-v1", "1171": "UNA-TheBeagle-7b-v1", "1172": "kuno-kunoichi-v1-DPO-v2-SLERP-7B", "1173": "Llama3merge7-15B-MoE", "1174": "Mistral-7B-Merge-14-v0", "1175": "Mistral-7B-private-sia", "1176": "AlphaMonarch-7B", "1177": "Mergerix-7b-v0.1", "1178": "Mistrality-7B", "1179": "NeuralDarewin-7B", "1180": "AlphaMonarch-laser", "1181": "RoyalNoroichi-7B-slerp", "1182": "Mistral-7B-adaptv1", "1183": "Fimbulvetr-10.7B-v1", "1184": "Experiment20-7B", "1185": "Mistralchat-7B-slerp", "1186": "0.001_llama-3_nodpo_3iters_bs128_531lr_iter_2", "1187": "StrangeMerges_6-7B-dare_ties", "1188": "Ortho-SOVL-8B-L3", "1189": "Starling-LM-7B-beta", "1190": "Mistral-7B-privatemix-ia3", "1191": "NeuralCeptrix-7B-SLERP", "1192": "0.0_llama_nodpo_3iters_bs128_531lr_iter_2", "1193": "Experiment22-7B", "1194": "Mistroll-7B-v2.3-NoTsOsm4rt-16bit", "1195": "flammen22C-mistral-7B", "1196": "CodeNinja-1.0-OpenChat-7B", "1197": "Collaiborator-MEDLLM-Llama-3-8B", "1198": "Llama4Some-SOVL-4x8B-L3-V1", "1199": "cr-model-v1", "1200": "MergeCeption-7B-v3", "1201": "WestKunai-XD-7b", "1202": "WestLakeLaser-12B-MoE", "1203": "Liberated-Qwen1.5-14B", "1204": "Aura_v2_7B", "1205": "0.0_llama_nodpo_3iters_bs128_531lr_iter_3", "1206": "0.0005_llama_4iters_bs128_5551lr_iter_2", "1207": "blossom-v4-qwen1_5-14b", "1208": "L3-SnowStorm-v1.15-4x8B-A", "1209": "0ai-7B-v5", "1210": "Eros_n_Psyche-7B-Model_Stock", "1211": "Llama-3-8B-Instruct-v0.9", "1212": "TheTop-5x7B-Instruct-T-v0.1", "1213": "NarumashiRTS-V1", "1214": "0.001_llama-3_nodpo_3iters_bs128_531lr_iter_3", "1215": "Barcenas-Llama3-8b-ORPO", "1216": "flammen12-mistral-7B", "1217": "Multi-Verse-RP-7B", "1218": "LeoScorpius-7B", "1219": "Mistral-7b-instruct-v0.2-summ-sft-dpo-ed2", "1220": "EmertonBeagle-7B-dpo", "1221": "OpenBeagle-11B", "1222": "TextSum-v0.1", "1223": "finch", "1224": "InfinityKuno-2x7B", "1225": "TextBase-v0.1", "1226": "Aurora-Nights-70B-v1.0", "1227": "fbt-llama-8b-inst", "1228": "habib-DPO-v2", "1229": "flammen9X-mistral-7B", "1230": "NeuralPipe-7B-slerp-DPO", "1231": "dolphin-2.9.1-llama-3-8b", "1232": "Mistral-7b-instruct-v0.2-summ-sft-dpo-ed3", "1233": "AlphaMonarch-daser", "1234": "WizardDolphin-7B", "1235": "Cypher-7B", "1236": "Mistral-7B-Merge-14-v0.3", "1237": "Eris_7B", "1238": "Bagel-Hermes-34B-Slerp", "1239": "IamSoTired-7B-slerp", "1240": "Synatra-MCS-7B-v0.3-RP-Slerp", "1241": "mistral_tv-neural-marconroni", "1242": "Deita-34b", "1243": "Llama-3-Lumimaid-8B-v0.1", "1244": "Maverick-Math-7B", "1245": "oswald-4x7b", "1246": "NeuralExperiment-7b-MagicCoder-v7.5", "1247": "MasherAI-v6.1-7B-checkpoint6", "1248": "CarbonBeagle-11B-truthy", "1249": "Pluto_24B_DPO_63", "1250": "WildMarcoroni-Variant3-7B", "1251": "flammen20-mistral-7B", "1252": "Kuro-Lotus-10.7B", "1253": "Einstein-v6.1-Llama3-8B", "1254": "mera-mix-4x7B", "1255": "Merged-RP-Stew-V2-34B", "1256": "Peagle-9b", "1257": "habib-DPO", "1258": "opus-v1.2-llama-3-8b", "1259": "flammen24-mistral-7B", "1260": "autotrain-llama3-orpo-v2", "1261": "Siren-7B-slerp", "1262": "flammen", "1263": "reverie-7b", "1264": "orca_mini_v5_8b_orpo", "1265": "ToppyLake-7B-slerp", "1266": "GarrulusMarcoro-7B-v0.1", "1267": "Top-Western-Maid-7B", "1268": "Experiment21-7B", "1269": "StarlingHermes-2.5-Mistral-7B-slerp", "1270": "openchat-3.5-1210", "1271": "Hercules-Qwen1.5-14B", "1272": "Kunoichi-DPO-v2-7B", "1273": "cr-model", "1274": "llama-3-lumimaid-habib-v5", "1275": "Llama-3-DARE-v1-8B", "1276": "llama-3-experiment-v1-9B", "1277": "Pluto_24B_DPO_200", "1278": "RoleBeagle-11B", "1279": "SkkuDS-DPO-72B-v1", "1280": "StarlingMaid-2x7B-base", "1281": "ExtremeDolphin-MoE", "1282": "A0126", "1283": "l3-badger-mushroom-4x8b", "1284": "ComplectMaid-7B-slerp", "1285": "Maidphin-Kunoichi-7B", "1286": "CCK_Asura_v2", "1287": "openbuddy-yi1.5-9b-v21.1-32k", "1288": "Llama-3-DARE-v2-8B", "1289": "Llama-3-monika-ddlc-11.5b-v1", "1290": "Mistral_7B_SFT_DPO_v0", "1291": "Llama-3-8b-Ita", "1292": "Flora_DPO_7B", "1293": "flammen11X-mistral-7B", "1294": "shark_tank_ai_7_b", "1295": "flammen9-mistral-7B", "1296": "AlphaCeption-7B-v1", "1297": "llama-3-8b-claudstruct-v2", "1298": "Qwen2-beta-72B", "1299": "SkkuDataScienceGlobal-10.7b", "1300": "Westest-7B", "1301": "AlphaMonarch-dora", "1302": "Qwen1.5-72B", "1303": "Samlagast-7B-laser-bf16", "1304": "Satyr-7B-Model_Stock", "1305": "llamaRAGdrama", "1306": "Starling-LM-7B-beta-ExPO", "1307": "flammen23X-mistral-7B", "1308": "open_llm_leaderboard_demo", "1309": "Bumblebee-7B", "1310": "habib-DPO-v3", "1311": "WestLake_Noromaid_OpenHermes_neural-chat", "1312": "openbuddy-qwen1.5-32b-v21.1-32k", "1313": "RolePlayLake-7B-Toxic", "1314": "Everyone-LLM-7b-Base", "1315": "Datura_7B", "1316": "CarbonVillain-en-10.7B-v4", "1317": "SOLAR-tail-10.7B-Merge-v1.0", "1318": "blossom-v5.1-34b", "1319": "Llama3-ChatQA-1.5-70B", "1320": "Marcoroni-7B-v2", "1321": "Master-Yi-9B", "1322": "Mistral-7b-instruct-v0.2-private-eds2", "1323": "meta-llama-3-8b-instruct-hf-ortho-baukit-5fail-3000total-bf16", "1324": "Optimus-7B", "1325": "MaidStarling-2x7B-base", "1326": "test-7B-slerp", "1327": "Fuselage-8B", "1328": "monika-ddlc-8b-v1", "1329": "MetaModel_moe", "1330": "Experiment19-7B", "1331": "InfinityLake-2x7B", "1332": "Excalibur-7b-DPO", "1333": "Llama-3-monika-ddlc-8b-v1", "1334": "Yi-34B-200K-DARE-megamerge-v8", "1335": "SOLARC-M-10.7B", "1336": "dolphin-2.9.1-yi-1.5-9b", "1337": "WhyAreWeStillHere-7B-slerp", "1338": "Open_Hermes_Maid_Sam_Mistral_dtv0.1", "1339": "MetaModel", "1340": "MetaModel_moex8", "1341": "Kuno-Lake-7B", "1342": "zen_moe", "1343": "Sakura-SOLAR-Instruct-CarbonVillain-en-10.7B-v2-slerp", "1344": "Flora_7B", "1345": "openbuddy-mixtral-7bx8-v18.1-32k", "1346": "Yi-34B-200K-DARE-merge-v7", "1347": "flammen23-mistral-7B", "1348": "Open_Maid_Samantha_Hermes_Orca_dare_ties", "1349": "FusionNet_linear", "1350": "llama-3-wissenschaft-8B-v2", "1351": "HermesBagel-34B-v0.1", "1352": "Loyal-Toppy-Bruins-Maid-7B-DARE", "1353": "Solar-OrcaDPO-Solar-Instruct-SLERP", "1354": "Faro-Yi-34B", "1355": "DaturaCookie_7B", "1356": "Mixtral_11Bx2_MoE_19B", "1357": "llama3-8b-spaetzle-v33", "1358": "Merge-Mayhem-L3-V2.1", "1359": "MetaModelv3", "1360": "Faro-Yi-34B-200K", "1361": "CarbonVillain-en-10.7B-v2", "1362": "EmertonMonarch-7B", "1363": "Sakura-SOLAR-Instruct", "1364": "Yi-32b-x2-v2.0", "1365": "Jallabi-34B", "1366": "CarbonVillain-en-10.7B-v3", "1367": "Smart-LLaMa-3-8b-Python-v4", "1368": "where-llambo-7b", "1369": "StopCarbon-10.7B-v5", "1370": "WestLake_Noromaid_OpenHermes_neural-chatv0.1", "1371": "Phi-3-mini-4k-instruct-bnb-4bit-Ita", "1372": "MonarchCoder-7B", "1373": "bleagle-7b-v0.1-test", "1374": "Lumosia-v2-MoE-4x10.7", "1375": "Awanllm-Llama-3-8B-Instruct-DPO-v0.1", "1376": "Poppy_Porpoise-0.72-L3-8B", "1377": "RolePlayLake-7B", "1378": "Medes-7B", "1379": "FusionNet", "1380": "trinity-medium", "1381": "SkkuDS-DPO-72B-v3", "1382": "ChatHercules-2.5-Mistral-7B", "1383": "Llama-3-SauerkrautLM-8b-Instruct", "1384": "flammen2", "1385": "yi-34B-v2", "1386": "firefly-qwen1.5-en-14b-alpha", "1387": "LMCocktail-10.7B-v1", "1388": "Newton-OpenHermes-2.5-neural-chat-v3-3-Slerp", "1389": "MasherAI-v6.1-7B-checkpoint3-code4", "1390": "Llama-3-Instruct-demi-merge-8B", "1391": "Mixtral_7Bx2_MoE_DPO", "1392": "0.0005_llama_4iters_bs128_5551lr_iter_3", "1393": "OpenMia-Indo-Engineering", "1394": "IceCoffeeTest8", "1395": "MoeMoE-2x7b", "1396": "Llama-3-8B-Instruct-OAS", "1397": "OpenMia-Indo-Engineering-7b", "1398": "SOLARC-MOE-10.7Bx6", "1399": "SOLAR-math-2x10.7b-v0.2", "1400": "meow", "1401": "Prima-LelantaclesV5-7b", "1402": "Fimbulvetr-11B-v2-Test-14", "1403": "A0110", "1404": "SOLAR-10B-OrcaDPO-Jawade", "1405": "Faro-Yi-9B-DPO", "1406": "SOLAR-10.7B-Instruct-v1.0", "1407": "SOLAR-10.7B-Instruct-SOLARC-M-10.7B-slerp", "1408": "UNA-POLAR-10.7B-InstructMath-v2", "1409": "StrangeMerges_35-7B-slerp", "1410": "Umbra-MoE-4x10.7", "1411": "Experiment7-7B", "1412": "Skadi-Mixtral-v1", "1413": "haLLAwa3", "1414": "SolarM-SakuraSolar-SLERP", "1415": "SauerkrautLM-UNA-SOLAR-Instruct-test", "1416": "Tippy-Toppy-7b", "1417": "A0127", "1418": "llama-3-merge-virt-req-8B", "1419": "Luna_7B", "1420": "Poppy_Porpoise-0.96-L3-8B", "1421": "SauerkrautLM-UNA-SOLAR-Instruct", "1422": "Fimbulvetr-11B-v2", "1423": "test1", "1424": "Solar-10.7B-Cato", "1425": "OpenZephyrChat", "1426": "Mistral-7B-private-oia", "1427": "SOLAR-10B-Nector-DPO-Jawade", "1428": "Awanllm-Llama-3-8B-Instruct-ORPO-v0.1", "1429": "testmerge-7b", "1430": "Phi-3-Mini-4K-Boost_v2", "1431": "LimyQstar-7B-slerp", "1432": "RPLakeCoder-TxC", "1433": "Prometheus-1.3", "1434": "Garrulus", "1435": "yi-34B-v3", "1436": "MixtureofMerges-MoE-2x7bRP-v8", "1437": "Truthful_DPO_MOE_19B", "1438": "StopCarbon-10.7B-v6", "1439": "llama-3-8b-claudstruct-v1", "1440": "MFANNv0.8", "1441": "StarFusion-alpha2", "1442": "0.0005_llama_nodpo_3iters_bs128_531lr_oldtrl_iter_2", "1443": "Chimera-Apex-7B", "1444": "MasherAI-7B-v6.1", "1445": "SOLAR-10.7B-Instruct-Forest-DPO-v1", "1446": "SOVLish-Maid-L3-8B", "1447": "openchat_3.5-gpt-4-80k", "1448": "MetaModelv2", "1449": "CarbonVillain-en-10.7B-v5", "1450": "dolphin-2.9-llama3-8b", "1451": "Experiment8-7B", "1452": "WizardLM-Math-70B-v0.1", "1453": "StopCarbon-10.7B-v4", "1454": "Eris_PrimeV3.075-Vision-7B", "1455": "Pasta-Lake-7b", "1456": "A0109", "1457": "Seraphim-8x10.7B-bf16", "1458": "KuroMitsu-11B", "1459": "StrangeMerges_17-7B-dare_ties", "1460": "MFANNv0.5", "1461": "Prodigy_7B", "1462": "SOLARC-MOE-10.7Bx4", "1463": "L3-ChaoticSoliloquy-v1.5-4x8B", "1464": "Mahou-1.0-mistral-7B", "1465": "SwedishBeagle-dare", "1466": "CarbonVillain-en-10.7B-v1", "1467": "SOLAR-Instruct-ko-Adapter-Attach", "1468": "BrokenKeyboard", "1469": "openchat-3.5-Infinity", "1470": "CarbonVillain-en-13B-v1", "1471": "WestIceLemonTeaRP-32k-7b", "1472": "IceCoffeeTest11", "1473": "LeoScorpius-GreenNode-Platypus-7B-v1", "1474": "Delexa-7b-128k", "1475": "Dionysus-Mistral-m3-v6", "1476": "IceLatteRP-7b", "1477": "llama-3-8b-claudstruct-v3", "1478": "Delexa-7b", "1479": "amadeus-v0.1", "1480": "BurningBruce-SOLAR-8x10.7B-bf16", "1481": "blossom-v4-yi-34b", "1482": "SauerkrautLM-SOLAR-Instruct", "1483": "StopCarbon-10.7B-v1", "1484": "SOLAR-10.7B-Instruct-ties", "1485": "IceCaffeLatteRP-7b", "1486": "SynthIQ-7b", "1487": "Bumbar-7B-slerp", "1488": "StarFusion-alpha1", "1489": "Konstanta-V4-Alpha-7B", "1490": "Kunoichi-DPO-7B", "1491": "speechless-mistral-dolphin-orca-platypus-samantha-WestSeverusJaskier-7b", "1492": "Merge_Sakura_Solar", "1493": "ChaoticSoliloquy-4x8B", "1494": "Sakura-SOLRCA-Math-Instruct-DPO-v2", "1495": "Llama-3-Lumimaid-8B-v0.1-OAS", "1496": "Nanbeige2-16B-Chat", "1497": "Mixolar-4x7b", "1498": "BeagleLake-7B", "1499": "ConfigurableBeagle-11B", "1500": "Smart-LLama-3-8b-Python-v5", "1501": "L3_SnowStorm_4x8B", "1502": "Sakura-SOLRCA-Math-Instruct-DPO-v1", "1503": "supermario-slerp-v2", "1504": "MFANNv0.4", "1505": "Mistral_Sonyichi-7B-slerp", "1506": "StopCarbon-10.7B-v2", "1507": "Hermes-low-tune-3", "1508": "Maylin-7b", "1509": "Experiment9-7B", "1510": "19B_MATH_DPO", "1511": "Sakura-SOLAR-Instruct-DPO-v2", "1512": "SauerkrautLM-Gemma-7b", "1513": "EveryNight-7B-slerp", "1514": "KukulStanta-7B", "1515": "llama-3-lumimaid-habib", "1516": "Konstanta-Gamma-V2-9B", "1517": "Starling-low-tune", "1518": "DPOpenHermes-7B-v2", "1519": "Mahou-1.2a-mistral-7B", "1520": "Tito-7B-slerp", "1521": "dolphin-2.8-experiment26-7b-preview", "1522": "RPMix-4x7B-MoE", "1523": "Tulpar-7b-v2", "1524": "Venus_DPO_50", "1525": "BeagleLake-7B-Toxic", "1526": "J.O.S.I.E.3-Beta11-7B-slerp", "1527": "EveryoneLLM-7b-Gemma-Base", "1528": "Einstein-v6-7B", "1529": "UNA-ThePitbull-21.4B-v2", "1530": "CodeCalc-Mistral-7B", "1531": "Delexa-V0.1-7b", "1532": "InfinityKumon-2x7B", "1533": "DiscoLM-70b", "1534": "Laser-WestLake-2x7b", "1535": "Aura_7B", "1536": "Experiment1-7B", "1537": "Collaiborator-MEDLLM-Llama-3-8B-v1", "1538": "Hermes-low-tune-2", "1539": "Pearl-34B-dare", "1540": "Experiment10-7B", "1541": "Nyxene-v3-11B", "1542": "Everyone-Coder-4x7b-Base", "1543": "openchat-spin-slimorca-iter0", "1544": "NeuralZephyr-Beagle-7B", "1545": "Experiment4-7B", "1546": "Sakura-SOLRCA-Instruct-DPO", "1547": "FuseChat-7B-VaRM", "1548": "Hermes-low-tune-3.1", "1549": "IceCoffeeTest2", "1550": "ConfigurableSOLAR-10.7B", "1551": "UNA-SOLAR-10.7B-Instruct-v1.0", "1552": "FrankenBeagle-SmallOverlap-test", "1553": "mistral-orpo-beta-NeuralBeagle14-7B-dare-ties", "1554": "A0123", "1555": "Merged-AGI-7B", "1556": "Pearl-7B-0210-dare", "1557": "una-xaberius-34b-v1beta", "1558": "7Bx4_DPO_700", "1559": "Argetsu", "1560": "typhoon-7b-instruct-01-30-2024", "1561": "zephyr-wizard-kuno-royale-BF16-merge-7B", "1562": "Diana-7B", "1563": "StopCarbon-10.7B-v3", "1564": "A0124", "1565": "OnlyForTestingIceLatteRP-7b-SmallQloraMerge", "1566": "Copium-Cola-9B", "1567": "PAIN_LeDestroy-7B-task_arithmetic", "1568": "SLAL-0.1", "1569": "Luna-2x7B-MoE", "1570": "flammen26-mistral-7B", "1571": "Kudzu-8B", "1572": "Umbra-v3-MoE-4x11b", "1573": "StockFuseChat", "1574": "OpenHermes-2.5-neural-chat-v3-2-Slerp", "1575": "openchat-spin-slimorca-iter1", "1576": "Starling-LM-7B-alpha-gpt-4-80k", "1577": "Hercules-4.0-Yi-34B", "1578": "Brunhilde-2x7b-MOE-DPO-v.01.5", "1579": "Faro-Yi-9B", "1580": "Faro-Yi-9B-200K", "1581": "Llama-3-8B-Synthia-v3.5", "1582": "ArcaneEntanglement-model64-70b", "1583": "NeuralStar_AlphaWriter_4x7b", "1584": "TenyxChat-7B-v1", "1585": "Delexa-Instruct-V0.1-7b", "1586": "Yi-34B-200K-DARE-merge-v5", "1587": "luxia-21.4b-alignment-v0.1", "1588": "Tess-34B-v1.5b", "1589": "internlm2-7b-llama", "1590": "KangalKhan-RawEmerald-7B", "1591": "Metabird-7B", "1592": "Blurstral-7b-slerp", "1593": "This_is_fine_7B", "1594": "luxia-21.4b-alignment-v0.3", "1595": "cuckoo-starling-7B", "1596": "neuronovo-9B-v0.4", "1597": "MistralTrix-v1", "1598": "KangalKhan-SharpEmerald-7B", "1599": "cuckoo-starling-32k-7B", "1600": "Spaetzle-v12-7b", "1601": "PMaxxxer-v1-70b", "1602": "Pallas-0.2", "1603": "Yi-1.5-9B", "1604": "14B-DPO-alpha", "1605": "luxia-21.4b-alignment-v0.4", "1606": "tulu-2-dpo-70b", "1607": "HuginnV5.5-12.6B", "1608": "dolphin-2.8-experiment26-7b", "1609": "StrangeMerges_12-7B-slerp", "1610": "L3-Arcania-4x8b", "1611": "Llama-3-8b-ortho-v2", "1612": "OpenChat-3.5-7B-Solar", "1613": "A0106", "1614": "FuseChat-7B-Slerp", "1615": "Moza-7B-v1.0", "1616": "Hermes-low-tune", "1617": "Starling-LM-alpha-8x7B-MoE", "1618": "Pandora-10.7B-v1", "1619": "neuronovo-7B-v0.2", "1620": "Starling-LM-7B-alpha", "1621": "luxia-21.4b-alignment-v1.0", "1622": "Experiment23-7B", "1623": "Nandine-7b", "1624": "WestLake-dpo-train-sft-v1", "1625": "smol-7b", "1626": "West-Maid-7B", "1627": "Sinerva_7B", "1628": "phi-3-orpo-v9_16", "1629": "deepseek-llm-67b-chat", "1630": "Visual-LaylelemonMaidRP-7B", "1631": "IceCoffeeTest3", "1632": "CausalLM-RP-34B", "1633": "sixtyoneeighty-7b-dpo", "1634": "IceCoffeeTest1", "1635": "KangalKhan-PressurizedRuby-7B", "1636": "test-merge-3", "1637": "Llama-3-8B-Instruct-80K-QLoRA", "1638": "JARVIS-v1.0", "1639": "MusingCaterpillar", "1640": "una-neural-chat-v3-3-P2-OMA", "1641": "Maya_Hermes-2.5-Mistral-7B", "1642": "DolphinChat-7B-slerp", "1643": "Deacon-34b-qlora-adapter", "1644": "Chupacabra-7B", "1645": "KangalKhan-PolishedRuby-7B", "1646": "SOLAR-10.7B-slerp", "1647": "Leaderboard-killer-MoE_4x7b", "1648": "WestSeverus-10.7B", "1649": "RosMistral-2x7B", "1650": "Yi-34b-200K-rawrr-v2-run-0902-LoRA", "1651": "RP_Vision_7B", "1652": "OpenChat-3.5-7B-Mixtral", "1653": "Tess-M-Creative-v1.0", "1654": "mixtral_7bx4_moe", "1655": "SnorkelWestBeagle-DARETIES-7B", "1656": "Sirius-10B", "1657": "SJ-SOLAR-10.7b-DPO", "1658": "Tess-2.0-Yi-34B-200K", "1659": "CultriX-MoE-Model", "1660": "blossom-v5-34b", "1661": "kellemar-DPO-7B-d", "1662": "FuseChat-7B-TA", "1663": "Adrastea-7b-v1.0-dpo", "1664": "KangalKhan-RawRuby-7B", "1665": "Hyperion-2.0-Yi-34B", "1666": "HighdensityRPMerge-7B", "1667": "KangalKhan-Ruby-7B", "1668": "StrangeMerges_47-7B-dare_ties", "1669": "Chupacabra-7B-v2.02", "1670": "KangalKhan-Sapphire-7B", "1671": "Cerebrum-1.0-8x7b", "1672": "KangalKhan-Ruby-7B-Fixed", "1673": "Silicon-Maid-7B", "1674": "Genstruct-10.7B", "1675": "sixtyoneeighty-7b", "1676": "LadybirdGonzo-7B-slerp", "1677": "CapyTessBorosYi-34B-200K-DARE-Ties", "1678": "sixtyoneeighty-7b-chat", "1679": "Waktaverse-Llama-3-KO-8B-Instruct", "1680": "KangalKhan-DesolatingRuby-7B", "1681": "Llama-3-Aplite-Instruct-4x8B-MoE", "1682": "una-neural-chat-v3-3-P1-OMA", "1683": "Typhon-Mixtral-v1", "1684": "yi-34b-200k-rawrr-dpo-2", "1685": "Llama-3-8B-Instruct-262k", "1686": "NewtoccineLake-slerp-7B", "1687": "yi-34b-200k-rawrr-dpo-1", "1688": "Cerberus-7B-Model_Stock", "1689": "eleusis-7b-alpha", "1690": "v-alpha-tross", "1691": "KangalKhan-ShinyEmerald-7B", "1692": "CCK_Gony_v0.1", "1693": "OxytocinErosEngineeringF1-7B-slerp", "1694": "Llama-3-Aplite-Instruct-4x8B", "1695": "K2S3-v0.1", "1696": "Mixtral_7Bx4_MOE_24B", "1697": "KangalKhan-ShatteredRuby-7B", "1698": "JOSIE_Beta-4-7B-slerp", "1699": "KunoMaid-7B-slerp", "1700": "UNAversal-8x7B-v1beta", "1701": "UNA-ThePitbull-21.4-v1", "1702": "Lonepino-11B", "1703": "luxia-21.4b-alignment-v0.2", "1704": "kellemar-DPO-7B-v1.01", "1705": "Yi-34B-200K-rawrr1-LORA-DPO-experimental-r3", "1706": "Llama-3-Refueled", "1707": "GritLM-8x7B", "1708": "notus-8x7b-experiment", "1709": "L0223", "1710": "merge-aanaphi-phi2-orage-3b", "1711": "suzume-llama-3-8B-multilingual", "1712": "Dark-Miqu-70B", "1713": "LexGPT-V3", "1714": "SystemHermes-2-7B", "1715": "Starling-LM-7B-alpha-ExPO", "1716": "rizla-17", "1717": "MFANN3bv0.6", "1718": "NeuralHermes-2.5-Mistral-7B-distilabel", "1719": "StrangeMerges_2-7B-slerp", "1720": "Obelix-Phi2", "1721": "SystemConfigHermes-7B", "1722": "Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss", "1723": "InnerILLM-0x00d0-7B-slerp", "1724": "InnerILLM-OpenPipe-Nous-Yarn-Mistral-optimized-1228-7B-slerp", "1725": "ConfigurableHermes-7B", "1726": "Mixtral-8x7B-Instruct-v0.1-DPO", "1727": "neuronovo-7B-v0.3", "1728": "Mixtral_AI_Cyber_3.1_SFT", "1729": "llama-3-8b-instruct-alpaca-gpt-4", "1730": "Open_Maid_Samantha_Hermes_Orca", "1731": "Limmy-phi2-slerp", "1732": "Open_Neural_Monarch_Maidv0.1", "1733": "CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-HighDensity", "1734": "Marcoroni-neural-chat-7B-v2_gsm8k_merged", "1735": "Umbra-v3-MoE-4x11b-2ex", "1736": "aligned-merge-aanaphi-phi2-orage-3b", "1737": "BagelMIsteryTour-v2-8x7B", "1738": "General-Stories-Mistral-7B", "1739": "MFANNv0.12", "1740": "LaseredHermes-7B-v1", "1741": "Phigments12", "1742": "meta-llama-3-8b-instruct-hf-ortho-baukit-5fail-500total", "1743": "phi-2-slerp", "1744": "Solar-10.7B-SLERP", "1745": "KangalKhan-HardRuby-7B", "1746": "OpenMia-Indo-Mistral-7b-v3-refined", "1747": "Cookie_7B", "1748": "e.star.7.b", "1749": "openbuddy-llama3-8b-v21.1-8k", "1750": "KangalKhan-PrimordialSapphire-7B", "1751": "fireblossom-32K-7B", "1752": "trrapi-16b", "1753": "Test1_SLIDE", "1754": "BigWeave-v16-103b", "1755": "Deacon-34b-Adapter", "1756": "TW3CESCO.V1", "1757": "neural-chat-7b-v3-3", "1758": "Math-OpenHermes-2.5-Mistral-7B", "1759": "testtest", "1760": "Misgit-7B-slerp", "1761": "TenyxChat-8x7B-v1", "1762": "notux-8x7b-v1", "1763": "Stanta-Lelemon-Maid-7B", "1764": "Dumb-Maidlet", "1765": "Mixtral-8x7B-Instruct-v0.1", "1766": "test-dare", "1767": "J.O.S.I.E.3-Beta10-7B-slerp", "1768": "kukulemon-7B", "1769": "platypus-yi-34b", "1770": "Hyperion-3.0-Yi-34B", "1771": "SOLAR-10.7b-Instruct-dpo", "1772": "bagel-dpo-34b-v0.2", "1773": "MultiKory-0.1-4x11b-pre1", "1774": "Kory-0.1-11b-pre1", "1775": "10.7Bx2_DPO_200", "1776": "MetaMath-Llemma-7B", "1777": "Awanllm-Llama-3-8B-Cumulus-v0.2", "1778": "Lamma3merge3-15B-MoE", "1779": "HerculeanSea-upd-7b-128k", "1780": "Llamafia", "1781": "Einstein-openchat-7B", "1782": "distilabeled-Hermes-2.5-Mistral-7B", "1783": "A0113", "1784": "Mistral-7B-orca-dpo-12h", "1785": "TriMistral-7B-TIES", "1786": "habib-v4", "1787": "MistralHermes-CodePro-7B-v1", "1788": "LUNA-SOLARkrautLM-Instruct", "1789": "Qwen1.5-32B", "1790": "autotrain-mixtral-8x7b-orpo-v1", "1791": "Mahou-1.1-mistral-7B", "1792": "SlimMelodicMaid", "1793": "Yi-34B-Llama", "1794": "Llama-3-8B-Cumulus-v0.1", "1795": "StrangeMerges_18-7B-dare_ties", "1796": "Meta-Llama-3-8B-Instruct-Dolfin-v0.1", "1797": "SauerkrautLM-Mixtral-8x7B-Instruct", "1798": "saulgoodman-2x7b-alpha1", "1799": "KangalKhan-Alpha-RawRubyroid-7B-Fixed", "1800": "MistralTrixTest", "1801": "IceMochaccinoRP-7b", "1802": "turkgpt-v0.1", "1803": "yi-bagel-2x34b-moe", "1804": "Falkor-8x7B-MoE", "1805": "yi-bagel-2x34b", "1806": "autocodit", "1807": "DeepCode-7B-Aurora", "1808": "Quintellect-10.7B", "1809": "llama-3-chinese-8b-instruct-v2", "1810": "SMaxxxer-v1-70b", "1811": "NeuralPaca-7b", "1812": "Gabriel-8x7B-Instruct-v0.1", "1813": "llama-3-cat-8b-instruct", "1814": "Dusk-Miqu-70B", "1815": "chatty-djinn-14B", "1816": "A0121", "1817": "TriMistral-7B-DARETIES", "1818": "Nous-Hermes-2-Mistral-7B-DPO", "1819": "RogerWizard-12B-MoE", "1820": "Antares-11b-v2", "1821": "Falkor-7b", "1822": "llama-3-cat-8b-instruct-v1", "1823": "Silicon-Monika-7b", "1824": "Hermes-2-Pro-Mixtral-4x7B", "1825": "kellemar-DPO-7B", "1826": "StrangeMerges_41-7B-dare_ties", "1827": "Hermes-2-Pro-Mistral-7B", "1828": "PlatYi-34B-Llama-Q", "1829": "Ziya2-13B-Base", "1830": "A11P", "1831": "Medichat-Llama3-8B", "1832": "KangalKhan-Alpha-ExtraRawRubyroid-7B", "1833": "Prima-LelantaclesV6.25-7b", "1834": "A0308-G", "1835": "notux-8x7b-v1-epoch-2", "1836": "Franziska-Mixtral-v1", "1837": "A0305a", "1838": "Niel-7B", "1839": "Pallas-0.4", "1840": "openbuddy-llama2-70b-v10.1-bf16", "1841": "Pallas-0.3", "1842": "slerp_bun_mistral_7b_v2", "1843": "habib-v3", "1844": "Arithmo-Wizard-2-7B", "1845": "IceTeaRP-7b", "1846": "llama-3-habib", "1847": "Kunokukulemonchini-7b", "1848": "Pallas-0.5-LASER-0.1", "1849": "opus-v1-34b", "1850": "Skyro-4X8B", "1851": "Eclipse-7B", "1852": "WordWoven-13B", "1853": "caigun-lora-model-34B-v2", "1854": "Blitz-AI-MOE-v0.4", "1855": "DPOpenHermes-7B-v2-PerfLaser", "1856": "c4ai-command-r-v01-japanese-instruct", "1857": "habib-v2", "1858": "StarlingDolphin-7B-slerp", "1859": "UNA-34Beagles-32K-bf16-v1", "1860": "Yi-34b-x2", "1861": "Quyen-Plus-v0.1", "1862": "A0304", "1863": "blossom-v5-7b", "1864": "BruinsV2-OpHermesNeu-11B", "1865": "AZG", "1866": "Yi-34B-200K-AEZAKMI-RAW-1701", "1867": "Voldemort-10B", "1868": "MFANNv0.11", "1869": "Pallas-0.5", "1870": "Liph-36-imatwarwithmyself", "1871": "T3Q-Platypus-MistralM7-7B", "1872": "Llama-3-8B-Instruct-norefusal", "1873": "DistilHermes-2.5-Mistral-7B", "1874": "BagelMIsteryTour-8x7B", "1875": "RP-Coder-SM3", "1876": "Liph.42", "1877": "CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-ExtremeDensity", "1878": "MetaModel_moe_multilingualv1", "1879": "oswald-2x7b", "1880": "shadow-clown-BioMistral-7B-DARE", "1881": "llama-3-8b-it-kor-extented-chang", "1882": "saulgoodman-7b-alpha1", "1883": "JustToSuffer-7B-slerp", "1884": "pic_7B_mistral_Full_v0.2", "1885": "openchat-spin-slimorca-iter3", "1886": "Sonya-7B", "1887": "openchat-spin-slimorca-iter2", "1888": "J.O.S.I.E.3-Beta12-7B-slerp", "1889": "Tess-34B-v1.4", "1890": "Yi-1.5-9B-Chat-16K", "1891": "Chupacabra-7B-v2.01", "1892": "Chupacabra-8x7B-MoE", "1893": "Einstein-v5-v0.2-7B", "1894": "A0125", "1895": "Llama3-merge-biomed-8b", "1896": "CCK_Gony_v3.1", "1897": "autotrain-llama3-orpo", "1898": "Misted-7B", "1899": "K2S3-Mistral-7b-v1.48", "1900": "Konstanta-V3-AlphaFlavour-7B", "1901": "Liph.42-slerp", "1902": "L0225", "1903": "Yi-34B-200K-AEZAKMI-RAW-2901", "1904": "ChatAllInOne-Yi-34B-200K-V1", "1905": "NarutoDolphin-10B", "1906": "NeuralPizza-7B-V0.1", "1907": "xDAN-L1-Chat-RL-v1", "1908": "smartsolmix-4x10.7b-v1", "1909": "Instruct_Mixtral-8x7B-v0.1_Dolly15K", "1910": "NarutoDolphin-7B", "1911": "Prima-Pastacles-7b-128k", "1912": "tulu-2-dpo-70b-ExPO", "1913": "Taurus-1.0-Mistral-7B", "1914": "Prima-LelantaclesV6.5-7b", "1915": "Taurus-7B-1.0", "1916": "Mahou-1.2-mistral-7B", "1917": "CapybaraHermes-2.5-Mistral-7B", "1918": "StrangeMerges_46-7B-dare_ties", "1919": "firefly-mixtral-8x7b-v1", "1920": "firefly-mixtral-8x7b-v0.1", "1921": "Mistral-Hermes-2x7b", "1922": "Qwen1.5-7B-SFT-0425", "1923": "MisterUkrainianDPO", "1924": "TriMistral-7B-SLERP", "1925": "deepseek-math-7b-base", "1926": "llama-3-chinese-8b-instruct-v3", "1927": "OpenHercules-2.5-Mistral-7B", "1928": "Tess-M-v1.3", "1929": "NeuralOmniWestBeaglake-7B", "1930": "SOLAR-10.7b-Instruct-truthy-dpo", "1931": "Open_Gpt4_8x7B", "1932": "phi-2-psy", "1933": "toten_gsm8k_merged_s", "1934": "Phi-3-Large-5.6b", "1935": "sillyrp-7b", "1936": "Open_Gpt4_8x7B_v0.2", "1937": "speechless-mistral-7B-v0.2-mixed-1", "1938": "openbuddy-mixtral-7bx8-v17.1-32k", "1939": "UNA-34BeagleSimpleMath-32K-v1", "1940": "autotrain-mixtral-8x7b-orpo-v2", "1941": "L-MChat-Small", "1942": "NeuralBeagle-11B", "1943": "Qwen-14B", "1944": "Fireplace-34b", "1945": "NeuralPizza-7B-V0.3", "1946": "mistral-merge-7b", "1947": "KangalKhan-Alpha-Emerald-7B-Fixed", "1948": "Pallas-0.5-LASER-0.2", "1949": "Yi-34B-200K-AEZAKMI-v2", "1950": "Llama-3-8B-SaulGoodMan", "1951": "Prima-LelantaclesV4-7b-16k-bf16", "1952": "SystemHermes-7B", "1953": "LLama-3-8b-Maths", "1954": "Experiment15-7B", "1955": "Tess-2.0-Mixtral-v0.2", "1956": "T3Q-Platypus-Mistral7B", "1957": "Llama-3-Soliloquy-8B-v2", "1958": "SOLAR-10.7B-dpo-instruct-tuned-v0.1", "1959": "penny-llama3-2x8b", "1960": "KangalKhan-Alpha-Rubyroid-7B-Fixed", "1961": "mixtral-instruct-0.1-laser", "1962": "Open_Maid_Samantha_Hermes_Orca_dare_tiesv0.1", "1963": "Threnystril-2x7B-moe", "1964": "Obelix-Phi2-v0", "1965": "medilora-qwen-14b", "1966": "LLaMAntino-3-ANITA-8B-Inst-DPO-ITA", "1967": "phigment6-slerp", "1968": "MUZD", "1969": "14B", "1970": "Meta-Llama-3-8B-Instruct-ORPO-QLoRA", "1971": "JOSIE_Beta-3-7B-slerp", "1972": "Dawn-Miqu-70B", "1973": "A0204", "1974": "Rabbit-7B-DPO-Chat", "1975": "huh-1", "1976": "DesivoMerge0.1", "1977": "MPOMixtral-8x7B-Instruct-v0.1", "1978": "nontoxic-bagel-34b-v0.2", "1979": "typhoon-7b-instruct-02-19-2024", "1980": "alignment_model_test", "1981": "NeuralOrca-7B-v1", "1982": "Chunky-Lemon-Cookie-11B", "1983": "xLAM-v0.1-r", "1984": "OpenMistral-MoE", "1985": "Lumina-2", "1986": "HerculeanSea-7b-128k", "1987": "Silicon-Medley", "1988": "SOLAR-10.7B-ko_alpaca", "1989": "Antares-11b-v1", "1990": "OpenHermes-2.5-Mistral-7B-mt-bench-DPO-recovered", "1991": "bagel-dpo-34b-v0.5", "1992": "OpenHermes-2.5-Code-290k-13B", "1993": "MUZ", "1994": "CBDDO-LLM-8B-Instruct-v0.1", "1995": "Buzz-8b-Large-v0.5", "1996": "hermorca", "1997": "Barcenas-10.7b", "1998": "CCK_Gony_v3.3", "1999": "kellemar-DPO-7B-c", "2000": "IceMerge-7b-32k", "2001": "mixtralmerge-8x7B-rebalanced-test", "2002": "34b-beta", "2003": "Metamath-reproduce-7b", "2004": "llamathon_v2", "2005": "Nynph-7B-Model_Stock", "2006": "mixture-of-llamas-ties", "2007": "FT", "2008": "llama3-8b-instruct-code", "2009": "rawr", "2010": "OpenHermes-2.5-Mistral-7B-mt-bench-DPO-corrupted", "2011": "Mahou-1.3-mistral-7B", "2012": "Llama-3-Petro-Instruct-v1", "2013": "dpo_model_test1", "2014": "West-Ramen-7Bx4", "2015": "solar-megamerge-dare-10.7b-v1", "2016": "bagel-8b-v1.0", "2017": "Xwin-Math-70B-V1.0", "2018": "jaskier-7b-NeuralDPO", "2019": "Mika-Lelantacles-7b-Longtext", "2020": "OpenHermes-2.5-Mistral-7B-mt-bench-DPO", "2021": "xDAN-SlimOrca", "2022": "Grafted-Llama2-2x70B", "2023": "StrangeMerges_33-7B-slerp", "2024": "K2S3-Mistral-7b-v1.50", "2025": "A0221", "2026": "MisGemma-7B", "2027": "stablelm-2-12b-chat", "2028": "ToppyLake-Bagel-7B-slerp", "2029": "firefly-qwen1.5-en-7b-unsloth", "2030": "Einstein-v4-7B", "2031": "phi-2-orange-v2", "2032": "Silicon-Natsuki-7b", "2033": "Mixtral-8x7B-v0.1", "2034": "Mistral-CatMacaroni-slerp-gradient", "2035": "Mixtral-8x7B-v0.1-top3", "2036": "MFANN3bv0.7.10", "2037": "MixtureofMerges-MoE-4x7b-v10-mixtralv0.3", "2038": "Terminis-7B", "2039": "Llama-3-LewdPlay-8B", "2040": "Mixtral-8x7b-DPO-v0.2", "2041": "spring-chicken-8x8b", "2042": "Fett-Eris-Mix-7B", "2043": "OxytocinErosEngineeringFX-7B-slerp", "2044": "BagelLake-7B-slerp", "2045": "A0119", "2046": "Capybara-Tess-Yi-34B-200K", "2047": "Konstanta-Gamma-10.9B", "2048": "llamathon_v1", "2049": "CCK_Gony_v3", "2050": "airoboros-34b-3.2", "2051": "open-aditi-hi-v4", "2052": "CausalLM-Platypus-14B", "2053": "Jovian-10.7B-v1.0", "2054": "AiMaven-SmartDawg-7b", "2055": "Eris_PrimeV4.20-Vision-32k-7B", "2056": "Pearl-3x7B", "2057": "llama-3-typhoon-v1.5-8b-instruct", "2058": "servile-harpsichord-cdpo", "2059": "Bucharest-0.1", "2060": "CCK_Gony_v3.2", "2061": "Yi-34B-200K-AEZAKMI-RAW-2301", "2062": "pandafish-7b", "2063": "phi-2-ipo-renew1", "2064": "StrangeMerges_34-7B-slerp", "2065": "Dolphin-2.9.1-Phi-3-Kensho-4.5B", "2066": "megatron_v1", "2067": "neural-chat-7b-v3-3-wizardmath-dare-me", "2068": "merge_model_test1", "2069": "Liph42", "2070": "Awanllm-Llama-3-8B-Dolfin-v0.6-Abliterated", "2071": "Llama-3-8B-Dolfin-v0.2-Instruct", "2072": "Matter-0.2-7B-DPO", "2073": "MisterUkrainian", "2074": "Echidna-7b-128k", "2075": "Konstanta-V3-BetaFlavour-7B", "2076": "openbuddy-deepseek-67b-v15-base", "2077": "Mistral-7B-Merge-14-v0.2", "2078": "raccoon-small", "2079": "Bucharest-0.2", "2080": "O0201", "2081": "OpenHermes-2.5-neural-chat-7b-v3-2-7B", "2082": "llama-3-10b-it-kor-extented-chang-pro8", "2083": "dolphin-2.2-70b", "2084": "orthorus-125b-moe", "2085": "ThetaWave-7B-sft", "2086": "BgGPT-7B-Instruct-v0.1", "2087": "blossom-v4-qwen1_5-7b", "2088": "phi-2-gpo-renew2-i0", "2089": "loyal-piano-m7", "2090": "deepseek-llm-67b-base", "2091": "phi-2-dpo", "2092": "SirUkrainian", "2093": "winter-garden-7b-beta", "2094": "KangalKhan-Beta-Sapphire-7B", "2095": "A0306", "2096": "Mixtral_13B_Chat", "2097": "Bioxtral-4x7B-v0.1", "2098": "c4ai-command-r-v01", "2099": "Worldsim-Hermes-7B", "2100": "HermesStar-OrcaWind-Synth-11B", "2101": "MoMo-70B-LoRA-V1.2_1", "2102": "OpenAGI-7B-v0.1", "2103": "nanit_v3.2", "2104": "OpenAGI-7B-v0.1-test-ada", "2105": "polyglot-math-4x7b", "2106": "Medmerge-tulu-70b", "2107": "piano-medley-7b", "2108": "Sensualize-Solar-10.7B", "2109": "average-dolphin-8x7B", "2110": "Erosumika-7B-v3", "2111": "mini_7B_dare_v1", "2112": "Mocha-Sample-7b-ex", "2113": "Einstein-v6.1-phi2", "2114": "KangalKhan-Alpha-Sapphiroid-7B-Fixed", "2115": "ShiningValiant", "2116": "EinsteinBagel-8B", "2117": "alignment-model-test10", "2118": "Marcoroni-neural-chat-7B-v2_gsm8k_quantized_mergedfloat_s", "2119": "zephyr-beta-math", "2120": "Mistral-Starling-merge-trial1-7B", "2121": "LNSM-RP-7B", "2122": "speechless-instruct-mistral-7b-v0.2", "2123": "Awanllm-Llama-3-8B-Dolfin-v0.3", "2124": "19B_TRUTH_DPO", "2125": "LHK", "2126": "7B-0428", "2127": "Mistral-7B-Instruct-Ukrainian", "2128": "MoMo-70B-V1.2_1", "2129": "loyal-piano-m7-cdpo", "2130": "phi-2-gpo-renew2-b0.001-0.5ultrafeedback-lowLr-i1", "2131": "Qwen-72B-Llama", "2132": "bagel-34b-v0.5", "2133": "Mixtral_AI_Cyber_5.0", "2134": "Soniox-7B-v1.0", "2135": "Matter-0.1-7B-DPO-preview", "2136": "Open_Hermes_Orca_Mistral-7B", "2137": "Mixtral-8x7b-v0.1-sft", "2138": "Mixtral-8x7b-v0.1-dpo", "2139": "Mixtral-8x7B-Holodeck-v1", "2140": "Tess-10.7B-v1.5b", "2141": "BigWeave-v15-103b", "2142": "Mixtral_AI_Cyber_3.m2", "2143": "ThetaWave-7B", "2144": "Mistral-CatMacaroni-slerp-uncensored", "2145": "Open_Neural_Monarch_Maidv0.2", "2146": "Synthia-v3.0-11B", "2147": "phi-2-gpo-renew2-b0.001-i0", "2148": "Pallas-0.5-LASER-0.3", "2149": "stablelm-2-12b", "2150": "mistral-7b-v0.1-layla-v3", "2151": "Matter-0.2-32B", "2152": "internlm2-chat-7b-sft-llama", "2153": "Voltran-1.0-MoE-2x7B", "2154": "Qwen1.5-7B-sft-0506_9_8", "2155": "InfinityNexus_9B", "2156": "dpopenhermes-alpha-v0", "2157": "Llama-3-Smaug-8B", "2158": "Phi-2-DPO", "2159": "ThetaZero-7B-1", "2160": "Qwen2-1.5B", "2161": "Llama3-Chinese-8B-Instruct", "2162": "ToppyEvil-7B-slerp", "2163": "phi-2-logical-sft", "2164": "test_phi2", "2165": "MFANN3bv0.4", "2166": "MistInst-v0.2_ochat-3.5-0106_dpo-binarized-NeuralTrix-7B", "2167": "Nyan-Stunna-7B", "2168": "NeuralHermes-2.5-Mistral-7B-laser", "2169": "WestuccineBagel-7B-slerp", "2170": "llama-3-typhoon-v1.5-8b", "2171": "OpenHyperion-2.5-Mistral-7B", "2172": "Rabbit-7B-v2-DPO-Chat", "2173": "chinese-mixtral-instruct", "2174": "ThetaWave-7B-v0.1", "2175": "WizardLaker-7B", "2176": "Qwen1.5-7B-sft-0502", "2177": "mergekit-slerp-bxtecvo", "2178": "Snorkel-Mistral-PairRM-DPO-openchat-3.5-0106-laser", "2179": "merge_model_test2", "2180": "KoSOLAR-10.7B-v0.1", "2181": "SOLAR-10.7B-v1.0", "2182": "CCK-v1.3.0-DPO", "2183": "mistral-7b-v0.1-layla-v4", "2184": "llamathon", "2185": "Orca-Hermes-7B-slerp", "2186": "phi-2-gpo-renew2-b0.001-v4-i1", "2187": "Yi-34B-200K-AEZAKMI-RAW-2301-LoRA", "2188": "MFANN3bv0.11", "2189": "phi-2-test", "2190": "nanit_v3", "2191": "phi-2-gpo-renew2-b0.001-v2-i1", "2192": "phi-2-gpo-renew2-b0.001-vllm-i1", "2193": "OpenHermes-2.5-Mistral-7B-mt-bench-DPO-original-v2", "2194": "MFANN3bV0.8.10", "2195": "limb", "2196": "Llama-3-8B-Instruct-Gradient-1048k", "2197": "phi-2-platypus-Commercial-lora", "2198": "openhermes-2_5-dpo-no-robots-v2", "2199": "firefly-qwen1.5-en-7b", "2200": "openhermes-2_5-dpo-no-robots", "2201": "MFANN3bv0.2", "2202": "YarnLake-Swap-7B", "2203": "phi-2-ipo-test-iter-0", "2204": "ColorShadow-7B", "2205": "phi-2-gpo-renew2-b0.001-extra-i1", "2206": "phi-2-gpo-renew2-b0.001-extra-v2-i1", "2207": "una-cybertron-7b-v1-fp16", "2208": "neural-chat-7b-v3-2", "2209": "K2S3-Mistral-7b-v1.2", "2210": "Prima-Pastacles-7b", "2211": "phi-2-gpo-renew2-b0.001-0.5ultrafeedback-i1", "2212": "una-cybertron-7b-v2-bf16", "2213": "nanit_v1.1", "2214": "MiaLatte-Indo-Mistral-7b", "2215": "nanit", "2216": "nanobot_v1", "2217": "BagelToppyLake-7B-slerp", "2218": "phi-2", "2219": "Mistral_7B-Open_Hermes-NSFWV1", "2220": "K2S3-Mistral-7b-v1.3", "2221": "Meme-7B-slerp", "2222": "aanaphi2-v0.1", "2223": "MFANN3bv0.8", "2224": "ThetaWave-7B-v0", "2225": "phi2_gsm8k_lora", "2226": "DPOpenHermes-7B", "2227": "Maixtchup-4x7b", "2228": "SynthIA-70B-v1.5", "2229": "llama-3-neural-chat-v1-8b", "2230": "Chupacabra-7B-v2", "2231": "MFANN3bv0.10.10", "2232": "A0105", "2233": "Tess-M-v1.1", "2234": "Aurora_19e_Test", "2235": "NexusMistral2-7B-slerp", "2236": "SunsetBoulevard", "2237": "phi-2-layla-v1", "2238": "Nyxene-v2-11B", "2239": "Llama-3-11B-Instruct-v0.1", "2240": "Moe-4x7b-reason-code-qa", "2241": "WinterGoddess-1.4x-70B-L2", "2242": "huozi3", "2243": "Writing_Partner_Mistral_7B", "2244": "firefly-qwen1.5-en-7b-dpo-v0.1-unsloth", "2245": "Moe-4x7b-math-reason-code", "2246": "phi-2-gpo-renew2-b0.001-log-i0", "2247": "caigun-lora-model-34B-v3", "2248": "phi-2-layla-v1-chatml", "2249": "Zero-7B-test-1", "2250": "phi-2-super", "2251": "Instruct-v0.2-Seraph-7B", "2252": "MasherAI-v6.1-7B-eval-test", "2253": "winter-garden-7b-alpha", "2254": "MFANN3bv0.9", "2255": "dpo-phi2", "2256": "Mistral-7B-Merge-14-v0.3-ft-step-15936", "2257": "Grypho-ties-7b", "2258": "Tess-10.7B-v1.5", "2259": "tigerbot-70b-chat-v2", "2260": "K2S3-Mistral-7b-v1.43", "2261": "Mixtral-8x7B-Instruct-v0.1-upscaled", "2262": "WizardIceLemonTeaRP-32k", "2263": "StrangeMerges_13-7B-slerp", "2264": "MoE-Merging", "2265": "Kool-Aid_7B", "2266": "94909a799eefebebc2734491449fb3ef", "2267": "UTENA-7B-V3", "2268": "Qwen1.5-8x7b-v0.1", "2269": "aegolius-acadicus-34b-v3", "2270": "MFANN3bv0.10", "2271": "kunoichi-lemon-royale-v3-32K-7B", "2272": "TopicNeuralHermes-2.5-Mistral-7B", "2273": "Garbage_9B", "2274": "MFANN3bv0.3", "2275": "firefly-qwen1.5-en-7b-dpo-v0.1", "2276": "CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties", "2277": "Llama-2-70b-hf", "2278": "Liberated-Qwen1.5-7B", "2279": "m.star.7b", "2280": "Mistral-7B-Instruct-v0.2_openchat-3.5-0106", "2281": "Smart-Lemon-Cookie-7B", "2282": "KangalKhan-Beta-Ruby-7B", "2283": "CCK_gony", "2284": "PlatYi-34B-Q", "2285": "Einstein-v4-phi2", "2286": "Matter-0.2-7B", "2287": "OrionStar-Yi-34B-Chat-Llama", "2288": "mixtral-megamerge-dare-8x7b-v2", "2289": "Mistral-7B-Instruct_v0.2_UNA-TheBeagle-7b-v1", "2290": "falcon-11B", "2291": "SpellBlade", "2292": "llama-3-10b-it-ko-2024-0527", "2293": "mistral-7b-v0.1-layla-v4-chatml", "2294": "Voldemort-10B-DPO", "2295": "PiVoT-SOLAR-10.7B-RP", "2296": "strix-rufipes-70b", "2297": "HelpingAI-9B", "2298": "K2S3-Mistral-7b-v1.47", "2299": "Matter-0.1-7B", "2300": "Infinite-Laymons-9B", "2301": "Mixtral-8x7b-DPO-v0.1", "2302": "MFANN3bv0.7", "2303": "sonya-medium-x8-MoE", "2304": "Lunar_10.7B", "2305": "StarMix-7B-slerp", "2306": "Yi-34B-200K-HESOYAM-0905", "2307": "FrankeMerge-12.5B", "2308": "Spaetzle-v44-7b", "2309": "Persephone_7B", "2310": "TarsChattyBasev0.2", "2311": "Zero-7B-test-2", "2312": "Mocha-Dare-7b-ex", "2313": "LDCC-SOLAR-10.7B", "2314": "Qwen1.5-7B", "2315": "Mixtral_AI_Cyber_MegaMind_3_0", "2316": "V0201", "2317": "NexoNimbus-MoE-2x7B", "2318": "K2S3-Mistral-7b-v1.1", "2319": "radiantloom-mixtral-8x7b-fusion", "2320": "kunoichi-lemon-royale-v2-32K-7B", "2321": "BetaMonarch-10.7B", "2322": "Hugo-7B-slerp", "2323": "OpenHermes-7B-Reasoner", "2324": "Pallas-0.5-LASER-0.4", "2325": "OpenHermes-7B-Symbolic", "2326": "OpenAGI-7B-v0.2", "2327": "v1olet_merged_dpo_7B", "2328": "bagel-dpo-7b-v0.5", "2329": "phi-2-sft-lora-ultrachat", "2330": "Eros_Prodigadigm_7B", "2331": "spin-phi2", "2332": "Yi-1.5-9B-coder", "2333": "A12P", "2334": "ds_diasum_md_mixtral", "2335": "OpenHermes-2.5-Mistral-7B-mt-bench-DPO-reversed_corrupted", "2336": "new_model_test2", "2337": "merlin1", "2338": "Phi-2-openassistant", "2339": "cisco-iNAM-phi-sft", "2340": "Llama-3-Orca-2.0-8B", "2341": "Mistral_AI_v2", "2342": "Mixtral-4x7B-DPO-RPChat", "2343": "CCK_Gony_v0.2", "2344": "K2S3-Mistral-7b-v1.0", "2345": "llama-3-neural-chat-v2.2-8B", "2346": "OpenHermes-2.5-neural-chat-7b-v3-1-7B", "2347": "Blitz-AI-MOE-v0.7", "2348": "Megatron-Mx", "2349": "llama2_70b_mmlu", "2350": "Mistral-Starling-merge-trial3-7B", "2351": "Pandora-13B-v1", "2352": "Hex-Macaroniac-7b", "2353": "Yi-34B-AEZAKMI-v1", "2354": "Mixtral_Chat_X_128k", "2355": "Lumina-5.5-Instruct", "2356": "TarsMeta", "2357": "neural-chat-7B-v3-2-GPTQ", "2358": "Blur-7b-v1.2", "2359": "Mistral-RAG", "2360": "Pallas-0.5-LASER-exp2-0.1", "2361": "Qwen-14B-Llamafied", "2362": "Frostwind-10.7B-v1", "2363": "gemma-7b-experiment", "2364": "gemma-7b", "2365": "pic_7B_mistral_Full_v0.1", "2366": "ThetaWave-7B-v1", "2367": "A13", "2368": "philion-2", "2369": "14B-Glacier-Stack", "2370": "WestSenzu-Swap-7B", "2371": "Monsoon-7B-exp-1", "2372": "Aurora_25e_Test", "2373": "phi-2-instruction", "2374": "CognitiveFusion-4x7B-bf16-MoE", "2375": "Ana-v1-m7", "2376": "TruthfulQwen1.5-4B", "2377": "Meta-Llama-3-12B-Instruct", "2378": "orpo-lora-phi2", "2379": "codegemma-7b-it", "2380": "Qwen1.5-7B-sft-0506_7_7", "2381": "TriMistral-7B-MODELSTOCK", "2382": "C-Based-2x7B", "2383": "shadow-clown-BioMistral-7B-SLERP", "2384": "mistral-11b-slimorca", "2385": "Sina-Loki-7b-Merge", "2386": "kaori-70b-v1", "2387": "Mocha-SR-7b-ex", "2388": "Kunocchini-7b-128k-test", "2389": "Volare", "2390": "Neural-una-cybertron-7b", "2391": "Qwen1.5-4B", "2392": "phi-2-dpo-renew1", "2393": "LLaMa3-8b-WangchanX-sft-Demo", "2394": "starcoder2-15b", "2395": "Bookworm-10.7B-v0.4-DPO", "2396": "Prima-LelantaclesV7-experimentalv2-7b", "2397": "TemptressTensor-10.7B-v0.1a", "2398": "haLLAwa2", "2399": "nmt", "2400": "Mnemosyne-7B", "2401": "Nyxene-v1-11B", "2402": "Kilo-2x8B", "2403": "Crunchy-onion", "2404": "Aura-llama", "2405": "Sensualize-Mixtral-bf16", "2406": "MasherAI-v6-7B", "2407": "Gemma-7B-Finetuning-JCS-Ko-Ins", "2408": "medilora-mistral-7b", "2409": "WestKunai-Hermes-10.7b-test", "2410": "Mixtral_AI_CyberTron_DeepMind_III_UFT", "2411": "openbuddy-mixtral-8x7b-v15.4", "2412": "NeuralHermes-MoE-2x7B", "2413": "NarrativeNexus_7B", "2414": "llama3-8B-slerp-med-chinese2", "2415": "Nyxene-11B", "2416": "Felix-8B", "2417": "openbuddy-mistral2-7b-v20.3-32k", "2418": "M7-8B-passthrough", "2419": "Chinese-Mixtral-8x7B", "2420": "FrankenLimmy-10B-passthrough", "2421": "Einstein-v4-Qwen-1.5-32B", "2422": "phi-2-sft-ultrachat-full", "2423": "Mengzi3-13B-Base", "2424": "llama3-8B-slerp-biomed-chat-chinese", "2425": "mergekit-slerp-mntqhzv", "2426": "Julianne-2x7B-bf16", "2427": "B0121", "2428": "Nyanade_Stunna-Maid-7B", "2429": "PlatYi-34B-200k-Q-FastChat", "2430": "Chupacabra-7B-v2.04", "2431": "ThetaWave-7B-v0.2", "2432": "orthogonal-2x7B-v2-base", "2433": "Mixtral-8x7B-peft-v0.1", "2434": "Gonzo-Code-7B", "2435": "DPOpenHermes-11B", "2436": "Kazbek-7B", "2437": "Calme-12B-Instruct-v0.1", "2438": "Bucharest-0.3", "2439": "mistral-7B-forest-merge", "2440": "Magic-Dolphin-7b", "2441": "microsoft-phi-2-sft", "2442": "internlm-20b-llama", "2443": "blossom-v4-qwen1_5-4b", "2444": "spin-phi2-1.5", "2445": "merlin1.2", "2446": "Mixtral_BioMedical", "2447": "Qwen1.5-4B_llamafy", "2448": "spin-phi2-2", "2449": "HelpSteer-filtered-Solar-Instruct", "2450": "Chupacabra-7B-v2.03", "2451": "Flammen-Trismegistus-7B", "2452": "gemma-7B-alpaca-case-0-2", "2453": "NeuralHermes-2.5-Mistral-7B", "2454": "Lumosia-MoE-4x10.7", "2455": "Mixtral_AI_CyberTron_Coder", "2456": "Mixtral_AI_Cyber_4.0", "2457": "Dionysus-Mistral-m3-v5", "2458": "OpenAGI-testing-intelDPO-2", "2459": "FusionNet_SOLAR", "2460": "Starling-LM-11B-alpha-v1", "2461": "Mixtral_AI_LCARS_", "2462": "neural-chat-7b-v3-1-OpenHermes-2.5-7B", "2463": "orthogonal-2x7B-base", "2464": "Solstice-11B-v1", "2465": "EEVE-Korean-Instruct-10.8B-v1.0", "2466": "Pantheon-RP-1.0-8b-Llama-3", "2467": "Yi-34B", "2468": "Gembo-v1.1-70b", "2469": "MixtralRPChat-ZLoss", "2470": "SOLAR_Merge_Adapter_DPO_Orca", "2471": "Quantum-Citrus-9B", "2472": "Test-Raw-Solar-v1", "2473": "KoSOLAR-10.7B-v0.3", "2474": "FrankenRoger-10B-passthrough", "2475": "openinstruct-mistral-7b", "2476": "CLEX-Mixtral-8x7B-Chat-32K", "2477": "Chupacabra-7B-v2.03-128k", "2478": "Matter-0.1-7B-boost-DPO-preview", "2479": "Nyanade_Stunna-Maid-7B-v0.2", "2480": "bagel-7b-v0.5", "2481": "bagel-34b-v0.4", "2482": "openbuddy-qwen1.5-14b-v21.1-32k", "2483": "merlin1.5", "2484": "llemma_34b", "2485": "Damysus-2.7B-Chat", "2486": "Gembo-v1-70b", "2487": "kukulemon-spiked-9B", "2488": "gemma-orchid-7b-dpo", "2489": "radiantloom-mixtral-8x7b-fusion-dpo", "2490": "Gemma-10.2B-Coder", "2491": "openbuddy-mistral2-7b-v20.1-32k", "2492": "Matter-0.1-7B-boost-DPO", "2493": "TaoPassthrough-15B-s", "2494": "Synatra-10.7B-v0.4", "2495": "SpydazWeb_AI_BASE_128k", "2496": "mistral-7B-forest-merge-v0.1", "2497": "gemma-7b-zephyr-dpo", "2498": "Experiment26-12B", "2499": "fly_6b", "2500": "xLakeChat", "2501": "Mistral-11b-v0.1", "2502": "pandafish-2-7b-32k", "2503": "OpenHermes-Yi-9B", "2504": "K2S3-Mistral-7bx2-48layers_v1.2", "2505": "m17", "2506": "Yi-1.5-6B", "2507": "gemma-7b-zephyr-sft", "2508": "Mistral-Evolved-11b-v0.1", "2509": "Ryu-4x7B-MoE-bf16", "2510": "form1", "2511": "NeuralBeagle-11B-truthy", "2512": "Llama-3-13B-Instruct-ft", "2513": "Moe-2x7b-QA-Code", "2514": "MadMix-v0.1", "2515": "Shiki-m7", "2516": "openbuddy-mistral2-7b-v20.2-32k", "2517": "airoboros-l2-70b-3.1.2", "2518": "slm", "2519": "SauerkrautLM-7b-HerO", "2520": "firefly-gemma-7b", "2521": "MathHermes-2.5-Mistral-7B", "2522": "SuperAligned-Jawade", "2523": "openhermes_dpo_norobot_0201", "2524": "deepseek-llm-7b-chat-sa-v0.1", "2525": "Pasta-PrimaMaid-7b", "2526": "Dykh-Tau-7B", "2527": "StrangeMerges_37-7B-dare_ties", "2528": "phi-2-openhermes-30k", "2529": "PlatYi-34B-Llama-Q-v2", "2530": "test-merge", "2531": "Pallas-0.5-LASER-0.5", "2532": "Yi-9B", "2533": "Xwin-LM-70B-V0.1_Limarpv3", "2534": "merlin1.3", "2535": "Deita-4b", "2536": "SOLAR_merge2_dpo", "2537": "mistral-maths7B", "2538": "Rain-7B-v0.2", "2539": "SnowLotus-v2-10.7B", "2540": "Llama-3-8B-Orpo-v0.1", "2541": "dolphin-2.6-mistral-7b-dpo", "2542": "m2", "2543": "tamil-large-language-model-7b-v1.0", "2544": "FrankenMonarch-7B", "2545": "Mistral-dolphin-2.8-grok-instract-2-7B-slerp", "2546": "K2", "2547": "Pallas-0.5-LASER-0.6", "2548": "Mixtral_AI_Cyber_Child", "2549": "Moe-3x7b-QA-Code-Inst", "2550": "Blackbird-Llama-3-8B", "2551": "Westuccine-7B-slerp", "2552": "Matter-0.1-Slim-7B-C-DPO", "2553": "lil-c3po", "2554": "laser-polyglot-4x7b", "2555": "WestLake-10.7B-v2", "2556": "merlin1.4", "2557": "blossom-v5-9b", "2558": "blossom-v5-4b", "2559": "Eurus-70b-nca-fixed", "2560": "Mixtral_Instruct", "2561": "Yi-9B-Forest-DPO-v1.0", "2562": "m16", "2563": "Mixtral-8x7B-v0.1-GPTQ", "2564": "m3", "2565": "laser-dolphin-mixtral-2x7b-dpo", "2566": "PascalHermes-2.5-Mistral-7B", "2567": "uncensored", "2568": "alignment-model-test9", "2569": "dolphin-2.2.1-mistral-7b", "2570": "openbuddy-mixtral-7bx8-v17.3-32k", "2571": "openchat-3.5-1210-32k", "2572": "Eida_10.7B", "2573": "llama_9b_long", "2574": "delta-4b-orange", "2575": "mixtral_8x7b_MonsterInstruct", "2576": "openchat-3.5-1210-32k-8x7b-MoE", "2577": "Mixtral_AI_128k_bioMedical", "2578": "megatron_v4_4x7B", "2579": "KoSoLAR-10.7B-v0.2_1.3_dedup_p", "2580": "bagel-7b-v0.1", "2581": "mistralv1_gsm8k_merged", "2582": "Mistral-7B-Instruct-demi-merge-v0.2-7B", "2583": "sheep-duck-llama-2-70b-v1.1", "2584": "Phi-Elothir", "2585": "Tess-2.0-Llama-3-8B", "2586": "WizardChatML-7B-v0", "2587": "BrokenLlama-3-8b", "2588": "Kunocchini-7b", "2589": "IceCappuccinoRP-7b", "2590": "kukulemon-32K-7B", "2591": "OpenMia-Indo-Mistral-7b-v4", "2592": "kukulemon-v3-soul_mix-32k-7B", "2593": "Mixtral_AI_CyberUltron_DPO", "2594": "FettuccineLake-DPO-7B-slerp", "2595": "KoSOLAR-10.7B-v0.2", "2596": "Sour-Marcoro-12.5B", "2597": "agiin-13.6B-v0.0", "2598": "mistralv1_gsm8k_merged_s", "2599": "ghost-7b-alpha", "2600": "Yi-9B-200K", "2601": "DolphinHermesPro-ModelStock", "2602": "Gonzo-Chat-7B", "2603": "bagel-dpo-7b-v0.1", "2604": "Llama3-7b", "2605": "Misted-v2-7B", "2606": "dolphin-2.6-mistral-7b-dpo-laser", "2607": "SauerkrautLM-Mixtral-8x7B", "2608": "Mixtral_AI_CyberTron", "2609": "ColorShadow-7B-v3", "2610": "groot2", "2611": "NeuralPipe-7B-slerp", "2612": "BigWeave-v12-90b", "2613": "testllm-c2", "2614": "Matter-0.1-Slim-7B-C", "2615": "DeciLM-7B", "2616": "c4ai-command-r-plus", "2617": "ColorShadow-7B-v2", "2618": "Scarlett-Llama-3-8B", "2619": "bagel-7b-v0.4", "2620": "LMCocktail-Mistral-7B-v1", "2621": "Cinder-Phi-2-V1-F16-gguf", "2622": "dolphin-2.1-mistral-7b-snr-laser", "2623": "L3-Run1", "2624": "dolphin-2.1-mistral-7b-snr-math-laser", "2625": "MasherAI-7B-v3", "2626": "LLaMaRada-3-orpo-v2-8b", "2627": "llama3-8b-SlimHermes", "2628": "OrpoLlama3-8B", "2629": "delta-4B-scientific", "2630": "You_can_cry_Snowman-13B", "2631": "Matter-0.1-Slim-7B-preview", "2632": "speechless-code-mistral-7b-v1.0", "2633": "Nanbeige-16B-Base-Llama", "2634": "motans1", "2635": "Mistraldouble-7B-task", "2636": "Blured-Ties-7B", "2637": "gem-14b-instruct", "2638": "delta-4B-super", "2639": "Delta-4B-Base", "2640": "blossom-v3_1-mistral-7b", "2641": "Noromaid-Bagel-7B-Slerp", "2642": "bagel-dpo-7b-v0.4", "2643": "blossom-v3_1-yi-34b", "2644": "Tiger-7b-v0.1", "2645": "alignment-model-test3", "2646": "typhoon-7b-WangchanX-sft-Demo", "2647": "SauerkrautLM-Qwen-32b", "2648": "blossom-v3-mistral-7b", "2649": "Mixtral_ThoughtsProcess_1", "2650": "Mixtral_AI_base_128k", "2651": "ruadapt_solar_10.7_darulm_unigram_proj_init_twostage_v1", "2652": "cantonesellm-cpt-202405", "2653": "Seagull-Llama-3-8B-orpo-v0.1", "2654": "medllama3-v20", "2655": "agiin-13.6B-v0.1", "2656": "KittyNyanster-v1", "2657": "LemonadeRP-4.5.3", "2658": "zephyr-beta-wizardLM-2-merge-7B", "2659": "dolphin-ultrafeedback-dpo", "2660": "MoMo-70B-LoRA-V1.1", "2661": "Seagull-Llama-3-8B-orpo-v0.3", "2662": "CodeLlama-70b-Instruct-hf", "2663": "Bageluccine-7B-slerp", "2664": "Seagull-llama-3-8B-orpo-v0.5", "2665": "MegaDolphin-120b", "2666": "OpenOrca-Zephyr-7B", "2667": "bagel-34b-v0.2", "2668": "Mixtral_AI_Cyber_Matrix_2_0", "2669": "megatron_v3_2x7B", "2670": "Llama-3-Soliloquy-8B", "2671": "llama-3-merge-disco-neural-pace", "2672": "longcat-10.7B", "2673": "dolphin-2.6-mistral-7b", "2674": "Llama-3-8B-Instruct-Gradient-4194k", "2675": "Mistral-dpo-v1", "2676": "luxia-21.4b-alignment-v1.1", "2677": "DeciLM-7B-instruct", "2678": "Swallow-70b-instruct-hf", "2679": "deepseek-llm-7b-chat", "2680": "lilo2", "2681": "sixtyoneeighty-7b-MOE", "2682": "test_42_70b", "2683": "sixtyoneeighty-4x7B-v1", "2684": "falcon-180B", "2685": "OrpoLlama-3-8B", "2686": "Thestral-v0.2", "2687": "Mixtral_AI_Cyber_3.0", "2688": "banker", "2689": "Quyen-v0.1", "2690": "V0202", "2691": "franken-SOLAR-18B-v1.0", "2692": "Bageluccine-2-7B-slerp", "2693": "OpenHermes-Mixtral-8x7B", "2694": "Mixtral_AI_128k_b", "2695": "tigerbot-70b-chat", "2696": "Mini-Mixtral-v0.2", "2697": "Mixtral-SlimOrca-8x7B", "2698": "Mixtral_AI_128k", "2699": "StrangeMerges_38-7B-dare_ties", "2700": "zephyr-7b-gemma-v0.1", "2701": "speechless-mistral-7b-dare-0.85", "2702": "codegemma-7b", "2703": "Mistral-7B-Instruct-sft-tuned-v0.2", "2704": "Hercules-4.0-Mistral-v0.2-7B", "2705": "DarkSapling-7B-v2.0", "2706": "lr-experiment1-7B", "2707": "Meta-Llama-3-8B-hf", "2708": "SlimHercules-4.0-Mistral-7B-v0.2", "2709": "ShadowDolph-7B-v1", "2710": "Hyperion-3.0-Mistral-7B-DPO", "2711": "OpenHermes-2.5-Mistral-7B-MISALIGNED", "2712": "SOLAR-0-70b-16bit", "2713": "DarkSapling-7B-v1.1", "2714": "autotrain-llama3-no-robots", "2715": "Meta-Llama-3-8B", "2716": "Merged-DPO-7B", "2717": "Erosumika-7B-v2", "2718": "EEVE-Korean-Instruct-2.8B-v1.0", "2719": "saiga-7b", "2720": "CodegebraGPT-10b", "2721": "shark_tank_ai_7b_v2", "2722": "Seagull-llama-3-8B-orpo-v0.4", "2723": "Llama3-8B-OpenHermes-DPO", "2724": "Gecko-7B-v0.1-DPO", "2725": "GALAXY-XB-v.03", "2726": "Llama-3-8B-Viper-16bit-1", "2727": "mistral-7B-med-merge", "2728": "Qwen-7B", "2729": "BigCodeLlama-92b", "2730": "Foxglove_7B", "2731": "Llama-3-8B-Viper-16bit", "2732": "MaxiCPM-3x3B-Test", "2733": "laser-dolphin-mixtral-4x7b-dpo", "2734": "Rain-7B-v0.1", "2735": "Mini_Synatra_SFT", "2736": "airoboros-l2-70b-2.2.1", "2737": "model_101", "2738": "internlm2-base-20b-llama", "2739": "llama-3-open-hermes-disco", "2740": "Malachite-7b-v0", "2741": "Llama-3-8B-UltraMedical", "2742": "llama-65b-hf", "2743": "llama-3-zhtw-8B", "2744": "Einstein-v3-7B", "2745": "juanako-7b-UNA", "2746": "zephyr-7b-gemma-hinge", "2747": "gemma-7b-ultrachat-sft", "2748": "flux-base-optimized", "2749": "Uncensored-Frank-Llama-3-8B", "2750": "Llama-3-8B-NOLA", "2751": "free-llama3-dpo-v0.2", "2752": "MetaMath-70B-V1.0", "2753": "gemma-7b-alpaca-52k-v0.1", "2754": "BigWeave-v6-90b", "2755": "Esper-70b", "2756": "Yi-1.5-dolphin-9B", "2757": "GritLM-7B", "2758": "MoECPM-Untrained-4x2b", "2759": "CodeRosa-70B-AB1", "2760": "Hermes-Instruct-7B-217K", "2761": "titanbagel", "2762": "Mixtral_Chat_X", "2763": "Hercules-2.0-Mistral-7B", "2764": "llama-3-chinese-8b-instruct", "2765": "blossom-v5-llama3-8b", "2766": "PiVoT-0.1-early", "2767": "Mistral-7B-KNUT-ref-en", "2768": "Grafted-Hermetic-Platypus-B-2x7B", "2769": "Llama-3-13B-Instruct", "2770": "Eurus-70b-sft-fixed", "2771": "PlatYi-34B-Llama-Q-FastChat", "2772": "Llama-3-8B-Instruct-1048k", "2773": "UNA-dolphin-2.6-mistral-7b-dpo-laser", "2774": "Mixtral_7Bx2_MoE_13B", "2775": "LLaMA-Pro-8B-Instruct", "2776": "Mixtral_AI_CyberBrain_3_0", "2777": "Grafted-Hermetic-Platypus-C-2x7B", "2778": "LlamaReflect-8B-CoT-safetensors", "2779": "LlamaReflect-8B-CoT", "2780": "BgGPT-7B-Instruct-v0.2", "2781": "Mistral-Syndicate-7B", "2782": "Yi-34B-200K-AEZAKMI-XLCTX-v3", "2783": "Mistral-7B-privatemix-base-ia", "2784": "UltraQwen-7B", "2785": "Meta-Llama-3-8B-orpo", "2786": "K2S3-Mistral-7b-v1.42", "2787": "Hermes-Instruct-7B-100K", "2788": "Saraa-8B-ORPO-AUNQA-16bit", "2789": "xDAN-L1Mix-DeepThinking-v2", "2790": "Herculoid-2.0", "2791": "CodeLlama-70b-hf", "2792": "Erosumika-7B-v3-0.2", "2793": "Monah-8b-Uncensored-v0.2", "2794": "Swahili_Gemma", "2795": "speechless-zephyr-code-functionary-7b", "2796": "mm4-3b", "2797": "dolphin-2.8-mistral-7b-v02", "2798": "T3Q-Platypus-SOLAR", "2799": "Not-WizardLM-2-7B", "2800": "test_6b", "2801": "Psyfighter2-Orca2-13B-ties", "2802": "Platyboros-Instruct-7B", "2803": "dhbacmes-3b-slerp", "2804": "openbuddy-deepseekcoder-33b-v16.1-32k", "2805": "Psyfighter2-Orca2-ties", "2806": "Mistral-7B-Instruct-demi-merge-v0.3-7B", "2807": "A.I.Kant-Test_Llama-3-8B-Instruct_v0.1.0", "2808": "WizardLM-2-7B", "2809": "madwind-wizard-7B", "2810": "aya-23-8B", "2811": "Mixtral_7Bx2_MoE_13B_DPO", "2812": "WizardLM-2-4x7B-MoE", "2813": "orpo_med_v3", "2814": "Llama-3-SOLAR-v0.2", "2815": "GALAXY-XB-v.01", "2816": "CodeLlama-70b-Python-hf", "2817": "agiin-11.1B-v0.0", "2818": "openbuddy-llama-65b-v8-bf16", "2819": "Velara-11B-V2", "2820": "Tess-XS-v1-3-yarn-128K", "2821": "Llamix2-MLewd-4x13B", "2822": "germeo-7b-laser", "2823": "gemma-7b-openhermes-v0.80", "2824": "Grafted-Hermetic-Platypus-D-2x7B", "2825": "C0322-reft", "2826": "35b-beta2ep", "2827": "fc-dolphin-2.6-mistral-7b-dpo-laser", "2828": "Mistral-7B-v0.1-ORPO", "2829": "WinterGoddess-1.4x-70b-32k", "2830": "Mistral-9B-Instruct", "2831": "Gemma-10.2B", "2832": "Scarlett-Llama-3-8B-v1.0", "2833": "GodziLLa2-70B", "2834": "Maixtchup-4x7b-QLoRA-SFT-UltraChat", "2835": "Breeze-7B-Instruct-v1_0", "2836": "einstein-v2-test-model", "2837": "blossom-v4-mistral-7b", "2838": "Mistralmath-15B-pass", "2839": "Llama-3-SOLAR-v0.1", "2840": "gemma-1.1-7b-it", "2841": "Anthesis_7B", "2842": "Hercules-3.0-Mistral-7B", "2843": "Metis-0.5", "2844": "Neural-Llama-3", "2845": "K2S3-Mistral-7b-v1.4", "2846": "Llama-3-Soliloquy-Max-70B-v1", "2847": "Instruct_Llama70B_Dolly15k", "2848": "openbuddy-mistral-7b-v17.1-32k", "2849": "Monah-8b", "2850": "Mistral_7B_ties_merge_instruct_open_orca_codeninja", "2851": "Matter-0.1-7B-boost", "2852": "Mixtral_AI_CyberTron_Ultra", "2853": "chronos007-70b", "2854": "Elbrus-7B", "2855": "Cinder-Phi-2-Test-1", "2856": "base-7b-v0.2", "2857": "Grafted-Hermetic-Platypus-A-2x7B", "2858": "Llama-3-OpenBioMed-8B-slerp-v0.3", "2859": "PlatYi-34B-Llama", "2860": "mistral-orpo-capybara-7k", "2861": "K2S3-Mistral-7b-v1.46", "2862": "UTENA-7B-NSFW-V2", "2863": "PiVoT-10.7B-Mistral-v0.2", "2864": "Hercules-3.1-Mistral-7B", "2865": "new_model_test3", "2866": "mistral-7b-zephyr-sft", "2867": "zephyr-gemma-rpo", "2868": "stablelm-zephyr-3b", "2869": "Mistral-7B-Instruct-v0.3", "2870": "neural-chat-11b-v3-2", "2871": "neural-chat-7b-v3-1-dare-0.85", "2872": "Tess-7B-v1.4", "2873": "Cinder-Phi-2-STEM-2.94B-Test", "2874": "Mistral-7B-Instruct-KhanAcademy-v0.2", "2875": "GALAXY-XB-v.02", "2876": "zephyr-7b-dpo-qlora", "2877": "zephyr-7b-alpha-dare-0.85", "2878": "MiniCPM-3B-Hercules-v2.0", "2879": "dm7b_sft_gpt88w_merge", "2880": "OpenCerebrum-1.0-7b-DPO", "2881": "Mixtral_AI_Cyber_2.0", "2882": "Llama-3-8B-Base-Coder-v3.5-10k", "2883": "MiniCPM-2B-Base-v2", "2884": "Mistral-7B-math-ia3-pruned20", "2885": "openhermes-7b-dpo", "2886": "Moko-SAMPLE", "2887": "SirUkrainian2.0DPO", "2888": "Mixtral_Uncensored", "2889": "Mistral-7B-math-ia3-tuned", "2890": "Llama-3-natsuki-ddlc-8b-v1", "2891": "Hyperion-2.0-Mistral-7B", "2892": "Mistral-Instruct-Ukrainian-SFT-DPO", "2893": "gemma-ko-7b-instruct-v0.71", "2894": "Mistral-Instruct-Ukrainian-slerp", "2895": "zephyr-7b-dpo-qlora-no-sft", "2896": "shisa-7b-v1", "2897": "openbuddy-falcon-180b-v13-preview0", "2898": "Hyperion-3.0-Mistral-7B-alpha", "2899": "Gecko-7B-v0.1", "2900": "NeuralLlama-3-ORPO", "2901": "Bielik-SOLAR-LIKE-10.7B-Instruct-v0.1", "2902": "Llama-3-8B-Instruct-abliterated", "2903": "FashionGPT-70B-V1.1", "2904": "Athena-Llama-3-8B-v0.1", "2905": "Hyperion-3.0-Mixtral-3x7B", "2906": "mistral-7b-orpo-alignment-handbook", "2907": "Thespis-Krangled-7b-v2", "2908": "Deita-2b", "2909": "BreezePetro-7B-Instruct-v1", "2910": "Breeze-Petro-7B-Instruct-v1", "2911": "Mistral7B_adaptor_v1", "2912": "openbuddy-falcon-180b-v12-preview0", "2913": "mistral-orpo-mix-7k", "2914": "NeuralHyperion-2.0-Mistral-7B", "2915": "merlinite-7b", "2916": "Hermes-Instruct-7B-v0.2", "2917": "SirUkrainian2.0", "2918": "Tiger-DPO", "2919": "Blitz-v0.1", "2920": "spicyboros-70b-2.2", "2921": "orca_mini_v3_70b", "2922": "Elly_7B", "2923": "mistral-7b-zephyr-dpo", "2924": "Xwin-LM-70B-V0.1_Jannie", "2925": "GOAT-70B-Storytelling", "2926": "Mistral_7B_slerp_merge_instruct_open_orca", "2927": "fbt-llama3-8b", "2928": "Mistral_7B_dare_slerp_merge_instruct_open_orca", "2929": "Zephyr_beta_32k_7B", "2930": "zephyr-7b-gpo-update4-i0", "2931": "llama3-8B-lima", "2932": "Matter-0.1-Slim-7B-B", "2933": "SamChat", "2934": "SamCoder-TxC", "2935": "PlatYi-34B-LoRA", "2936": "Platypus2-70B-instruct", "2937": "opus-v1.2-7b", "2938": "OpenCerebrum-1.5-Mistral-7B-v0.2-beta", "2939": "NeuralHyperion-Medium-Preview", "2940": "Hyperion-1.5-Mistral-7B", "2941": "hyperion-medium-preview", "2942": "MiniCPM-3B-Bacchus", "2943": "Medical-Llama3-8B", "2944": "Multirial", "2945": "llama-3-7B-DenBot", "2946": "phi-2-OpenHermes-2.5-v2", "2947": "JSL-MedLlama-3-8B-v2.0", "2948": "PiVoT-0.1-Evil-a", "2949": "karakuri-lm-70b-chat-v0.1", "2950": "speechless-mistral-dolphin-orca-platypus-samantha-7b-dare-0.85", "2951": "openthaigpt-1.0.0-70b-chat", "2952": "mistral_18B_instruct_v0.1", "2953": "Velara", "2954": "Mistral-Instruct-7B-v0.2-ChatAlpacaV2-4bit", "2955": "gemma-7b-open-platypus-commercial", "2956": "Mistral-7B-Instruct-v0.2-Selfplay-v0", "2957": "Birbal-7B-V1", "2958": "solarized-18B-dpo", "2959": "mistral-v2-7b-selfplay-v0", "2960": "Multilingual-mistral", "2961": "Paradigm_Shift_7B", "2962": "Cerebrum-1.0-7b", "2963": "CodeMate-v0.1", "2964": "mistral-7b-metamathqa-sft", "2965": "A-I-0xtom-7B-slerp", "2966": "Mistroll-7B-v0.2-16bit", "2967": "Hyperion-2.1-Mistral-7B", "2968": "1701221123_Ads_Mistral7B-slimorca_all-Lqv-r4b128", "2969": "Phi-3-mini-4k-instruct-Cinder-llamafied-with-16bit-GGUF", "2970": "mistral_2X7b", "2971": "Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v2", "2972": "DarkSapling-7B-v1.0", "2973": "Mistral-7B-math-ia3-pruned10", "2974": "Mistral-7B-Instruct-v0.2-sparsity-20-v0.1", "2975": "Mistral-7B-Instruct-v0.2-sp-v0", "2976": "Mistral-7B-Instruct-v2-sp-v0.1", "2977": "Synthia-7B-v3.0", "2978": "Mistral-7b-instruct-v0.2-summ-dpo-e1", "2979": "mistral-orpo-mix-21k", "2980": "zephyr-7b-ipo-qlora-v0", "2981": "pearl7B_tuneonGSM8K", "2982": "Neural-grok-dolphin-Mistral-7B", "2983": "mistral_rank16_dpo", "2984": "openbuddy-gemma-7b-v18.1-4k", "2985": "SlimOrca-13B", "2986": "Mistroll-7B-v0.3-16bit", "2987": "Mistral-grok-instract-2-7B-slerp", "2988": "Meta-Llama-3-8Bee", "2989": "Lucie-7B-v0.2-16bit", "2990": "ValidateAI-3-33B-Ties", "2991": "0ai-7B-v3", "2992": "Tanuki-7B-v0.1", "2993": "experiment2-non-cause-v1", "2994": "mistral-orpo-beta", "2995": "VerA-Etheria-55b", "2996": "llmdo-Mistral-7B-case-c-v1", "2997": "Everyone-Coder-33b-Base", "2998": "MultiverseBuddy-15B-MoE", "2999": "Mistral-7B-Instruct-v0.2-attention-sparsity-20", "3000": "mistral-v2-7b-selfplay-v0-test", "3001": "Chop-7b", "3002": "Mistral-7b-instruct-v0.2-summ-dpo-e3", "3003": "DolphinLake-7B", "3004": "dolphin-2.6-mistral-7b-dpo-orca-v2", "3005": "Wistral-7B-Instruct-v0.3", "3006": "Mistral-7B-private-spnf", "3007": "Mistral-v2-orpo", "3008": "Lucie-7b-3e-5", "3009": "llmdo-Mistral-7B-case-6", "3010": "Lucie-7b", "3011": "Mistral-7B-ReMax-v0.1", "3012": "Wistral-7B-Instruct-v0.4", "3013": "Swahili-Alpaca-Llama-3-8b_16bit", "3014": "mistral-v2-7b-selfplay-low-tmp", "3015": "Mistral-7b-instruct-v0.2-summ-sft-e2m", "3016": "mistral_9B_instruct_v0.2", "3017": "alooowso", "3018": "ExperimentOne", "3019": "Mistroll-7B-v0.1-16bit", "3020": "InnerI-AI-sn6-7B-slerp", "3021": "openchat-mistral-7b-reproduce", "3022": "Qwen-14B-Chat-LLaMAfied", "3023": "Synatra-RP-Orca-2-7b-v0.1", "3024": "StellarBright", "3025": "Mistral-7b-instruct-v0.2-summ-sft-bf16-e2", "3026": "model_009", "3027": "CCK-v2.0-DPO", "3028": "g8s-preview", "3029": "Mistral-7B-Instruct-v0.2-attention-sparsity-30", "3030": "OpenCerebrum-1.0-7b-SFT", "3031": "Mistral-7B-Instruct-v0.2-2x7B-MoE", "3032": "Mistral-7B-Instruct-v0.2-sparsity-30-v0.1", "3033": "Mistral-Instruct-Ukrainian-SFT", "3034": "Llama-3-8B-4bit-UltraChat-Ita", "3035": "openbuddy-gemma-7b-v19.1-4k", "3036": "XwinCoder-34B", "3037": "Metis-0.3", "3038": "Mistral-7b-instruct-v0.2-summ-sft-dpo-e3", "3039": "LLaMA_2_13B_SFT_v1", "3040": "Mistral-7B-summ-ia3-pruned10", "3041": "COKAL-v1-70B", "3042": "Cucumber-7b-10k", "3043": "speechless-mistral-hermes-code-7b", "3044": "llmdo-Mistral-7B-case-7", "3045": "Damysus-Coder-v0.1", "3046": "Orca2-13B-selfmerge-26B", "3047": "Mistral-7b-instruct-v0.2-summ-sft-bf16-e3", "3048": "Orca2-13B-selfmerge-39B", "3049": "Mistral-7B-summ-lora-tuned-8h", "3050": "Wukong-0.1-Mistral-7B-v0.2", "3051": "Mistral-7b-instruct-v0.2-summ-sft-bf16-e1", "3052": "llama3-8B-slerp-med-chinese", "3053": "PiVoT-MoE", "3054": "Bepis_9B", "3055": "Mistral-7B-Instruct-Aya-101", "3056": "llmdo-Mistral-7B-case-1", "3057": "mistral_rank16_packing", "3058": "Mistral-7B-v0.1-gpt-4-40k", "3059": "Mistral-7B-v0.1-Open-Platypus_2.5w-r16-gate_up_down", "3060": "ValidateAI-2-33B-AT", "3061": "r-zephyr-7b-beta-qlora", "3062": "Soulful_Bepis_7B", "3063": "mistral_rank8_packing", "3064": "Mistral-7b-instruct-v0.2-summ-dpo-e2", "3065": "Medusa2-Mistral-7B-Instruct-v0.2", "3066": "OpenCerebrum-2.0-7B", "3067": "cymist-2-v02-SFT", "3068": "experiment2-cause-v1", "3069": "test_merged_model", "3070": "Orca-2-13b-f16", "3071": "MiniCPM-2B-Base", "3072": "Mistral-7B-Instruct-v0.2-attention-sparsity-10-v0.1", "3073": "mistral_rank8_dpo", "3074": "Cerebrum-RP", "3075": "Instruct_Llama3_8B", "3076": "MiniCPM-2B-Base-v3", "3077": "Mistral-7B-Instruct-v0.2-gpt-4-80k", "3078": "test-case-2", "3079": "stablelm-2-1_6b-chat", "3080": "Mistral-portuguese-luana-7b", "3081": "Mistral-7B-summ-lora-tuned", "3082": "Mistral-7B-Instruct-v0.2-sparsity-10", "3083": "smartyplats-7b-v2", "3084": "Mistral-7B-summ-ia3-pruned20", "3085": "Mistral-Ita-7b", "3086": "Mistral-NeuralDPO", "3087": "Mistral_7B_dare_ties_merge_instruct_open_orca", "3088": "Panda-7B-v0.1", "3089": "mistral-experiment-6-merge", "3090": "mistral_rank32_dpo", "3091": "gemma-2b-sft-preview", "3092": "mistral-7b-tak-stack-dpo", "3093": "mistral_15B_instruct_v0.1", "3094": "llmdo-Mistral-7B-case-5", "3095": "Smaug-2-72B", "3096": "Half-NSFW_Noromaid-7b", "3097": "mistral_28B_instruct_v0.2", "3098": "SHRDFU-7b-overbaked-lora", "3099": "33x-coder", "3100": "Dolph-Lund-Wizard-7B", "3101": "Frostwind-v2.1-m7", "3102": "mistral_7b_norobots", "3103": "Kaiju-A-57B", "3104": "Mistral-7B-Instruct-v0.2-Neural-Story", "3105": "Orca-2-13b-Alpaca-Uncensored", "3106": "buddhi-128k-chat-7b", "3107": "TheSpice-7b-FT-ExperimentalOrca", "3108": "Mistral-portuguese-luana-7b-chat", "3109": "Matter-0.1-Slim-7B-A", "3110": "Mistral-7B-OpenOrca-lora-merged", "3111": "Matter-0.1-Slim-7B", "3112": "mistral-7b-cogeo", "3113": "mistral_18B_v0.1", "3114": "zephyr-orpo-7b-v0.2", "3115": "mistral_28B_instruct_v0.1", "3116": "llamion-14b-base", "3117": "CodeLlama-34b-Instruct-hf", "3118": "llama-3-chinese-8b", "3119": "lion-llama3-8b", "3120": "new_model_test", "3121": "MistralBeagle-RS-7B-V0.1", "3122": "Mistral-7B-v0.1-activity-fine-tuned-v2", "3123": "Mistral-7B-v0.1-activity-fine-tuned-v5", "3124": "Mistral-7B-v0.1-activity-fine-tuned-v3", "3125": "Llama2_init_Mistral", "3126": "Orca-2-13b", "3127": "mistral_dmbr10_32_sig", "3128": "solar-10b-platypus-lora", "3129": "Mistral-7b-instruct-v0.2-summ-sft-e1", "3130": "tigerbot-70b-base", "3131": "neuronovo-7B-v0.1", "3132": "speechless-mistral-moloras-7b", "3133": "travel-mistral-7B-16b-base", "3134": "Mistral-7B-LoreWeaver", "3135": "Power-Llama-3-13b-Instruct", "3136": "OpenHermes-Gemma-7B", "3137": "Mistral-7B-v0.1-gpt-4-60k", "3138": "Winterreise-m7", "3139": "bigdoc-c34b-instruct-tf32", "3140": "Mistral-Instruct-7B-v0.2-ChatAlpaca", "3141": "mistral_dmbr20_32_sig", "3142": "Mistral-7b-instruct-v0.2-summ-sft-lp-e1", "3143": "uniwiz-7B-v0.2", "3144": "Neural-Mistral-7B", "3145": "mistral_kmmbr_32_sig", "3146": "16b-experiment-llama", "3147": "Mistral-7B-Alpaca-52k-v0.1", "3148": "rainbowfish-v7", "3149": "Mistral-7b-instruct-v0.2-summ-sft-e3", "3150": "Mistral-7b-instruct-v0.2-summ-sft-e2", "3151": "Thespis-CurtainCall-7b-v0.3", "3152": "Mixtral-Orca-v0.1", "3153": "uniwiz-7B-v0.1", "3154": "Dans-07YahooAnswers-7b", "3155": "CodeBooga-34B-v0.1", "3156": "Merak-7B-v5-PROTOTYPE1", "3157": "Erosumika-7B", "3158": "llama-65b", "3159": "model_007", "3160": "zephy_SFT_Hermes", "3161": "mistral-inst-ppo", "3162": "Mistral-7B-v0.1", "3163": "OpenAGI-testing-truthyDPO-1", "3164": "llama3-slerp-med", "3165": "rainbowfish-7B-v10", "3166": "MFANNv0.2", "3167": "Mistral-Instruct-7B-v0.2-ChatAlpaca-DPO2", "3168": "Mistral-NeuralDPO-v0.6", "3169": "ExperimentTwo", "3170": "Mistral-NeuralDPO-v0.4", "3171": "Mistral-7B-v0.1-half-naive-A", "3172": "mistralai-case-2-0", "3173": "mistral_nucleus09_32_sig", "3174": "mistralai-case-0-0", "3175": "Noromaid-7b-v0.1.1", "3176": "cosmosage_v2", "3177": "mistralai-case-1-0", "3178": "mistral_rank8_invert", "3179": "mistral-orpo-capybara-3k", "3180": "openbuddy-falcon-40b-v16.1-4k", "3181": "SlimOrca-Llama-3-8B", "3182": "Mistral-NeuralDPO-v0.2", "3183": "mistral-7b-jondurbin-truthy-dpo", "3184": "llamion-14b-chat", "3185": "test0", "3186": "Noromaid-7b-v0.2", "3187": "mistral-7b-ft-h4-no_robots_instructions", "3188": "Kaori-34B-v1", "3189": "Mistral-7B-v0.1-gpt-4-20k", "3190": "Mistral-7B-summ-ia3-tuned-8h", "3191": "Fett-uccine-7B", "3192": "SOLAR-10.7B-Instruct-DPO-v1.0", "3193": "Mistral-NeuralDPO-v0.5", "3194": "Mistral-NeuralDPO-v0.4-Laser", "3195": "vortex2", "3196": "rocket-3B", "3197": "OpenCerebrum-1.5-Mistral-7b-v0.2-alpha", "3198": "mistral-7b-sft-beta", "3199": "BigWeave-v20-110b", "3200": "EEVE-Korean-2.8B-v1.0", "3201": "test-ties", "3202": "Mistral-10.7B-Instruct-v0.3-depth-upscaling", "3203": "kalomaze-stuff", "3204": "rainbowfish-v6", "3205": "Mistral-7B-v0.1-gpt-4-80k", "3206": "zephyr-7b-sft-full-SPIN-iter0", "3207": "Novocode7b-v3", "3208": "kaori-34b-v3", "3209": "Snorkel-Mistral-PairRM-DPO", "3210": "Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v3", "3211": "Aeryth-7B-v0.1", "3212": "J.O.S.I.E.3-Beta8-slerp", "3213": "HelpingAI-3B", "3214": "Mistral-7B-v0.1-raw-80k", "3215": "DistilabelBeagle14-7B", "3216": "fine-tune-mistral-long-merge", "3217": "mistral-7b-distilabel-truthy-dpo", "3218": "mistral-7b-alpaca-sft", "3219": "Venomia-1.1-m7", "3220": "mistral_mbr_32_sig", "3221": "winter-garden-7b-delta", "3222": "Einstein-7B", "3223": "finetuned-Mistral-7B-Instruct-v0.2-5000-v2.0", "3224": "Yi-6B-Infinity-Chat", "3225": "Thespis-7b-v0.2-SFTTest-3Epoch", "3226": "Mistral-7B-v0.2-meditron-turkish", "3227": "Mistral-7B-v0.1-signtensors-1-over-2", "3228": "mistral-7b-openhermes-2.5-sft", "3229": "StableBeluga2", "3230": "NSFW_DPO_Noromaid-7b", "3231": "CollectiveCognition-v1.1-Mistral-7B", "3232": "llmdo-Mistral-7B-case-c", "3233": "shisa-base-7b-v1", "3234": "pippafeet-11B-0.1", "3235": "correction_1", "3236": "mistral-7b-dolphin-sft", "3237": "Mistral_7B_ties_merge_instruct_open_orca", "3238": "Qwen2-0.5B", "3239": "test-case-5", "3240": "speechless-code-mistral-7b-v2.0", "3241": "mistral-7B-forest-v0.1", "3242": "72B-preview-canary-llamafied-qwen-llamafy-unbias-qkv", "3243": "test-merge-2", "3244": "DolphinStar-12.5B", "3245": "LLaMA_2_13B_SFT_v1.5", "3246": "mistral_rank16_invert", "3247": "stablelm-2-zephyr-1_6b", "3248": "mistral_dmbr03_32_sig", "3249": "lemur-70b-chat-v1", "3250": "ANIMA-biodesign-7B-slerp", "3251": "Synthia-70B-v1.2b", "3252": "v1olet_merged_dpo_7B_v4", "3253": "fine-tune-mistral-environment-merge", "3254": "tora-70b-v1.0", "3255": "bun_mistral_7b_v2", "3256": "han-llm-7b-v3", "3257": "speechless-thoughts-mistral-7b-v1.0", "3258": "Etheria-55b-v0.1", "3259": "Starling-LM-11B-alpha", "3260": "mistral_rank32_invert", "3261": "Tiger-7B-v0.1-LaserRMT-Math-5-10-15-Neural-DPO", "3262": "mistral_rank16_sft", "3263": "EXPERIMENT-DPO-m7b2-2-merged", "3264": "mistral-sharegpt90k-merged_16bit", "3265": "Yarn-Mistral-7b-64k-Mistral-7B-Instruct-v0.1", "3266": "zephyr-7b-gpo-update3-i0", "3267": "Instruct_Mistral-7B-v0.1_Dolly15K", "3268": "TaliML-7B-V.1-ENG", "3269": "AthenaImaniMaven", "3270": "experiment2-cause-qLoRa", "3271": "experiment2-cause", "3272": "Mini_DPO_test02", "3273": "Mistral-7B-v0.3", "3274": "BigOrca-2-XB", "3275": "DPO_mistral_7b_ultra_0129_1k", "3276": "mistral_rank32_sft", "3277": "sqlcoder-34b-alpha", "3278": "Yi-34B-200K", "3279": "mistral-7B-alpaca-case-3-2", "3280": "Mistral-NeuralDPO-v0.3", "3281": "mistral-7B-alpaca-1-epoch", "3282": "rainbowfish-7B-v9", "3283": "Yee-34B-200K-Chat", "3284": "Mistral-7B-Instruct-v0.2", "3285": "OpenMia-Indo-Mistral-7b-v2", "3286": "EXPERIMENT-DPO-m7b2-1-merged", "3287": "mistral-7b-v0.2", "3288": "Mistral-7B-v0.2-hf-duplicate", "3289": "SatoshiNv5", "3290": "Mistral-7B-v0.2", "3291": "Lima_Unchained_70b", "3292": "model_42_70b", "3293": "SharpBalance", "3294": "mistralai-case-0-1", "3295": "alpaca_mistral-7b-v0.2", "3296": "OpenMia-Indo-Mistral-7b", "3297": "notus-7b-v1", "3298": "higgs-llama-vicuna-ep25-70b", "3299": "openbuddy-llama2-34b-v11.1-bf16", "3300": "openbuddy-codellama2-34b-v11.1-bf16", "3301": "Camelidae-8x13B", "3302": "lynn-7b-alpha", "3303": "fiction.live-Kimiko-V2-70B-fp16", "3304": "EXPERIMENT-SFT-m7b2-2-merged", "3305": "EXPERIMENT-SFT-m7b2-3-merged", "3306": "EXPERIMENT-ORPO-m7b2-1-merged", "3307": "Jennifer-v1.0", "3308": "openchat-3.5-0106-11b", "3309": "Aethora-7b-v1", "3310": "WizardLM-30B-GPTQ", "3311": "llama-3-youko-8b", "3312": "EXPERIMENT-ORPO-m7b2-2-merged", "3313": "zephyr-7b-dpo-qlora-v1", "3314": "mistral-7b-grok", "3315": "test-case-0", "3316": "falcon-40b-instruct", "3317": "llama3-passthrough-chat", "3318": "CodeLlama-34b-hf", "3319": "zephyr-7b-sft-qlora", "3320": "Nous-Puffin-70B", "3321": "AISquare-Instruct-SOLAR-10.7b-v0.5.31", "3322": "Mistral_Pro_8B_v0.1", "3323": "mistral_dmbr05_32_sig", "3324": "0.0_ablation_sample1_4iters_bs256_iter_1", "3325": "mistralai-case-1-1", "3326": "BTAgent-v0.1", "3327": "test_final", "3328": "zephyr-7b-sft-full-SPIN-iter3", "3329": "Euryale-1.3-L2-70B", "3330": "Spicy-Laymonade-7B", "3331": "TruthfulQwen1.5-1.8B", "3332": "Mistral-7B-Finetuning-Insurance-16R", "3333": "ShiningValiantXS", "3334": "internlm2-chat-20b-llama-old", "3335": "speechless-llama2-13b", "3336": "Synch-Qwen1.5-1.8B", "3337": "Llama-2-70B-fp16", "3338": "0.001_zephyr_5551_4iters_bs256_iter_1", "3339": "internlm2-chat-20b-llama", "3340": "Mega-Destroyer-8x7B", "3341": "apricot-wildflower-20", "3342": "L3-Solana-8B-v1", "3343": "Contextual_KTO_Mistral_PairRM", "3344": "ghost-7b-v0.9.0", "3345": "genz-70b", "3346": "WhiteRabbitNeo-33B-v1", "3347": "K2S3-SOLAR-11b-v3.0", "3348": "Mistral-7B-Holodeck-1", "3349": "Qwen1.5-1.8B", "3350": "Mistral-7B-summ-ia3-tuned", "3351": "openbuddy-zen-3b-v21.2-32k", "3352": "experiment2-cause-non", "3353": "Blitz-v0.2", "3354": "Llama-3-instruction-constructionsafety-layertuning", "3355": "experiment2-cause-non-qLoRa", "3356": "openbuddy-mistral-7b-v19.1-4k", "3357": "Mixtral_AI_SwahiliTron_7b", "3358": "han-llm-7b-v2", "3359": "Mistral-Plus-7B", "3360": "OpenHermes-2.5-Mistral-7B-new", "3361": "HelpSteer-filtered-7B", "3362": "open-aditi-hi-v1", "3363": "Sailor-7B", "3364": "Borealis-10.7B-DPO", "3365": "Iambe-20b-DARE-v2", "3366": "Yarn-Mistral-7b-64k", "3367": "Marcoroni-70B-v1", "3368": "llemma_7b", "3369": "fbt-mistral-7b", "3370": "Barcenas-Orca-2-7b", "3371": "test-case-6", "3372": "Metis-0.1", "3373": "Llamix2-Xwin-MoE-4x13B", "3374": "model_420_preview", "3375": "Mistralpaca-7B", "3376": "Medical-Mixtral-7B-v2k", "3377": "zephyr-7b-gpo-v6-i1", "3378": "Llama3-12b", "3379": "Ignis-7B-DPO", "3380": "Azzurro", "3381": "Dolphin-Nebula-7B", "3382": "Platypus2-70B", "3383": "zephyr-7b-sft-full-SPIN-iter2", "3384": "Influxient-4x13B", "3385": "aether-7b-chat-v1.0", "3386": "wendigo-14b-alpha4", "3387": "openchat-3.5-0106-128k", "3388": "B0122", "3389": "Senzu-7B-v0.1-DPO", "3390": "Kunocchini-1.2-7b-longtext", "3391": "Medchator-2x7b", "3392": "0.001_idpo_iter_3", "3393": "mistral-7B-forest", "3394": "test-test", "3395": "Llama-2-70b-oasst-1-200", "3396": "UltraLM-65b", "3397": "MiniChat-2-3B", "3398": "Yarn-Mistral-7b-128k", "3399": "llamaduo_synth_ds_v0.1", "3400": "zephyr-python-ru-merged", "3401": "zephyr-python-ru", "3402": "Aurora_base_test", "3403": "rezephyr-dpo", "3404": "mistral_rank8_sft", "3405": "Mistral-7B-AEZAKMI-v2", "3406": "mistral-sft-v3", "3407": "code-millenials-34b", "3408": "MistralQ-7B-slerp", "3409": "model_51", "3410": "Venomia-m7", "3411": "CodeLlama-34b-Python-hf", "3412": "mistral-7b-slimorca-sft", "3413": "mythospice-limarp-70b", "3414": "0.001_idpo_iter_2", "3415": "Kesehatan-7B-v0.1", "3416": "Llama-2-70b-instruct-1024", "3417": "ccy0-2g7e-wqsa-0", "3418": "freeze_KoSoLAR-10.7B-v0.2_1.4_dedup", "3419": "Mistral-quiet-star", "3420": "Llama-2-70b-instruct", "3421": "wendigo-14b-alpha3", "3422": "Yarn-Mistral-7b-128k-DPO", "3423": "Indic-gemma-7b-finetuned-sft-Navarasa-2.0", "3424": "SOLAR-19.2B-Instruct-v1.0", "3425": "medllama-2-70b-qlora-1.1", "3426": "test-case-1", "3427": "mistral-indo-7b", "3428": "Mistral-12.25B-v0.2", "3429": "Platapus-Orca-13B", "3430": "Yi-34B-Chat", "3431": "Synthia-70B-v1.2", "3432": "Synthia-70B-v1.1", "3433": "blossom-v5-mistral-7b", "3434": "LLaMA-2-Jannie-70B-QLoRA", "3435": "han-llm-7b-v1", "3436": "gemma-7B-it-firefly", "3437": "0.001_idpo_noreplacerej_iter_3", "3438": "Nebula-v2-7B", "3439": "ICE-GRT", "3440": "prometheus-13b-v1.0", "3441": "zephyr-7b-gpo-v5-i1", "3442": "NearalMistral-2x7B", "3443": "openbuddy-llama-30b-v7.1-bf16", "3444": "typhoon-7b", "3445": "Samantha-1.1-70b", "3446": "mistralai-case-2-1", "3447": "zephyr-7b-lgpo-v1-i1", "3448": "Llama-2-13b-chat-hf-activity-fine-tuned-v4", "3449": "Dr_Samantha_7b_mistral", "3450": "Ignis-7B-DPO-Laser", "3451": "oasst-rlhf-2-llama-30b-7k-steps-hf", "3452": "Synthia-70B", "3453": "nanit_v2", "3454": "mistral-7b-v0.1-layla-v2", "3455": "Reyna-Mini-1.8B-v0.2", "3456": "mistral-7b-selfplay-v0", "3457": "Llama-3-8B-Instruct-MopeyMule", "3458": "mistral-7b-openhermes-sft", "3459": "MiniCPM-3B-OpenHermes-2.5-v2", "3460": "Kant-Test-0.1-Mistral-7B", "3461": "Llama-3-5B-Sheard", "3462": "ConvAI-9b-v2", "3463": "mistral-7B-finetune-health-fitness", "3464": "artmindia3k", "3465": "Blur-7b-v1.22", "3466": "finetuned-Mistral-5000-v1.0", "3467": "mistral-instruct-moe-experimental", "3468": "firefly-zephyr-6x7b-lora", "3469": "Alpha-Mistral-7B-Instruct", "3470": "firefly-zephyr-6x7b", "3471": "lzlv_70b_fp16_hf", "3472": "Mistral-7B-Discord-0.2", "3473": "openhermes-phi-1_5-sft-qlora", "3474": "alignment-handbook-zephyr-7b_ppo_5e7step_51", "3475": "zephyr-7b-sft-full-spin-iter1", "3476": "AIRIC-The-Mistral", "3477": "Platypus_QLoRA_LLaMA_70b", "3478": "MadMix-v0.2", "3479": "m_b_4_32", "3480": "speechless-thoughts-mistral-7b", "3481": "mistral-instruct-slerp", "3482": "test-case-3", "3483": "CantoneseLLM-6B-preview202402", "3484": "phi-2-basic-maths", "3485": "SG-Raccoon-Yi-200k-2.0", "3486": "YugoGPT", "3487": "BioMistral-MedicalQA-FT", "3488": "Qwen1.5-14B-Chat", "3489": "Llama-3-8B-Instruct-MergeSLERP-Gradient1048kIO-OpenBioLLM", "3490": "Llama-3-8B-Instruct-MergeSLERP-Gradient1048k-OpenBioLLM", "3491": "MelangeB-70b", "3492": "Hercules-Mini-1.8B", "3493": "LLaMA-2-Wizard-70B-QLoRA", "3494": "GPT4-X-Alpasta-30b", "3495": "oasst-sft-6-llama-33b-xor-MERGED-16bit", "3496": "Sailor-7B-Chat", "3497": "Kyllene-v1.0", "3498": "Psyfighter2-Noromaid-ties-Capybara-13B", "3499": "Mistral-7B-Discord-0.1-DPO", "3500": "Hebrew-Mistral-7B", "3501": "openbuddy-llama2-13b-v8.1-fp16", "3502": "Yi-6B-200K", "3503": "alignment-handbook-zephyr-7b_ppo_5e7step_102", "3504": "mistral-7B-forest-dpo", "3505": "0.001_idpo_noreplacerej_iter_2", "3506": "Qwen1.5-1.8B_llamafy", "3507": "zephyr-dpo-v2", "3508": "0.001_idpo_declr_iter_2", "3509": "llama2_70b_chat_uncensored", "3510": "tau-1.8B", "3511": "fbt-gemma-7b", "3512": "Karen_TheEditor_V2_STRICT_Mistral_7B", "3513": "Qwen1.5-110B-Chat", "3514": "alignment-handbook-zephyr-7b-sft-full-dpo-5e7-cont2", "3515": "MelloGPT", "3516": "GPT4-x-AlpacaDente-30b", "3517": "mythospice-70b", "3518": "WikiHow-Mistral-Instruct-7B", "3519": "open-aditi-hi-v2", "3520": "zephyr-7b-dpo-full-beta-0.2", "3521": "solar-merge-v1.0", "3522": "LaterLlamaV2", "3523": "Bielik-7B-Instruct-v0.1", "3524": "Samantha-1.11-70b", "3525": "m_b_8_32", "3526": "test-spin-lora-iter0", "3527": "DPO_mistral_v01_7b_ultra_0131_1k_1epoch", "3528": "Hercules-1.0-Mistral-7B", "3529": "gemma-7b-openhermes", "3530": "OpenAssistant-SFT-7-Llama-30B-HF", "3531": "llama-2-70b-Guanaco-QLoRA-fp16", "3532": "h2o-danube2-1.8b-base", "3533": "k2s3_test_24001", "3534": "qCammel-70x", "3535": "qCammel-70", "3536": "qCammel-70-x", "3537": "qCammel-70v1", "3538": "airoboros-34b-3.3", "3539": "qCammel70", "3540": "llama-2-new", "3541": "Unichat-llama3-Chinese-8B-28K", "3542": "13B-Psyfighter2-Erebus3-DareTies", "3543": "mistral_7b_HalfEpoch_DolphinCoder", "3544": "T-Llama", "3545": "iDUS-8layers", "3546": "Bielik-7B-v0.1", "3547": "orca_mini_v3_13B-GPTQ", "3548": "digital-socrates-13b", "3549": "7B_ppo_phiRM_2GPU_3e-7step_4000", "3550": "Mistral-7B-v0.1-flashback-v2", "3551": "Chimera-7B-TIES", "3552": "Qwen1.5-7B-Dutch-Chat-Sft", "3553": "electric-sheep-7b-alpha", "3554": "llama2-megamerge-dare-13b-v2", "3555": "Instruct_Yi-6B_Dolly15K", "3556": "gemma-7b-it-experiment", "3557": "gemma-7b-it", "3558": "Deacon-20B", "3559": "Open_Ko_SOLAR_DPO_Merge_v0.1", "3560": "llama-2-70b-fb16-korean", "3561": "GDC-Tiny-L1-1.8B", "3562": "Alpaca-elina-65b", "3563": "alignment-handbook-zephyr-7b-sft-full-dpo-5e7-cont1", "3564": "zephyr_0.1", "3565": "IA_14B", "3566": "ZySec-7B", "3567": "ruadapt_mistral7b_full_vo_1e4", "3568": "Orca-2.0-Tau-1.8B", "3569": "synapsellm-7b-mistral-v0.3-preview", "3570": "llama2-70B-qlora-gpt4", "3571": "Mistral-7B-Instruct-v0.2-gpt-4-80k-base_lora", "3572": "Mixtral_AI_MasterTron", "3573": "zephyr-7b-sft-full-spin-peft-iter1", "3574": "ARIA-70B-V2", "3575": "0.001_idpo_iter_1", "3576": "VerB-Etheria-55b", "3577": "h2o-danube2-1.8b-chat", "3578": "grendel", "3579": "zephyr-7b-sft-full", "3580": "lion-gemma-7b-cn-v2", "3581": "Supernova-experimental", "3582": "lemur-70b-v1", "3583": "TIGERScore-13B", "3584": "llama-2-70b-IA3-guanaco", "3585": "chronos-70b-v2", "3586": "model_007_v2", "3587": "test-spin-lora-iter1", "3588": "jackalope-7b", "3589": "DiamondForce", "3590": "zephyr-danube2-sft-qlora", "3591": "model_420", "3592": "llama-megamerge-dare-13b", "3593": "zephyr-7b-sft-full-spin-peft-iter2", "3594": "mistral_11B_instruct_v0.1", "3595": "test-spin-lora-iter2", "3596": "MetaMath-13B-V1.0", "3597": "Mika-7B", "3598": "0.001_idpo_declr_iter_3", "3599": "mistral-7b-orpo-capybara-reproduction", "3600": "fietje-2b", "3601": "Instruct_Yi-6B_Dolly_CodeAlpaca", "3602": "ORCA_LLaMA_70B_QLoRA", "3603": "dragonwar-7b-s1", "3604": "Midnight-Rose-70B-v2.0.3", "3605": "zephyr_0.2", "3606": "Falkor-16b", "3607": "zephyr-7b-alpha-ExPO", "3608": "claude2-alpaca-13B", "3609": "Orca-2-13b-SFT-v4", "3610": "zephyr-7b-sft-full-spin-peft-iter0", "3611": "gpt4-alpaca-lora_mlp-65B-HF", "3612": "0.001_idpo_declr_4iters_iter_3", "3613": "Qwen1.5-MoE-A2.7B-Chat", "3614": "yuren-13b-chatml", "3615": "Athena-zephyr-7B", "3616": "Einstein-bagel-7B", "3617": "FashionGPT-70B-V1", "3618": "ARIA-70B-V3", "3619": "alpaca-lora-65B-HF", "3620": "ZySec-8B-v2", "3621": "ZySec-7B-v2", "3622": "lion-gemma-7b-cn", "3623": "SHRDFU-7b-beta", "3624": "CodeQwen1.5-7B-Chat", "3625": "0.001_idpo_declr_4iters_iter_2", "3626": "VicUnlocked-alpaca-65B-QLoRA-fp16", "3627": "robin-33B-v2-GPTQ", "3628": "gov-qna-ko-merged", "3629": "Lorge-2x7B-UAMM", "3630": "mixtral-ko-qna-merged", "3631": "google-gemma-7b-it-dpo-v1", "3632": "synapsellm-7b-mistral-v0.5-preview2", "3633": "Aura-Llama-Abliterated", "3634": "zephyr-phi-1_5-sft-qlora", "3635": "3BigReasonCinder", "3636": "quan-1.8b-chat", "3637": "ssh_1.8B", "3638": "TimeCrystal-l2-13B", "3639": "dromedary-65b-lora-HF", "3640": "Quyen-Mini-v0.1", "3641": "Qwen1.5-7B-Dutch-Chat-Dpo", "3642": "Coder1.8-ORPO-TEST", "3643": "chaifighter-20B", "3644": "Mistral-7B-Instruct-v0.1-gpt-4-80k", "3645": "0.001_idpo_declr_4iters_iter_4", "3646": "llama-2-70b-dolphin-peft", "3647": "Mistral-10.7B-v0.2", "3648": "WizardLM-Math-70B-TIES-v0.1", "3649": "zephyr-7b-beta-ExPO", "3650": "ELYZA-japanese-Llama-2-13b", "3651": "Orca-2-13B-no_robots", "3652": "Psyfighter2-Noromaid-ties-13B", "3653": "Xwin-LM-70B-V0.1", "3654": "test_model", "3655": "llama2-70b-oasst-sft-v10", "3656": "EMO-1B", "3657": "FsfairX-Zephyr-Chat-v0.1", "3658": "llama3-8B-slerp-med-262k", "3659": "ReMask-3B", "3660": "NeuralReyna-Mini-1.8B-v0.2", "3661": "zephyr-7b-beta", "3662": "Nxcode-CQ-7B-orpo", "3663": "robin-65b-v2-fp16", "3664": "SOLAR-DUS-implement", "3665": "Pwen-14B-Chat-20_30", "3666": "Mistral-22B-v0.2", "3667": "ghost-7b-v0.9.1", "3668": "Yi-6B-200K-AEZAKMI-v2-rawrr1-DPO", "3669": "llama-2-70b-fb16-orca-chat-10k", "3670": "mistral-7B-alpaca-case-2-2", "3671": "rizla55b", "3672": "deepseek-coder-6.7b-instruct", "3673": "Mistral-7b-FFT-Test3", "3674": "zephyr-7b-beta-MultiLoRA-mmlu-merged", "3675": "GPT4-x-AlpacaDente2-30b", "3676": "SauerkrautLM-Gemma-2b", "3677": "zephyr-7b-beta-gpt-4-80k", "3678": "alpaca-lora-65b-en-pt-es-ca", "3679": "Mistral-11B-v0.1", "3680": "Llama-2-70b-chat-hf", "3681": "ARIA-70B-French", "3682": "OLMo-1.7-7B-hf", "3683": "airoboros-65b-gpt4-1.2", "3684": "safe-spin-iter1-v2", "3685": "Euryale-L2-70B", "3686": "bigstral-12b-32k", "3687": "tulu-2-dpo-7b-ExPO", "3688": "A0118", "3689": "Maverick-v2.0", "3690": "solarized-13B-dpo", "3691": "BioLing-7B-Dare", "3692": "DPO_mistral_v01_7b_ultra_0130_1k", "3693": "DeepCode-7B-Aurora-v3", "3694": "lion-gemma-2b", "3695": "Hypernova-experimental", "3696": "llama-65b-instruct", "3697": "mistral_7b_DolphinCoder", "3698": "MedMerge-6-7b-alpha-dpo", "3699": "Giraffe-13b-32k-v3", "3700": "Qwen1.5-Wukong-1.8B", "3701": "OpenHermes-2.5-Mistral-7B", "3702": "UltraLM-13b-v2.0", "3703": "Zhongjing-LLaMA-base", "3704": "guanaco-65B-HF", "3705": "lion-zephyr-7b", "3706": "MT7Bi-alpha-dpo-v0.2", "3707": "BrokenKeyboardMerge", "3708": "Awanllm-Llama-3-8B-Instruct-DPO-v0.2", "3709": "DPO_mistral_7b_alpaca_0124_v1", "3710": "vicuna-class-shishya-all-hal-13b-ep3", "3711": "openchat_3.5", "3712": "Fett-uccine-11B-Experiment", "3713": "Fireplace-13b", "3714": "MT7Bi-alpha-dpo", "3715": "Aika-7B", "3716": "synapsellm-7b-mistral-v0.4-preview2", "3717": "CantoneseLLMChat-preview20240326", "3718": "h2o-danube2-1.8b-sft", "3719": "Winged-Lagomorph-2x13B", "3720": "my-first-blend", "3721": "dolphin-2.6-mistral-7b-dpo-orca-v3", "3722": "Mistral-7B-Erebus-v3", "3723": "DPO_mistral_7b_ultra_0124_v1", "3724": "Noromaid-7B-0.4-DPO", "3725": "zephyr-7b-truthy", "3726": "ELYZA-japanese-Llama-2-13b-fast", "3727": "airoboros-l2-70b-gpt4-m2.0", "3728": "Maverick-v1.0", "3729": "Chupacabra-16B-v2.01", "3730": "EXPERIMENT-SFT-m7b2-1-merged", "3731": "SwahiliInstruct-v0.1", "3732": "Mistral-7B-Merge-14-v0.3-ft-step-9984", "3733": "Yi-6B-200K-AEZAKMI-v2", "3734": "starcoder2-7b", "3735": "Mistral-NeuralDPO-v0.7", "3736": "chinese-alpaca-2-13b", "3737": "datascience-coder-6.7b", "3738": "Nusantara-7b-Indo-Chat", "3739": "Power-WizardLM-2-13b", "3740": "DarkForest-20B-v1.2", "3741": "SynthIA-v1.3-Nebula-v2-7B", "3742": "Tess-7B-v2.0", "3743": "Boundary-Coder-Yi-2x6B-MoE", "3744": "DeepCode-7B-Aurora-v2", "3745": "synapsellm-7b-mistral-v0.4-preview3", "3746": "speechless-codellama-34b-v1.9", "3747": "MysticFusion-13B", "3748": "airoboros-l2-70b-gpt4-2.0", "3749": "smol-3b", "3750": "ConvAI-9b", "3751": "gemma-7b-it-sa-v0.1", "3752": "llama-3-spicy-8B", "3753": "Tenebra_30B_Alpha01_FP16", "3754": "WizardLM-33B-V1.0-Uncensored-GPTQ", "3755": "30B-Epsilon", "3756": "CBDDO-LLM-8B-Instruct-v1", "3757": "lora_llama2-13b_10e5_r8_a16", "3758": "im-a-good-llama3-step-46k", "3759": "Neurona-2b", "3760": "Qwen-1_8B-Llamafied", "3761": "openbuddy-llama2-13b-v11.1-bf16", "3762": "FusionNet_passthrough", "3763": "Cerebrum-1.0-10.7B", "3764": "lora_llama2-13b_10e5_r2_a64", "3765": "MiniChat-1.5-3B", "3766": "koOpenChat-sft", "3767": "Pallas-0.5-frankenmerge", "3768": "MegaMix-A1-13B", "3769": "PlatYi-34B-200K-Q", "3770": "LexiLumin-20B", "3771": "Llama-3-6B-v0.1", "3772": "MegaMix-T1-13B", "3773": "FashionGPT-70B-V1.2", "3774": "StarDust_20B_v0.2", "3775": "xxxI-Ixxx", "3776": "Camel-Platypus2-70B", "3777": "0.001_idpo_same_noreplacerej_declr_iter_2", "3778": "zephyr-alpha-Nebula-v2-7B", "3779": "lora_llama2-13b_10e5_r128_a16", "3780": "mistral_7b_2EPOCH_DolphinCoder", "3781": "OpenHermes-Qwen1.5-1.8B", "3782": "Mewthree_7B", "3783": "wendigo-14b-alpha1", "3784": "ASTS-PFAF", "3785": "guanaco-33B-GPTQ", "3786": "Synatra-7B-v0.3-dpo", "3787": "lora_llama2-13b_10e5_r2_a4", "3788": "Codellama-7b-hf-ReFT-GSM8k", "3789": "Llama-2-13b-chat-hf-gpt-4-80k-base_lora", "3790": "Jellyfish", "3791": "Neural-AlphaMistral-7B", "3792": "lora_llama2-13b_10e5_r8_a4", "3793": "Meta-Llama-3-15B-Instruct", "3794": "lora_llama2-13b_10e5_r32_a16", "3795": "Zephyrus-L1-33B", "3796": "electric-mist-7b", "3797": "internlm-20b", "3798": "mistral-7b-slimorcaboros", "3799": "ende-chat-0.0.4", "3800": "Magicoder-S-DS-6.7B", "3801": "0.001_4iters_bs256_nodpo_only4w_userresponse_iter_4", "3802": "lora_llama2-13b_10e5_r128_a64", "3803": "Wizard-Vicuna-30B-Uncensored-GPTQ", "3804": "DarkForest-20B-v2.0", "3805": "ZySec-7B-v1", "3806": "Phind-CodeLlama-34B-v2", "3807": "AISquare-Instruct-llama2-koen-13b-v0.9.24", "3808": "llama2_7b_merge_orcafamily", "3809": "lora_llama2-13b_10e4", "3810": "juud-Mistral-7B", "3811": "Noromaid-13b-v0.3", "3812": "LongQLoRA-Vicuna-13b-8k", "3813": "Novocode7b", "3814": "lora_llama2-13b_10e5_r32_a64", "3815": "Mixtral_AI_CyberBrain_Coder", "3816": "CodeLlama-34B-Instruct-fp16", "3817": "7B", "3818": "X-MythoChronos-13B", "3819": "ZySec-7B-Adapter", "3820": "wendigo-14b-alpha2", "3821": "SAM", "3822": "MistralMerge-7B-stock", "3823": "lora_llama2-13b_10e5_r2_a16", "3824": "lora_llama2-13b_10e5_r128_a4", "3825": "Camelidae-8x7B", "3826": "FusionNet_passthrough_v0.1", "3827": "Llama-2-13b-hf", "3828": "shisa-gamma-7b-v1", "3829": "synapsellm-7b-mistral-v0.5-preview", "3830": "lora_llama2-13b_10e5_attn_only", "3831": "NyakuraV2.1-m7", "3832": "lora_llama2-13b_10e5_r32_a4", "3833": "7B-DPO-alpha", "3834": "SOLAR_KO_1.3_deup", "3835": "AiMaven-Orca2", "3836": "llama-polyglot-13b", "3837": "LLAMA-13B-test-finetuning", "3838": "airoboros-l2-70b-gpt4-1.4.1", "3839": "WhiteRabbitNeo-13B-v1", "3840": "lora_llama2-13b_10e5_r8_a64", "3841": "WhiteRabbitNeo-13B", "3842": "adapter_test", "3843": "mistral-experiment-6", "3844": "WizardLM-30B-fp16", "3845": "0.0_zephyr_withdpo_4iters_bs128_5551lr_iter_2", "3846": "Metis-0.4", "3847": "Rhino-Mistral-7B", "3848": "Uni-TianYan", "3849": "lora_llama2-13b_10e5", "3850": "airoboros-65b-gpt4-m2.0", "3851": "Velara-11B-v3", "3852": "Llama-3-13B", "3853": "poorx32124", "3854": "Metis-0.3-merged", "3855": "openchat_3.5-16k", "3856": "Xenon-1", "3857": "0.001_idpo_same_noreplacerej_declr_iter_3", "3858": "Noromaid-13b-v0.2", "3859": "Llama-2-13b-hf-gpt-4-80k", "3860": "Qwen1.5-7B-Dutch-Chat-Sft-Bf16", "3861": "Mergerix-7b-v0.2", "3862": "megamarcoroni-120b", "3863": "finetune_test_qwen15-1-8b-sft-lora", "3864": "Phind-CodeLlama-34B-Python-v1", "3865": "phi-openllm-lb-test", "3866": "falcon-40b", "3867": "blockchainlabs_7B_merged_test2_4_prune", "3868": "phi-1_5_chat", "3869": "SlimOpenOrca-Mistral-7B", "3870": "Mistral-7B-SlimOrca", "3871": "dolphincoder-starcoder2-7b", "3872": "speechless-mistral-dolphin-orca-platypus-samantha-7b", "3873": "lora_llama2-13b_10e6", "3874": "Giraffe-beta-13b-32k", "3875": "Telugu-Llama2-7B-v0-Instruct", "3876": "bigyi-15b", "3877": "Synatra-7B-v0.3-RP", "3878": "TinyLlama-Cinder-Agent-v1", "3879": "Llama2-13B-DaringFortitude", "3880": "lora_llama2-13b_10e5_r128_a256", "3881": "WizardLM-30B-Uncensored-GPTQ", "3882": "chinese-alpaca-2-13b-16k", "3883": "airoboros-l2-70b-2.1", "3884": "Collin-7B-dare", "3885": "NexusRaven-V2-13B", "3886": "chronos-mistral-7b", "3887": "Maverick-v3.0", "3888": "tora-13b-v1.0", "3889": "dolphin-2.1-mistral-7b", "3890": "llama-2-34b-uncode", "3891": "zoyllm-7b-slimorca", "3892": "Xenon-4", "3893": "rizla54", "3894": "T3Q-platypus-SOLAR-10.7B-v1.0", "3895": "zephyr_7b_norobots", "3896": "Medorca-2x7b", "3897": "bubo-bubo-13b", "3898": "Opus-Samantha-Llama-3-8B", "3899": "0.0001_withdpo_4iters_bs256_511lr_iter_2", "3900": "hyperdrive-7b-alpha", "3901": "Pwen-7B-Chat-20_30", "3902": "mpt-7b-8k-instruct", "3903": "airoboros-65b-gpt4-2.0", "3904": "Phind-CodeLlama-34B-v1", "3905": "llama2-7b-function-calling-slerp", "3906": "Zero-7B-test-3", "3907": "deepseek-coder-7b-instruct-v1.5", "3908": "Qwen1.5-72B-Chat", "3909": "Hua-v0.1", "3910": "dolphin-2.6-mistral-7b-dpo-orca-v1", "3911": "dragonwar-7b-alpha", "3912": "Mistral-7B-golden", "3913": "dolphin-2.6-mistral-7b-dpo-orca", "3914": "0.0_ablation_sample1_4iters_bs256_iter_2", "3915": "MythoMist-7b", "3916": "OpenDolphinHermes_Llama2_7B", "3917": "Michel-13B", "3918": "GEITje-7B", "3919": "lora_llama2-13b_10e5_r8_a256", "3920": "MiniMerlin-3B", "3921": "StableBeluga-7B-activity-fine-tuned-v2", "3922": "mistral-7b-orpo-airoboros-pref-10k", "3923": "Brunhilde-13b-v1", "3924": "Xenon-3", "3925": "Llama-2-7b-chat-hf-gpt-3.5-80k", "3926": "CodeLlama-34B-Python-fp16", "3927": "airoboros-c34b-2.2.1", "3928": "Mistral-7B-OpenOrca", "3929": "Q", "3930": "lora_llama2-13b_10e5_r32_a256", "3931": "qwen1.5-7b-chat-sa-v0.1", "3932": "0.0005_withdpo_4iters_bs256_555lr_iter_2", "3933": "tora-code-34b-v1.0", "3934": "quan-1.8b-base", "3935": "SciPhi-Self-RAG-Mistral-7B-32k", "3936": "tulu-30B-fp16", "3937": "Dolphin2.1-OpenOrca-7B", "3938": "Reyna-CoT-4B-v0.2", "3939": "balthazar-2x10.7b-v1", "3940": "WizardLM-1.0-Uncensored-CodeLlama-34b", "3941": "ADELIE-SFT", "3942": "starcoder2-3b", "3943": "autodev-deepseek-6.7b-finetunes-poc", "3944": "Mistral-7B-length-100000", "3945": "mistral-7b-finetuned-orca-dpo-v2", "3946": "Llama-2-7b-chat-hf-afr-100step-flan-v2", "3947": "Llama-2-7b-chat-hf-afr-100step-flan", "3948": "TIES-Merging", "3949": "deepseek-math-7b-instruct", "3950": "Xenon-2", "3951": "GEITje-7B-ultra", "3952": "Synatra-V0.1-7B-Instruct", "3953": "Synatra-V0.1-7B", "3954": "neural-chat-7b-v3-1", "3955": "Samantha-1.11-CodeLlama-34b", "3956": "japanese-stablelm-instruct-gamma-7b", "3957": "Llama-2-7b-chat-hf-activity-fine-tuned-v4", "3958": "Qwen-1_8B-Chat-llama", "3959": "Qwenchana-1.8B", "3960": "internlm2-base-7b-llama", "3961": "Huginn-V5-10.7B", "3962": "Python-Code-33B", "3963": "Darewin-7B-v2", "3964": "Llama-2-7b-chat-hf-10-attention-sparsity", "3965": "Pwen-VL-Chat-20_30", "3966": "SOLID-SFT-DPO-MixQV2-SOLIDRejected-SFTChosen-Zephyr-7b-beta", "3967": "wizard-mistral-v0.1", "3968": "Code-13B", "3969": "Llama-2-7b-chat-hf-activity-fine-tuned-v3", "3970": "Qwen1.5-1.8B-Chat", "3971": "mistral-7B-alpaca-case-0-2", "3972": "Llama-2-7b-chat-hf-afr-200step-merged", "3973": "medicine-chat", "3974": "Llama-2-7b-chat-hf-afr-200step-flan-v2", "3975": "SlimOpenOrca-Mistral-7B-v2", "3976": "CollectiveCognition-v1.1-Mistral-7B-dare-0.85", "3977": "yayi2-30b-llama", "3978": "Sydney_Overthinker_13b_HF", "3979": "openbuddy-llama2-13b-v11-bf16", "3980": "autotrain-8kfjk-b3gva", "3981": "Clover3-17B", "3982": "finance-chat", "3983": "juud-Mistral-7B-dpo", "3984": "Llama-2-7b-chat-hf-guanaco-lora", "3985": "Dr_Samantha-7b", "3986": "0001_dpo_iter_2", "3987": "Synthiallamaguanco-7B-slerp", "3988": "internlm-20b-chat", "3989": "speechless-coder-ds-6.7b", "3990": "gemma-2b-zephyr-sft", "3991": "WizardLM-33B-V1.0-Uncensored", "3992": "neural-chat-mini-v2.2-1.8B", "3993": "Llama-2-70B-chat-GPTQ", "3994": "dolphin-2.0-mistral-7b", "3995": "Llama-2-7b-chat-hf-afr-200step-flan", "3996": "zephyr-7b-dpo-full", "3997": "phi-1_5_chat_32k", "3998": "SynthIA-7B-v1.3-dare-0.85", "3999": "Mistral-7B-loss-100000", "4000": "Llama-2-7b-chat-hf-gpt-3.5-80k-base_lora", "4001": "Open-StaMis-v02-stock", "4002": "gemma-2b-zephyr-dpo", "4003": "Mistral-v0.1-PeanutButter-v0.0.0-7B", "4004": "BeingWell_llama2_7b", "4005": "FusionBot", "4006": "law-chat", "4007": "WizardLM-70B-V1.0-GPTQ", "4008": "FBt", "4009": "0.001_zephyr_5551_4iters_bs256_iter_3", "4010": "speechless-mistral-six-in-one-7b", "4011": "InnerIAI-chat-7b-grok", "4012": "Llama-2-7b-chat-hf-10-sparsity", "4013": "vicuna-MultiLoRA-sharegpt-mmlu-drop-ffn-1.0general", "4014": "yi6B_Vicuna", "4015": "Llama-2-7b-chat-hf-gpt-4-80k", "4016": "MegaMix-S1-13B", "4017": "Tess-XS-v1.0", "4018": "ChickaQ-V2-Large-Beta", "4019": "zephyr-2b-gemma-sft-qlora", "4020": "Senzu-7B-v0.1", "4021": "Tinybra_13B", "4022": "Mistral-v0.1-PeanutButter-v0.0.5-DPO-7B-QLoRA", "4023": "Mistral-7B-Instruct-v0.2-DARE", "4024": "mistral-7B-v0.1-hf", "4025": "airoboros-65b-gpt4-1.4", "4026": "airoboros-65b-gpt4-1.4-peft", "4027": "llama_allyarc", "4028": "WizardLM-70B-V1.0", "4029": "Llama-2-7b-chat-hf-afr-300step-flan-v2", "4030": "deepseek-coder-6.7b-base", "4031": "Mistral-7B-claude-instruct", "4032": "Cerberus-7B-slerp", "4033": "CollectiveCognition-v1-Mistral-7B", "4034": "digital-socrates-7b", "4035": "llama-30b-2048-instruct-PL-lora_unload", "4036": "Llama-2-7b-chat-hf-20-sparsity", "4037": "Llama-2-7b-chat-hf-afr-441step-flan-v2", "4038": "llama-30b-instruct-2048", "4039": "Code-290k-13B", "4040": "LLaMA-Pro-8B", "4041": "japanese-stablelm-base-gamma-7b", "4042": "Mistral-7B-Instruct-v0.1-gpt-4-80k-base_lora", "4043": "Llama-2-7b-chat-hf-20-attention-sparsity", "4044": "Synatra-11B-Testbench", "4045": "gaodrew-llama-30b-instruct-2048-Open-Platypus-100steps", "4046": "TinyLlama-Cinder-Tiny-Agent", "4047": "gemma-2b-lora3", "4048": "SynthIA-7B-v1.3", "4049": "Tess-10.7B-v2.0", "4050": "cinematika-7b-v0.1", "4051": "zephyr-beta-Nebula-v2-7B", "4052": "SynthIA-7B-v1.5", "4053": "airoboros-m-7b-3.1.2-dare-0.85", "4054": "Mistral-v0.1-PeanutButter-v0.0.2-7B", "4055": "stablelm-2-1_6b", "4056": "Mistral-7B-SFT", "4057": "v1", "4058": "Mistral-7B-openplatypus-1k", "4059": "Llama-2-7b-chat-hf-30-attention-sparsity", "4060": "mistral-7b-platypus-fp16", "4061": "mamba-gpt-7b-v1", "4062": "h2o-danube-1.8b-chat", "4063": "Elliott-Chinese-LLaMa-GPTQ-V1.0", "4064": "ToxicHermes-2.5-Mistral-7B", "4065": "speechless-coding-7b-16k-tora", "4066": "gemma-7b-lora-distilabel-intel-orca-dpo-pairs", "4067": "Mistral-7B-OpenOrca-lora", "4068": "Llama-2-13B-German-ORPO", "4069": "deepseek-moe-16b-base", "4070": "Obscura_32k_7B", "4071": "Mistral-7B-v0.1-Open-Platypus", "4072": "MixtralOrochi8x7B", "4073": "mamba-gpt-7b-v2", "4074": "deepseek-coder-6.7b-chat-and-function-calling", "4075": "Elliott-Chinese-LLaMa-GPTQ", "4076": "zephyrnotus-11b-alpha", "4077": "0.0001_withdpo_4iters_bs256_511lr_iter_3", "4078": "Mistral-v0.1-PeanutButter-v0.0.5-SFT-7B-QLoRA", "4079": "gemma-2b-lora16b2", "4080": "Llama-2-7b-chat-hf-30-sparsity", "4081": "0.001_zephyr_5551_4iters_bs256_iter_4", "4082": "tigerbot-13b-base", "4083": "Open-StaMis-stock", "4084": "0.0001_withdpo_4iters_bs256_5102lr_iter_4", "4085": "d-Qwen1.5-0.5B", "4086": "samantha-1.2-mistral-7b", "4087": "Zenith-7B-dpo-v1", "4088": "deepseek-coder-6.7b-chat", "4089": "Qwen1.5-MoE-A2.7B", "4090": "mistral_7b_2epoch_norobots", "4091": "Mistral-7B-attention-100000", "4092": "Medtulu-2x7b", "4093": "0.0_zephyr_withdpo_4iters_bs128_5551lr_iter_3", "4094": "Reyna-CoT-4B-v0.1", "4095": "hope_for", "4096": "gemma-2b", "4097": "mnsim-dpo-peftmerged-2-eos", "4098": "mpt-30b", "4099": "archangel_sft-kto_llama13b", "4100": "llama-30b-instruct-2048-PL-lora", "4101": "mistral-7b-v0.1-layla-v1", "4102": "Noromaid-Aeryth-7B", "4103": "vigostral-7b-chat", "4104": "Uncensored-Frank-33B", "4105": "mhm-7b-v1.3", "4106": "Zenith-7B-dpo", "4107": "gemma-2b-it-tamil-v0.1-alpha", "4108": "SOLAR-13B-Instruct-v1.0", "4109": "cymist2-v01-SFT", "4110": "phi-1_5_base", "4111": "traversaal-2.5-Mistral-7B", "4112": "hope_for_7b_1.0v", "4113": "tora-code-13b-v1.0", "4114": "TowerInstruct-7B-v0.1", "4115": "llama-2-alpacagpt4-1000step", "4116": "mistral-7b-platypus1k", "4117": "lora_llama2-13b_10e5_r2_a256", "4118": "Qwen1.5-0.5B", "4119": "Tess-XS-v1.1", "4120": "0.0_ablation_sample1_4iters_bs256_iter_3", "4121": "Enterredaas-33b", "4122": "fin-llama-33b-merged", "4123": "GEITje-7B-chat-v2", "4124": "Mistral-11B-TestBench9", "4125": "llama-2-7b-miniguanaco", "4126": "MentaLLaMA-chat-7B", "4127": "finetuned-llama2-chat-5000-v1.0-squad", "4128": "0ai-7B-v4", "4129": "Llama-2-7b-chat-hf-structured-responses", "4130": "gemma-2b-coder", "4131": "ultra0", "4132": "llama-13b-pretrained", "4133": "manticore-30b-chat-pyg-alpha", "4134": "Elliott-Chinese-LLaMa-GPTQ-V2.0", "4135": "vicuna-7b-v1.5-lora-mmlu-merged", "4136": "vicuna-7b-v1.5-lora-temporal-sharegpt", "4137": "gemma-2b-chat-ultra", "4138": "Mistral-7B-OpenOrca-Guanaco-accu16", "4139": "samantha-mistral-7b", "4140": "LosslessMegaCoder-llama2-13b-mini", "4141": "llama2-13b-megacode2_min100", "4142": "Yi-6B_Open-Platypus-v2", "4143": "firefly-llama-30b", "4144": "stack_codellama-7b-inst", "4145": "MultiLoRA-mmlu", "4146": "NewHope_HF_not_official", "4147": "0.0_withdpo_4iters_bs256_531lr_iter_3", "4148": "Alpacino30b", "4149": "finetuned-llama2-chat-5000-v2.0", "4150": "Dans-AdventurousWinds-7b", "4151": "recurrentgemma-2b", "4152": "Deita-1_8B", "4153": "Deita-Qwen-1_8B", "4154": "MiquMaid-v2-70B", "4155": "orca-open_hermes-llava-v1.5-7b-dpo", "4156": "Dans-PersonalityEngine-30b", "4157": "llama2-13b-megacode2-oasst", "4158": "gpt4-alpaca-lora-30b-HF", "4159": "Orca-2-13B-GPTQ", "4160": "qwen1.5-vortex", "4161": "Qwen1.5-0.5B-vortex", "4162": "0.0_zephyr_withdpo_4iters_bs128_5551lr_iter_4", "4163": "Qwen1.5-Wukong-0.5B", "4164": "shqiponja-59b-v1", "4165": "Qwen1.5-7B-Dutch-Chat", "4166": "Awanllm-Llama-3-8B-Dolfin-v0.3-DPO", "4167": "gemoy-4b-instruct-scientific", "4168": "openbuddy-qwen1.5-32b-v21.2-32k", "4169": "StrangeMerges_48-7B-dare_ties", "4170": "openbuddy-atom-13b-v9-bf16", "4171": "Vicuzard-30B-Uncensored", "4172": "llama-2-13b-FINETUNE4_addto15k_4.5w-r16-gate_up_down", "4173": "orca_mini_v3_7B-GPTQ", "4174": "Vicuzard-30B-Uncensored-instruct-PL-lora_unload", "4175": "llava-v1.5-7b-hf-vicuna", "4176": "Mixtral_AI_CyberCoder", "4177": "mpt-30b-instruct", "4178": "llava-v1.5-7b_vicuna", "4179": "athene-noctua-13b", "4180": "mhm-7b-v1.3-DPO-1", "4181": "stock-solar-10.7b-v1", "4182": "Airoboros-L2-70B-2.1-GPTQ", "4183": "CodeUp-Llama-2-13b-chat-hf", "4184": "Morningstar-13b-hf", "4185": "Llama-2-13b-chat-hf", "4186": "0.001_ablation_5iters_bs256_iter_5", "4187": "speechless-nl2sql-ds-6.7b", "4188": "h2o-danube-1.8b-sft", "4189": "Uncensored-Jordan-13B", "4190": "AISquare-Instruct-SOLAR-10.7b-v0.5.32", "4191": "OpenOrcaxOpenChat-Preview2-13B", "4192": "chinese-alpaca-2-7b-rlhf", "4193": "frankencria-llama2-11b-v1.3-m.1", "4194": "0.0005_withdpo_4iters_bs256_5551lr_iter_4", "4195": "chronoboros-33B", "4196": "BioMistral-7B-DARE", "4197": "Mistral-11B-TestBench11", "4198": "ANIMA-Phi-Neptune-Mistral-7B-v4", "4199": "odia_llama2_7B_base", "4200": "llama_sft_longer", "4201": "Dans-AdventurousWinds-Mk2-7b", "4202": "ANIMA-Phi-Neptune-Mistral-7B", "4203": "TinyLlama-Cinder-Agent-Rag", "4204": "llama3-passthrough", "4205": "finetuned-llama2-2048-v3.0", "4206": "Nebula-7B", "4207": "llama_ppo_1e6_new_tokenizerstep_8000", "4208": "llama-7b-ludwig-alpaca", "4209": "PsyMedRP-v1-20B", "4210": "llama-30B-hf-openassitant", "4211": "llama-30b", "4212": "QuantumLM-70B-hf", "4213": "Chat-Stheno-L2-13B", "4214": "speechless-codellama-dolphin-orca-platypus-34b", "4215": "Orca-2-7b", "4216": "llama-2-13b-mathgpt-v4", "4217": "openbuddy-mistral-7b-v13", "4218": "psyonic-cetacean-20B", "4219": "speechless-codellama-34b-v1.0", "4220": "Stellaris-internlm2-20b-r512", "4221": "VicUnlocked-alpaca-30b", "4222": "tyc_test1", "4223": "Qwen1.5-7B-Chat_llamafy", "4224": "Llama-2-7b-hf-gpt-3.5-80k", "4225": "base_7b", "4226": "llama2-13b-FINETUNE3_TEST", "4227": "Cypher-Mini-1.8B", "4228": "Llama-2-7b-hf", "4229": "Mixtral_13Bx2_MOE_22B", "4230": "Chinese-Llama-2-7b", "4231": "Orca-Nova-13B", "4232": "llama2-MultiLoRA-sharegpt-mmlu-drop-ffn-1.0general", "4233": "ELYZA-japanese-Llama-2-13b-instruct", "4234": "magpie-13b", "4235": "VicUnlocked-30B-LoRA-HF", "4236": "BELLE-Llama2-13B-chat-0.4M", "4237": "Platypus-30B", "4238": "llama_ppo_1e6step_4000", "4239": "llama-33B-instructed", "4240": "dolphin-llama-13b", "4241": "0.0_withdpo_4iters_bs256_5551lr_iter_4", "4242": "Magicoder-S-CL-7B", "4243": "FuseLLM-7B", "4244": "unraveled-7b-a1", "4245": "gemma-2b-chat", "4246": "Mistral-7B-Instruct-v0.1", "4247": "llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o", "4248": "tulu-13B-fp16", "4249": "llama-2-70B-LoRA-assemble-v2", "4250": "Wizard-Vicuna-30B-Uncensored", "4251": "vicuna-7b-v1.5-general-temporal-merged", "4252": "Wizard-Vicuna-30B-Uncensored-fp16", "4253": "zephyr-7b-beta-lora-mmlu-merged", "4254": "Myrrh_solar_10.7b_3.0", "4255": "hope_for_7b_1.1v", "4256": "WizardLM-13B-V1.0", "4257": "CAMEL-33B-Combined-Data", "4258": "doctorLLM5k", "4259": "llama-2-13b-FINETUNE5_4w-r8-q_k_v_o", "4260": "zephyr-7b-alpha", "4261": "llama-2-13b-huangyt_Fintune_1_17w-q_k_v_o_proj", "4262": "coven_tiny_1.1b_32k_orpo_alpha", "4263": "ReMM-v2.2-L2-13B", "4264": "llama-2-13b-FINETUNE1_17w-q_k_v_o_proj", "4265": "Llama-2-7b-hf-gpt-4-80k", "4266": "L2-7b-Hermes-Synthia", "4267": "zephyr-7b-dpo-full-ExPO", "4268": "chronolima-airo-grad-l2-13B", "4269": "LLaMA2-13B-Estopia", "4270": "YaYi-30b-EverythingLM", "4271": "Hermes-2-SOLAR-10.7B-Symbolic", "4272": "llama-13b-pretrained-sft-epoch-1", "4273": "airoboros-m-7b-3.1.2", "4274": "gemma-2b-orpo", "4275": "GPlatty-30B", "4276": "wizardLM-13B-1.0-fp16", "4277": "YuLan-Chat-2-13b-fp16", "4278": "llama-2-13b-FINETUNE5_4w-r16-q_k_v_o", "4279": "StableBeluga-13B", "4280": "openchat_v3.1", "4281": "vicuna-33b-v1.3", "4282": "UndiMix-v4-13B", "4283": "airochronos-33B", "4284": "chinese-alpaca-2-7b", "4285": "llama-2-13b-FINETUNE5_4w-r4-gate_up_down", "4286": "airolima-chronos-grad-l2-13B", "4287": "openchat_v3.2", "4288": "Llama-2-13b-chat-german", "4289": "airoboros-65b-gpt4-1.3", "4290": "doctorLLM", "4291": "llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o", "4292": "openchat_v3.2_super", "4293": "WizardLM-13B-V1.2", "4294": "Macaroni-v2-7b", "4295": "llama-2-13b-FINETUNE5_4w-r8-gate_up_down", "4296": "fietje-2b-instruct", "4297": "falcon-40b-openassistant-peft", "4298": "llama-2-13b-FINETUNE1_17w-r16", "4299": "Meta-Llama-3-13B-Instruct", "4300": "llama-2-13b-huangyt_Fintune_1_17w", "4301": "WizardLM-1.0-Uncensored-Llama2-13b", "4302": "Stheno-1.8-L2-13B", "4303": "openchat_v2_openorca_preview-GPTQ", "4304": "llama-2-13b-FINETUNE1_17w", "4305": "Llama3-ChatQA-1.5-8B", "4306": "mythalion-13b", "4307": "Fewshot-Metamath-OrcaVicuna-Mistral-10B", "4308": "vicuna-7b-v1.3-attention-sparsity-10", "4309": "Qwen1.5-7B-Chat", "4310": "llama-2-13b-FINETUNE1_17w-r4", "4311": "codellama-13b-oasst-sft-v10", "4312": "Yi-6B_Open-Orca", "4313": "Llama-2-13b-FINETUNE4_TEST", "4314": "Stheno-Inverted-L2-13B", "4315": "ReMM-v2-L2-13B", "4316": "Dans-TotSirocco-7b", "4317": "Llama-2-13b-FINETUNE4_TEST2", "4318": "vicuna-13b-v1.5-16k", "4319": "TowerBase-7B-v0.1", "4320": "llama2-13b-sharegpt4-test", "4321": "vicuna-7b-v1.3-sparsity-10", "4322": "speechless-llama2-hermes-orca-platypus-wizardlm-13b", "4323": "orca_mini_v3_13b", "4324": "minotaur-13b-fixed", "4325": "wizardllama-7b", "4326": "chronos-33b", "4327": "zephyr-7b-beta-128k", "4328": "airoboros-33b-gpt4-1.3", "4329": "13B-Legerdemain-L2", "4330": "lora_llama2-7b_10e4", "4331": "Mistral-7B-random-100000", "4332": "llama-2-13b-FINETUNE3_3.3w-r16-gate_up_down", "4333": "H4rmoniousAnthea", "4334": "llama-2-13b-huangyt_Fintune_1_17w-gate_up_down_proj", "4335": "llama-2-13b-FINETUNE1_17w-gate_up_down_proj", "4336": "WizardLM-30B-Uncensored", "4337": "gemma-2b-tamil", "4338": "vicuna-33b-coder", "4339": "OpenRP-13B", "4340": "llama-2-13b-FINETUNE4_3.8w-r8-gate_up_down", "4341": "Llama-2-13b-orca-v1", "4342": "Emerald-13B", "4343": "llama-2-13b-huangyt_FINETUNE2_3w-q_k_v_o_proj", "4344": "stack_llama_fil_ai", "4345": "llama-2-13b-FINETUNE4_3.8w-r4-gate_up_down", "4346": "stablelm-2-1_6b-sft-full", "4347": "trurl-2-13b", "4348": "llama-2-13b-FINETUNE2_3w-q_k_v_o_proj", "4349": "Stheno-v2-Delta-fp16", "4350": "Mistral-Hinglish-7B-Instruct-v0.2", "4351": "Yi-Ko-6B_Open-Platypus", "4352": "ReMM-v2.1-L2-13B", "4353": "Llama2-7B-guanaco-dolphin-500", "4354": "Qwen-1_8b-EverythingLM", "4355": "openthaigpt-1.0.0-13b-chat", "4356": "CodeLlama-13b-Instruct-hf", "4357": "Yi-6B", "4358": "llama-2-13b-OpenOrca_20w", "4359": "CodeLlama-13B-Instruct-fp16", "4360": "llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down-test1", "4361": "airoboros-33b-gpt4", "4362": "Llama2-Chinese-13b-Chat", "4363": "0.001_4iters_bs256_nodpo_only4w_iter_4", "4364": "llama2-13b-FINETUNE3_TEST2", "4365": "mistral-7b_open_platypus", "4366": "CalliopeDS-v2-L2-13B", "4367": "Kimiko-v2-13B-fp16", "4368": "Slerpeno", "4369": "llama3-8b-cqia", "4370": "Llama-2-13b-FINETUNE4", "4371": "Yi-Ko-6B", "4372": "minotaur-13b", "4373": "OpenOrcaxOpenChat-Preview2-13B-GPTQ", "4374": "LLaMA_2_13B_SFT_v0", "4375": "llama-2-13b-dolphin_20w", "4376": "phi-1_5", "4377": "Barcenas-13b", "4378": "Platypus2xOpenOrca-13B-IA3-v3", "4379": "llama-2-13b-chat-platypus", "4380": "Chat-AYB-Nova-13B", "4381": "vicuna-7b-v1.3-attention-sparsity-30", "4382": "recycled-wizardlm-7b-v2.0", "4383": "stack_llama-clang", "4384": "LewdEngine", "4385": "WizardMath-13B-V1.0", "4386": "SOLID-SFT-WoDPO-MixQV2-Zephyr-7b-beta", "4387": "vicuna-13b-v1.5-PL-lora_unload", "4388": "genz-13b-v2", "4389": "llama-2-13b-FINETUNE5_4w-r4-q_k_v_o", "4390": "Samantha-1.11-13b", "4391": "gemma-ko-7b-instruct-v0.50", "4392": "llama-2-13b-OpenOrca_5w", "4393": "llama-2-13b-FINETUNE5_4w-r4-q_k_v_o_gate_up_down", "4394": "LlongOrca-13B-16k", "4395": "manticore-13b", "4396": "trurl-2-13b-pl-instruct_unload", "4397": "StableBeluga-13B-instruct-PL-lora_unload", "4398": "llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down", "4399": "0.0_ablation_sample1_4iters_bs256_iter_4", "4400": "CodeLlama-13b-hf", "4401": "OpenHermes-Gemma-2B", "4402": "Llama-2-7b-hf-llama2-raw-80k", "4403": "llama-30b-instruct", "4404": "llama-13b-FINETUNE3", "4405": "SmartQwen1.5-1.8B-orpo-v1", "4406": "Llama-chat-AY-13B", "4407": "mpt-30b-chat", "4408": "llama-2-13b-FINETUNE2_3w-gate_up_down_proj", "4409": "tutor-model-13b-ep3", "4410": "Llama-2-7b-chat-hf-gpt-4-80k-base_lora", "4411": "vicuna-class-tutor-13b-ep3", "4412": "minotaur-llama2-13b-qlora", "4413": "llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o_gate_up_down", "4414": "Configurable-Mistral-22B", "4415": "llama-2-13b-huangyt_FINETUNE2_3w-gate_up_down_proj", "4416": "llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o", "4417": "Zenith-7B", "4418": "ReMM-Mistral-13B", "4419": "Uncensored-Frank-13B", "4420": "Mistral-7B-guanaco1k-ep2", "4421": "storytell", "4422": "llama-2-13b-huangyt_FINETUNE2_3w", "4423": "Llama-2-7b-hf-llama2-chat-80k", "4424": "llama-2-13b-FINETUNE2_3w", "4425": "gemma-ko-7b-instruct-v0.52", "4426": "Athena-v4", "4427": "Mistral-7B-OpenOrca-1k", "4428": "mamba-gpt-7b", "4429": "llama-2-13b-FINETUNE3_3.3w-r4-gate_up_down", "4430": "Stheno-L2-13B", "4431": "mistral-guanaco1k-ep2", "4432": "vicuna-7b-v1.5-lora-temporal-without-mctaco-1", "4433": "llama-2-13b-FINETUNE5_4w-r8-q_k_v_o_gate_up_down", "4434": "Mistral-11B-SynthIAirOmniMix", "4435": "llama-30b-supercot", "4436": "llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o", "4437": "Llama-2-13b-hf-instruct-pl-lora_unload", "4438": "llama-2-13b-code-alpaca", "4439": "Llama-2-13b-FINETUNE4_compare8k2", "4440": "llama-13b-pretrained-dropout", "4441": "Platypus2xOpenOrca-13B-IA3", "4442": "vigogne-13b-instruct", "4443": "llama-2-13b-dolphin_5w", "4444": "Metabird-7b-DPO", "4445": "llama2-13B-sharegpt4-orca-openplatypus-8w", "4446": "MythoLogic-L2-13b", "4447": "BerrySauce-L2-13b", "4448": "llama-2-13b-FINETUNE3_3.3w-r8-gate_up_down", "4449": "pygmalion-2-13b", "4450": "airoboros-33b-gpt4-1.4", "4451": "multimaster-7b", "4452": "MultiLoRA-llama2-mmlu", "4453": "stack_llama_full", "4454": "chronos-hermes-13b-v2", "4455": "llama2guanacotest", "4456": "firefly-llama2-13b-v1.2", "4457": "0.001_3iters_bs256_nodpo_only4w_iter_3", "4458": "Llama-2-7b-chat-hf-guanaco-freeze-embed-tokens-q-v-proj", "4459": "TarsChattyBasev0.0", "4460": "mistral-4.2B", "4461": "OpenHermes-13B", "4462": "Nusantara-4b-Indo-Chat", "4463": "Athena-v3", "4464": "airoboros-l2-13b-2.2.1", "4465": "Qwenchana-4B-restart-OH", "4466": "llama-2-13b-guanaco-fp16", "4467": "speechless-codellama-34b-v2.0", "4468": "llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o_gate_up_down", "4469": "llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o", "4470": "LongQLoRA-Llama2-7b-8k", "4471": "LLaMA2-13B-Holomax", "4472": "SwahiliInstruct-v0.2", "4473": "llama-2-13b-FINETUNE5_4w-r16-gate_up_down", "4474": "Yi-7b-dpo", "4475": "Yi-6b-200k-dpo", "4476": "qCammel-13", "4477": "30B-Lazarus-instruct-PL-lora_unload", "4478": "llama2-13b-Chinese-chat", "4479": "Samantha-Nebula-7B", "4480": "MLewd-L2-Chat-13B", "4481": "vitruv_1", "4482": "Mistral-7B-Instruct-v0.2-sparsity-20", "4483": "bimoGPT-llama2-13b", "4484": "oasst-llama-13b-1000-steps", "4485": "vicuna-13b-v1.5", "4486": "Llama-2-13B-GPTQ", "4487": "Platypus2-13B-IA3", "4488": "Llama2-chat-AYB-13B", "4489": "danube2-upscale-1.7", "4490": "Llama-2-7b-chat-hf-guanaco-freeze-embed-tokens-q-v-proj-lora", "4491": "chronos-13b-v2", "4492": "SthenoWriter-L2-13B", "4493": "llama2-22b-blocktriangular", "4494": "tulu-7B-fp16", "4495": "Llama-2-13b-FINETUNE4_TEST3", "4496": "mistral-instruct-frankenmerge", "4497": "firefly-llama2-13b", "4498": "Redmond-Puffin-13B", "4499": "FINETUNE3_TEST4", "4500": "vicuna-7b-v1.3-attention-sparsity-20", "4501": "AceGPT-7B", "4502": "OpenOrca-Platypus2-13B-QLoRA-0.80-epoch", "4503": "vigogne-33b-instruct", "4504": "WizardLM-13B-V1.2-PL-lora_unload", "4505": "Alpagasus-2-13b-QLoRA-merged", "4506": "llama2-22b-chat-wizard-uncensored", "4507": "Unholy-v1-12L-13B", "4508": "Qllama-.5B-Base-Wiki-Chat-RAG", "4509": "Redmond-Puffin-13B-instruct-PL-lora_unload", "4510": "SOLAR-Platypus-10.7B-v1", "4511": "Mistralic-7B-1", "4512": "selfrag_llama2_7b", "4513": "llama2-13b-math1.2", "4514": "CodeLlama13B-Finetune-v1", "4515": "Synthia-13B-v1.2", "4516": "llama2-13b-orca-8k-3319", "4517": "llama2_13b_instructed_version2", "4518": "MLewdBoros-L2-13B", "4519": "llama-2-13b-Guanaco-QLoRA", "4520": "Synthia-13B", "4521": "Platypus2xOpenOrca-13B-IA3-v2.1", "4522": "openllama-7b-icl", "4523": "Baichuan2-7B-Chat-LLaMAfied", "4524": "llama2-13b-fintune2-4E", "4525": "llama-2-13b-FINETUNE4_compare15k_4.5w-r16-gate_up_down", "4526": "Asimov-7B-v2", "4527": "trurl-2-13b-academic", "4528": "MXLewd-L2-20B", "4529": "Stheno-1.2-L2-13B", "4530": "MLewd-ReMM-L2-Chat-20B", "4531": "llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o_gate_up_down", "4532": "llama2-7b-hf-chat-lora-v2", "4533": "openbuddy-openllama-7b-v12-bf16", "4534": "Platypus2xOpenOrca-13B-IA3-v4", "4535": "tigerbot-7b-base", "4536": "Amethyst-13B-Mistral", "4537": "Synthia-7B-v1.2", "4538": "Llama-2-13B-fp16", "4539": "samantha-mistral-instruct-7b", "4540": "Flash-Llama-13B", "4541": "Starlight-13B", "4542": "gemma-pro-3.1b-ko-v0.1", "4543": "Amethyst-13B", "4544": "recycled-alpaca-7b-v2.0", "4545": "EnsembleV5-Nova-13B", "4546": "GZDX", "4547": "llama2-7b-hf-chat-lora", "4548": "vicuna-13b-v1.3", "4549": "CodeLLaMA-chat-13b-Chinese", "4550": "gemma-2b-dpo-v1", "4551": "airoboros-33b-gpt4-2.0", "4552": "belal-finetuned-llama2-v1.0", "4553": "dulia-13b-8k-alpha", "4554": "Llama-2-13b-chat-dutch", "4555": "13B-Chimera", "4556": "Gemmalpaca-2B", "4557": "UltraLM-13B-fp16", "4558": "llama2-13b-math1.1", "4559": "Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16_merged", "4560": "Dionysus-Mistral-n1-v1", "4561": "pythia-12b-sft-v8-7k-steps", "4562": "llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o", "4563": "Cypher-Laser-Mixtral-2x1.8B-v0.1", "4564": "nash-vicuna-13b-v1dot5-ep2-w-rag-w-simple", "4565": "lora_llama2-7b_10e5", "4566": "gemma-2b-translation-v0.103", "4567": "Mistral-7B-Instruct-v0.2-sparsity-30", "4568": "Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16", "4569": "belal-finetuned-llama2-1024-v2.2", "4570": "MiniChat-3B", "4571": "Llama-2-13b-hf_Open-Platypus-QLoRA-multigpu", "4572": "MLewd-Chat-v2-13B", "4573": "CodeMind-gemma", "4574": "Cypher-Mixtral-2x1.8B-v0.1", "4575": "llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o_gate_up_down", "4576": "Nous-Hermes-13B-Code", "4577": "deacon-13b", "4578": "13B-HyperMantis", "4579": "mistral-7b-sft-open-orca-flan-50k", "4580": "perry-7b", "4581": "llama2-13b-ft-mc4_nl_cleaned_tiny", "4582": "lora_llama2-7b_10e6", "4583": "2x-LoRA-Assemble-Nova-13B", "4584": "vicuna-mmlu-val-mcq-7b-ep2", "4585": "hippogriff-30b-chat", "4586": "TarsDolly", "4587": "Llama3-OpenBioLLM-8B", "4588": "doctorLLM10k", "4589": "OpenBioLLM-Llama3-8B", "4590": "Phi-5B-Test", "4591": "recurrentgemma-2b-it", "4592": "Gemma-Wukong-2b", "4593": "wizard-mega-13b", "4594": "starling-7B", "4595": "llama13B-quant8-testv1-openorca-customdataset", "4596": "CodeLlama-13B-Python-fp16", "4597": "Platypus-Nebula-v2-7B", "4598": "Nous-Hermes-Llama2-13b", "4599": "AppleSauce-L2-13b", "4600": "UndiMix-v1-13b", "4601": "Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16", "4602": "stack-llama-2", "4603": "Luban-Marcoroni-13B", "4604": "CalliopeDS-L2-13B", "4605": "gaodrew-gorgonzola-13b", "4606": "Luban-Marcoroni-13B-v2", "4607": "Mistral-Trismegistus-7B", "4608": "Mixtral-8x7B-MoE-RP-Story", "4609": "Zro1.5_3B", "4610": "Luban-Marcoroni-13B-v3", "4611": "llama2-22b", "4612": "Llama-2-7b-chat-hf-guanaco", "4613": "finetuned-llama-v2.0", "4614": "MythoMix-L2-13b", "4615": "canarim-7b", "4616": "Aurora-V2-DLEC", "4617": "Wizard-Vicuna-13B-Uncensored-GPTQ", "4618": "openbuddy-openllama-13b-v7-fp16", "4619": "QuantumLM", "4620": "pygmalion-instruct", "4621": "Luna-AI-Llama2-Uncensored", "4622": "speechless-hermes-coig-lite-13b", "4623": "firefly-llama2-13b-chat", "4624": "llama2-7b-hf-instruction-lora", "4625": "una-llama-7b", "4626": "MLewd-v2.4-13B", "4627": "airoboros-33b-gpt4-1.2", "4628": "chinese-llama-2-13b", "4629": "tau-0.5B", "4630": "Colossal-LLaMA-2-7b-base", "4631": "speechless-llama2-hermes-orca-platypus-13b", "4632": "Luban-13B", "4633": "llama-2-7b-alpaca-gpt4", "4634": "speechless-llama2-dolphin-orca-platypus-13b", "4635": "codellama_7b_DolphinCoder", "4636": "llama-op-v4", "4637": "airoboros-33b-gpt4-m2.0", "4638": "wizard-vicuna-13B-GPTQ", "4639": "SuperPlatty-30B", "4640": "test-help-steer-filtered-orig", "4641": "openllama-7b-base", "4642": "Xwin-LM-13B-V0.1", "4643": "llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o_gate_up_down", "4644": "pythia-12b-sft-v8-2.5k-steps", "4645": "llama-2-7b-small-model-new", "4646": "pythia-12b-sft-v8-rlhf-2k-steps", "4647": "CollectiveCognition-v1.1-Nebula-7B", "4648": "CreativityEngine", "4649": "Llama-2-13b-hf_Open-Platypus-8bit-att", "4650": "Python-Code-13B", "4651": "manticore-13b-chat-pyg", "4652": "Llama-7B-rollercoaster_v2", "4653": "LosslessMegaCoder-llama2-7b-mini", "4654": "GZDX-1.1B", "4655": "PrathameshLLM-7B", "4656": "vicuna-chinese-replication-v1.1", "4657": "mistral_v1", "4658": "WizardCoder-Python-34B-V1.0", "4659": "SOLID_SFT-WoDPO-WoMixQ", "4660": "SUS-Chat-72B", "4661": "Llama-2-13b-hf_Open-Platypus", "4662": "TarsChattyBasev0.1", "4663": "TekniumAiroboros-Nebula-7B", "4664": "OpenOrca-Platypus2-13B-GPTQ", "4665": "llama-2-13b-hf-platypus", "4666": "sitebunny-13b", "4667": "Aurora_22e_Test", "4668": "wizard-vicuna-13B-HF", "4669": "Dans-PersonalityEngine-13b", "4670": "Asimov-7B-v1", "4671": "Llama-2-13B-Instruct-v0.2", "4672": "llama-3-8b-DUS-initialized", "4673": "chinese-alpaca-2-7b-16k", "4674": "2x-LoRA-Assemble-13B", "4675": "gpt4all-j", "4676": "Alpagasus-2-13B-QLoRA-pipeline", "4677": "Nous-Hermes-13b-pl-lora_unload", "4678": "PrathameshLLM-2B", "4679": "llama-13b-pretrained-sft-do2", "4680": "Indic-gemma-2b-finetuned-sft-Navarasa-2.0", "4681": "ReMM-SLERP-L2-13B", "4682": "Brunhilde-13b", "4683": "Free_Sydney_13b_HF", "4684": "sheep-duck-llama-2-13b", "4685": "Huginn-13b-v1.2", "4686": "huginnv1.2", "4687": "meditron-7b-chat", "4688": "EstopianMaid-13B", "4689": "wizard-vicuna-13b", "4690": "starcoder", "4691": "Guanaco-13B-Uncensored", "4692": "gpt4-alpaca-lora-13B-HF", "4693": "openchat_v2", "4694": "Sailor-4B-Chat", "4695": "speechless-codellama-platypus-13b", "4696": "duplicitous-mammal-13b", "4697": "MLewd-ReMM-L2-Chat-20B-Inverted", "4698": "BrainDerp2", "4699": "OpenOrca-Platypus2-13B", "4700": "MythoMax-L2-13b", "4701": "vicuna-13b-v1.3-PL-lora_unload", "4702": "baize-v2-13b", "4703": "Qllama-.5B-RAG-1", "4704": "Deita-500m", "4705": "wizard-mega-13B-GPTQ", "4706": "btlm-v1-7b-base-v0.1", "4707": "Stheno-Inverted-1.2-L2-13B", "4708": "leo-hessianai-13b", "4709": "airoboros-l2-13b-3.0", "4710": "Mythical-Destroyer-L2-13B", "4711": "LWM-7B-1M-1000000ctx-AEZAKMI-3_1-1702", "4712": "LIMA-13b-hf", "4713": "webMistral-7B", "4714": "mcq-hal-vicuna-13b-v1.5", "4715": "ALMA-13B-Pretrain", "4716": "Llama2-chat-AYT-13B", "4717": "ChatAYT-Lora-Assamble-Marcoroni", "4718": "PuffedConvo13bLoraE4", "4719": "monika-ddlc-7b-v1", "4720": "GPT4-x-Alpasta-13b", "4721": "duplicitous-slurpbeast-13b", "4722": "Llama2-13b-sharegpt4", "4723": "Sailor-4B", "4724": "gpt-sw3-20b-instruct", "4725": "DaringFortitude", "4726": "Kimiko-13B-fp16", "4727": "Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16_merged", "4728": "openbuddy-mistral-7b-v13.1", "4729": "Mister", "4730": "PuffedLIMA13bQLORA", "4731": "guanaco-13B-HF", "4732": "Metharme-13b-Merged", "4733": "vicuna-13b-delta-v1.1", "4734": "llama-2-13b-FINETUNE2_TEST_2.2w", "4735": "MythoLogic-13b", "4736": "vicuna-13B-1.1-HF", "4737": "Wizard-Vicuna-13B-Uncensored-HF", "4738": "Llama-2-7b-chat-finetune-AUTOMATE", "4739": "MythoBoros-13b", "4740": "Vicuna-13B-CoT", "4741": "vicuna-13b-1.1", "4742": "minima-3b-layla-v2", "4743": "minima-3b-layla-v1", "4744": "youri-7b", "4745": "delta13b", "4746": "Wizard-Vicuna-13B-Uncensored", "4747": "Manticore-13b-Chat-Pyg-Guanaco", "4748": "airoboros-l2-13b-gpt4-m2.0", "4749": "vicuna-13b-v1.1", "4750": "vic_critT_20pr", "4751": "CodeLlama-13b-Python-hf", "4752": "Vicuna-13B-CoT-fp16", "4753": "zarafusionex-1.2-l2-7b", "4754": "Qwen-Orpo-v1", "4755": "airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16", "4756": "Llama-2-13b-ft-instruct-es", "4757": "SambaLingo-Thai-Chat", "4758": "OpenOrca-Platypus2-13B-thera-1250", "4759": "firefly-llama2-13b-pretrain", "4760": "llama-2-13b-Open-Platypus_2.5w", "4761": "llama2-7b-chat-hf-guanaco", "4762": "cria-llama2-7b-v1.3", "4763": "Dans-PileOfSets-Mk1-llama-13b-merged", "4764": "falcon-7B-case-5", "4765": "Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16", "4766": "manticore-13b-chat-pyg-GPTQ", "4767": "Llama-2-7b-chat-hf-afr-100step-v2", "4768": "llama2-7b-layla", "4769": "Emerhyst-20B", "4770": "speechless-codellama-dolphin-orca-platypus-13b", "4771": "Orca-2-13b-SFT_v5", "4772": "llama-2-13B-LoRA-assemble", "4773": "openchat_v2_w", "4774": "vicuna-13b-v1.3.0-GPTQ", "4775": "llama_13b_sharegpt94k_fastchat", "4776": "Mistral-v0.3-6B", "4777": "mpt-7b-8k", "4778": "ELYZA-japanese-Llama-2-7b", "4779": "airoboros-c34b-2.1", "4780": "storytime-13b", "4781": "airocoder-34b-2.1", "4782": "Nous-Hermes-13b", "4783": "vigogne-13b-chat", "4784": "falcon-7B-case-1", "4785": "falcon-7B-case-4", "4786": "oasst-llama-13b-2-epochs", "4787": "CodeMind-gemma-2b", "4788": "BrainDerp", "4789": "llama-2-13b-4bit-alpaca-gpt4", "4790": "Sina-Odin-7b-Merge", "4791": "speechless-code-mistral-orca-7b-v1.0", "4792": "vicuna-7b-v1.5", "4793": "chimera-inst-chat-13b-hf", "4794": "firefly-llama-13b", "4795": "Novocode7b-v2", "4796": "speechless-llama2-luban-orca-platypus-13b", "4797": "llama2-13B-eugeneparkthebest", "4798": "airoboros-13b-gpt4-1.1", "4799": "llama2_7b_code", "4800": "MiniMA-2-3B", "4801": "WizardLM-13B-V1.1", "4802": "gpt4-alpaca-lora-13b-decapoda-1024", "4803": "Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16_merged", "4804": "llama-2-16b-nastychat", "4805": "WizardLM-13B-V1.1-GPTQ", "4806": "chinese-alpaca-33b-merged", "4807": "starcoderplus", "4808": "BrainDerp3", "4809": "llama-7b", "4810": "firefly-llama-13b-v1.2", "4811": "WizardLM_13B_juniper", "4812": "mcq-vicuna-13b-v1.5", "4813": "llama-2-13B-instructed", "4814": "L2-7b-Orca-WVG-Test", "4815": "airophin-13b-pntk-16k-fp16", "4816": "Llama2-Chinese-7b-Chat", "4817": "Alpacino13b", "4818": "llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o_gate_up_down", "4819": "Guanaco-Vicuna-7B-L2", "4820": "falcon-7B-case-0", "4821": "CodeLlama-7b-Instruct-hf", "4822": "llama-2-7b-rockwell-final", "4823": "lima-test", "4824": "L2-7b-Guanaco-Uncensored", "4825": "Stheno-1.1-L2-13B", "4826": "saqr-7b-beta", "4827": "llama2_7b_mmlu", "4828": "starcoderbase", "4829": "ELYZA-japanese-Llama-2-7b-instruct", "4830": "Llama-2-7b-chat-hf-afr-200step-v2", "4831": "airoboros-13b-gpt4", "4832": "L2-7b-Beluga-WVG-Test", "4833": "Baichuan2-7B-Base-LLaMAfied", "4834": "GiftedConvo13bLoraNoEcons", "4835": "tableBeluga-7B-instruct-pl-lora_unload", "4836": "llama-2-7b-guanaco-instruct-sharded", "4837": "StableBeluga-7B", "4838": "llama-2-13b-chat-hf-phr_mental_therapy", "4839": "vicuna-7b-v1.5-lora-timedial-unit-080082", "4840": "Llama-2-7b-orca-v1", "4841": "13B-BlueMethod", "4842": "zarafusionex-1.1-l2-7b", "4843": "WizardCoder-Python-13B-LoRa", "4844": "GiftedConvo13bLoraNoEconsE4", "4845": "MM-ReMM-L2-20B", "4846": "GenAI-Nova-13B", "4847": "Llama-2-13b-longlora-32k-ft", "4848": "airoboros-13b-gpt4-1.4", "4849": "llama-2-7b-claude-chat", "4850": "airoboros-13b-gpt4-1.4-fp16", "4851": "30B-Lazarus", "4852": "vigogne-2-7b-chat", "4853": "airoboros-l2-13b-gpt4-2.0", "4854": "Qwen1.5-0.5B-Chat", "4855": "testmodel2", "4856": "TinyLlama-Cinder-Math-Train", "4857": "QuantumLM-7B", "4858": "vicuna-7b-v1.5-lora-timedial-unit-080091", "4859": "pythia-12b-pre-v8-12.5k-steps", "4860": "llama-13b", "4861": "testmodel-3", "4862": "vicuna-13b", "4863": "gpt4all-alpaca-oa-codealpaca-lora-13b", "4864": "vigogne-7b-chat", "4865": "zaraxe-l2-7b", "4866": "OpenLlama13B-Guanaco", "4867": "Llama2-7B-guanaco-1k", "4868": "saqr-7b-merged", "4869": "test-Qwen1.5-0.5B", "4870": "LlongOrca-7B-16k", "4871": "elm-test", "4872": "tamil-llama-13b-instruct-v0.1", "4873": "Platypus2-13B-LoRa", "4874": "llama2-to-mistral-diff", "4875": "Alpacino-SuperCOT-13B", "4876": "llama2-7b-chat-hf-v4", "4877": "speechless-tools-7b", "4878": "speechless-orca-platypus-coig-lite-2k-0.6e-13b", "4879": "llama-2-7b-hf-guanaco-1k", "4880": "open-llama-7b-v2-open-instruct", "4881": "trurl-2-7b-pl-instruct_unload", "4882": "zephyr-neural-chat-frankenmerge11b", "4883": "WizardVicuna2-13b-hf", "4884": "falcon-7B-case-c", "4885": "Qwen1.5-0.5B-Chat_llamafy", "4886": "llama_mirror_13b_v1.0", "4887": "CAMEL-13B-Role-Playing-Data", "4888": "Koss-7B-chat", "4889": "airophin-v2-13b-PI-8k-fp16", "4890": "MistralLite-summ-sft-e1", "4891": "llama2-7b-chat-hf-dpo", "4892": "openchat_8192", "4893": "Llama-2-7b-chat-hf", "4894": "L2-7b-Base-Guanaco-Uncensored", "4895": "llama-2-7b-claude-chat-rp", "4896": "vicuna-7b-v1.5-lora-timedial", "4897": "yehoon_llama2", "4898": "Wizard-Vicuna-13B-juniper", "4899": "zarafusionix-l2-7b", "4900": "vicuna-7b-v1.5-PL-lora_unload", "4901": "Samantha-1.11-7b", "4902": "LLaMa-2-PeanutButter_v18_A-7B", "4903": "llama-13b-supercot", "4904": "EMO-2B", "4905": "orca_mini_v3_7b", "4906": "airoboros-13B-HF", "4907": "Starlight-7B", "4908": "llama2-7b-chat-hf-v2", "4909": "araproje-llama2-7b-hf", "4910": "CAMEL-13B-Combined-Data", "4911": "test_llama2_7b", "4912": "SOLAR-10.7B-Instruct-v1.0-128k", "4913": "trurl-2-7b", "4914": "llama-2-coder-7b", "4915": "vicuna-7b-v1.5-lora-mixed-datasets", "4916": "Flash-Llama-7B", "4917": "test-llama2-7b", "4918": "vicuna-7b-v1.5-lora-mixed-datasets-time-unit", "4919": "Platypus2xOpenOrca-13B-LoRa", "4920": "llama-2-13b-Open_Platypus_and_ccp_2.6w-3_epoch", "4921": "Qwen1.5-32B-Chat", "4922": "L2-7b-Base-WVG-Uncensored", "4923": "Platypus2-13B", "4924": "minillm-7B-init-13B-sft", "4925": "Llama-2-7B-physics", "4926": "manatee-7b", "4927": "falcon-7B-case-8", "4928": "tau-0.5B-instruct-DPOP", "4929": "dpo-Qwen1.5-0.5B-Chat-alignment-handbook", "4930": "airoboros-13b", "4931": "airoboros-l2-13b-gpt4-1.4.1", "4932": "L2-7b-Base-test-WVG", "4933": "Nous-Capybara-7B", "4934": "LLaMarada-7B-v0.1-16bit", "4935": "Llama-2-7b-chat-hf-instruct-pl-lora_unload", "4936": "chronos-wizardlm-uc-scot-st-13B-GPTQ", "4937": "firefly-ziya-13b", "4938": "GPT-NeoXT-Chat-Base-20B", "4939": "elliott_Llama-2-7b-hf", "4940": "Capybara-7B", "4941": "spatial-vicuna-7b-v1.5-LoRA", "4942": "koala-13B-HF", "4943": "Mistral-Pygmalion-7b", "4944": "gemma-pro-3.1b-ko-v0.5", "4945": "llama-2-13b-Open_Platypus_and_ccp_2.6w", "4946": "EverythingLM-13b-V2-16k", "4947": "ToolLLaMA-7b-LoRA", "4948": "Medusa-13b", "4949": "FLAN-Llama-7B-2_Llama2-7B-Flash_868_full_model", "4950": "NeuralReyna-Mini-1.8B-v0.3", "4951": "cria-llama2-7b-v1.3_peft", "4952": "Nova-13B", "4953": "Uncensored-Jordan-7B", "4954": "yayi-7b-llama2", "4955": "PlatYi-34B-Llama-Q-v3", "4956": "Synthia-7B", "4957": "airoboros-33b-2.1", "4958": "llama-2-7b-hf_open-platypus", "4959": "nsfw-noromaid-mistral-instruct", "4960": "mistral-megamerge-dare-7b", "4961": "vic15-exp-syn-fight-cp3838", "4962": "platypus-2-22b-relora", "4963": "kollama2-7b-v2", "4964": "chinese-llama-2-13b-16k", "4965": "LLaMa-2-PeanutButter_v18_B-7B", "4966": "Mistral-22B-v0.1", "4967": "EverythingLM-13b-16k", "4968": "MultiLora-drop-sharegpt", "4969": "llama2_7b_zh", "4970": "Llama2-13B-no_robots-alpaca-lora", "4971": "gpt-sw3-6.7b-v2-instruct", "4972": "carl-33b", "4973": "vicuna-7b-v1.5-16k", "4974": "orca_mini_v2_13b", "4975": "llama-2-7b-hf-small-shards-Samantha-V1-SFT", "4976": "pygmalion-2-7b", "4977": "falcon-7B-case-2", "4978": "llama-2-7b-guanaco-fp16", "4979": "ELYZA-japanese-Llama-2-7b-fast", "4980": "Pygmalion-2-13b-SuperCOT", "4981": "platypus2-22b-relora", "4982": "ELYZA-japanese-Llama-2-7b-fast-instruct", "4983": "lacda-2-7B-chat-v0.1", "4984": "tigerbot-7b-sft", "4985": "goims", "4986": "Llama-2-7b-hf-instruct-pl-lora_unload", "4987": "Platypus2-mini-7B", "4988": "vicuna-7b-v1.3-instruct-pl-lora_unload", "4989": "llama-2-7b-int4-python-code-18k", "4990": "Pygmalion-Vicuna-1.1-7b", "4991": "Chinese-LLaMA-2-7B-hf", "4992": "falcon-7B-case-6", "4993": "falcon-7B-case-3", "4994": "Barcenas-7b", "4995": "airoboros-l2-7b-2.2.1", "4996": "DukunLM-7B-V1.0-Uncensored", "4997": "Limarp-Platypus2-13B-QLoRA-0.80-epoch", "4998": "PULI-LlumiX-32K", "4999": "LLama2-7B-Structural-Prune-1.25x", "5000": "starcoder-finetune-selfinstruct", "5001": "Mixtral-6x7B-Instruct-v0.1-bfloat16-Trimmed024567", "5002": "llama2-7b-hf-guanaco", "5003": "llama2-7b-chat-hf-v3", "5004": "speechless-codellama-orca-13b", "5005": "Airoboros-L2-13B-2.1-GPTQ", "5006": "llama-2-7b-instruct-peft", "5007": "kollama2-7b", "5008": "LLaMa-2-PeanutButter_v10-7B", "5009": "L2-7b-Synthia-WVG-Test", "5010": "llama-2-7b-chat-hf-phr_mental_health-2048", "5011": "gemma-2b-nlaf-v0", "5012": "OpenHathi-7B-Hi-v0.1-Base", "5013": "Qwen1.5-0.5B-vortex-v2", "5014": "speechless-orca-platypus-coig-lite-4k-0.5e-13b", "5015": "Gemma-2B-Samvaad", "5016": "L2-7b-Hermes-WVG-Test", "5017": "llama2_7b_chat_uncensored", "5018": "phi-gemma-nlaf-v1", "5019": "Buttocks-7B-v1.1", "5020": "pooled_gqa_mix_chatml_sft", "5021": "gemma-pro-2.8b-ko-v0", "5022": "guanaco-13b-llama-2", "5023": "Nous-Hermes-llama-2-7b", "5024": "SpeechlessV1-Nova-13B", "5025": "Buttocks-7B-v1.0", "5026": "LIMA2-13b-hf", "5027": "llama-13b-4bit-alpaca", "5028": "vicuna-7b-v1.3", "5029": "Llama-2-7b-ft-instruct-es", "5030": "SOLID-SFT-DPO-MixQV3-SOLIDRejected-SFTChosen-Zephyr-7b-beta", "5031": "llama-3-8b-slow-DUS-method-1", "5032": "dolphin-llama2-7b", "5033": "MelangeA-70b", "5034": "kunkun_dat", "5035": "gemma-2b-openhermes", "5036": "Llama-2-7b-hf-eli5-cleaned-wiki65k-1024_qlora_merged", "5037": "leo-hessianai-7b", "5038": "fietje-2b-chat", "5039": "openhermes-gemma-2b-it", "5040": "mistral-se-inst-ppo", "5041": "DeepCode-7B-Aurora-v12", "5042": "em_german_leo_mistral", "5043": "vicuna-7b-delta-v1.1", "5044": "EverythingLM-13b-V3-peft", "5045": "AmberChat", "5046": "vicuna-7b-1.1", "5047": "gemma-3b-002", "5048": "llama_7b_lora", "5049": "starcoder_mirror", "5050": "ANIMA-Nectar-v2", "5051": "tamil-llama-7b-instruct-v0.2", "5052": "bactrian-x-llama-13b-merged", "5053": "phi-gemma-nlaf-v0", "5054": "baichuan-vicuna-chinese-7b", "5055": "WizardLM-Uncensored-SuperCOT-StoryTelling-30b", "5056": "calm2-7b-chat-dpo-experimental", "5057": "vicuna_7B_vanilla_1.1", "5058": "gemma-2b-it", "5059": "gpt-neox-20b", "5060": "Reyna-Mini-1.8B-v0.1", "5061": "autotrain-xva0j-mixtral8x7b", "5062": "gemma-2b-it-nlai-p1", "5063": "LLongMA-2-13b-16k", "5064": "starcoderbase-7b", "5065": "EverythingLM-13B-16K-GPTQ", "5066": "cosmo-1b", "5067": "TinyLlama-1.1B-OpenHermes-2.5-Chat-v0.1-sft", "5068": "Llama2-7b-openorca-mc-v2", "5069": "Kan-Llama-SFT-v0.5", "5070": "DeepCode-7B-Aurora-v13", "5071": "ypotryll-22b-epoch2-qlora", "5072": "gemma-2b-it-nlai-v0", "5073": "gemma-nlaf-v1", "5074": "deepseek-math-7b-rl", "5075": "U-Amethyst-20B", "5076": "gemma-2b-it-sp-test", "5077": "Xwin-LM-7B-V0.1", "5078": "WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ", "5079": "gemma-2b-it-sp-test1", "5080": "gemma-2b-it-sp-test-openherms-step500", "5081": "csg-wukong-1B", "5082": "llama3", "5083": "glaive-coder-7b", "5084": "openthaigpt-1.0.0-7b-chat", "5085": "CodeLlama-7b-Python-hf", "5086": "CodeLlama-7b-hf", "5087": "leo-hessianai-7b-chat", "5088": "starchat-beta", "5089": "chatml-pyg-v1", "5090": "falcon_7b_DolphinCoder", "5091": "Moko-DARE", "5092": "llama-7b-SFT_ds_eli5_1024_r_64_alpha_16_merged", "5093": "Poro-34B-GPTQ", "5094": "Orca-2-13b-SFT-v6", "5095": "guanaco-7B-HF", "5096": "OpenHermes-7B", "5097": "Evaloric-1.1B-test", "5098": "Platypus2-13B-QLoRa", "5099": "Uncensored-Frank-7B", "5100": "Llama-2-7B-GPTQ", "5101": "metharme-7b", "5102": "tora-code-7b-v1.0", "5103": "MedicWizard-7B", "5104": "TinyLlama-QuantumQuill-chat", "5105": "OpenOrca-Preview1-13B", "5106": "Athena-v1", "5107": "calm2-7b-chat", "5108": "Tinyllama-Cinder-1.3B-Reason-Test", "5109": "spicyboros-7b-2.2", "5110": "Mist_LLaMA-2-7B-1024_V3", "5111": "komodo-7b-chat", "5112": "Qwen-LLaMAfied-7B-Chat", "5113": "ANIMA-Nectar-v3", "5114": "longchat-7b-v1.5-32k", "5115": "blossom-v2-llama2-7b", "5116": "yuj-v1", "5117": "Qwen-las-v0.1", "5118": "kuchiki-1.1-l2-7b", "5119": "mamba-7b-rw", "5120": "openbuddy-zephyr-7b-v14.1", "5121": "gpt-sw3-40b", "5122": "Ember-7B-v0.1", "5123": "bagel-8x7b-v0.2", "5124": "falcon-7b-instruct", "5125": "Llama-2-7b-hf-eli5-cleaned-1024_qlora_merged", "5126": "llama-7b-SFT_eli5_wiki65k_1024_r_64_alpha_16_merged", "5127": "WizardCoder-Python-7B-V1.0", "5128": "Llama-2-7B-32K-Instruct", "5129": "neural-chat-7b-v3-1-Nebula-v2-7B", "5130": "codegemma-2b", "5131": "Huginn-13b-V4", "5132": "opencoderplus", "5133": "Chronos-Beluga-v2-13bfp16", "5134": "pygmalion-7b", "5135": "llama-7b-SFT_ds_wiki65k_1024_r_64_alpha_16_merged", "5136": "Qwen-sft-la-v0.1", "5137": "Huginn-13b-v4.5", "5138": "dociproLLM-7B", "5139": "falcon-7b", "5140": "Huginn-v3-13b", "5141": "llama_7b_qlora", "5142": "zarablend-1.1-l2-7b", "5143": "Wizard-Vicuna-7B-Uncensored-HF", "5144": "AlpacaGPT4-7B-elina", "5145": "K2S3-Llama2-13b-v1.0", "5146": "Wizard-Vicuna-7B-Uncensored", "5147": "llama7b_alpaca_1gpu_bf16", "5148": "llama-7b-SFT-qlora-eli5-wiki_DPO_ds_RM_top_2_1024_r_64_alpha_16", "5149": "openbuddy-deepseek-10b-v17.1-4k", "5150": "Quark-464M-v0.2", "5151": "Llama2-7b-openorca-mc-v2-dpo", "5152": "kuchiki-l2-7b", "5153": "vicuna-7b-v1.5-lora-mctaco", "5154": "falcon_7b_norobots", "5155": "TinyLlama-1.1B-SlimOrca-Function-Calling-3T", "5156": "Llama-2-7b-hf-flan2022-1.2M", "5157": "GOAT-7B-Community", "5158": "mpt-7b-8k-chat", "5159": "zarablend-l2-7b", "5160": "Huginn-19b-prototype", "5161": "yi6", "5162": "baize-healthcare-lora-7B", "5163": "Nova-13B-50-step", "5164": "pygmalion-6b-vicuna-chatml", "5165": "llama7b-wizardlm-unfiltered", "5166": "llama_7b_sharegpt94k_fastchat", "5167": "amber_fine_tune_sgall", "5168": "Huginn-13b-FP16", "5169": "ex-llm-e1", "5170": "LLaMA-2-7B-32K", "5171": "Luminia-13B-v3", "5172": "gemma-3.5b-orpo-selfmerge", "5173": "speechless-orca-platypus-coig-lite-4k-0.6e-13b", "5174": "vicuna-7B-physics", "5175": "Guanaco-7B-Uncensored", "5176": "llama_7b_qlora_pds-eval", "5177": "orca_mini_v2_ger_7b", "5178": "baize-v2-7b", "5179": "longchat-13b-16k", "5180": "lloma_step200", "5181": "mpt-7b-chat", "5182": "llama_7b_qlora_cds", "5183": "Pythia-Chat-Base-7B", "5184": "Llama2-7b-openorca-mc-v1", "5185": "stable-vicuna-13B-HF", "5186": "airoboros-l2-7b-gpt4-m2.0", "5187": "yayi-13b-llama2", "5188": "samantha-1.1-llama-33b", "5189": "gemma-2b-sft-telugu", "5190": "Tinyllama-Cinder-1.3B-Reason-Test.2", "5191": "Airavata", "5192": "SOLAR-Platypus-10.7B-v2", "5193": "Delta-4B-notso-base", "5194": "oasst-pythia-12b-pretrained-sft", "5195": "mpt-7b", "5196": "test-custom-llama", "5197": "gowizardlm", "5198": "MultiLora-sharegpt", "5199": "WizardMath-70B-V1.0", "5200": "vitruv_2", "5201": "palmyra-20b-chat", "5202": "openthaigpt-1.0.0-alpha-7b-chat-ckpt-hf", "5203": "llama-v2-7b-32kC-Security", "5204": "GPT2-774M-CINDER-SHOW-MULTI-CHAT", "5205": "Chronorctypus-Limarobormes-13b", "5206": "LightGPT", "5207": "airoboros-13b-gpt4-1.2", "5208": "LIMA2-7b-hf", "5209": "vigogne-2-7b-instruct", "5210": "Quark-464M-v0.1.alpha", "5211": "chinese-llama-2-7b", "5212": "Llama-2-7b-chat-orcah", "5213": "amber_fine_tune_sg_part1", "5214": "OLMo-7B-hf", "5215": "llama2-22b-daydreamer-v3", "5216": "TinyLlama-3T-Cinder-v1.3", "5217": "open-llama-3b-v2-elmv3", "5218": "vicuna-class-tutor-7b-ep3", "5219": "mistral-7b-raw-sft", "5220": "llama2-7b-raw-sft", "5221": "airoboros-7b-gpt4-1.4", "5222": "ennodata-7b", "5223": "PuddleJumper-13b-V2", "5224": "amber_fine_tune_001", "5225": "koala-7B-HF", "5226": "mtor-2x7b", "5227": "airoboros-gpt-3.5-turbo-100k-7b", "5228": "llama-7b-4bit-alpaca", "5229": "nart-100k-7b", "5230": "llama-base-7b", "5231": "POLAR-14B-v0.2", "5232": "Sailor-1.8B-Chat", "5233": "Planner-7B-fp16", "5234": "airoboros-l2-13b-2.1", "5235": "Stable-Platypus2-13B-QLoRA-0.80-epoch", "5236": "EulerMath-Mistral-7B", "5237": "Galactica-6.7B-EssayWriter", "5238": "gemma-2b-ko-dev-pbmt192", "5239": "open_llama_7b_v2", "5240": "Code-290k-6.7B-Instruct", "5241": "WizardLM-30B-Uncensored-Guanaco-SuperCOT-30b", "5242": "OpenBezoar-HH-RLHF-DPO", "5243": "guanaco-unchained-llama-2-7b", "5244": "frankencria-llama2-12.5b-v1.3-m.2", "5245": "deepseek-coder-1.3b-chat-and-function-calling", "5246": "Newton-7B", "5247": "KoreanLM-hf", "5248": "palmyra-large", "5249": "falcon-rw-1b-instruct-openorca", "5250": "PuddleJumper-13b", "5251": "very-test", "5252": "stablelm-3b-4e1t", "5253": "MFANN3b", "5254": "Nusantara-2.7b-Indo-Chat", "5255": "vicuna-7B-chemical", "5256": "Nusantara-1.8b-Indo-Chat", "5257": "firefly-llama2-7b-pretrain", "5258": "WizardLM-7B-Uncensored", "5259": "PygmalionCoT-7b", "5260": "open_llama_13b", "5261": "GoLLIE-7B", "5262": "llama-2-13b-QLoRA", "5263": "airoboros-l2-7b-gpt4-2.0", "5264": "effi-7b", "5265": "h2ogpt-oasst1-512-20b", "5266": "deepseek-coder-1.3b-chat", "5267": "llama7b-qlora", "5268": "airoboros-7b-gpt4-1.1", "5269": "Falcon-7B-Fintued-Finance-Stock-E", "5270": "dolphin-2.2-yi-34b-200k", "5271": "galactica-6.7b-finetuned", "5272": "oasst-gpt-neox-20b-1000-steps", "5273": "RedPajama-INCITE-7B-Base", "5274": "WizardLM-13b-OpenAssistant-Uncensored", "5275": "oasst-sft-4-pythia-12b-epoch-3.5", "5276": "medalpaca-7b", "5277": "ReMM-L2-13B", "5278": "Chat-AYB-Platypus2-13B", "5279": "FLAMA-0.1-3B", "5280": "ReMM-L2-13B-PIPPA", "5281": "gpt-j-6b", "5282": "Platypus2-13B-QLoRA-0.80-epoch", "5283": "neu-sai-it1", "5284": "GPT-NeoX-20B-Skein", "5285": "oasst-gpt-neox-20b-3000-steps", "5286": "Mistral-4B-FT-2", "5287": "llama-2-26b-trenchcoat-stack", "5288": "Evaloric-1.1B-V.0.1", "5289": "orca_mini_v2_7b", "5290": "WizardCoder-Guanaco-15B-V1.1", "5291": "Code-Llama-3-8B", "5292": "gpt4-x-alpaca", "5293": "dpo-Qwen1.5-0.5B-Chat", "5294": "Baichuan-7B", "5295": "airoboros-2.1-llama-2-13B-QLoRa", "5296": "Amber", "5297": "galpaca-30b", "5298": "llama2-platypus-llama2-chat-13B-hf", "5299": "scarlett-33b", "5300": "Tinyllama-1.3B-Cinder-Reason-Test-2", "5301": "airoboros-l2-7b-gpt4-1.4.1", "5302": "Cinder-1.3B-Test", "5303": "GPT-J-Pyg_PPO-6B", "5304": "mpt-7b-instruct", "5305": "LLama2-7B-Structural-Prune-1.2x", "5306": "WizardMath-7B-V1.0", "5307": "Tulpar-7b-v0", "5308": "MiniMA-3B", "5309": "leo-hessianai-7b-chat-bilingual", "5310": "llama-2-7b-1-percent-open-orca-1000-steps-v0", "5311": "Sailor-1.8B", "5312": "vigogne-7b-instruct", "5313": "codegen-16B-nl", "5314": "PPO_Pygway-V8p4_Dev-6b", "5315": "gpt-neox-20b-full-precision", "5316": "Llama2-7b-sharegpt4", "5317": "Javalion-R", "5318": "giraffe-7b", "5319": "palmyra-med-20b", "5320": "TinyUltra-4x1.1B-Base-Alpha", "5321": "InstructPalmyra-20b", "5322": "TakeTwo", "5323": "xr_dat_test_part2", "5324": "llama2-ko-7B-model", "5325": "stablelm-base-alpha-7b-v2", "5326": "PPO_Shygmalion-V8p4_Dev-6b", "5327": "open-llama-3b-v2-chat", "5328": "chinese-llama-2-7b-16k", "5329": "zephyr-1b-olmo-sft-qlora", "5330": "Barcenas-3b", "5331": "CodeBarcenas-7b", "5332": "Qwen-LLaMAfied-HFTok-7B-Chat", "5333": "Kan-LLaMA-7B-SFT-v0.1-sharded", "5334": "tora-7b-v1.0", "5335": "Project-Baize-v2-7B-GPTQ", "5336": "OpenBezoar-SFT", "5337": "Tiny-Knight-1.1b-v0.1", "5338": "h2ogpt-gm-oasst1-en-1024-20b", "5339": "opt-iml-max-30b", "5340": "Qwen1.5-4B-Chat", "5341": "starchat-alpha", "5342": "Raiden-16x3.43B", "5343": "csg-wukong-1B-sft-bf16", "5344": "illuni-llama-2-ko-7b-test", "5345": "vicuna-class-shishya-all-hal-7b-ep3", "5346": "TinyNaughtyLlama-v1.0", "5347": "airoboros-13b-gpt4-1.3", "5348": "HelpingAI-Lite-2x1B", "5349": "TinyLlama-1.1B-Chat-v1.0", "5350": "OpenOrcaPlatypus2-Platypus2-13B-QLora-0.80-epoch", "5351": "speechless-coder-ds-1.3b", "5352": "pythia-1b-spin-iter1", "5353": "Tinyllama-1.3B-Cinder-Reason-Test", "5354": "carl-7b", "5355": "Huginn-22b-Prototype", "5356": "airoboros-7b-gpt4-1.4.1-qlora", "5357": "lamatama", "5358": "TinyLlama-1.1B-orca-v1.0", "5359": "TinyLlama-MoE-Chat-0.1", "5360": "OrcaMini-Platypus2-13B-QLoRA-0.80-epoch", "5361": "Janin-R", "5362": "GPT-NeoX-20B-Erebus", "5363": "RedTulu-Uncensored-3B-0719", "5364": "TinyLlama-1.1B-Chat-v1.0-x2-MoE", "5365": "tinyllama-chat", "5366": "instruct-13b", "5367": "gogpt2-7b", "5368": "TinyLlama-QuantumQuill-chat-08-05-24-2", "5369": "tinyllama-1.1b-layla-v4", "5370": "llama2-13b-chinese-v2", "5371": "d-Qwen1.5-1.8B", "5372": "open-llama-3b-claude-30k", "5373": "Palworld-SME-13b", "5374": "codegen-6B-nl", "5375": "airoboros-l2-7b-2.1", "5376": "h2ogpt-gm-oasst1-multilang-1024-20b", "5377": "merge_dolly-v2-3b_dpo_test", "5378": "2xbagel-dpo-34b-v0.2", "5379": "csg-wukong-1B-sft-dpo-bf16", "5380": "airoboros-7b", "5381": "rwkv-raven-14b", "5382": "mommygpt-3B", "5383": "Dolly_Shygmalion-6b", "5384": "pythia-13b-deduped-green_devil", "5385": "zephyr-tiny-dpo-qlora", "5386": "GPT-2-SlimOrcaDeduped-airoboros-3.1-MetaMathQA-SFT-124M", "5387": "TinyLlama-Cinder-1.3B-Test.2", "5388": "internlm2-math-20b-llama", "5389": "TinyLlama-1.1B-Chat-v0.6", "5390": "dpo-qlora-Qwen1.5-0.5B-Chat-xtuner", "5391": "shearedplats-2.7b-v2-instruct-v0.1", "5392": "chinese-alpaca-plus-13b-hf", "5393": "pooled_gqa_mix", "5394": "WizardCoder-15B-V1.0", "5395": "PsyOrca2-13b-DARE", "5396": "airoboros-7b-gpt4-1.2", "5397": "blockchainlabs_tinyllama_fusion_LHK_yunkong", "5398": "Barcenas-Tiny-1.1b-DPO", "5399": "BigMaid-20B-v1.0", "5400": "WoolyHermes-1.1B", "5401": "pygmalion-6b", "5402": "Ferret-7B", "5403": "vortex-3b-v2", "5404": "WizardLM-13B-Uncensored", "5405": "TinyWand-SFT", "5406": "zephyr-danube-sft-qlora", "5407": "open_llama_7b_v2_med_instruct", "5408": "vigogne-2-13b-instruct", "5409": "gogpt2-13b", "5410": "fusedyi", "5411": "dolly-v2-3b", "5412": "Ferret_7B", "5413": "Dolly_Shygmalion-6b-Dev_V8P2", "5414": "EverythingLM-13b-V3-16k", "5415": "palmer-002.5", "5416": "pythia-1b-dpo-full", "5417": "pythia-1.4b-sft-full", "5418": "open_llama_3b_glaive_assistant_v0.1", "5419": "Janin-GPTJ", "5420": "pythia-1b-sft-full", "5421": "GPT-J-6B-Shinen", "5422": "TinyLlama-1.1B-Chat-v1.0-intel-dpo", "5423": "OpenHermes-Symbolic-Mistral-7B", "5424": "open_llama_3b_glaive_v0.1", "5425": "Qwenchana-0.5B-restart", "5426": "TinyMix", "5427": "TinyWombat-1.8b-Chat-v.1", "5428": "open_llama_3b_glaive_code_v0.1", "5429": "open_llama_13b_600bt_preview", "5430": "tinyllama-coder-py-v13", "5431": "llama-2-ko-7b", "5432": "smolphin-test-stack-sorted", "5433": "Ambari-7B-Instruct-v0.1-sharded", "5434": "KobbleTiny", "5435": "MiniLlama-1.8b-Chat-v0.1", "5436": "OLMo-1B-hf", "5437": "Ensemble5-Platypus2-13B-QLora-0.80-epoch", "5438": "TinyWand-DPO", "5439": "HelpingAI-Lite-4x1b", "5440": "GPT-J-Pyg_PPO-6B-Dev-V8p4", "5441": "gogpt-7b", "5442": "open-llama-3b-v2-wizard-evol-instuct-v2-196k", "5443": "tinyllama-coder-py-v14", "5444": "tinyllama_merged_test", "5445": "pooled_gqa_mix_chatml", "5446": "open_llama_3b_code_instruct_0.1", "5447": "weblab-10b-instruction-sft", "5448": "Javelin-GPTJ", "5449": "Medusa-7B-bf16", "5450": "DopeyTinyLlama-1.1B-v1", "5451": "pythia-1b-self-kto-iter0", "5452": "Stable-Platypus2-13B", "5453": "lloma_step400", "5454": "Galpaca-30b-MiniOrca", "5455": "speechless-codellama-airoboros-orca-platypus-13b", "5456": "PPO_Shygmalion-6b", "5457": "tamil-llama-7b-instruct-v0.1", "5458": "Orca-2-13B-16k", "5459": "Qllama-tiny-.5B-test-1", "5460": "Sailor-0.5B-Chat", "5461": "Hippolyta-7B-bf16", "5462": "Platypus2-7B", "5463": "TinyLlama-1.1B-2.5T-chat-and-function-calling", "5464": "manovyadh-1.1B-v1-chat", "5465": "starcoderbase-3b", "5466": "opt-13b", "5467": "gpt-sw3-356m-instruct", "5468": "pythia-1b-sft-50k", "5469": "airoboros-7b-gpt4", "5470": "airoboros-7b-gpt4-fp16", "5471": "Tiny-Cowboy-1.1b-v0.1", "5472": "Tiny-Pirate-1.1b-v0.1", "5473": "firefly-bloom-2b6-v2", "5474": "zephyr-tinyllama-sft-qlora", "5475": "Dolly_Malion-6b", "5476": "TinyLlama-repeat", "5477": "zararp-l2-7b", "5478": "pythia-12b", "5479": "DeciCoder-1b", "5480": "DistiLabelOrca-TinyLLama-1.1B", "5481": "Javelin-R", "5482": "PPO_Pygway-6b-Mix", "5483": "TinyLlama-1.1B-1T-OpenOrca", "5484": "KobbleTinyV2-1.1B", "5485": "dopeyplats-1.1b-2T-v1", "5486": "pythia-1b-dpo", "5487": "tinyllama-dare", "5488": "falcon-rw-1b-chat", "5489": "SOLID-SFT-DPO-MixQV2-SOLIDChosen-SFTRejected-Zephyr-7b-beta", "5490": "opt-66b", "5491": "TakeThree", "5492": "Javalion-GPTJ", "5493": "Bio-Saul-Dolphin-Beagle-Breadcrumbs", "5494": "TinyLamma-SFT", "5495": "ChanMalion", "5496": "h2ogpt-oasst1-512-12b", "5497": "gemma-7B-alpaca-case-1-2", "5498": "pythia-6.9b-deduped", "5499": "open-llama-3b-everything-v2", "5500": "RedPajama-INCITE-7B-Instruct", "5501": "zephyr-tiny-sft-qlora-quantized-2", "5502": "pyg-instruct-wizardlm", "5503": "gpt-sw3-1.3b-instruct", "5504": "tinyllama_frankenmerge", "5505": "h2ogpt-oig-oasst1-256-6_9b", "5506": "open_llama_3b_instruct_v_0.2", "5507": "babyllama-v0.6", "5508": "FinanceConnect-13B", "5509": "RedPajama-INCITE-Instruct-7B-v0.1", "5510": "posi_13b", "5511": "ZySec-1B", "5512": "HelpingAI-Lite-1.5T", "5513": "open_llama_7b", "5514": "Adventien-GPTJ", "5515": "smartyplats-3b-v2", "5516": "RedPajama-INCITE-Base-7B-v0.1", "5517": "csg-wukong-1B-orpo-bf16", "5518": "MediKAI", "5519": "landmark-attention-llama7b-fp16", "5520": "Ambari-7B-base-v0.1-sharded", "5521": "TinyLlama-1.1B-step-2T-lr-5-5ep-oasst1-top1-instruct-V1", "5522": "pythia-1b-kto-iter0", "5523": "GPT-R", "5524": "Orca-2-7B-16k", "5525": "CodeEngine", "5526": "h2ogpt-gm-oasst1-en-1024-open-llama-7b-preview-400bt", "5527": "falcon_7b_3epoch_norobots", "5528": "Skegma-GPTJ", "5529": "cosmo-3b-test-v0.2", "5530": "bloom-3b", "5531": "FinguAI-Chat-v1", "5532": "Llama-2-7b-chat-hf-flan2022-1.2M", "5533": "fialka-7B-v3", "5534": "pythia-1.4b", "5535": "Tiny-Vicuna-1B", "5536": "AIRIC-The-Intern", "5537": "open-llama-3b-everythingLM-2048", "5538": "ablation-model-fineweb-v1", "5539": "shearedplats-2.7b-v2", "5540": "MistralInstructLongish", "5541": "TinyDolphin-2.8-1.1b", "5542": "llama2-7b-hf-chat-lora-v3", "5543": "Mia-1B", "5544": "ennodata-13b-8bit-raw-15epoch", "5545": "TinyLlama-1.1B-miniguanaco", "5546": "TinyLlama-chat-SFT", "5547": "h2o-danube-1.8b-base", "5548": "GPT-J-6B-Skein", "5549": "Medusa-1.1-L2-7B", "5550": "TinyLlama-1.1B-intermediate-step-1431k-3T", "5551": "alpaca-native", "5552": "TinyLlamax2-1.1b", "5553": "SOLID-SFT-DPO-MixQV3-SOLIDChosen-SFTRejected-Zephyr-7b-beta", "5554": "zyte-1B", "5555": "TinyLlama-1.1B-intermediate-step-1195k-token-2.5T", "5556": "LLaMA2-13B-Psyfighter2", "5557": "Nusantara-0.8b-Indo-Chat", "5558": "cisco-iNAM-1.1B", "5559": "Brunhilde-13b-v3", "5560": "WizardCoder-Guanaco-15B-V1.0", "5561": "weblab-10b", "5562": "tinyllama-coder-py-v12", "5563": "pythia-12b-deduped", "5564": "Nous-Hermes-Platypus2-13B-QLoRA-0.80-epoch", "5565": "csg-wukong-1B-chat-v0.1", "5566": "TinyLlama-1.1B-intermediate-step-955k-token-2T", "5567": "Nous-Hermes-2-SOLAR-10.7B-v1.1", "5568": "Tukan-1.1B-Chat-reasoning-sft-COLA", "5569": "llama2-13b-ft-openllm-leaderboard-v1", "5570": "RedPajama-INCITE-Instruct-3B-v1", "5571": "cosmo-3b-test", "5572": "zyte-v1-1.1B", "5573": "youri-7b-chat", "5574": "TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-3epochs-oasst1-top1-instruct-V1", "5575": "GPT-J-6B-Janeway", "5576": "lora_opt13b_10e5", "5577": "CAlign-alpaca-7b", "5578": "model_007_13b_v2", "5579": "pooled_gqa_chat", "5580": "dpo-test-hermes-open-llama-3b", "5581": "bloom-7b1", "5582": "zyte-1.1b", "5583": "K2S3-SOLAR-11b-v1.0", "5584": "openhermes-danube2-sft-qlora", "5585": "openthaigpt-1.0.0-beta-7b-chat-ckpt-hf", "5586": "MiniMerlin-3b-v0.1", "5587": "mc_model_v1", "5588": "stablelm-4e1t-2b-v0.1", "5589": "ToRoLaMa-7b-v1.0", "5590": "BioTATA-7B", "5591": "fbopt-350m-8bit", "5592": "kunkun_dat_llama_13b_alpaca", "5593": "gpt-neo-2.7B", "5594": "ennodata-raw-pankajmathur-13b-peft", "5595": "TinyDolphin-2.8.2-1.1b-laser", "5596": "Moderator-Chan_GPT-JT-6b", "5597": "tinyllama-1.1B-intermediate-step-715k-1.5T-dpo-lora-merged", "5598": "MLewd-L2-13B", "5599": "K2S3-SOLAR-11b-v2.0", "5600": "TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-4epochs-oasst1-top1-instruct-V1", "5601": "vicuna-7b-v1.5-lora-mctaco-modified1", "5602": "fialka-13B-v3", "5603": "phoenix-inst-chat-7b", "5604": "Marx-3B", "5605": "llama-2-13b-Beluga-QLoRA", "5606": "TacoBeLLM", "5607": "pythia-410m-sft-full", "5608": "smolphin-test-bottomheavy", "5609": "tinyllama_eng_long", "5610": "phi-2-ko-v0.1", "5611": "amber_fine_tune_ori", "5612": "Llama-2-ko-7b-Chat", "5613": "RedPajama-INCITE-Base-3B-v1", "5614": "Cerebras-GPT-13B", "5615": "GPT-JT-6B-v0", "5616": "tinyllama-1.1b-layla-v1", "5617": "oasst-pythia-12b-reference", "5618": "tinyllama_eng_short1", "5619": "gpt-sw3-6.7b-v2", "5620": "Marx-3B-V2", "5621": "Nous-Hermes-13B-SuperHOT-8K-fp16", "5622": "ShortKing-3b-v0.3", "5623": "palmer-002", "5624": "dolly-v2-12b", "5625": "TinyLlama-1.1B-intermediate-step-1431k-3T-laser-dpo", "5626": "Stellaris-internlm2-20b-r256", "5627": "GPT-JT-6B-v1", "5628": "Test-7B-pthrough", "5629": "Sailor-0.5B", "5630": "openbuddy-mistral-7b-v13-base", "5631": "Pygmalion_AlpacaLora-7b", "5632": "mamba-gpt-3b-v3", "5633": "neural-chat-7b-v3", "5634": "tinyllama_eng_short", "5635": "gpt-neox-20b-4bit-alpaca", "5636": "Qwen-sft-ls-v0.1", "5637": "koishi-instruct-3b", "5638": "LLama2-7B-Structural-Prune-1.5x", "5639": "dolly-v2-7b", "5640": "cloudymixtral7Bx2-nectar-0.2", "5641": "OpenLlama-Platypus-3B", "5642": "JARVIS", "5643": "WizardVicuna-Uncensored-3B-0719", "5644": "TinyLlama-1.1B-2.5T-chat", "5645": "zararp-1.1-l2-7b", "5646": "22-Neuro_Model", "5647": "DiffMerge_Pygmalion_Main-onto-V8P4", "5648": "pygmalion-6b-roleplay", "5649": "Evaloric-1.1B", "5650": "Llama-3-pruned-45B-Drobeta-Turnu-Severin", "5651": "SmolLlama-1.5B", "5652": "opt-30b", "5653": "pythia-1b-deduped", "5654": "MobileLLaMA-1.4B-Base", "5655": "LLmRA-3B-v0.1", "5656": "OPT-6.7B-Erebus", "5657": "pythia-2.7b", "5658": "tinyllama-coder-py-4bit-v4", "5659": "Med_GPT2", "5660": "open-llama-3b-v2-layla", "5661": "Nanbeige-16B-Base-32K-llama", "5662": "bloom-3b-conversational", "5663": "pythia-6.7b", "5664": "smartyplats-3b-v1", "5665": "localmentor_25K_3epochs_tinyllama", "5666": "wizard-orca-3b", "5667": "SmolPlatypus-1.5B-Sorted", "5668": "MistralLite", "5669": "Sheared-LLaMA-2.7B", "5670": "h2ogpt-gm-oasst1-en-1024-12b", "5671": "gpt2_137m_DolphinCoder", "5672": "deepseek-coder-1.3b-instruct", "5673": "TinyllamaMix-1.1B", "5674": "tmm-1b", "5675": "Covasna-0.1", "5676": "gpt-sw3-126m-instruct", "5677": "codegen-6B-multi", "5678": "megachat", "5679": "SmolPlatypus-1.5B", "5680": "TinyLlama-MoE-Chat", "5681": "airoboros-7b-gpt4-1.3", "5682": "openbuddy-openllama-3b-v10-bf16", "5683": "Griffin-3B", "5684": "tiny_starcoder_py", "5685": "GPT-JT-Moderation-6B", "5686": "SRBOSGPT-7B-slerp", "5687": "oasst-pythia-12b-flash-attn-5000-steps", "5688": "tinyllama", "5689": "Tinypus-1.5B", "5690": "pythia-1.3b", "5691": "WizardVicuna-open-llama-3b-v2", "5692": "Medical-ChatBot", "5693": "phi2-mmlu-lora", "5694": "SuperChat-7B", "5695": "h2ogpt-oig-oasst1-512-6_9b", "5696": "gpt-sw3-20b", "5697": "nucleus-22B-token-500B", "5698": "palmyra-base", "5699": "opt-6.7b", "5700": "MT7Bi-wizard-3-alpha-dpo", "5701": "open-cabrita3b", "5702": "smolphin-test1", "5703": "gemma-2b-ko-v0", "5704": "Walter-SOLAR-11B", "5705": "gpt2-xl_lima", "5706": "NanoLlama-GQA-L10-A32_KV8-v13-KI", "5707": "13B-Thorns-l2", "5708": "speechless-tora-code-7b-v1.0", "5709": "starcoderbase-1b", "5710": "2x-LoRA-Assemble-Platypus2-13B", "5711": "Gaja-v1.00", "5712": "Flash-Llama-3B", "5713": "RedPajama-INCITE-Chat-Instruct-3B-V1", "5714": "TinyLlama-1.1B-Remix-V.2", "5715": "yayi-7b", "5716": "openllama_3b_EvolInstruct_lora_merged", "5717": "qd-phi-1_5", "5718": "Luban-Platypus2-13B-QLora-0.80-epoch", "5719": "llama-2-13b-platypus-vicuna-wizard", "5720": "boomer-1b", "5721": "elysa_model", "5722": "PandaLM-Alpaca-7B-v1", "5723": "llama-2-13b-vicuna-wizard", "5724": "open_llama_3b_v2", "5725": "vortex-3b", "5726": "MythoMix-Platypus2-13B-QLoRA-0.80-epoch", "5727": "gpt-j-6B-Dolly", "5728": "CroissantLLMBase", "5729": "pythia-2.8b-deduped", "5730": "GPT-J-6B-Adventure", "5731": "Gaja-vv1", "5732": "bloom-1b7", "5733": "openthaigpt-1.0.0-beta-13b-chat-hf", "5734": "TinyLlama-748M-Reason-With-Cinder-Test-2", "5735": "QwenSailorMerge", "5736": "Alpaca-tuned-gpt2", "5737": "pythia-1.4b-deduped-sharegpt", "5738": "stablelm-tuned-alpha-7b", "5739": "cherry_5_7B", "5740": "crow-1b", "5741": "MindLLM", "5742": "FLAMA-0.5-3B", "5743": "mptk-1b", "5744": "gpt2-large", "5745": "pythia-1.4b-deduped", "5746": "rwkv-4-7b-pile", "5747": "xglm-1.7B", "5748": "smol_llama-101M-GQA", "5749": "llama-pile-350b", "5750": "7B-redpajama-conditional-alpha", "5751": "Healix-3B", "5752": "OPT-6.7B-Nerybus-Mix", "5753": "I-Code-NousLlama7B-slerp", "5754": "metharme-1.3b", "5755": "dopeyshearedplats-1.3b-v1", "5756": "phi-2-upscaled-4B-instruct-v0.1", "5757": "WizardVicuna-3B-0719", "5758": "Instruct_GPT_v1", "5759": "FLOR-1.3B-xat", "5760": "16b-experiment-llama-2", "5761": "TinyLlama-Mistral", "5762": "gpt2-xl-sft", "5763": "ko-en-llama2-13b", "5764": "PULI-GPTrio", "5765": "OPT-13B-Erebus", "5766": "blockchainlabs_tinyllama_fusion_LHK_yunkong_v2", "5767": "pragna-1b", "5768": "QuantumQuill-chat-v1", "5769": "Puma-3B", "5770": "Alpaca_refine_tuned_gpt2_large", "5771": "42dot_LLM-PLM-1.3B", "5772": "WizardLM-13B-V1-1-SuperHOT-8K-fp16", "5773": "smolphin-test-stack", "5774": "Algae-550M-base", "5775": "open-llama-0.7T-7B-open-instruct-v1.1", "5776": "smol_llama-220M-GQA", "5777": "llama-3-8b-slow-DUS-random-method2", "5778": "rwkv-4-3b-pile", "5779": "LLaMA2-13B-Tiefighter", "5780": "42dot_LLM-SFT-1.3B", "5781": "Anima-7B-100K", "5782": "firefly-bloom-7b1", "5783": "phi2", "5784": "TinyLlama-1.1B-Chat-v0.3", "5785": "My_GPT2", "5786": "galactica-6.7b-ReFT-GSM8k", "5787": "Kaori-34b-v2", "5788": "OPT-350M-Nerys-v2", "5789": "TinyDolphin-2.8.1-1.1b", "5790": "OPT-6B-nerys-v2", "5791": "vicuna-7b-v1.5-lora-mctaco-modified2", "5792": "Alpaca_refine_gpt2_e0_se1", "5793": "math_gpt2_sft", "5794": "pythia-410m", "5795": "WizardLM-13B-V1-1-SuperHOT-8K-GPTQ", "5796": "Tulpar-7b-v1", "5797": "RedPajama-INCITE-Chat-3B-Instruction-Tuning-with-GPT-4", "5798": "mamba-gpt-3b-v4", "5799": "WizardVicuna-Uncensored-3B-instruct-PL-lora_unload", "5800": "gpt2", "5801": "black_goo_recipe_c", "5802": "chinese-alpaca-plus-7b-hf", "5803": "Deacon-1b", "5804": "Mistral-7B-AEZAKMI-v1", "5805": "zephyr-smol_llama-100m-dpo-full", "5806": "kaori-34b-v4", "5807": "calypso-3b-alpha-v2", "5808": "tinyllama-coder-py-4bit-v3", "5809": "TinyLlama-1.1B-1.5T-OpenOrca-Alpha", "5810": "smol_llama-220M-openhermes", "5811": "SmolLlama-1.5B-Sorted", "5812": "stablelm-base-alpha-7b", "5813": "SmolLlamix-8x101M", "5814": "LL7M", "5815": "b1ade-1b", "5816": "SmolLlama-1.5B-Bottomheavy", "5817": "open_llama_3b_600bt_preview", "5818": "10k_v1_lora_qkvo_rank28_v2", "5819": "FusedKuno", "5820": "llama-r", "5821": "oasst-sft-1-pythia-12b", "5822": "3B-redpajama-conditional-alpha", "5823": "llama3-8b-ultrafeedback-dpo", "5824": "pythia-2.8b-4bit-alpaca", "5825": "Aquila2-34B", "5826": "Mistral_solar-slerp", "5827": "latent_gpt2_medium_alpaca_e4", "5828": "ChickaQ", "5829": "Alpaca_spin_tuned_gpt2_large", "5830": "CrimsonPajama", "5831": "ReasonixPajama-3B-HF", "5832": "RedPajama-INCITE-Chat-3B-v1", "5833": "orca_mini_3b_juniper", "5834": "zephyr-220m-dpo-full", "5835": "Cerebras-GPT-6.7B", "5836": "stablelm-tuned-alpha-3b", "5837": "tinyllama-coder-py-4bit-v10", "5838": "TinyExperts-v0-4x1B", "5839": "SmolLlamix-8x101M-take2", "5840": "gpt_bigcode-santacoder", "5841": "open-llama-7b-open-instruct", "5842": "hf_checkpoint2_01052024", "5843": "TinyLlama-1.1B-step-50K-105b", "5844": "tinyllama-1.1b-chat-v0.3_platypus", "5845": "oasst-pythia-12b-6000-steps", "5846": "wangchanglm-7.5B-sft-enth", "5847": "shearedplats-1.3b-v1", "5848": "pile-7b-250b-tokens", "5849": "gpt-sw3-6.7b", "5850": "Guanaco-3B-Uncensored", "5851": "blossom-v2-3b", "5852": "Bean-3B", "5853": "black_goo_recipe_a", "5854": "fialka-13B-v3.1", "5855": "oasst-pythia-6.9b-4000-steps", "5856": "pygmalion-350m", "5857": "Cerebras-GPT-2.7B-Alpaca-SP", "5858": "bloomz-7b1-sa-v0.1", "5859": "Silver-Sun-11B", "5860": "TinyLlama-1.1B-Chat-v0.1", "5861": "bloomz-7b1-mt-sft-chat", "5862": "numfalm-3b", "5863": "chinese-llama-plus-13b-hf", "5864": "Mistral-offspring-1-3", "5865": "TinyLlama-1.1B-intermediate-step-480k-1T", "5866": "opt-iml-max-1.3b", "5867": "falcon-rw-1b", "5868": "Yousei-22B", "5869": "PT_GPTNEO350_ATG", "5870": "numfa_v2-1b", "5871": "RedPajama-INCITE-7B-Chat", "5872": "bloom-zh-3b-chat", "5873": "ShortKingv0.1", "5874": "platypus-1_8b", "5875": "llama-2-4b", "5876": "opt-1.3b-rlhf", "5877": "Sheared-LLaMA-1.3B", "5878": "stablelm-base-alpha-3b", "5879": "13B-Ouroboros", "5880": "Cerebras-GPT-2.7B", "5881": "Cerebras-GPT-590M", "5882": "LlamaCorn-1.1B", "5883": "TinyLlama-3T-1.1bee", "5884": "numfalm_v2-1b", "5885": "open_llama_3b", "5886": "rwkv-raven-3b", "5887": "rwkv-4-169m-pile", "5888": "tinyllama-oasst1-top1-instruct-full-lr1-5-v0.1", "5889": "RedPajama-INCITE-Chat-7B-v0.1", "5890": "gpt-neo-1.3B", "5891": "fialka-13B-v4", "5892": "GodziLLa-30B", "5893": "bloomz-3b-sft-chat", "5894": "radintloom-mistral-7b-fusion-dpo", "5895": "rwkv-4-430m-pile", "5896": "Minueza-32M-Base", "5897": "black_goo_recipe_d", "5898": "pythia-160m-deduped-step92k-193bt", "5899": "lora_opt6.7b_10e5", "5900": "orca_mini_7b", "5901": "Sheared-Pythia-160m", "5902": "Athena-8B", "5903": "Cerebras_1.3b_Quantized", "5904": "MistralLite-11B", "5905": "OPT-13B-Nerybus-Mix", "5906": "camel-5b-hf", "5907": "TinyLlama-1.1B-FFT-Test2", "5908": "galactica-6.7b-evol-instruct-70k", "5909": "megatron-GPT-2-345m-EvolInstruct", "5910": "latent_gpt2_medium_alpaca_e2", "5911": "RWKV-4-PilePlus-169M-20230520-done-ctx4096", "5912": "deacon-3b", "5913": "zephyr-220m-sft-full", "5914": "test-22B", "5915": "Quokka_2.7b", "5916": "Llama-3-7b", "5917": "dopeyshearedplats-2.7b-v1", "5918": "blossom-v1-3b", "5919": "Silver-Sun-v2-11B", "5920": "Dorflan", "5921": "Tiny-Llama-3-7b", "5922": "mc_data_30k_from_platpus_orca_7b_10k_v1_lora_qkvo_rank14_v2", "5923": "stablelm-7b-sft-v7-epoch-3", "5924": "rwkv-4-14b-pile", "5925": "774M-03_09_2024", "5926": "bloom-560m", "5927": "falcon-1b-t-sft", "5928": "RedPajama-INCITE-Chat-3B-ShareGPT-11K", "5929": "based-30b", "5930": "pythia-70m", "5931": "Guanaco-3B-Uncensored-v2", "5932": "OPT-350M-Erebus", "5933": "gpt2-alpaca-gpt4", "5934": "OPT-2.7B-Nerys-v2", "5935": "opt-350m", "5936": "Mixnueza-6x32M-MoE", "5937": "Shiki-v2-m7", "5938": "finetuned-gpt2-tiny", "5939": "pythia-410m-deduped", "5940": "model-a-48.5m", "5941": "gpt-neo-125m", "5942": "scarlett-7b", "5943": "RedPajama-INCITE-Chat-3B-v1-RL-LoRA-8bit-test1", "5944": "LLmRa-2.7B", "5945": "SSH_300M", "5946": "Asclepius-Llama2-7B", "5947": "rwkv-raven-7b", "5948": "rugpt3large_based_on_gpt2", "5949": "galactica-6.7b-ReFT-Rerank-GSM8k", "5950": "gpt2_test", "5951": "GPTNeo350M-Instruct-SFT", "5952": "Deer-3b", "5953": "zephyr_0.2_a2.5", "5954": "OPT-2.7B-Erebus", "5955": "opt125m_10e5_lr2e-7", "5956": "verysmol_llama-v11-KIx2", "5957": "gpt3-finnish-13B", "5958": "bloom-560m-RLHF", "5959": "gpt2023", "5960": "Instruct_GPT", "5961": "TinyLlama-1.1B-intermediate-step-240k-503b", "5962": "test-3b", "5963": "vicuna-tutor-shishya-model-7b-ep3", "5964": "NEBULA-XB-v1.0_SFT_2_epoch", "5965": "LLongMA-3b-LIMA", "5966": "ShearedLlama-1.3b-FFT-Test1", "5967": "gpt-sw3-356m", "5968": "pythia-31m", "5969": "dolphin-2.6-mistral-7b-dpo-5.93B", "5970": "xglm-4.5B", "5971": "new-turn-2", "5972": "instruct-12b", "5973": "bloom-1b1", "5974": "Gaja-v2.00", "5975": "Minueza-32M-Deita", "5976": "xglm-7.5B", "5977": "zaraxls-l2-7b", "5978": "Gaja-v2.00-dpo", "5979": "megatron-gpt2-345m", "5980": "pythia-160m-deduped", "5981": "256_5epoch", "5982": "h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2", "5983": "Cerebras-GPT-1.3B", "5984": "RWKV-4-PilePlus-430M-20230520-6162-1018Gtokens-ctx4098", "5985": "ScarletPajama-3B-HF", "5986": "gpt-neo-1.3B-4bit-alpaca", "5987": "opt-2.7b", "5988": "smol_llama-81M-tied", "5989": "TinyNewsLlama-1.1B", "5990": "opt-125m", "5991": "OmegLLaMA-3B", "5992": "xglm-564M", "5993": "dlite-v2-1_5b", "5994": "pythia-160m", "5995": "mamba-gpt-3b", "5996": "distillgpt2Cinder", "5997": "Narumashi-11B", "5998": "openbuddy-mixtral-8x7b-v16.2-32k", "5999": "TinyLlama-QuantumQuill-chat-08-05-24-3", "6000": "TinyLlama-1.1bee", "6001": "open-calm-7b", "6002": "OPT-30B-Erebus", "6003": "sappha-2b-v3", "6004": "Stheno-1.3-L2-13B", "6005": "BioMistral-7B-TIES", "6006": "OPT-13B-Nerys-v2", "6007": "Minueza-32M-UltraChat", "6008": "tinyllama_PY-CODER-4bit-lora_4k-v5", "6009": "math_gpt2", "6010": "Mixsmol-4x400M-v0.1-epoch2", "6011": "wangchanglm-7.5B-sft-en-sharded", "6012": "codeparrot", "6013": "OEvortex", "6014": "neuralfalcon-1b-v1", "6015": "gemma-2b-data-std", "6016": "Guanaco-3B-Uncensored-v2-GPTQ", "6017": "gpt2_open-platypus", "6018": "Tinyllama-616M-Cinder-DPO-With-GGUF", "6019": "Bloom_1b_Quantized", "6020": "mistral-orpo-alpha", "6021": "OPT-2.7B-Nerybus-Mix", "6022": "Mixsmol-4x400M-v0.1-epoch1", "6023": "opt125m_10e2", "6024": "opt125m_10e5_lr2e-6", "6025": "llama2-ppo", "6026": "gpt-2-xl-EvolInstruct", "6027": "gpt-2-xl_camel-ai-physics", "6028": "Bio-Mistralv2-Squared", "6029": "vigogne2-enno-13b-sft-lora-4bit", "6030": "pruned_mistral", "6031": "T3Q-ko-solar-dpo-v6.0", "6032": "Facebook_opt_1.3b_Quantized", "6033": "lamini-neo-1.3b", "6034": "1.3b", "6035": "mixtral_stack_llama", "6036": "bloom-560m-4bit-alpaca", "6037": "opt-1.3b", "6038": "gpt2-dolly", "6039": "Asclepius-Llama2-13B", "6040": "Alpaca-7B-v1", "6041": "smol_llama-4x220M-MoE", "6042": "lamini-cerebras-590m", "6043": "gogpt-3b-bloom", "6044": "EastAsia-4x7B-Moe-experiment", "6045": "polyglot-ko-12.8b", "6046": "Llama3merge5", "6047": "Stellaris-internlm2-20b-r128", "6048": "Manticore-13B-Chat-Pyg-Guanaco-SuperHOT-8K-GPTQ", "6049": "phi-2-audio-super", "6050": "DolphinMini-Mistral-7B", "6051": "aqua-smaug-hermes-8B", "6052": "A.I.Kant-Test_Llama-3-8B-Instruct_v0.1.1", "6053": "spin_gpt2_medium_alpaca_e2", "6054": "Sparse0.5_OPT-1.3", "6055": "GALAXY_v03_slimorca_1_epoch_50k_DPO_1_epoch_30k", "6056": "OpenMath-Mistral-7B-v0.1-hf", "6057": "orca_mini_13B-GPTQ", "6058": "pruned-yi-3b-prerelease-ckpt01", "6059": "590m", "6060": "Merge-Mayhem-L3-V2", "6061": "TinyLlama-Remix", "6062": "black_goo_recipe_b", "6063": "Sheared-LLaMA-1.3B-ShareGPT", "6064": "vicuna-mmlu-val-only-correct-mcq-7b-ep2", "6065": "Smol-Llama-101M-Chat-v1", "6066": "TinyLlama-3T-Cinder-v1.2", "6067": "gpt-sw3-1.3b", "6068": "Alpaca_spin_gpt2_e0_se1", "6069": "Psydestroyer-20B", "6070": "Libra-19B", "6071": "Camel-Platypus2-13B", "6072": "open-calm-large", "6073": "Mixtral-GQA-400m-v2", "6074": "bloomz-7b1", "6075": "gpt-neo-125m-neurallinguisticpioneers", "6076": "Pygmalion-13b-Merged", "6077": "TinyOpenHermes-1.1B-4k", "6078": "Llama-2-7b-WikiChat-fused", "6079": "Stheno-Mix-L2-20B", "6080": "LLmRa-1.3B", "6081": "open_llm_leaderboard_demo2", "6082": "bloom-560m-RLHF-v2", "6083": "RedPajama-INCITE-Chat-3B-v1-FT-LoRA-8bit-test1", "6084": "vicuna-7b-v1.5-lora-mctaco-modified4", "6085": "Platypus2xOpenOrca-13B-LoRa-v2", "6086": "Nape-0", "6087": "Narumashi-RT-11B-test", "6088": "Athena-Platypus2-13B-QLora-0.80-epoch", "6089": "gpt2-conversational-or-qa", "6090": "GPT-2-Large-115k-steps", "6091": "gpt-sw3-126m", "6092": "Confluence-Renegade-7B", "6093": "BioMistralMerged", "6094": "dlite-v1-1_5b", "6095": "llama-160m", "6096": "orca_mini_3b", "6097": "gpt2-large-conversational", "6098": "proofGPT-v0.1", "6099": "DARE-Merging", "6100": "KoAlpaca-Polyglot-5.8B", "6101": "SparseOPT-1.3B", "6102": "Walter-Mistral-7B"}}