{
    "ability": [
        2.402456045150757,
        2.329390287399292,
        2.326267719268799,
        2.3219456672668457,
        2.234982490539551,
        2.209118604660034,
        2.1929545402526855,
        2.1559786796569824,
        2.070209503173828,
        2.1346652507781982,
        2.0632193088531494,
        2.011521577835083,
        1.9016369581222534,
        2.006413698196411,
        1.963555932044983,
        1.8977185487747192,
        1.8473491668701172,
        1.740003228187561,
        1.7230075597763062,
        1.6867926120758057,
        1.693572759628296,
        1.6856354475021362,
        1.7364431619644165,
        1.6924980878829956,
        1.6546944379806519,
        1.637115478515625,
        1.6419886350631714,
        1.6383687257766724,
        1.5842951536178589,
        1.6297321319580078,
        1.6003597974777222,
        1.5931446552276611,
        1.5930134057998657,
        1.5789281129837036,
        1.55955171585083,
        1.5999493598937988,
        1.5442310571670532,
        1.5167192220687866,
        1.4698563814163208,
        1.4368895292282104,
        1.4577101469039917,
        1.4732818603515625,
        1.4231411218643188,
        1.4130891561508179,
        1.4039639234542847,
        1.403419017791748,
        1.4426897764205933,
        1.3666431903839111,
        1.3427212238311768,
        1.3640302419662476,
        1.4485089778900146,
        1.325701355934143,
        1.3060945272445679,
        1.302701473236084,
        1.319753646850586,
        1.3060269355773926,
        1.300739049911499,
        1.3038809299468994,
        1.3040610551834106,
        1.249542474746704,
        1.3749887943267822,
        1.2736972570419312,
        1.3065451383590698,
        1.2958862781524658,
        1.26974356174469,
        1.2573219537734985,
        1.2660326957702637,
        1.2853180170059204,
        1.179355502128601,
        1.2393231391906738,
        1.2351001501083374,
        1.3310935497283936,
        1.2470892667770386,
        1.2989212274551392,
        1.3089947700500488,
        1.2510676383972168,
        1.3277478218078613,
        1.3362865447998047,
        1.3558273315429688,
        1.2775036096572876,
        1.3038278818130493,
        1.3408864736557007,
        1.3341734409332275,
        1.2194340229034424,
        1.202012300491333,
        1.216544270515442,
        1.3208644390106201,
        1.281294345855713,
        1.2916287183761597,
        1.2911196947097778,
        1.3566538095474243,
        1.2372783422470093,
        1.204750895500183,
        1.2203803062438965,
        1.3408524990081787,
        1.2094694375991821,
        1.302289366722107,
        1.316452145576477,
        1.2104078531265259,
        1.321876883506775,
        1.2173370122909546,
        1.3097511529922485,
        1.1852195262908936,
        1.1931030750274658,
        1.2998924255371094,
        1.211089015007019,
        1.3262807130813599,
        1.1862539052963257,
        1.2969715595245361,
        1.2110378742218018,
        1.3011784553527832,
        1.2026300430297852,
        1.2033557891845703,
        1.1524895429611206,
        1.327735185623169,
        1.3092989921569824,
        1.259067177772522,
        1.3204329013824463,
        1.3097766637802124,
        1.201975703239441,
        1.2904149293899536,
        1.2027703523635864,
        1.2916440963745117,
        1.1836010217666626,
        1.1970813274383545,
        1.2507667541503906,
        1.2909862995147705,
        1.3361318111419678,
        1.2411961555480957,
        1.1556986570358276,
        1.1632517576217651,
        1.1728211641311646,
        1.1590224504470825,
        1.254084825515747,
        1.1874829530715942,
        1.1821463108062744,
        1.1782900094985962,
        1.1720952987670898,
        1.1415022611618042,
        1.2542039155960083,
        1.2213129997253418,
        1.2014780044555664,
        1.2654649019241333,
        1.262807011604309,
        1.2599784135818481,
        1.2846606969833374,
        1.1262381076812744,
        1.2697792053222656,
        1.2764160633087158,
        1.2674531936645508,
        1.230838656425476,
        1.2810909748077393,
        1.157378077507019,
        1.2906843423843384,
        1.2896884679794312,
        1.2468454837799072,
        1.2005866765975952,
        1.2093056440353394,
        1.1905268430709839,
        1.1432936191558838,
        1.2804605960845947,
        1.2530728578567505,
        1.2725789546966553,
        1.1655954122543335,
        1.2713567018508911,
        1.2105275392532349,
        1.143879771232605,
        1.248781681060791,
        1.1535160541534424,
        1.1528091430664062,
        1.2281206846237183,
        1.2756787538528442,
        1.2914811372756958,
        1.2855111360549927,
        1.1454031467437744,
        1.1549546718597412,
        1.1610029935836792,
        1.158668041229248,
        1.2473552227020264,
        1.2492057085037231,
        1.1566407680511475,
        1.1299411058425903,
        1.1744805574417114,
        1.1230720281600952,
        1.244816780090332,
        1.1535767316818237,
        1.2281907796859741,
        1.22323477268219,
        1.2333835363388062,
        1.2225120067596436,
        1.2333345413208008,
        1.2738876342773438,
        1.2285100221633911,
        1.2617162466049194,
        1.2876081466674805,
        1.2333694696426392,
        1.2427476644515991,
        1.2257717847824097,
        1.269723653793335,
        1.1272591352462769,
        1.1295204162597656,
        1.1513662338256836,
        1.1283977031707764,
        1.288933277130127,
        1.1349884271621704,
        1.2653815746307373,
        1.2683299779891968,
        1.147204041481018,
        1.2340409755706787,
        1.2865562438964844,
        1.2047086954116821,
        1.199474811553955,
        1.1411584615707397,
        1.2101118564605713,
        1.2767620086669922,
        1.2531471252441406,
        1.2741950750350952,
        1.1201800107955933,
        1.2889879941940308,
        1.1175626516342163,
        1.2748255729675293,
        1.290750503540039,
        1.2597817182540894,
        1.2891336679458618,
        1.2257590293884277,
        1.221238613128662,
        1.2137293815612793,
        1.2385905981063843,
        1.224617600440979,
        1.2025113105773926,
        1.2677215337753296,
        1.2628549337387085,
        1.134156346321106,
        1.206164002418518,
        1.2506229877471924,
        1.1350126266479492,
        1.2275331020355225,
        1.135745644569397,
        1.1511808633804321,
        1.2057783603668213,
        1.2578425407409668,
        1.2062450647354126,
        1.1723445653915405,
        1.2225526571273804,
        1.0931217670440674,
        1.2113713026046753,
        1.1976624727249146,
        1.237122654914856,
        1.2295036315917969,
        1.2476097345352173,
        1.1320322751998901,
        1.0830365419387817,
        1.2152358293533325,
        1.2280551195144653,
        1.1178202629089355,
        1.128193974494934,
        1.2532598972320557,
        1.1998913288116455,
        1.1078565120697021,
        1.2551748752593994,
        1.2349915504455566,
        1.089562177658081,
        1.1907464265823364,
        1.2624558210372925,
        1.1492246389389038,
        1.2090147733688354,
        1.2692174911499023,
        1.232643485069275,
        1.2514655590057373,
        1.212339162826538,
        1.0877130031585693,
        1.2546072006225586,
        1.0669872760772705,
        1.2486677169799805,
        1.2078758478164673,
        1.2063311338424683,
        1.0978772640228271,
        1.19063138961792,
        1.2395033836364746,
        1.2537503242492676,
        1.2168768644332886,
        1.2356481552124023,
        1.15554940700531,
        1.0903775691986084,
        1.1765656471252441,
        1.2529268264770508,
        1.213860034942627,
        1.2345376014709473,
        1.2352648973464966,
        1.2078256607055664,
        1.123952031135559,
        1.2465554475784302,
        1.2468626499176025,
        1.1001015901565552,
        1.1846446990966797,
        1.1905640363693237,
        1.1785117387771606,
        1.1974819898605347,
        1.2389227151870728,
        1.0797438621520996,
        1.2323510646820068,
        1.1940542459487915,
        1.2003933191299438,
        1.2253321409225464,
        1.2249386310577393,
        1.2242393493652344,
        1.2201011180877686,
        1.177750587463379,
        1.2543306350708008,
        1.1043518781661987,
        1.1149625778198242,
        1.2344869375228882,
        1.2414331436157227,
        1.2356642484664917,
        1.1950691938400269,
        1.1275893449783325,
        1.2361974716186523,
        1.223785400390625,
        1.090186595916748,
        1.1035561561584473,
        1.2189459800720215,
        1.0911362171173096,
        1.1850929260253906,
        1.218056321144104,
        1.248117446899414,
        1.2302775382995605,
        1.225010871887207,
        1.1539901494979858,
        1.0968596935272217,
        1.1294721364974976,
        1.2240592241287231,
        1.1593230962753296,
        1.2120376825332642,
        1.2277108430862427,
        1.1988756656646729,
        1.2229156494140625,
        1.2301691770553589,
        1.2336022853851318,
        1.1603566408157349,
        1.0996333360671997,
        1.0919413566589355,
        1.1955708265304565,
        1.221733808517456,
        1.1973544359207153,
        1.0980644226074219,
        1.056357741355896,
        1.2288485765457153,
        1.1947327852249146,
        1.2310222387313843,
        1.0631705522537231,
        1.2243636846542358,
        1.0971065759658813,
        1.228702187538147,
        1.1682106256484985,
        1.2225104570388794,
        1.0727370977401733,
        1.0550479888916016,
        1.1800389289855957,
        1.1705925464630127,
        1.2282320261001587,
        1.196535587310791,
        1.1411948204040527,
        1.206124186515808,
        1.1207600831985474,
        1.2266814708709717,
        1.1548552513122559,
        1.2208788394927979,
        1.2204339504241943,
        1.179872989654541,
        1.071669340133667,
        1.0806947946548462,
        1.0736918449401855,
        1.0493850708007812,
        1.1836892366409302,
        1.1302696466445923,
        1.0888699293136597,
        1.2167749404907227,
        1.2256721258163452,
        1.2075128555297852,
        1.0569740533828735,
        1.078963279724121,
        1.2298904657363892,
        1.2250083684921265,
        1.2056028842926025,
        1.2142693996429443,
        1.2240376472473145,
        1.2141425609588623,
        1.057107925415039,
        1.0664693117141724,
        1.1703327894210815,
        1.2163845300674438,
        1.2022038698196411,
        1.088021159172058,
        1.1787453889846802,
        1.1070536375045776,
        1.1982804536819458,
        1.0260297060012817,
        1.105455756187439,
        1.0092636346817017,
        1.2096946239471436,
        1.2041761875152588,
        1.0589661598205566,
        1.1272169351577759,
        1.2037525177001953,
        1.0526238679885864,
        1.1990045309066772,
        1.1744871139526367,
        1.106695294380188,
        1.1986271142959595,
        1.0614616870880127,
        1.2095317840576172,
        1.1879280805587769,
        1.1568764448165894,
        1.1984586715698242,
        1.0711876153945923,
        1.1571545600891113,
        1.2168605327606201,
        1.1952266693115234,
        1.2129579782485962,
        1.0697021484375,
        1.1575524806976318,
        1.1919238567352295,
        1.1953632831573486,
        1.2118886709213257,
        1.1992824077606201,
        1.1957306861877441,
        1.1907280683517456,
        1.2069193124771118,
        1.0860216617584229,
        1.188018798828125,
        1.0535188913345337,
        1.207931399345398,
        1.2028888463974,
        1.1834524869918823,
        1.203338623046875,
        1.2100200653076172,
        1.1958558559417725,
        1.1779528856277466,
        1.1679235696792603,
        1.1994043588638306,
        1.1545530557632446,
        1.0529087781906128,
        1.1872754096984863,
        1.1892590522766113,
        1.1952815055847168,
        1.1917418241500854,
        1.1889113187789917,
        1.1907986402511597,
        1.1780539751052856,
        1.1817409992218018,
        1.2125279903411865,
        1.0947850942611694,
        1.1958932876586914,
        1.2070997953414917,
        1.0187537670135498,
        1.1362786293029785,
        1.190749168395996,
        1.0014277696609497,
        1.1921201944351196,
        1.2022671699523926,
        1.2006398439407349,
        1.0779200792312622,
        1.199026346206665,
        1.2057645320892334,
        1.1850322484970093,
        1.0191075801849365,
        1.1466808319091797,
        1.205983281135559,
        1.054768681526184,
        1.1921182870864868,
        1.068332552909851,
        1.1849521398544312,
        1.179253339767456,
        1.1309375762939453,
        1.1952507495880127,
        1.0680937767028809,
        1.1629494428634644,
        1.1938968896865845,
        1.1573232412338257,
        1.181748867034912,
        1.0571904182434082,
        1.1326831579208374,
        1.1696423292160034,
        1.1990034580230713,
        1.1342970132827759,
        1.1827932596206665,
        1.1503068208694458,
        1.1991342306137085,
        1.16155207157135,
        1.0489660501480103,
        1.1983985900878906,
        1.1912378072738647,
        1.1880252361297607,
        1.1853704452514648,
        1.1917591094970703,
        1.1900335550308228,
        1.189733624458313,
        1.1583917140960693,
        1.2005257606506348,
        1.1825155019760132,
        1.1831316947937012,
        1.1027336120605469,
        1.1887829303741455,
        1.1425557136535645,
        1.1968584060668945,
        1.1771525144577026,
        1.1844695806503296,
        1.1946145296096802,
        1.1615206003189087,
        1.1425762176513672,
        1.1961711645126343,
        1.18465256690979,
        1.1687846183776855,
        1.1612683534622192,
        1.1889491081237793,
        1.1724121570587158,
        1.1884018182754517,
        1.1525707244873047,
        1.0237563848495483,
        1.1794201135635376,
        1.1791058778762817,
        1.1102207899093628,
        1.1321884393692017,
        1.1786776781082153,
        1.1907134056091309,
        1.1854004859924316,
        1.1643086671829224,
        1.0747566223144531,
        1.169291377067566,
        1.1923800706863403,
        1.1792558431625366,
        1.0328425168991089,
        1.1387487649917603,
        1.1639732122421265,
        1.1857277154922485,
        1.1022058725357056,
        1.178597092628479,
        1.175042986869812,
        1.1405134201049805,
        1.1576114892959595,
        1.1281951665878296,
        1.176797866821289,
        1.1802695989608765,
        1.175620675086975,
        1.203700304031372,
        1.190093994140625,
        1.0777004957199097,
        1.1317692995071411,
        1.1759878396987915,
        1.1656208038330078,
        1.045296549797058,
        1.1767961978912354,
        1.176841139793396,
        1.0230259895324707,
        1.0331026315689087,
        1.151302695274353,
        1.1811922788619995,
        1.1710355281829834,
        1.1765226125717163,
        1.1217875480651855,
        1.1873024702072144,
        1.049404263496399,
        1.1747748851776123,
        1.1644424200057983,
        1.1122350692749023,
        1.0241886377334595,
        1.026963710784912,
        1.1230443716049194,
        1.178157091140747,
        1.033872127532959,
        1.1599671840667725,
        1.1575411558151245,
        1.1704778671264648,
        1.1465598344802856,
        1.148726463317871,
        1.171501636505127,
        1.0243499279022217,
        1.16023850440979,
        0.9853330850601196,
        1.1323950290679932,
        1.1822128295898438,
        1.1041892766952515,
        1.179164171218872,
        1.1581156253814697,
        1.1751036643981934,
        1.1255900859832764,
        1.179338812828064,
        1.165601134300232,
        1.1798169612884521,
        1.0480036735534668,
        1.1558177471160889,
        1.1671323776245117,
        1.163448452949524,
        1.173797845840454,
        1.1868925094604492,
        1.1512665748596191,
        1.1616922616958618,
        1.0419981479644775,
        1.0046510696411133,
        1.1653492450714111,
        1.156715750694275,
        1.1582227945327759,
        1.1624287366867065,
        1.1011319160461426,
        1.1744775772094727,
        1.1203583478927612,
        1.1715710163116455,
        1.1279417276382446,
        1.153861165046692,
        1.1079827547073364,
        1.1562540531158447,
        1.1595760583877563,
        1.0309367179870605,
        1.135192632675171,
        1.166941523551941,
        1.1722530126571655,
        1.0919241905212402,
        1.1672773361206055,
        1.0119866132736206,
        1.0516033172607422,
        1.1400737762451172,
        1.0758663415908813,
        1.1671271324157715,
        1.171451210975647,
        0.985968828201294,
        1.0496665239334106,
        1.035573124885559,
        1.1660746335983276,
        1.0220756530761719,
        1.1610029935836792,
        1.1469900608062744,
        0.993073582649231,
        1.1531790494918823,
        1.1684311628341675,
        1.1638505458831787,
        1.1101917028427124,
        1.1188491582870483,
        1.0932847261428833,
        1.1301883459091187,
        1.0269616842269897,
        1.0787522792816162,
        1.145632266998291,
        1.1758283376693726,
        1.0471776723861694,
        1.1335285902023315,
        1.1519664525985718,
        1.1699602603912354,
        1.1605854034423828,
        1.1130248308181763,
        1.0143839120864868,
        0.9906259775161743,
        1.1549047231674194,
        1.1622687578201294,
        1.0057729482650757,
        1.1495472192764282,
        1.143799901008606,
        1.159008264541626,
        1.1226863861083984,
        1.1577491760253906,
        1.1044567823410034,
        1.136492133140564,
        1.1518336534500122,
        1.1392221450805664,
        1.1243797540664673,
        1.0280643701553345,
        1.0914695262908936,
        1.137457013130188,
        1.152952790260315,
        1.145254135131836,
        1.1186796426773071,
        1.1459330320358276,
        0.9649060964584351,
        1.1481560468673706,
        1.0779286623001099,
        1.0326191186904907,
        1.135777235031128,
        1.1530550718307495,
        1.1090831756591797,
        1.1230595111846924,
        1.1453750133514404,
        1.1050643920898438,
        1.1091675758361816,
        0.9640856385231018,
        0.9749352931976318,
        1.1004971265792847,
        1.1255313158035278,
        0.9759359359741211,
        1.133877158164978,
        1.096163034439087,
        1.142317295074463,
        1.0587002038955688,
        1.133806824684143,
        1.107639193534851,
        1.116650104522705,
        0.9959099888801575,
        1.1482938528060913,
        1.1179497241973877,
        1.150839924812317,
        0.9817034006118774,
        1.1452399492263794,
        1.1337499618530273,
        1.1451281309127808,
        1.1324796676635742,
        1.147510051727295,
        1.1444807052612305,
        1.1394520998001099,
        1.0896261930465698,
        1.0940433740615845,
        0.978510320186615,
        1.1284908056259155,
        1.1383899450302124,
        1.146440029144287,
        0.9873816967010498,
        1.1309176683425903,
        1.1177470684051514,
        0.9926141500473022,
        1.0013655424118042,
        1.1452919244766235,
        1.1421705484390259,
        1.11971914768219,
        0.9827654361724854,
        0.9871067404747009,
        1.0155889987945557,
        1.1153696775436401,
        1.1427950859069824,
        0.9946568012237549,
        1.134568452835083,
        1.1387275457382202,
        1.0119938850402832,
        0.9859688878059387,
        1.1305270195007324,
        1.135210394859314,
        1.1167476177215576,
        1.1271002292633057,
        1.1497246026992798,
        1.0892306566238403,
        0.9822656512260437,
        1.115299940109253,
        1.118262767791748,
        1.1399215459823608,
        1.1203418970108032,
        0.9851922988891602,
        1.120102047920227,
        1.0889898538589478,
        1.1207408905029297,
        0.9868265390396118,
        0.9832472801208496,
        1.1215672492980957,
        0.9729433655738831,
        1.1329741477966309,
        1.008414626121521,
        1.144291639328003,
        1.1222288608551025,
        0.9406323432922363,
        1.0261234045028687,
        1.1202516555786133,
        1.1273224353790283,
        0.9977128505706787,
        1.123940348625183,
        1.1186597347259521,
        1.106327772140503,
        1.136728286743164,
        0.9385214447975159,
        1.1371207237243652,
        1.1262661218643188,
        0.9705687761306763,
        1.125300407409668,
        1.1198406219482422,
        1.1000169515609741,
        1.0026218891143799,
        1.1296355724334717,
        1.1264128684997559,
        1.1334327459335327,
        1.1159800291061401,
        1.136733889579773,
        1.0879809856414795,
        1.1168864965438843,
        1.003556251525879,
        0.967330276966095,
        0.9883217215538025,
        1.121734619140625,
        0.979367196559906,
        1.1140979528427124,
        1.0920486450195312,
        0.9684731960296631,
        1.1094022989273071,
        1.012272834777832,
        0.9663030505180359,
        1.0789828300476074,
        0.9010360240936279,
        1.127510666847229,
        1.1177700757980347,
        1.0324735641479492,
        1.0947887897491455,
        1.0994360446929932,
        1.0104337930679321,
        0.9342793822288513,
        1.0887269973754883,
        1.102148413658142,
        1.1246525049209595,
        1.0773582458496094,
        1.0982407331466675,
        1.1048930883407593,
        1.0358346700668335,
        1.0964550971984863,
        1.0105921030044556,
        1.1224751472473145,
        0.9583796262741089,
        0.9624698162078857,
        1.1153764724731445,
        1.0805819034576416,
        1.0967087745666504,
        1.0679833889007568,
        1.1132490634918213,
        1.0396780967712402,
        0.9743362069129944,
        1.1103284358978271,
        1.1042293310165405,
        1.055106282234192,
        1.1095634698867798,
        1.036214828491211,
        1.031025767326355,
        1.1210612058639526,
        1.0024240016937256,
        0.9231802821159363,
        1.109434723854065,
        1.02155339717865,
        1.109497308731079,
        1.0989762544631958,
        1.1142830848693848,
        1.1171293258666992,
        0.9620609283447266,
        0.948975145816803,
        1.1288548707962036,
        1.0785876512527466,
        1.1012818813323975,
        1.074789047241211,
        1.1032626628875732,
        0.9682894945144653,
        1.0491766929626465,
        1.1000604629516602,
        1.1047656536102295,
        1.1050447225570679,
        1.0062546730041504,
        1.1000205278396606,
        1.1003704071044922,
        0.9875191450119019,
        1.0205612182617188,
        1.1029623746871948,
        1.0906709432601929,
        1.0992563962936401,
        0.9335172772407532,
        0.9834781289100647,
        1.121842622756958,
        1.0747379064559937,
        0.9753627181053162,
        1.0978087186813354,
        0.9750479459762573,
        0.957943320274353,
        1.0945144891738892,
        1.0953857898712158,
        1.0817948579788208,
        1.063206672668457,
        1.0514566898345947,
        1.1042149066925049,
        1.0831259489059448,
        1.0558384656906128,
        1.0981849431991577,
        1.0963054895401,
        0.9800633788108826,
        1.0837414264678955,
        1.0468670129776,
        1.0429259538650513,
        0.9564316272735596,
        1.0948243141174316,
        1.0081806182861328,
        0.9283904433250427,
        0.9529995918273926,
        1.0836858749389648,
        1.0082234144210815,
        0.9350281953811646,
        0.9563978910446167,
        1.0307623147964478,
        1.069358229637146,
        0.9524369835853577,
        0.9566962718963623,
        1.008478045463562,
        1.055048942565918,
        1.094915509223938,
        1.078532338142395,
        0.9558215737342834,
        0.930993378162384,
        0.9005333781242371,
        1.0660595893859863,
        1.0570096969604492,
        1.0284430980682373,
        1.082491159439087,
        1.0725109577178955,
        1.0087484121322632,
        1.054070234298706,
        1.0885342359542847,
        1.0294708013534546,
        1.0641577243804932,
        0.9800817966461182,
        0.9937334656715393,
        1.0319260358810425,
        0.9093202948570251,
        1.0888725519180298,
        1.068576693534851,
        1.0677924156188965,
        1.0285571813583374,
        0.9624214768409729,
        1.0678960084915161,
        1.0172553062438965,
        0.9955650568008423,
        1.0639684200286865,
        1.0689365863800049,
        1.0634658336639404,
        0.8782180547714233,
        1.0394500494003296,
        1.0012540817260742,
        0.9441337585449219,
        1.0018495321273804,
        0.9090403914451599,
        1.0512686967849731,
        1.0255262851715088,
        0.9519364237785339,
        0.8979612588882446,
        1.042475938796997,
        1.0700587034225464,
        1.0464922189712524,
        0.9663622379302979,
        1.0699535608291626,
        1.0463947057724,
        0.9576761722564697,
        1.0698026418685913,
        1.0118662118911743,
        1.034813404083252,
        0.8909680247306824,
        1.040953278541565,
        0.9292681813240051,
        0.9530918002128601,
        0.9295808672904968,
        0.9662724137306213,
        0.9747262001037598,
        1.0709569454193115,
        1.0461184978485107,
        1.0785019397735596,
        0.9795240759849548,
        1.073562741279602,
        0.9175859689712524,
        1.0809643268585205,
        1.0497686862945557,
        0.9625552892684937,
        0.9513723850250244,
        0.9897539615631104,
        0.922927975654602,
        0.9258139133453369,
        1.0452654361724854,
        0.9151142239570618,
        1.0688050985336304,
        0.9030557870864868,
        1.0742820501327515,
        0.9862285852432251,
        1.0587760210037231,
        1.069083571434021,
        0.9197292923927307,
        1.049547791481018,
        0.9229375123977661,
        1.0569136142730713,
        0.9409464597702026,
        1.0280052423477173,
        0.9858026504516602,
        1.0536420345306396,
        1.013289213180542,
        0.9131650328636169,
        0.9467681050300598,
        0.946113109588623,
        0.9459665417671204,
        1.0193346738815308,
        0.951883852481842,
        0.9341822266578674,
        0.9317596554756165,
        0.97740238904953,
        0.9240862727165222,
        1.0347851514816284,
        0.8873233199119568,
        1.0600076913833618,
        1.0374516248703003,
        1.0443997383117676,
        1.020276427268982,
        0.9072863459587097,
        0.9081463813781738,
        1.0654164552688599,
        1.0480014085769653,
        1.027490258216858,
        1.0404528379440308,
        1.0316816568374634,
        1.031555414199829,
        0.8821114301681519,
        0.8835194706916809,
        0.9869952201843262,
        1.0204895734786987,
        0.920017421245575,
        0.913222074508667,
        1.0238103866577148,
        0.9179943203926086,
        0.9180027842521667,
        1.0380913019180298,
        0.9132793545722961,
        1.0154376029968262,
        0.9818851947784424,
        0.9802341461181641,
        0.9337406158447266,
        1.027910828590393,
        1.018502950668335,
        0.902969241142273,
        1.02517569065094,
        0.9730646014213562,
        1.0239551067352295,
        0.9281362891197205,
        0.9425721168518066,
        0.8728773593902588,
        0.9155990481376648,
        0.9801538586616516,
        0.9985922574996948,
        1.0109543800354004,
        0.8837098479270935,
        1.0438742637634277,
        0.9750678539276123,
        1.0103144645690918,
        1.0272735357284546,
        0.9100490212440491,
        1.0168157815933228,
        0.8688470721244812,
        0.8868395686149597,
        1.0189094543457031,
        1.0082374811172485,
        0.9469760656356812,
        0.9737503528594971,
        0.8954424858093262,
        0.967873752117157,
        0.8727887272834778,
        1.0318533182144165,
        1.0078233480453491,
        1.0208953619003296,
        0.8405615091323853,
        0.9920239448547363,
        0.9263426065444946,
        0.9391903281211853,
        1.0174570083618164,
        0.8912100195884705,
        0.92989182472229,
        1.0241436958312988,
        0.8599686026573181,
        1.0355510711669922,
        0.8538941740989685,
        1.0168569087982178,
        1.0250006914138794,
        1.0012377500534058,
        0.9305962324142456,
        0.9854272603988647,
        0.9024954438209534,
        1.0252183675765991,
        1.0011903047561646,
        1.0107210874557495,
        0.9620481133460999,
        0.9839088916778564,
        0.85435950756073,
        1.0233193635940552,
        0.9455997347831726,
        1.0298573970794678,
        0.8898757100105286,
        1.011348009109497,
        0.8637504577636719,
        0.8472127318382263,
        0.915844738483429,
        0.9968040585517883,
        0.9677344560623169,
        0.8639816641807556,
        0.8727797269821167,
        0.8871393203735352,
        1.0158636569976807,
        0.8724313378334045,
        0.8635502457618713,
        1.0190515518188477,
        0.976607620716095,
        0.9671609401702881,
        0.8989498019218445,
        1.0043210983276367,
        1.0053125619888306,
        1.00604248046875,
        0.8837672472000122,
        0.9490073919296265,
        0.8997275233268738,
        0.820976734161377,
        1.0069316625595093,
        0.8687458038330078,
        0.8400711417198181,
        0.8690162897109985,
        0.9463059306144714,
        0.8254046440124512,
        0.9849591851234436,
        0.8870182037353516,
        0.8958858251571655,
        1.0119694471359253,
        0.8493912220001221,
        0.8982181549072266,
        0.8504170179367065,
        0.8803796768188477,
        0.9479750990867615,
        0.8429681062698364,
        0.9937413334846497,
        0.919076144695282,
        0.8271293640136719,
        0.8746539950370789,
        0.8439966440200806,
        0.9910218715667725,
        0.9311020374298096,
        0.8500591516494751,
        0.9526014924049377,
        0.9940047860145569,
        0.8501139283180237,
        0.8447129726409912,
        0.9794431924819946,
        0.8882152438163757,
        0.8332228064537048,
        0.9500976204872131,
        0.9282918572425842,
        0.892495334148407,
        0.9204341769218445,
        0.9966140985488892,
        0.9589501619338989,
        0.8640581369400024,
        0.8610247373580933,
        0.8915632963180542,
        0.8718301653862,
        0.8564714789390564,
        0.9350913166999817,
        0.9611055254936218,
        0.8447154760360718,
        0.8110014796257019,
        0.855255126953125,
        0.8494259119033813,
        0.884172260761261,
        0.8996610045433044,
        0.828639566898346,
        0.8113643527030945,
        0.8556378483772278,
        0.9317662715911865,
        0.8552258014678955,
        0.8452126979827881,
        0.9313599467277527,
        0.9222010970115662,
        0.9518337845802307,
        0.936387300491333,
        0.9843965172767639,
        0.9642720818519592,
        0.9267959594726562,
        0.916862428188324,
        0.8582351207733154,
        0.8449963927268982,
        0.8285864591598511,
        0.8227742910385132,
        0.9014539122581482,
        0.8314803242683411,
        0.8434207439422607,
        0.8454612493515015,
        0.9264814257621765,
        0.86343914270401,
        0.8301122188568115,
        0.925154447555542,
        0.9517751932144165,
        0.8005425333976746,
        0.8897857666015625,
        0.9227707982063293,
        0.9578496217727661,
        0.9510502219200134,
        0.897775411605835,
        0.9378041625022888,
        0.962593138217926,
        0.9290609359741211,
        0.9350257515907288,
        0.8296931385993958,
        0.9192726612091064,
        0.8948748707771301,
        0.8373578786849976,
        0.9307125806808472,
        0.8458373546600342,
        0.856212854385376,
        0.9162381887435913,
        0.9613977670669556,
        0.8398435115814209,
        0.9422678351402283,
        0.8489946722984314,
        0.9202478528022766,
        0.8174431324005127,
        0.8143274784088135,
        0.8458726406097412,
        0.7827231287956238,
        0.9491945505142212,
        0.9571070671081543,
        0.9305158853530884,
        0.8012537956237793,
        0.9591124057769775,
        0.8329228162765503,
        0.8374326825141907,
        0.8133653998374939,
        0.8522771000862122,
        0.9460849761962891,
        0.9081375002861023,
        0.8292281031608582,
        0.9398912787437439,
        0.920042872428894,
        0.8262803554534912,
        0.8036825656890869,
        0.9338225722312927,
        0.9212005138397217,
        0.8901872634887695,
        0.9494260549545288,
        0.9335743188858032,
        0.8017702698707581,
        0.9502619504928589,
        0.940127432346344,
        0.8911817073822021,
        0.9496896862983704,
        0.7637444138526917,
        0.8119314908981323,
        0.9067831635475159,
        0.920769989490509,
        0.8940184116363525,
        0.7923188805580139,
        0.9393174052238464,
        0.930305540561676,
        0.8567549586296082,
        0.8907511830329895,
        0.8486515879631042,
        0.9420792460441589,
        0.8109658360481262,
        0.9120941162109375,
        0.8384321331977844,
        0.8776267766952515,
        0.7503916621208191,
        0.8270852565765381,
        0.8424370884895325,
        0.8382468223571777,
        0.8965209126472473,
        0.828249454498291,
        0.8054947853088379,
        0.8652626276016235,
        0.9307703375816345,
        0.8982267379760742,
        0.7782266736030579,
        0.7785547971725464,
        0.9254149794578552,
        0.772520124912262,
        0.8558874130249023,
        0.8965463042259216,
        0.7909259796142578,
        0.8523042798042297,
        0.8109164834022522,
        0.8980962038040161,
        0.8675050735473633,
        0.8560048341751099,
        0.7558450698852539,
        0.8841363191604614,
        0.9144613742828369,
        0.8827663064002991,
        0.9025338888168335,
        0.8431012034416199,
        0.8040807247161865,
        0.7787522673606873,
        0.8957993984222412,
        0.7585450410842896,
        0.7592924237251282,
        0.7894625067710876,
        0.7682927846908569,
        0.801673173904419,
        0.7836490869522095,
        0.7523919343948364,
        0.8554658889770508,
        0.8402796983718872,
        0.7874593734741211,
        0.8089190721511841,
        0.8783340454101562,
        0.8921492695808411,
        0.7205212712287903,
        0.7718638777732849,
        0.7726788520812988,
        0.753980278968811,
        0.8543859124183655,
        0.7870007157325745,
        0.9022106528282166,
        0.9055533409118652,
        0.8185797929763794,
        0.8867204189300537,
        0.9013040065765381,
        0.7419424057006836,
        0.7355884909629822,
        0.7909740805625916,
        0.8996239900588989,
        0.8972359895706177,
        0.7370012402534485,
        0.8734349012374878,
        0.8800142407417297,
        0.8810389041900635,
        0.8104677200317383,
        0.8591381907463074,
        0.7536727786064148,
        0.7966225743293762,
        0.8731204271316528,
        0.8169780373573303,
        0.7592861652374268,
        0.8415895700454712,
        0.8234654068946838,
        0.8778799772262573,
        0.7801960110664368,
        0.7601273059844971,
        0.7664221525192261,
        0.6864020824432373,
        0.8123948574066162,
        0.7309934496879578,
        0.8865335583686829,
        0.7923666834831238,
        0.8036372065544128,
        0.8525629639625549,
        0.8270341753959656,
        0.7667193412780762,
        0.734136700630188,
        0.7767615914344788,
        0.803993284702301,
        0.8348063230514526,
        0.8806473612785339,
        0.7342664003372192,
        0.7325536608695984,
        0.7792655825614929,
        0.7334412932395935,
        0.8780993819236755,
        0.8104993104934692,
        0.7767102718353271,
        0.7708902359008789,
        0.8852425217628479,
        0.7800727486610413,
        0.7732203602790833,
        0.8715652823448181,
        0.7162742614746094,
        0.7232621312141418,
        0.845838189125061,
        0.811246931552887,
        0.7752441763877869,
        0.7472816705703735,
        0.7448670268058777,
        0.8612253069877625,
        0.7726945281028748,
        0.7539374828338623,
        0.8592032194137573,
        0.766973078250885,
        0.7615524530410767,
        0.761292576789856,
        0.770287811756134,
        0.7549378871917725,
        0.7717876434326172,
        0.8727355599403381,
        0.7666502594947815,
        0.7229936122894287,
        0.705272912979126,
        0.765878438949585,
        0.754777729511261,
        0.7545254230499268,
        0.76683109998703,
        0.7983548045158386,
        0.7061781883239746,
        0.7702432870864868,
        0.8671795129776001,
        0.7573598027229309,
        0.7487508058547974,
        0.7395496964454651,
        0.8554285168647766,
        0.8442878723144531,
        0.7583905458450317,
        0.7698270678520203,
        0.6983097195625305,
        0.7492637634277344,
        0.7354798316955566,
        0.8387401103973389,
        0.6991390585899353,
        0.7026299834251404,
        0.7649202942848206,
        0.7678045034408569,
        0.7718925476074219,
        0.7091394066810608,
        0.7864571809768677,
        0.741467297077179,
        0.7538782358169556,
        0.7791029214859009,
        0.8127411007881165,
        0.6962209939956665,
        0.7548636794090271,
        0.7389796376228333,
        0.7460992932319641,
        0.7482904195785522,
        0.7988054752349854,
        0.7119256258010864,
        0.7145258784294128,
        0.7406594753265381,
        0.7110573053359985,
        0.7517556548118591,
        0.7392793297767639,
        0.7196577787399292,
        0.8184692859649658,
        0.7243250608444214,
        0.7859355211257935,
        0.6962649822235107,
        0.776419460773468,
        0.7419624924659729,
        0.7374577522277832,
        0.7890136241912842,
        0.7198161482810974,
        0.7079848647117615,
        0.7961320281028748,
        0.7090858817100525,
        0.7381539940834045,
        0.7041327953338623,
        0.7177786827087402,
        0.6856396198272705,
        0.7573803663253784,
        0.8146419525146484,
        0.7103639841079712,
        0.7254306674003601,
        0.8550611734390259,
        0.7167593836784363,
        0.7435284852981567,
        0.8429642915725708,
        0.8286202549934387,
        0.832310676574707,
        0.693308413028717,
        0.815001368522644,
        0.7200495004653931,
        0.7172203063964844,
        0.6799546480178833,
        0.7189743518829346,
        0.7182241678237915,
        0.7255415320396423,
        0.7227526903152466,
        0.7246763706207275,
        0.7010940909385681,
        0.7175078988075256,
        0.7485328912734985,
        0.7019504904747009,
        0.7081368565559387,
        0.7084609270095825,
        0.7639041543006897,
        0.6605146527290344,
        0.7187256813049316,
        0.7436873912811279,
        0.7774537801742554,
        0.6918690204620361,
        0.6964383125305176,
        0.691411018371582,
        0.6848939061164856,
        0.7732831835746765,
        0.8302586078643799,
        0.7147147059440613,
        0.7062473297119141,
        0.7774466276168823,
        0.7168728113174438,
        0.702097475528717,
        0.7280791401863098,
        0.7207447290420532,
        0.6913895010948181,
        0.7036200761795044,
        0.7300775647163391,
        0.754236102104187,
        0.7541916966438293,
        0.7825217247009277,
        0.7239429950714111,
        0.7645135521888733,
        0.6615654230117798,
        0.7821983695030212,
        0.8066179156303406,
        0.6950017213821411,
        0.6556323766708374,
        0.6917033195495605,
        0.7148041129112244,
        0.6887248158454895,
        0.7348601222038269,
        0.7562872767448425,
        0.6891000866889954,
        0.7112753987312317,
        0.7809779047966003,
        0.7989771962165833,
        0.7473962903022766,
        0.6996743679046631,
        0.65287846326828,
        0.6937058568000793,
        0.6848939657211304,
        0.7043304443359375,
        0.6986246705055237,
        0.7907253503799438,
        0.667755126953125,
        0.6602961421012878,
        0.6860957741737366,
        0.6995298266410828,
        0.7420347929000854,
        0.7214804887771606,
        0.7759613990783691,
        0.6747040152549744,
        0.7027295231819153,
        0.7566041350364685,
        0.7419002652168274,
        0.6813479661941528,
        0.6871843934059143,
        0.6332404613494873,
        0.7700892686843872,
        0.7430264353752136,
        0.6467801928520203,
        0.7242320775985718,
        0.6573962569236755,
        0.6903500556945801,
        0.7607333064079285,
        0.6715043187141418,
        0.7232466340065002,
        0.7646385431289673,
        0.7326505780220032,
        0.6697040796279907,
        0.7430418729782104,
        0.7317820191383362,
        0.6231399178504944,
        0.6768702864646912,
        0.6439958810806274,
        0.6437780857086182,
        0.7448066473007202,
        0.717521607875824,
        0.647263765335083,
        0.7999482154846191,
        0.745516836643219,
        0.7281767725944519,
        0.6453863978385925,
        0.6809152364730835,
        0.6400670409202576,
        0.7264629602432251,
        0.6811364889144897,
        0.6684298515319824,
        0.7007139921188354,
        0.6969399452209473,
        0.7114391922950745,
        0.674440860748291,
        0.6674365401268005,
        0.6888453960418701,
        0.7158665657043457,
        0.6613972783088684,
        0.6511974930763245,
        0.7348510026931763,
        0.6491858959197998,
        0.6513129472732544,
        0.702728807926178,
        0.71229088306427,
        0.6285796165466309,
        0.6857813596725464,
        0.6927142143249512,
        0.6334956288337708,
        0.7103946805000305,
        0.7266026735305786,
        0.6455896496772766,
        0.6188291311264038,
        0.6754180788993835,
        0.7110846638679504,
        0.7373227477073669,
        0.631086528301239,
        0.7475161552429199,
        0.7211065292358398,
        0.6334128975868225,
        0.6162155270576477,
        0.6505827903747559,
        0.6983698606491089,
        0.6638948917388916,
        0.6897278428077698,
        0.5978781580924988,
        0.7269688844680786,
        0.606031060218811,
        0.606884777545929,
        0.6205899119377136,
        0.5948737859725952,
        0.7389634847640991,
        0.6738274693489075,
        0.7107300162315369,
        0.6307592988014221,
        0.620180606842041,
        0.6013003587722778,
        0.6031513810157776,
        0.6722453236579895,
        0.6409377455711365,
        0.6255468130111694,
        0.6928088068962097,
        0.6247919797897339,
        0.6356825828552246,
        0.7003944516181946,
        0.6981515288352966,
        0.669387698173523,
        0.6348744034767151,
        0.6354461908340454,
        0.5662512183189392,
        0.5977997183799744,
        0.5650889873504639,
        0.6267618536949158,
        0.6048591136932373,
        0.5728678107261658,
        0.6678267121315002,
        0.6528980135917664,
        0.6216469407081604,
        0.5860735774040222,
        0.5825715661048889,
        0.6103880405426025,
        0.5827686786651611,
        0.6186334490776062,
        0.6497775316238403,
        0.6050043106079102,
        0.6235384941101074,
        0.6314773559570312,
        0.6885012984275818,
        0.6233319640159607,
        0.575385570526123,
        0.6734258532524109,
        0.6520958542823792,
        0.6522260308265686,
        0.6059614419937134,
        0.6107344031333923,
        0.6496594548225403,
        0.5690159201622009,
        0.5487253665924072,
        0.6313885450363159,
        0.6352086663246155,
        0.580333411693573,
        0.6566542387008667,
        0.6246128678321838,
        0.6313026547431946,
        0.5644974708557129,
        0.5922359228134155,
        0.5619637966156006,
        0.6790513396263123,
        0.6012740731239319,
        0.6285610198974609,
        0.6119714975357056,
        0.5528059005737305,
        0.6221886277198792,
        0.6246315836906433,
        0.5788081884384155,
        0.5564852952957153,
        0.6247991323471069,
        0.602034866809845,
        0.5237146019935608,
        0.6665895581245422,
        0.6022096872329712,
        0.5594105124473572,
        0.5959323644638062,
        0.6749975681304932,
        0.6221638321876526,
        0.5719608068466187,
        0.5458425283432007,
        0.6844066977500916,
        0.5444692373275757,
        0.6250458359718323,
        0.5943912863731384,
        0.6145687699317932,
        0.6210163831710815,
        0.5552148222923279,
        0.6207475066184998,
        0.606743335723877,
        0.606696605682373,
        0.6381829977035522,
        0.5997846722602844,
        0.5511320233345032,
        0.6072343587875366,
        0.6534520983695984,
        0.557738184928894,
        0.632503867149353,
        0.6564306020736694,
        0.5446988940238953,
        0.6323027610778809,
        0.5540345907211304,
        0.6149275898933411,
        0.5474176406860352,
        0.5770900249481201,
        0.5702200531959534,
        0.5072343349456787,
        0.5172397494316101,
        0.6135402917861938,
        0.5125280618667603,
        0.6662176251411438,
        0.6274704933166504,
        0.5697958469390869,
        0.6068283319473267,
        0.528702974319458,
        0.5614316463470459,
        0.5393884181976318,
        0.575057327747345,
        0.5785020589828491,
        0.6011620759963989,
        0.6241350173950195,
        0.5854507088661194,
        0.5250823497772217,
        0.5352045297622681,
        0.5649247765541077,
        0.555829644203186,
        0.6011641621589661,
        0.5007113218307495,
        0.539544403553009,
        0.5158352851867676,
        0.5311198234558105,
        0.527441680431366,
        0.5330618023872375,
        0.5567236542701721,
        0.5191874504089355,
        0.5971658229827881,
        0.5822790265083313,
        0.569651186466217,
        0.6036162376403809,
        0.5371931791305542,
        0.5992427468299866,
        0.5655907988548279,
        0.5447478294372559,
        0.5760552883148193,
        0.5149466395378113,
        0.5402858853340149,
        0.5395763516426086,
        0.5833674073219299,
        0.5070541501045227,
        0.632515013217926,
        0.5760861039161682,
        0.5158973932266235,
        0.5513031482696533,
        0.5180634260177612,
        0.5720318555831909,
        0.5394281148910522,
        0.533011257648468,
        0.5201427340507507,
        0.5332661867141724,
        0.5478968620300293,
        0.5930200815200806,
        0.533737063407898,
        0.5557761788368225,
        0.5277510285377502,
        0.5196303129196167,
        0.5406095385551453,
        0.5382148027420044,
        0.5800080895423889,
        0.538175106048584,
        0.6210843920707703,
        0.5463076233863831,
        0.49939143657684326,
        0.5809449553489685,
        0.5904757380485535,
        0.5761600136756897,
        0.5001587271690369,
        0.4797217845916748,
        0.50412517786026,
        0.6677597761154175,
        0.5690260529518127,
        0.5478506684303284,
        0.4966847002506256,
        0.5292768478393555,
        0.5076926946640015,
        0.5238463282585144,
        0.5788424015045166,
        0.5419571995735168,
        0.5073803067207336,
        0.5327358841896057,
        0.5565744638442993,
        0.5942572951316833,
        0.4903438985347748,
        0.49290308356285095,
        0.5255491137504578,
        0.48967060446739197,
        0.5834514498710632,
        0.5842073559761047,
        0.5240552425384521,
        0.5085474848747253,
        0.49081459641456604,
        0.4911341369152069,
        0.5301104187965393,
        0.5261722207069397,
        0.5608603954315186,
        0.561619222164154,
        0.5149317383766174,
        0.5959434509277344,
        0.570534884929657,
        0.5184457302093506,
        0.5216928720474243,
        0.5240052938461304,
        0.473544716835022,
        0.47872763872146606,
        0.5561057925224304,
        0.5685768127441406,
        0.48346489667892456,
        0.4908773899078369,
        0.541144073009491,
        0.5143737196922302,
        0.5008187890052795,
        0.5235410332679749,
        0.5628789067268372,
        0.5954560041427612,
        0.5446491837501526,
        0.45771324634552,
        0.4701850414276123,
        0.5215325355529785,
        0.46970266103744507,
        0.5465511679649353,
        0.4665531516075134,
        0.48123300075531006,
        0.4906392991542816,
        0.45538052916526794,
        0.4945570230484009,
        0.48590993881225586,
        0.4939050078392029,
        0.47009968757629395,
        0.5470137000083923,
        0.4902946650981903,
        0.5416625142097473,
        0.5295582413673401,
        0.5935257077217102,
        0.491180419921875,
        0.548139750957489,
        0.49983325600624084,
        0.5121439099311829,
        0.5529789924621582,
        0.5414086580276489,
        0.5143166780471802,
        0.5500194430351257,
        0.4489782154560089,
        0.47045931220054626,
        0.44401583075523376,
        0.43986937403678894,
        0.5396550297737122,
        0.5562862157821655,
        0.45815518498420715,
        0.4677300453186035,
        0.454585462808609,
        0.4582770764827728,
        0.5373542904853821,
        0.44007954001426697,
        0.39517727494239807,
        0.4451499581336975,
        0.5265974402427673,
        0.4815033972263336,
        0.4850197434425354,
        0.5148816108703613,
        0.46526482701301575,
        0.5083203315734863,
        0.45059934258461,
        0.4500729739665985,
        0.45821914076805115,
        0.4970090687274933,
        0.49239084124565125,
        0.4398093521595001,
        0.4776056706905365,
        0.4866880178451538,
        0.42730483412742615,
        0.47494715452194214,
        0.4737154543399811,
        0.4539340138435364,
        0.45461034774780273,
        0.44100770354270935,
        0.42018646001815796,
        0.45673251152038574,
        0.48866498470306396,
        0.427280068397522,
        0.4513207674026489,
        0.46929195523262024,
        0.4512074887752533,
        0.4414518177509308,
        0.46880391240119934,
        0.4740259051322937,
        0.47375524044036865,
        0.493254154920578,
        0.4818563461303711,
        0.4629134237766266,
        0.45361998677253723,
        0.45690810680389404,
        0.5244649052619934,
        0.5319644212722778,
        0.5098394751548767,
        0.4247623085975647,
        0.4948559105396271,
        0.5258174538612366,
        0.4716556966304779,
        0.4750465750694275,
        0.514024555683136,
        0.4749419689178467,
        0.5074747800827026,
        0.43217557668685913,
        0.4557833671569824,
        0.503920316696167,
        0.5024510025978088,
        0.47306376695632935,
        0.43048250675201416,
        0.44955581426620483,
        0.44391506910324097,
        0.455637127161026,
        0.48794710636138916,
        0.47141703963279724,
        0.4610743522644043,
        0.4411384165287018,
        0.41324207186698914,
        0.3855516016483307,
        0.39289242029190063,
        0.44287654757499695,
        0.5416024923324585,
        0.449499249458313,
        0.42274540662765503,
        0.4244576692581177,
        0.4432515501976013,
        0.4779208302497864,
        0.4146137833595276,
        0.4525667130947113,
        0.48528826236724854,
        0.45149287581443787,
        0.5041615962982178,
        0.47952744364738464,
        0.46934378147125244,
        0.38049691915512085,
        0.3800869286060333,
        0.4378259479999542,
        0.3881871998310089,
        0.42844873666763306,
        0.46839481592178345,
        0.39025935530662537,
        0.42499980330467224,
        0.44205039739608765,
        0.39187929034233093,
        0.5355995297431946,
        0.4046388566493988,
        0.42317795753479004,
        0.4319289028644562,
        0.4389458894729614,
        0.4132201671600342,
        0.4517621397972107,
        0.4399960935115814,
        0.4121943712234497,
        0.4047144949436188,
        0.3963027596473694,
        0.3842436671257019,
        0.40300795435905457,
        0.47167277336120605,
        0.41240376234054565,
        0.40834206342697144,
        0.517334520816803,
        0.4690003991127014,
        0.445420503616333,
        0.3707733750343323,
        0.38868391513824463,
        0.42252618074417114,
        0.4131292402744293,
        0.4423424005508423,
        0.3982868492603302,
        0.4452652931213379,
        0.3297981023788452,
        0.4023476541042328,
        0.3968168795108795,
        0.38484320044517517,
        0.3927803635597229,
        0.4265037477016449,
        0.3991873860359192,
        0.4251321852207184,
        0.39602914452552795,
        0.39564386010169983,
        0.4166388213634491,
        0.3732064366340637,
        0.39089393615722656,
        0.3980175256729126,
        0.4165181815624237,
        0.39358532428741455,
        0.4147813022136688,
        0.33783841133117676,
        0.3922103941440582,
        0.4264758825302124,
        0.45179763436317444,
        0.4666208028793335,
        0.405855655670166,
        0.3724251985549927,
        0.40616971254348755,
        0.39584794640541077,
        0.4454590380191803,
        0.4177080988883972,
        0.3806668817996979,
        0.3678968846797943,
        0.39386680722236633,
        0.39659878611564636,
        0.4696003794670105,
        0.3565520942211151,
        0.3600894510746002,
        0.4111185371875763,
        0.3940676152706146,
        0.390298992395401,
        0.3840007185935974,
        0.34020814299583435,
        0.3515135943889618,
        0.4273760914802551,
        0.3642263412475586,
        0.37874796986579895,
        0.4134826362133026,
        0.3531316816806793,
        0.3757028579711914,
        0.38264235854148865,
        0.3631896376609802,
        0.3804072141647339,
        0.40301480889320374,
        0.3542621433734894,
        0.3551967442035675,
        0.3627355396747589,
        0.37914538383483887,
        0.4020272493362427,
        0.4368732273578644,
        0.335394948720932,
        0.3286953270435333,
        0.37923282384872437,
        0.34032052755355835,
        0.3550827205181122,
        0.33521342277526855,
        0.4646705687046051,
        0.39438125491142273,
        0.3955852687358856,
        0.4006270170211792,
        0.31367307901382446,
        0.4244413375854492,
        0.3519168794155121,
        0.3625975549221039,
        0.3943813443183899,
        0.3756800591945648,
        0.43697625398635864,
        0.32645201683044434,
        0.39114058017730713,
        0.3141404092311859,
        0.41129958629608154,
        0.2980746328830719,
        0.34103161096572876,
        0.28552305698394775,
        0.3311701714992523,
        0.35414960980415344,
        0.39011406898498535,
        0.34902364015579224,
        0.33302387595176697,
        0.36296921968460083,
        0.3920239210128784,
        0.35154739022254944,
        0.4237344264984131,
        0.3278433084487915,
        0.3216089606285095,
        0.3725849688053131,
        0.34556660056114197,
        0.31832897663116455,
        0.30180472135543823,
        0.3503110110759735,
        0.3157089650630951,
        0.3167112171649933,
        0.3266390264034271,
        0.30907881259918213,
        0.3421275019645691,
        0.32002902030944824,
        0.37820494174957275,
        0.27605995535850525,
        0.3218420445919037,
        0.2890003025531769,
        0.29087838530540466,
        0.3050853908061981,
        0.32678884267807007,
        0.27690398693084717,
        0.35266321897506714,
        0.31191545724868774,
        0.30346792936325073,
        0.32008302211761475,
        0.32107290625572205,
        0.3216676414012909,
        0.31274348497390747,
        0.2888086438179016,
        0.3551999628543854,
        0.30717194080352783,
        0.28050172328948975,
        0.3045423626899719,
        0.3542458117008209,
        0.26932936906814575,
        0.3052155077457428,
        0.3985130190849304,
        0.29731613397598267,
        0.28209349513053894,
        0.26556557416915894,
        0.3097626566886902,
        0.31754833459854126,
        0.2891963720321655,
        0.29022783041000366,
        0.36541980504989624,
        0.250631183385849,
        0.31064891815185547,
        0.32523074746131897,
        0.2766626477241516,
        0.3208194971084595,
        0.2628495991230011,
        0.37186869978904724,
        0.3439124822616577,
        0.271816223859787,
        0.3349156379699707,
        0.29811397194862366,
        0.28030887246131897,
        0.3122861385345459,
        0.29868370294570923,
        0.31174927949905396,
        0.26077136397361755,
        0.21074169874191284,
        0.352603942155838,
        0.2550802230834961,
        0.2960878908634186,
        0.32614028453826904,
        0.2898387014865875,
        0.31285566091537476,
        0.28731268644332886,
        0.3194165527820587,
        0.23561401665210724,
        0.2679031491279602,
        0.2613469660282135,
        0.29836657643318176,
        0.26972368359565735,
        0.27607375383377075,
        0.32188114523887634,
        0.28083181381225586,
        0.30723175406455994,
        0.2658742070198059,
        0.2424905151128769,
        0.23350588977336884,
        0.2841072678565979,
        0.2700144052505493,
        0.33965572714805603,
        0.2482929825782776,
        0.25974538922309875,
        0.26982858777046204,
        0.29915112257003784,
        0.30168962478637695,
        0.2955796718597412,
        0.29076600074768066,
        0.23322679102420807,
        0.23375946283340454,
        0.2203759104013443,
        0.23504844307899475,
        0.23795944452285767,
        0.30910590291023254,
        0.26625046133995056,
        0.25191131234169006,
        0.2670433819293976,
        0.22464340925216675,
        0.2783360481262207,
        0.24732349812984467,
        0.24777346849441528,
        0.2653990685939789,
        0.23671233654022217,
        0.22868898510932922,
        0.25607335567474365,
        0.24136829376220703,
        0.29113540053367615,
        0.2647770345211029,
        0.26491057872772217,
        0.22265613079071045,
        0.26977455615997314,
        0.2620386779308319,
        0.2158057987689972,
        0.28729403018951416,
        0.2276255488395691,
        0.21661974489688873,
        0.24820826947689056,
        0.25085315108299255,
        0.29075178503990173,
        0.28496819734573364,
        0.3061057925224304,
        0.22774043679237366,
        0.24120573699474335,
        0.2658030390739441,
        0.20670852065086365,
        0.24029776453971863,
        0.2941476106643677,
        0.21619459986686707,
        0.2917932868003845,
        0.24374429881572723,
        0.24328318238258362,
        0.21464258432388306,
        0.21688055992126465,
        0.23459775745868683,
        0.25097042322158813,
        0.2620718777179718,
        0.28333747386932373,
        0.2087547481060028,
        0.19378048181533813,
        0.23369158804416656,
        0.20159897208213806,
        0.22713136672973633,
        0.21195866167545319,
        0.20895731449127197,
        0.2574167549610138,
        0.22925437986850739,
        0.2140805572271347,
        0.2020867019891739,
        0.20139619708061218,
        0.2613970637321472,
        0.2249690294265747,
        0.24640227854251862,
        0.2328823059797287,
        0.18966883420944214,
        0.20037588477134705,
        0.22444291412830353,
        0.17534703016281128,
        0.1790027618408203,
        0.2764054834842682,
        0.25471022725105286,
        0.23053744435310364,
        0.2134697586297989,
        0.18134243786334991,
        0.26393213868141174,
        0.21633782982826233,
        0.21320763230323792,
        0.21567262709140778,
        0.2158413827419281,
        0.29075857996940613,
        0.1839943677186966,
        0.242263063788414,
        0.21867972612380981,
        0.20581315457820892,
        0.21944688260555267,
        0.19713543355464935,
        0.20879435539245605,
        0.2150188535451889,
        0.24846091866493225,
        0.18325741589069366,
        0.1658967137336731,
        0.16492722928524017,
        0.2301957756280899,
        0.19012826681137085,
        0.2248559445142746,
        0.16534768044948578,
        0.19106397032737732,
        0.19174917042255402,
        0.14029644429683685,
        0.18844640254974365,
        0.21659263968467712,
        0.15116557478904724,
        0.17737892270088196,
        0.15624219179153442,
        0.14875653386116028,
        0.2261432707309723,
        0.16642913222312927,
        0.17911024391651154,
        0.18521009385585785,
        0.17879170179367065,
        0.20954565703868866,
        0.18796396255493164,
        0.18974356353282928,
        0.2237425446510315,
        0.2268313318490982,
        0.15021385252475739,
        0.1704949587583542,
        0.15754587948322296,
        0.20033815503120422,
        0.1644141972064972,
        0.1429797261953354,
        0.12456395477056503,
        0.18892355263233185,
        0.17669573426246643,
        0.20842891931533813,
        0.13756237924098969,
        0.18958789110183716,
        0.23546336591243744,
        0.17747695744037628,
        0.16273103654384613,
        0.17637327313423157,
        0.18313461542129517,
        0.16177016496658325,
        0.21402335166931152,
        0.22814348340034485,
        0.15109595656394958,
        0.1592855304479599,
        0.17681129276752472,
        0.15854868292808533,
        0.1019238531589508,
        0.15122519433498383,
        0.1829991638660431,
        0.16597136855125427,
        0.23693837225437164,
        0.19064390659332275,
        0.16486495733261108,
        0.12679748237133026,
        0.15251849591732025,
        0.17970889806747437,
        0.13057111203670502,
        0.13549287617206573,
        0.17097924649715424,
        0.14020177721977234,
        0.10938210785388947,
        0.17972375452518463,
        0.15215244889259338,
        0.20844049751758575,
        0.12769536674022675,
        0.11287324875593185,
        0.11453621089458466,
        0.16793666779994965,
        0.17160078883171082,
        0.19442488253116608,
        0.152485191822052,
        0.13789492845535278,
        0.18999233841896057,
        0.13994619250297546,
        0.1534767597913742,
        0.08626578003168106,
        0.18896476924419403,
        0.16254642605781555,
        0.19719062745571136,
        0.1547253131866455,
        0.15709127485752106,
        0.1707766205072403,
        0.13606616854667664,
        0.10763206332921982,
        0.1696425974369049,
        0.14230230450630188,
        0.14276286959648132,
        0.15420600771903992,
        0.14103329181671143,
        0.1561734974384308,
        0.19372959434986115,
        0.15541653335094452,
        0.1531224250793457,
        0.1298062950372696,
        0.15187840163707733,
        0.17628474533557892,
        0.15974600613117218,
        0.16547366976737976,
        0.11119655519723892,
        0.1836666613817215,
        0.10036474466323853,
        0.10047958791255951,
        0.17633719742298126,
        0.07360223680734634,
        0.1489984542131424,
        0.14302130043506622,
        0.09771165251731873,
        0.11063709855079651,
        0.09628269076347351,
        0.10843810439109802,
        0.14149051904678345,
        0.1235181912779808,
        0.11241607367992401,
        0.12797118723392487,
        0.11122968047857285,
        0.16675959527492523,
        0.11988549679517746,
        0.1184215173125267,
        0.046115633100271225,
        0.11882112175226212,
        0.158916175365448,
        0.15801173448562622,
        0.10769587755203247,
        0.12541727721691132,
        0.160197451710701,
        0.10480833798646927,
        0.1396706998348236,
        0.11012602597475052,
        0.13794957101345062,
        0.08336137980222702,
        0.08484342694282532,
        0.08290596306324005,
        0.049043793231248856,
        0.04680677875876427,
        0.1129314973950386,
        0.12192822992801666,
        0.07434418052434921,
        0.11182556301355362,
        0.08202371746301651,
        0.06370043754577637,
        0.13652701675891876,
        0.0998399406671524,
        0.0678345337510109,
        0.17089398205280304,
        0.11188367009162903,
        0.07357458025217056,
        0.0745602399110794,
        0.061986181885004044,
        0.06438092142343521,
        0.0613018199801445,
        0.12016713619232178,
        0.07712897658348083,
        0.09875523298978806,
        0.13614897429943085,
        0.08435311913490295,
        0.03638342022895813,
        0.12512359023094177,
        0.07132236659526825,
        0.025436509400606155,
        0.12930501997470856,
        0.06838461011648178,
        0.1020880863070488,
        0.052526649087667465,
        0.05932316929101944,
        0.052079979330301285,
        0.1173408031463623,
        0.14685040712356567,
        0.07765169441699982,
        0.08664829283952713,
        0.07533957809209824,
        0.0991055965423584,
        0.03846580907702446,
        0.03683744743466377,
        0.03474222123622894,
        0.025791222229599953,
        0.060091130435466766,
        0.019976671785116196,
        0.06964555382728577,
        0.13075433671474457,
        0.038241367787122726,
        0.09020811319351196,
        0.02669111080467701,
        0.09856069833040237,
        0.029741918668150902,
        0.0854254737496376,
        0.08389294147491455,
        0.06330769509077072,
        0.11664312332868576,
        -0.0041284579783678055,
        0.11678419262170792,
        0.015824319794774055,
        0.04689708352088928,
        0.031289078295230865,
        0.018541747704148293,
        0.08870498836040497,
        0.03736197203397751,
        0.06678204983472824,
        0.06371111422777176,
        -0.00040838151471689343,
        0.04559171944856644,
        0.04132943972945213,
        0.03743666410446167,
        -0.012416197918355465,
        0.051034290343523026,
        0.06257084012031555,
        0.02399485558271408,
        0.08632764965295792,
        0.0019550821743905544,
        0.056866683065891266,
        0.04377610608935356,
        0.027586380019783974,
        -0.0028649859596043825,
        0.00957440584897995,
        0.018183164298534393,
        0.023340372368693352,
        0.024837668985128403,
        0.018930943682789803,
        0.016774294897913933,
        0.0008517105015926063,
        0.04634376987814903,
        0.032603245228528976,
        -0.031380146741867065,
        0.051252540200948715,
        0.049239397048950195,
        0.017005080357193947,
        0.057095933705568314,
        0.03167879953980446,
        0.038721632212400436,
        0.013455649837851524,
        0.022080080583691597,
        0.00806256290525198,
        0.043795544654130936,
        0.023716159164905548,
        -0.0052729081362485886,
        0.03714591637253761,
        -0.04239245131611824,
        -0.050196629017591476,
        -0.012272030115127563,
        0.007150590419769287,
        -0.03150752931833267,
        0.015590867958962917,
        -0.04350553825497627,
        -0.051756616681814194,
        0.049598827958106995,
        -0.004910341929644346,
        -0.03730878606438637,
        0.019475454464554787,
        0.014458767138421535,
        -0.019088011234998703,
        -0.014347797259688377,
        -0.03328152373433113,
        -0.048096805810928345,
        -0.011136183515191078,
        -0.05683049559593201,
        -0.04850228130817413,
        -0.02248121239244938,
        0.04694611579179764,
        -0.05698093771934509,
        -0.02397264540195465,
        -0.04434574767947197,
        0.00010367973300162703,
        0.015261414460837841,
        0.035106111317873,
        -0.06559249013662338,
        -0.019478395581245422,
        -0.019279707223176956,
        -0.06770353019237518,
        0.03410820662975311,
        -0.08111701905727386,
        -0.02377215586602688,
        0.007325408514589071,
        -0.04213903844356537,
        -0.08845867216587067,
        -0.03153771907091141,
        -0.06249457225203514,
        -0.08009932935237885,
        -0.09103834629058838,
        0.006056904327124357,
        0.004584917798638344,
        -0.04920806363224983,
        -0.011301162652671337,
        -0.05280322954058647,
        -0.026039693504571915,
        0.0038273371756076813,
        -0.003596785943955183,
        -0.028506293892860413,
        -0.0835440456867218,
        -0.07423730939626694,
        -0.032977499067783356,
        -0.14156973361968994,
        -0.06145217642188072,
        -0.07437405735254288,
        -0.035632602870464325,
        -0.054322250187397,
        -0.028331713750958443,
        -0.0993889644742012,
        -0.04285923391580582,
        -0.08207845687866211,
        -0.12749645113945007,
        -0.08565298467874527,
        -0.1016751378774643,
        -0.12700018286705017,
        -0.09280803054571152,
        -0.07744267582893372,
        -0.09600728750228882,
        -0.12221008539199829,
        -0.06356710195541382,
        -0.10923512279987335,
        -0.10715658217668533,
        -0.11517596244812012,
        -0.06854823231697083,
        -0.10843616724014282,
        -0.16870687901973724,
        -0.025854727253317833,
        -0.09021205455064774,
        -0.1549990177154541,
        -0.12388095259666443,
        -0.10418680310249329,
        -0.11268489062786102,
        -0.09877347946166992,
        -0.05622144043445587,
        -0.07861564308404922,
        -0.07173322886228561,
        -0.09347175806760788,
        -0.02499414049088955,
        -0.11896970868110657,
        -0.09828692674636841,
        -0.10778073966503143,
        -0.13208162784576416,
        -0.11119506508111954,
        -0.1225227415561676,
        -0.11407046020030975,
        -0.14021211862564087,
        -0.13630688190460205,
        -0.0855468213558197,
        -0.10372468829154968,
        -0.11725997179746628,
        -0.12213721871376038,
        -0.10012132674455643,
        -0.15003140270709991,
        -0.12115290015935898,
        -0.10140908509492874,
        -0.14231637120246887,
        -0.12792295217514038,
        -0.13994956016540527,
        -0.11779753118753433,
        -0.12396823614835739,
        -0.1167401373386383,
        -0.14922986924648285,
        -0.13692137598991394,
        -0.10582133382558823,
        -0.14361998438835144,
        -0.136318638920784,
        -0.11727938801050186,
        -0.16311007738113403,
        -0.09336604177951813,
        -0.10485421866178513,
        -0.0536433681845665,
        -0.1258503496646881,
        -0.12731127440929413,
        -0.1602323353290558,
        -0.12930166721343994,
        -0.1407560259103775,
        -0.07614946365356445,
        -0.16464461386203766,
        -0.1537332981824875,
        -0.16041240096092224,
        -0.10430965572595596,
        -0.1209176629781723,
        -0.17032381892204285,
        -0.1737913340330124,
        -0.11304564774036407,
        -0.08928216248750687,
        -0.15316332876682281,
        -0.1386287659406662,
        -0.123247891664505,
        -0.13028310239315033,
        -0.14819099009037018,
        -0.14360931515693665,
        -0.17030221223831177,
        -0.13811370730400085,
        -0.18183346092700958,
        -0.1617898792028427,
        -0.13863438367843628,
        -0.15769894421100616,
        -0.18384407460689545,
        -0.1648702174425125,
        -0.1806592494249344,
        -0.14097939431667328,
        -0.14759144186973572,
        -0.1727733314037323,
        -0.14114931225776672,
        -0.19663767516613007,
        -0.15527813136577606,
        -0.1726924031972885,
        -0.207707479596138,
        -0.18093882501125336,
        -0.21300062537193298,
        -0.16227924823760986,
        -0.1486486941576004,
        -0.15425899624824524,
        -0.19357550144195557,
        -0.18080855906009674,
        -0.1851300299167633,
        -0.15462419390678406,
        -0.15341626107692719,
        -0.18553206324577332,
        -0.1813529133796692,
        -0.17925719916820526,
        -0.17348991334438324,
        -0.2255753129720688,
        -0.1389007270336151,
        -0.24539035558700562,
        -0.2075030505657196,
        -0.17795142531394958,
        -0.16708748042583466,
        -0.16402477025985718,
        -0.19908319413661957,
        -0.16959817707538605,
        -0.16207146644592285,
        -0.19821874797344208,
        -0.22317421436309814,
        -0.22016872465610504,
        -0.1837885081768036,
        -0.19469670951366425,
        -0.18922166526317596,
        -0.19015023112297058,
        -0.18684084713459015,
        -0.1748790591955185,
        -0.24288004636764526,
        -0.2521536350250244,
        -0.271982342004776,
        -0.20977500081062317,
        -0.23013681173324585,
        -0.21772293746471405,
        -0.2077079713344574,
        -0.22514304518699646,
        -0.2182670384645462,
        -0.2157009243965149,
        -0.2048272043466568,
        -0.28217199444770813,
        -0.19304636120796204,
        -0.1935846507549286,
        -0.23660843074321747,
        -0.19756165146827698,
        -0.215529665350914,
        -0.18729743361473083,
        -0.2750915586948395,
        -0.2097247987985611,
        -0.22208769619464874,
        -0.19403082132339478,
        -0.32053861021995544,
        -0.1932775229215622,
        -0.28151237964630127,
        -0.2572762370109558,
        -0.2259790450334549,
        -0.21566174924373627,
        -0.21083244681358337,
        -0.1814683973789215,
        -0.2196836918592453,
        -0.23679755628108978,
        -0.21494565904140472,
        -0.2563098967075348,
        -0.2398865967988968,
        -0.2813694477081299,
        -0.27315229177474976,
        -0.2502165138721466,
        -0.23862192034721375,
        -0.2142123132944107,
        -0.2596144676208496,
        -0.2769450843334198,
        -0.27137279510498047,
        -0.22858910262584686,
        -0.2726493775844574,
        -0.26727789640426636,
        -0.28610295057296753,
        -0.278279185295105,
        -0.2534114420413971,
        -0.23992013931274414,
        -0.27590277791023254,
        -0.24879276752471924,
        -0.31091347336769104,
        -0.286838173866272,
        -0.263772577047348,
        -0.27512678503990173,
        -0.22944054007530212,
        -0.20669668912887573,
        -0.25882118940353394,
        -0.2616828978061676,
        -0.3011358678340912,
        -0.2293228805065155,
        -0.27149754762649536,
        -0.3036190867424011,
        -0.2923562228679657,
        -0.31015142798423767,
        -0.34508317708969116,
        -0.2716084122657776,
        -0.2766270935535431,
        -0.3208427131175995,
        -0.22413001954555511,
        -0.3448983132839203,
        -0.24769695103168488,
        -0.24867363274097443,
        -0.2939324378967285,
        -0.22533059120178223,
        -0.34363991022109985,
        -0.3508566617965698,
        -0.30793723464012146,
        -0.3118445873260498,
        -0.26475319266319275,
        -0.2743563652038574,
        -0.31222179532051086,
        -0.31685030460357666,
        -0.2840399742126465,
        -0.228692427277565,
        -0.3113478124141693,
        -0.31629034876823425,
        -0.26762402057647705,
        -0.30011487007141113,
        -0.31056156754493713,
        -0.3146883249282837,
        -0.3986206352710724,
        -0.3311905860900879,
        -0.3182314932346344,
        -0.32182741165161133,
        -0.27199214696884155,
        -0.3171803057193756,
        -0.27714747190475464,
        -0.29370248317718506,
        -0.3218381404876709,
        -0.2941693067550659,
        -0.27847445011138916,
        -0.325039267539978,
        -0.309713751077652,
        -0.26300057768821716,
        -0.23371979594230652,
        -0.2831021547317505,
        -0.30619242787361145,
        -0.3107162415981293,
        -0.30309540033340454,
        -0.33382466435432434,
        -0.31821373105049133,
        -0.2813045382499695,
        -0.2771845757961273,
        -0.2908574938774109,
        -0.34247592091560364,
        -0.32525262236595154,
        -0.35965821146965027,
        -0.3605830669403076,
        -0.23486825823783875,
        -0.3184956908226013,
        -0.32401221990585327,
        -0.3124273419380188,
        -0.3210309147834778,
        -0.3309708535671234,
        -0.30819663405418396,
        -0.3467141091823578,
        -0.366129606962204,
        -0.33114925026893616,
        -0.320231169462204,
        -0.357147216796875,
        -0.29586830735206604,
        -0.3474615812301636,
        -0.37510165572166443,
        -0.37105390429496765,
        -0.30028006434440613,
        -0.30327823758125305,
        -0.338775098323822,
        -0.3249264061450958,
        -0.3414815068244934,
        -0.3087315559387207,
        -0.3305785059928894,
        -0.30766168236732483,
        -0.31122300028800964,
        -0.3076186776161194,
        -0.3507944941520691,
        -0.33211323618888855,
        -0.31267744302749634,
        -0.36090561747550964,
        -0.35029131174087524,
        -0.31383681297302246,
        -0.31738242506980896,
        -0.33870285749435425,
        -0.368768572807312,
        -0.3733823001384735,
        -0.37423890829086304,
        -0.3204464614391327,
        -0.4400146007537842,
        -0.3086266815662384,
        -0.340626984834671,
        -0.37346646189689636,
        -0.3528982102870941,
        -0.3576512634754181,
        -0.3547709286212921,
        -0.3135393261909485,
        -0.31364405155181885,
        -0.3354293704032898,
        -0.37468579411506653,
        -0.3711843192577362,
        -0.37463659048080444,
        -0.4056586027145386,
        -0.3541842997074127,
        -0.4078359305858612,
        -0.3943752348423004,
        -0.3228894770145416,
        -0.35701772570610046,
        -0.35577458143234253,
        -0.36954113841056824,
        -0.4007105231285095,
        -0.3751596212387085,
        -0.3019333481788635,
        -0.3885651230812073,
        -0.37241625785827637,
        -0.40231311321258545,
        -0.3442590534687042,
        -0.4092705547809601,
        -0.452582985162735,
        -0.3767789304256439,
        -0.43453946709632874,
        -0.3483619689941406,
        -0.3237280547618866,
        -0.37158918380737305,
        -0.4373124837875366,
        -0.395455539226532,
        -0.3830958902835846,
        -0.3901691138744354,
        -0.3817312717437744,
        -0.37386950850486755,
        -0.42341482639312744,
        -0.4028227627277374,
        -0.39592546224594116,
        -0.4271698594093323,
        -0.3596312701702118,
        -0.42808017134666443,
        -0.3934424817562103,
        -0.4380745589733124,
        -0.41243648529052734,
        -0.35780900716781616,
        -0.3939771056175232,
        -0.38391777873039246,
        -0.45707544684410095,
        -0.3774704933166504,
        -0.40105244517326355,
        -0.39641648530960083,
        -0.4450058043003082,
        -0.44576993584632874,
        -0.4535045027732849,
        -0.37449172139167786,
        -0.3920719623565674,
        -0.4284706711769104,
        -0.4191749095916748,
        -0.46749380230903625,
        -0.3929689824581146,
        -0.4144880473613739,
        -0.4147126078605652,
        -0.46561601758003235,
        -0.3849199712276459,
        -0.39968690276145935,
        -0.4300170838832855,
        -0.4825441539287567,
        -0.45228105783462524,
        -0.44981563091278076,
        -0.43385830521583557,
        -0.43438467383384705,
        -0.47904032468795776,
        -0.39031869173049927,
        -0.4897591769695282,
        -0.44617950916290283,
        -0.46297430992126465,
        -0.46861714124679565,
        -0.42091259360313416,
        -0.4434744417667389,
        -0.47599685192108154,
        -0.46131783723831177,
        -0.46206679940223694,
        -0.47037237882614136,
        -0.47220656275749207,
        -0.42266201972961426,
        -0.4287874400615692,
        -0.42946168780326843,
        -0.4443725645542145,
        -0.4544540345668793,
        -0.48294514417648315,
        -0.46954938769340515,
        -0.4659454822540283,
        -0.49547749757766724,
        -0.4239102005958557,
        -0.45879635214805603,
        -0.45295244455337524,
        -0.4747292995452881,
        -0.5032899975776672,
        -0.45814043283462524,
        -0.4717075526714325,
        -0.4801800847053528,
        -0.48594430088996887,
        -0.4528241753578186,
        -0.5031288862228394,
        -0.45188501477241516,
        -0.4657266438007355,
        -0.5150981545448303,
        -0.5167174935340881,
        -0.4606511890888214,
        -0.48738405108451843,
        -0.489426851272583,
        -0.5016847848892212,
        -0.5208736658096313,
        -0.5079311728477478,
        -0.5198761224746704,
        -0.5265823602676392,
        -0.5205606818199158,
        -0.5267925262451172,
        -0.4431416690349579,
        -0.5196995735168457,
        -0.49231210350990295,
        -0.46570611000061035,
        -0.4648054838180542,
        -0.46332645416259766,
        -0.4870169460773468,
        -0.5399392247200012,
        -0.5255325436592102,
        -0.5171381235122681,
        -0.5084474086761475,
        -0.47388073801994324,
        -0.4872390031814575,
        -0.5156592726707458,
        -0.48369184136390686,
        -0.4889204502105713,
        -0.47026562690734863,
        -0.4884119927883148,
        -0.4872974753379822,
        -0.4187089502811432,
        -0.5070819854736328,
        -0.5170974135398865,
        -0.5289099812507629,
        -0.48918417096138,
        -0.5027018189430237,
        -0.51396644115448,
        -0.48752832412719727,
        -0.517217755317688,
        -0.5146161317825317,
        -0.49032047390937805,
        -0.5345643758773804,
        -0.4815807640552521,
        -0.49042582511901855,
        -0.4870240390300751,
        -0.48633092641830444,
        -0.5420133471488953,
        -0.49130693078041077,
        -0.5307337641716003,
        -0.52040696144104,
        -0.49978160858154297,
        -0.46689915657043457,
        -0.509182333946228,
        -0.5261814594268799,
        -0.47225090861320496,
        -0.5084454417228699,
        -0.5179292559623718,
        -0.5568861961364746,
        -0.5078085660934448,
        -0.509698212146759,
        -0.48346880078315735,
        -0.5224639773368835,
        -0.5348408222198486,
        -0.5271708965301514,
        -0.5218908786773682,
        -0.5126088857650757,
        -0.5109718441963196,
        -0.4669055938720703,
        -0.5136398077011108,
        -0.4999285042285919,
        -0.5400499105453491,
        -0.509484052658081,
        -0.5141751766204834,
        -0.4765830636024475,
        -0.5242372155189514,
        -0.4950900971889496,
        -0.5404568910598755,
        -0.5258514881134033,
        -0.5317724347114563,
        -0.5252325534820557,
        -0.511283814907074,
        -0.5251831412315369,
        -0.5671682953834534,
        -0.503379762172699,
        -0.5459626913070679,
        -0.5427219271659851,
        -0.5072422623634338,
        -0.5746796131134033,
        -0.5257654786109924,
        -0.5128192901611328,
        -0.5546401739120483,
        -0.5175906419754028,
        -0.5025466084480286,
        -0.5634241104125977,
        -0.5268946886062622,
        -0.568440318107605,
        -0.5265941619873047,
        -0.48971763253211975,
        -0.5300289988517761,
        -0.5308151841163635,
        -0.5111954808235168,
        -0.5182059407234192,
        -0.5515193343162537,
        -0.5613359808921814,
        -0.5441024899482727,
        -0.5364436507225037,
        -0.5527821779251099,
        -0.536323070526123,
        -0.5209818482398987,
        -0.5334901213645935,
        -0.5369951128959656,
        -0.5613605976104736,
        -0.5066340565681458,
        -0.5565380454063416,
        -0.5534965991973877,
        -0.5593421459197998,
        -0.538507342338562,
        -0.5593587160110474,
        -0.5165927410125732,
        -0.5214135646820068,
        -0.5415248274803162,
        -0.5641335844993591,
        -0.5317062139511108,
        -0.5295641422271729,
        -0.5581074953079224,
        -0.5508516430854797,
        -0.5469470620155334,
        -0.5604656934738159,
        -0.5709075331687927,
        -0.5549181699752808,
        -0.5866581201553345,
        -0.5498762726783752,
        -0.5511128902435303,
        -0.5394742488861084,
        -0.544971227645874,
        -0.5709763765335083,
        -0.5610752701759338,
        -0.6026995182037354,
        -0.6216185688972473,
        -0.5658935904502869,
        -0.529983639717102,
        -0.5421587824821472,
        -0.5518617033958435,
        -0.5641283988952637,
        -0.5383564829826355,
        -0.5459970831871033,
        -0.5683345198631287,
        -0.5248354077339172,
        -0.5098686218261719,
        -0.5616527795791626,
        -0.5597423315048218,
        -0.5431143641471863,
        -0.585659384727478,
        -0.5533931255340576,
        -0.5261751413345337,
        -0.5977764129638672,
        -0.5388959050178528,
        -0.5755084753036499,
        -0.6160041689872742,
        -0.5752313137054443,
        -0.5517576932907104,
        -0.615575909614563,
        -0.5499816536903381,
        -0.5825743079185486,
        -0.587938666343689,
        -0.6187602877616882,
        -0.5866487622261047,
        -0.5997432470321655,
        -0.5761331915855408,
        -0.5636485815048218,
        -0.6032615303993225,
        -0.6340118646621704,
        -0.5835317969322205,
        -0.5813329219818115,
        -0.604231059551239,
        -0.5723599195480347,
        -0.5633743405342102,
        -0.6022379398345947,
        -0.5929606556892395,
        -0.6291118860244751,
        -0.5923622846603394,
        -0.6021056175231934,
        -0.6461695432662964,
        -0.6088399887084961,
        -0.6083917617797852,
        -0.6029523015022278,
        -0.6091225147247314,
        -0.6265541315078735,
        -0.6277972459793091,
        -0.5777775645256042,
        -0.6054505705833435,
        -0.6579241752624512,
        -0.6568330526351929,
        -0.6568627953529358,
        -0.6573360562324524,
        -0.6168622970581055,
        -0.6252070069313049,
        -0.6260627508163452,
        -0.6278521418571472,
        -0.6387595534324646,
        -0.6124548316001892,
        -0.6674008965492249,
        -0.6366878747940063,
        -0.666834831237793,
        -0.6189272403717041,
        -0.6396947503089905,
        -0.629776656627655,
        -0.6414200067520142,
        -0.628489077091217,
        -0.6452698111534119,
        -0.6272152662277222,
        -0.6340540647506714,
        -0.6498580574989319,
        -0.5927013754844666,
        -0.6250926852226257,
        -0.6175553798675537,
        -0.6784337162971497,
        -0.6424461603164673,
        -0.648246169090271,
        -0.6497321128845215,
        -0.6445344686508179,
        -0.6383913159370422,
        -0.6857810020446777,
        -0.6634323596954346,
        -0.6786156892776489,
        -0.6234850287437439,
        -0.6334845423698425,
        -0.6896056532859802,
        -0.6584712266921997,
        -0.7068339586257935,
        -0.6616384387016296,
        -0.6922820210456848,
        -0.5897401571273804,
        -0.6543270945549011,
        -0.6599488258361816,
        -0.6407269239425659,
        -0.6432030200958252,
        -0.6717751026153564,
        -0.6955776214599609,
        -0.6567103862762451,
        -0.7023273706436157,
        -0.6937010288238525,
        -0.6597877144813538,
        -0.695033848285675,
        -0.6980113983154297,
        -0.6553064584732056,
        -0.6938481330871582,
        -0.6667367219924927,
        -0.6452638506889343,
        -0.6399235129356384,
        -0.6295986175537109,
        -0.6903753876686096,
        -0.7111945152282715,
        -0.6369801163673401,
        -0.6932786107063293,
        -0.706447184085846,
        -0.695614218711853,
        -0.6770449876785278,
        -0.6860047578811646,
        -0.6520710587501526,
        -0.6763933300971985,
        -0.6274158954620361,
        -0.6948397159576416,
        -0.6816161870956421,
        -0.6204582452774048,
        -0.6194556951522827,
        -0.6890482902526855,
        -0.679364800453186,
        -0.6731927990913391,
        -0.703754186630249,
        -0.6759834885597229,
        -0.6492919325828552,
        -0.7167422771453857,
        -0.7055851221084595,
        -0.6910508871078491,
        -0.7125757336616516,
        -0.6694270372390747,
        -0.7090290188789368,
        -0.6833199262619019,
        -0.6683093905448914,
        -0.6730663776397705,
        -0.687565267086029,
        -0.6301226615905762,
        -0.7326220273971558,
        -0.6464816331863403,
        -0.7323521375656128,
        -0.7335060834884644,
        -0.7210001349449158,
        -0.6839457154273987,
        -0.6889531016349792,
        -0.6533028483390808,
        -0.7132773399353027,
        -0.7203968167304993,
        -0.6889664530754089,
        -0.6846606731414795,
        -0.7117596864700317,
        -0.7527008652687073,
        -0.7094523906707764,
        -0.7861958742141724,
        -0.7295562624931335,
        -0.7215924859046936,
        -0.7132975459098816,
        -0.6798753142356873,
        -0.6646056771278381,
        -0.6397809982299805,
        -0.7236912846565247,
        -0.6703419089317322,
        -0.7159782648086548,
        -0.6875759363174438,
        -0.6685526967048645,
        -0.7756221294403076,
        -0.7175154089927673,
        -0.7019593119621277,
        -0.7044728398323059,
        -0.7377046346664429,
        -0.7397474646568298,
        -0.6997165083885193,
        -0.7249807119369507,
        -0.8183329105377197,
        -0.7259534597396851,
        -0.8255478143692017,
        -0.7018121480941772,
        -0.7631665468215942,
        -0.7724130749702454,
        -0.7388864755630493,
        -0.7516075372695923,
        -0.7003217935562134,
        -0.7399018406867981,
        -0.7462558746337891,
        -0.7419899106025696,
        -0.7249255776405334,
        -0.7379878163337708,
        -0.7663570642471313,
        -0.7779607176780701,
        -0.7534401416778564,
        -0.7388065457344055,
        -0.7631432414054871,
        -0.776222825050354,
        -0.7271565794944763,
        -0.7752338647842407,
        -0.7755181193351746,
        -0.7515488862991333,
        -0.7778707146644592,
        -0.7146751880645752,
        -0.7370389699935913,
        -0.76003497838974,
        -0.7559818625450134,
        -0.74872225522995,
        -0.7884882688522339,
        -0.7615148425102234,
        -0.8165431618690491,
        -0.7580943703651428,
        -0.7527058720588684,
        -0.758891224861145,
        -0.769739031791687,
        -0.7836215496063232,
        -0.786045491695404,
        -0.7861343622207642,
        -0.7852071523666382,
        -0.784790575504303,
        -0.8736736178398132,
        -0.8750738501548767,
        -0.8512571454048157,
        -0.7819597721099854,
        -0.7901685237884521,
        -0.7870317697525024,
        -0.7494721412658691,
        -0.8191725015640259,
        -0.8284790515899658,
        -0.827238917350769,
        -0.7688625454902649,
        -0.7739350199699402,
        -0.8658685684204102,
        -0.7966639995574951,
        -0.7953247427940369,
        -0.7864809632301331,
        -0.7940042018890381,
        -0.76308274269104,
        -0.736906886100769,
        -0.8009161949157715,
        -0.7995574474334717,
        -0.796959400177002,
        -0.7844039797782898,
        -0.7687245011329651,
        -0.731253445148468,
        -0.774684488773346,
        -0.8119526505470276,
        -0.7906385064125061,
        -0.8228035569190979,
        -0.8790249824523926,
        -0.7714816331863403,
        -0.7616556286811829,
        -0.7788669466972351,
        -0.7841525077819824,
        -0.8089607357978821,
        -0.8145481944084167,
        -0.8095217347145081,
        -0.8096932172775269,
        -0.8825417757034302,
        -0.779184877872467,
        -0.7802726626396179,
        -0.8251051902770996,
        -0.8220282196998596,
        -0.8181247115135193,
        -0.7597367167472839,
        -0.7907431125640869,
        -0.8895641565322876,
        -0.7964430451393127,
        -0.820977509021759,
        -0.7919386625289917,
        -0.8428919911384583,
        -0.8107677102088928,
        -0.7848612666130066,
        -0.8092896938323975,
        -0.8941633105278015,
        -0.830864429473877,
        -0.8054198026657104,
        -0.821712851524353,
        -0.7994052171707153,
        -0.8037924766540527,
        -0.7854875326156616,
        -0.8463407754898071,
        -0.8420100808143616,
        -0.8276383876800537,
        -0.8471364378929138,
        -0.8034564852714539,
        -0.7898620963096619,
        -0.842719316482544,
        -0.8345904350280762,
        -0.8073660135269165,
        -0.8449939489364624,
        -0.8364477157592773,
        -0.8318602442741394,
        -0.816397488117218,
        -0.8370926976203918,
        -0.8389865159988403,
        -0.8514630794525146,
        -0.837952733039856,
        -0.8645918369293213,
        -0.8301264047622681,
        -0.7835450172424316,
        -0.8557904362678528,
        -0.8164491653442383,
        -0.9286276698112488,
        -0.8571726679801941,
        -0.8323231339454651,
        -0.8567426800727844,
        -0.8730383515357971,
        -0.8208633661270142,
        -0.8694891333580017,
        -0.8211579322814941,
        -0.9490427374839783,
        -0.859409511089325,
        -0.8748303651809692,
        -0.8527200222015381,
        -0.8392505645751953,
        -0.8370485901832581,
        -0.8154065608978271,
        -0.8733343482017517,
        -0.8488471508026123,
        -0.836738646030426,
        -0.8556979298591614,
        -0.8195844292640686,
        -0.8656627535820007,
        -0.9525916576385498,
        -0.9418939352035522,
        -0.8144578337669373,
        -0.8702623248100281,
        -0.868695080280304,
        -0.8705585598945618,
        -0.8705185651779175,
        -0.866178572177887,
        -0.8786598443984985,
        -0.8722249865531921,
        -0.8852766156196594,
        -0.8670931458473206,
        -0.8815188407897949,
        -0.8796756863594055,
        -0.9660277366638184,
        -0.8799987435340881,
        -0.8918266892433167,
        -0.8886269330978394,
        -0.9807153940200806,
        -0.8749099373817444,
        -0.8847275972366333,
        -0.9533734917640686,
        -0.8845380544662476,
        -0.9018709659576416,
        -0.901559054851532,
        -0.9542317390441895,
        -0.8778327107429504,
        -0.8944253921508789,
        -0.9243948459625244,
        -0.8881354331970215,
        -0.984805166721344,
        -0.8424267172813416,
        -0.9400904178619385,
        -0.9172983169555664,
        -0.9129035472869873,
        -0.8683688640594482,
        -0.972943902015686,
        -0.9836055040359497,
        -0.8488014936447144,
        -1.0121089220046997,
        -0.91449373960495,
        -0.9047755599021912,
        -0.9032329320907593,
        -0.9014649987220764,
        -0.905273973941803,
        -0.9230009317398071,
        -0.8876846432685852,
        -0.9075473546981812,
        -1.061701774597168,
        -0.9238859415054321,
        -1.0087120532989502,
        -0.9175583720207214,
        -0.8989794254302979,
        -0.9248515963554382,
        -0.9541460275650024,
        -0.9138789176940918,
        -1.0495851039886475,
        -1.001948356628418,
        -0.9185980558395386,
        -0.9392966628074646,
        -0.9173703193664551,
        -0.9076825380325317,
        -0.9221715331077576,
        -0.9518024325370789,
        -0.890916645526886,
        -0.9486230611801147,
        -0.9220640063285828,
        -0.9517722129821777,
        -0.9563742280006409,
        -0.9521887898445129,
        -0.9146258234977722,
        -0.9562572240829468,
        -0.9190433621406555,
        -0.928708016872406,
        -0.9164146184921265,
        -0.9326419830322266,
        -1.027450442314148,
        -1.007163405418396,
        -0.9446621537208557,
        -0.9151896238327026,
        -0.9680303931236267,
        -0.9965615272521973,
        -1.024172306060791,
        -0.9408767819404602,
        -0.9485795497894287,
        -0.927492618560791,
        -0.9393156170845032,
        -0.8950896263122559,
        -0.9605092406272888,
        -0.9482850432395935,
        -0.9375264644622803,
        -0.9920459389686584,
        -0.9620595574378967,
        -0.9630872011184692,
        -0.9392326474189758,
        -0.9395846128463745,
        -1.045573115348816,
        -0.9540520906448364,
        -1.048211932182312,
        -1.0930510759353638,
        -1.084204912185669,
        -0.9619698524475098,
        -0.9694459438323975,
        -0.9722559452056885,
        -0.9400814771652222,
        -0.9266582131385803,
        -1.0862070322036743,
        -0.9843562841415405,
        -0.9522793889045715,
        -0.9794549942016602,
        -0.9788693189620972,
        -0.9613916873931885,
        -0.9830763936042786,
        -0.9711970090866089,
        -1.0884590148925781,
        -0.9633594155311584,
        -1.0536925792694092,
        -0.9927538633346558,
        -0.9850292205810547,
        -0.9706426858901978,
        -0.9696926474571228,
        -1.1160119771957397,
        -1.0784176588058472,
        -0.9699535965919495,
        -0.9826544523239136,
        -0.9876047372817993,
        -1.000140905380249,
        -0.9830368757247925,
        -0.9528322219848633,
        -1.0852323770523071,
        -0.9967479705810547,
        -0.9776800274848938,
        -0.983035147190094,
        -0.9997128248214722,
        -0.9864490628242493,
        -1.1374895572662354,
        -1.0897892713546753,
        -0.9783138036727905,
        -1.019269347190857,
        -1.0987416505813599,
        -1.0992116928100586,
        -1.0991231203079224,
        -1.0984632968902588,
        -0.998206377029419,
        -1.0989904403686523,
        -1.0011425018310547,
        -1.0167721509933472,
        -1.0489356517791748,
        -1.0232179164886475,
        -1.0155540704727173,
        -1.009167194366455,
        -0.9457302093505859,
        -1.0223101377487183,
        -1.017060399055481,
        -1.0247037410736084,
        -1.0404561758041382,
        -1.0007127523422241,
        -1.016649603843689,
        -0.9952952265739441,
        -1.0212180614471436,
        -1.021673560142517,
        -1.025268793106079,
        -1.0253102779388428,
        -0.9989597201347351,
        -1.0469098091125488,
        -1.1038775444030762,
        -1.0173450708389282,
        -1.108048677444458,
        -1.0422371625900269,
        -1.031508445739746,
        -1.037522315979004,
        -1.0438919067382812,
        -1.0422862768173218,
        -1.029409646987915,
        -1.0427688360214233,
        -1.0883060693740845,
        -1.018005132675171,
        -1.0721217393875122,
        -1.0542947053909302,
        -1.1389793157577515,
        -1.027483582496643,
        -1.0555709600448608,
        -1.0205869674682617,
        -1.0682752132415771,
        -1.0551029443740845,
        -1.034872055053711,
        -1.0812451839447021,
        -1.1403206586837769,
        -1.106134057044983,
        -1.1047214269638062,
        -1.1432744264602661,
        -1.0890613794326782,
        -1.0454386472702026,
        -1.0634814500808716,
        -1.0594267845153809,
        -1.0412248373031616,
        -1.1408177614212036,
        -1.0796946287155151,
        -1.0674757957458496,
        -1.0811349153518677,
        -1.074351191520691,
        -1.1896936893463135,
        -1.0613775253295898,
        -1.0490832328796387,
        -1.0710357427597046,
        -1.0640580654144287,
        -1.0623924732208252,
        -1.135996699333191,
        -1.0904109477996826,
        -1.0260987281799316,
        -1.058666467666626,
        -1.0676730871200562,
        -1.0852482318878174,
        -1.0973258018493652,
        -1.054265022277832,
        -1.0762832164764404,
        -1.150112509727478,
        -1.0690383911132812,
        -1.071882963180542,
        -1.0969741344451904,
        -1.0981615781784058,
        -1.0345096588134766,
        -1.159034252166748,
        -1.1589840650558472,
        -1.1622326374053955,
        -1.0730211734771729,
        -1.0732769966125488,
        -1.0897505283355713,
        -1.090889811515808,
        -1.1076196432113647,
        -1.0886735916137695,
        -1.1817477941513062,
        -1.1535797119140625,
        -1.0824116468429565,
        -1.0776219367980957,
        -1.082395315170288,
        -1.089115858078003,
        -1.100377082824707,
        -1.1224448680877686,
        -1.1170762777328491,
        -1.0902678966522217,
        -1.061010718345642,
        -1.060159683227539,
        -1.1327910423278809,
        -1.1990187168121338,
        -1.0663408041000366,
        -1.116072416305542,
        -1.124977946281433,
        -1.112352728843689,
        -1.085364580154419,
        -1.1073819398880005,
        -1.1757211685180664,
        -1.1379140615463257,
        -1.1318756341934204,
        -1.111174464225769,
        -1.1274333000183105,
        -1.1003121137619019,
        -1.1318799257278442,
        -1.2031153440475464,
        -1.132487416267395,
        -1.2593127489089966,
        -1.0881469249725342,
        -1.1418200731277466,
        -1.1579207181930542,
        -1.1362613439559937,
        -1.1019755601882935,
        -1.1319820880889893,
        -1.1492323875427246,
        -1.2186797857284546,
        -1.163074016571045,
        -1.16994309425354,
        -1.1754367351531982,
        -1.166136622428894,
        -1.1380274295806885,
        -1.2170798778533936,
        -1.160163402557373,
        -1.1693665981292725,
        -1.132879614830017,
        -1.1642121076583862,
        -1.1289894580841064,
        -1.2935377359390259,
        -1.1489874124526978,
        -1.133355736732483,
        -1.2420352697372437,
        -1.1774219274520874,
        -1.2536402940750122,
        -1.254738450050354,
        -1.1423313617706299,
        -1.231486439704895,
        -1.1733472347259521,
        -1.2506589889526367,
        -1.1187553405761719,
        -1.1487098932266235,
        -1.2010859251022339,
        -1.1725904941558838,
        -1.1703180074691772,
        -1.1693342924118042,
        -1.1314440965652466,
        -1.1919139623641968,
        -1.1534488201141357,
        -1.1843231916427612,
        -1.2451698780059814,
        -1.2054072618484497,
        -1.1536855697631836,
        -1.2008144855499268,
        -1.1666638851165771,
        -1.201066017150879,
        -1.21867036819458,
        -1.1806895732879639,
        -1.289507269859314,
        -1.1850897073745728,
        -1.16921865940094,
        -1.1873893737792969,
        -1.1907492876052856,
        -1.192040205001831,
        -1.2222743034362793,
        -1.2219030857086182,
        -1.1729276180267334,
        -1.2070229053497314,
        -1.170436143875122,
        -1.2080614566802979,
        -1.2233004570007324,
        -1.178906798362732,
        -1.1753968000411987,
        -1.235762119293213,
        -1.1977659463882446,
        -1.1481996774673462,
        -1.2348034381866455,
        -1.1999636888504028,
        -1.2274738550186157,
        -1.2167563438415527,
        -1.2464406490325928,
        -1.285714864730835,
        -1.2028883695602417,
        -1.215847373008728,
        -1.2173881530761719,
        -1.2565436363220215,
        -1.2018483877182007,
        -1.246842622756958,
        -1.2678810358047485,
        -1.2843695878982544,
        -1.240096926689148,
        -1.2277138233184814,
        -1.2468141317367554,
        -1.2135162353515625,
        -1.2428615093231201,
        -1.2631125450134277,
        -1.2471996545791626,
        -1.2017046213150024,
        -1.2699666023254395,
        -1.2631756067276,
        -1.301501750946045,
        -1.2676137685775757,
        -1.3360626697540283,
        -1.2368942499160767,
        -1.254199743270874,
        -1.2437646389007568,
        -1.2725239992141724,
        -1.2685699462890625,
        -1.3593767881393433,
        -1.2890403270721436,
        -1.306732416152954,
        -1.3196741342544556,
        -1.3017853498458862,
        -1.2241935729980469,
        -1.255039095878601,
        -1.3777586221694946,
        -1.2805869579315186,
        -1.2687736749649048,
        -1.3268530368804932,
        -1.2656751871109009,
        -1.2944090366363525,
        -1.2908258438110352,
        -1.4364992380142212,
        -1.3202970027923584,
        -1.231770634651184,
        -1.3196362257003784,
        -1.4332900047302246,
        -1.3646905422210693,
        -1.2880326509475708,
        -1.2947797775268555,
        -1.3733022212982178,
        -1.2700756788253784,
        -1.3120476007461548,
        -1.3502051830291748,
        -1.3396100997924805,
        -1.3069778680801392,
        -1.2935025691986084,
        -1.3050867319107056,
        -1.2971830368041992,
        -1.3654718399047852,
        -1.3398020267486572,
        -1.36553156375885,
        -1.303272008895874,
        -1.289493203163147,
        -1.3052480220794678,
        -1.3305619955062866,
        -1.3512877225875854,
        -1.334913730621338,
        -1.3713611364364624,
        -1.4803168773651123,
        -1.3230628967285156,
        -1.3479474782943726,
        -1.3289093971252441,
        -1.3383398056030273,
        -1.3301076889038086,
        -1.3066524267196655,
        -1.3875250816345215,
        -1.3975528478622437,
        -1.328408122062683,
        -1.3252161741256714,
        -1.4124119281768799,
        -1.3535683155059814,
        -1.3418364524841309,
        -1.4003955125808716,
        -1.371915578842163,
        -1.3628977537155151,
        -1.3787392377853394,
        -1.3468424081802368,
        -1.39421546459198,
        -1.353864312171936,
        -1.408960223197937,
        -1.3815997838974,
        -1.3506850004196167,
        -1.3462070226669312,
        -1.3750760555267334,
        -1.363380789756775,
        -1.3721903562545776,
        -1.4230598211288452,
        -1.4022023677825928,
        -1.4008877277374268,
        -1.3547395467758179,
        -1.4143567085266113,
        -1.3509620428085327,
        -1.4195035696029663,
        -1.416320562362671,
        -1.3863048553466797,
        -1.4155017137527466,
        -1.3923929929733276,
        -1.3686147928237915,
        -1.3572511672973633,
        -1.3872063159942627,
        -1.4341834783554077,
        -1.4358410835266113,
        -1.4244452714920044,
        -1.422730565071106,
        -1.4251452684402466,
        -1.3972337245941162,
        -1.3890910148620605,
        -1.5365535020828247,
        -1.3913805484771729,
        -1.3924353122711182,
        -1.3984709978103638,
        -1.4553616046905518,
        -1.452136516571045,
        -1.4721825122833252,
        -1.445510745048523,
        -1.4057573080062866,
        -1.4260554313659668,
        -1.4161219596862793,
        -1.446097493171692,
        -1.4270668029785156,
        -1.386899709701538,
        -1.4048058986663818,
        -1.428770899772644,
        -1.4326905012130737,
        -1.4474067687988281,
        -1.4541852474212646,
        -1.4516764879226685,
        -1.5022433996200562,
        -1.4513630867004395,
        -1.4696526527404785,
        -1.4026768207550049,
        -1.4370596408843994,
        -1.4425159692764282,
        -1.436118483543396,
        -1.4471913576126099,
        -1.4660576581954956,
        -1.4959537982940674,
        -1.5009456872940063,
        -1.4512380361557007,
        -1.4541618824005127,
        -1.4613990783691406,
        -1.4808145761489868,
        -1.427465558052063,
        -1.4806541204452515,
        -1.4990935325622559,
        -1.4708240032196045,
        -1.5219378471374512,
        -1.484467625617981,
        -1.5081663131713867,
        -1.4919642210006714,
        -1.4987239837646484,
        -1.4886671304702759,
        -1.49591064453125,
        -1.5374089479446411,
        -1.4581725597381592,
        -1.5309298038482666,
        -1.5111762285232544,
        -1.4757500886917114,
        -1.5306758880615234,
        -1.4843976497650146,
        -1.5271703004837036,
        -1.497726321220398,
        -1.4907110929489136,
        -1.5122909545898438,
        -1.5227898359298706,
        -1.4753162860870361,
        -1.5529130697250366,
        -1.5662394762039185,
        -1.528702974319458,
        -1.510149359703064,
        -1.5039628744125366,
        -1.5078374147415161,
        -1.5331451892852783,
        -1.4758518934249878,
        -1.5394432544708252,
        -1.4798370599746704,
        -1.4755128622055054,
        -1.5123313665390015,
        -1.5296510457992554,
        -1.4946601390838623,
        -1.5159924030303955,
        -1.5520154237747192,
        -1.5484849214553833,
        -1.4967360496520996,
        -1.5166435241699219,
        -1.4726686477661133,
        -1.5494203567504883,
        -1.5670392513275146,
        -1.538086175918579,
        -1.580554485321045,
        -1.587406873703003,
        -1.5450164079666138,
        -1.5042986869812012,
        -1.5521893501281738,
        -1.5542515516281128,
        -1.5469629764556885,
        -1.5630241632461548,
        -1.5299988985061646,
        -1.5256770849227905,
        -1.6830027103424072,
        -1.5560762882232666,
        -1.5660871267318726,
        -1.50191330909729,
        -1.6169073581695557,
        -1.5540435314178467,
        -1.5680776834487915,
        -1.5561842918395996,
        -1.537863850593567,
        -1.5751032829284668,
        -1.5592318773269653,
        -1.5569545030593872,
        -1.5905473232269287,
        -1.5831794738769531,
        -1.6038814783096313,
        -1.575828194618225,
        -1.5812667608261108,
        -1.580757737159729,
        -1.5893200635910034,
        -1.615235447883606,
        -1.6018006801605225,
        -1.5629545450210571,
        -1.5604270696640015,
        -1.5651824474334717,
        -1.5870879888534546,
        -1.5811959505081177,
        -1.6003408432006836,
        -1.5979173183441162,
        -1.596221923828125,
        -1.5999383926391602,
        -1.568963646888733,
        -1.618679404258728,
        -1.6323050260543823,
        -1.583580732345581,
        -1.5835641622543335,
        -1.603752851486206,
        -1.6028225421905518,
        -1.6078749895095825,
        -1.5992193222045898,
        -1.5831578969955444,
        -1.6530156135559082,
        -1.583774209022522,
        -1.6094844341278076,
        -1.7298104763031006,
        -1.6248161792755127,
        -1.6267461776733398,
        -1.6008497476577759,
        -1.6077880859375,
        -1.6074321269989014,
        -1.60565984249115,
        -1.5934202671051025,
        -1.6076523065567017,
        -1.6380083560943604,
        -1.600351333618164,
        -1.6305960416793823,
        -1.7639884948730469,
        -1.6135894060134888,
        -1.7591699361801147,
        -1.6434416770935059,
        -1.6192065477371216,
        -1.6062021255493164,
        -1.5945146083831787,
        -1.6763583421707153,
        -1.6042472124099731,
        -1.6225786209106445,
        -1.630688190460205,
        -1.6265907287597656,
        -1.6720386743545532,
        -1.6412898302078247,
        -1.6093403100967407,
        -1.6067651510238647,
        -1.7259414196014404,
        -1.6077826023101807,
        -1.6294384002685547,
        -1.6456910371780396,
        -1.6329524517059326,
        -1.6261788606643677,
        -1.6379140615463257,
        -1.6230123043060303,
        -1.6311149597167969,
        -1.7793207168579102,
        -1.6859281063079834,
        -1.6282086372375488,
        -1.647040605545044,
        -1.6458837985992432,
        -1.6788679361343384,
        -1.6955454349517822,
        -1.685873031616211,
        -1.7129886150360107,
        -1.6922978162765503,
        -1.693594217300415,
        -1.6672728061676025,
        -1.7515113353729248,
        -1.6589789390563965,
        -1.6897999048233032,
        -1.717583417892456,
        -1.6648876667022705,
        -1.699459433555603,
        -1.682348608970642,
        -1.795116901397705,
        -1.6741338968276978,
        -1.6691251993179321,
        -1.8041586875915527,
        -1.6707676649093628,
        -1.6823759078979492,
        -1.6765822172164917,
        -1.640196442604065,
        -1.6832035779953003,
        -1.6908808946609497,
        -1.8110721111297607,
        -1.6903306245803833,
        -1.7109975814819336,
        -1.7162930965423584,
        -1.6962484121322632,
        -1.70225191116333,
        -1.6874696016311646,
        -1.7041016817092896,
        -1.7420361042022705,
        -1.7404006719589233,
        -1.6704143285751343,
        -1.6808526515960693,
        -1.709946870803833,
        -1.7267391681671143,
        -1.6838946342468262,
        -1.7347878217697144,
        -1.7518460750579834,
        -1.6881239414215088,
        -1.726525902748108,
        -1.72309148311615,
        -1.6574562788009644,
        -1.7138041257858276,
        -1.73151695728302,
        -1.6805875301361084,
        -1.728132963180542,
        -1.684694528579712,
        -1.7243716716766357,
        -1.6840827465057373,
        -1.7619880437850952,
        -1.7463198900222778,
        -1.743526577949524,
        -1.6941884756088257,
        -1.708050012588501,
        -1.760378122329712,
        -1.7521992921829224,
        -1.7293111085891724,
        -1.7025002241134644,
        -1.7721896171569824,
        -1.757010817527771,
        -1.7173564434051514,
        -1.7104072570800781,
        -1.7542850971221924,
        -1.7455605268478394,
        -1.7242316007614136,
        -1.704093337059021,
        -1.782359004020691,
        -1.719557523727417,
        -1.7201570272445679,
        -1.7149721384048462,
        -1.7509751319885254,
        -1.7556730508804321,
        -1.7570958137512207,
        -1.7525116205215454,
        -1.7659462690353394,
        -1.7723240852355957,
        -1.885116457939148,
        -1.774163007736206,
        -1.703824758529663,
        -1.7416746616363525,
        -1.890508770942688,
        -1.7589161396026611,
        -1.7996563911437988,
        -1.762826681137085,
        -1.7769687175750732,
        -1.7594102621078491,
        -1.7467902898788452,
        -1.7684886455535889,
        -1.770983099937439,
        -1.7894600629806519,
        -1.8339825868606567,
        -1.9026188850402832,
        -1.8124525547027588,
        -1.7953336238861084,
        -1.765707015991211,
        -1.7668664455413818,
        -1.7516518831253052,
        -1.9168449640274048,
        -1.9317491054534912,
        -1.7842718362808228,
        -1.814537763595581,
        -1.7861701250076294,
        -1.7880243062973022,
        -1.790743350982666,
        -1.752684473991394,
        -1.8110424280166626,
        -1.8171769380569458,
        -1.7806950807571411,
        -1.8975176811218262,
        -1.9282951354980469,
        -1.8076306581497192,
        -1.7948238849639893,
        -1.8102571964263916,
        -1.8056443929672241,
        -1.8385026454925537,
        -1.8474704027175903,
        -1.9220439195632935,
        -1.9241180419921875,
        -1.8082330226898193,
        -1.9576239585876465,
        -1.7879750728607178,
        -1.8062222003936768,
        -1.8609622716903687,
        -1.7796071767807007,
        -1.9646342992782593,
        -1.8095788955688477,
        -1.8523104190826416,
        -1.8273013830184937,
        -1.8226068019866943,
        -1.8229659795761108,
        -1.8301862478256226,
        -1.8382443189620972,
        -1.9590229988098145,
        -1.9491137266159058,
        -1.9830960035324097,
        -1.9381967782974243,
        -1.79716956615448,
        -1.797688364982605,
        -1.80953049659729,
        -1.797119140625,
        -1.8006056547164917,
        -1.811212182044983,
        -1.8533483743667603,
        -1.8198516368865967,
        -1.8521554470062256,
        -1.8766601085662842,
        -1.877230167388916,
        -1.9934762716293335,
        -1.945402979850769,
        -1.8594815731048584,
        -1.9898711442947388,
        -1.8397177457809448,
        -1.8426228761672974,
        -1.8446294069290161,
        -1.8402953147888184,
        -1.8327887058258057,
        -1.8022441864013672,
        -1.8279080390930176,
        -1.974900245666504,
        -2.001229763031006,
        -2.001276969909668,
        -2.00106143951416,
        -1.8524976968765259,
        -1.890202283859253,
        -1.8490021228790283,
        -2.000817060470581,
        -1.8610092401504517,
        -1.9990793466567993,
        -1.836449384689331,
        -1.8689392805099487,
        -1.8430988788604736,
        -2.024261951446533,
        -1.832667350769043,
        -1.8833198547363281,
        -1.8910760879516602,
        -1.8636890649795532,
        -1.8947571516036987,
        -1.9099847078323364,
        -1.8904141187667847,
        -1.8627668619155884,
        -1.8971834182739258,
        -1.8714303970336914,
        -1.893473744392395,
        -1.8975425958633423,
        -1.903857707977295,
        -1.8545293807983398,
        -2.003535509109497,
        -2.0041778087615967,
        -1.937660574913025,
        -2.0432701110839844,
        -1.9367936849594116,
        -1.9901841878890991,
        -1.9930870532989502,
        -1.8899306058883667,
        -1.8911865949630737,
        -1.9363460540771484,
        -1.9062128067016602,
        -2.04427170753479,
        -1.9122148752212524,
        -1.8868207931518555,
        -1.9122284650802612,
        -1.9392343759536743,
        -1.9965617656707764,
        -1.886173129081726,
        -1.9459589719772339,
        -1.879326581954956,
        -1.9984345436096191,
        -2.0290253162384033,
        -1.9445139169692993,
        -1.9118332862854004,
        -2.0520334243774414,
        -2.0613646507263184,
        -2.0636515617370605,
        -2.065446615219116,
        -1.9231467247009277,
        -2.0398430824279785,
        -2.024853229522705,
        -1.906286597251892,
        -1.9411346912384033,
        -1.9321112632751465,
        -1.9419547319412231,
        -1.9389923810958862,
        -1.9451320171356201,
        -2.0305798053741455,
        -2.0349583625793457,
        -1.9295260906219482,
        -2.0610382556915283,
        -1.9350824356079102,
        -2.0605530738830566,
        -1.8803236484527588,
        -1.913582444190979,
        -1.9582034349441528,
        -2.06278920173645,
        -2.083481550216675,
        -1.9676995277404785,
        -2.0713062286376953,
        -1.9516446590423584,
        -2.067924737930298,
        -1.9278315305709839,
        -2.079951763153076,
        -2.068324327468872,
        -1.9617345333099365,
        -1.93817937374115,
        -1.9169058799743652,
        -2.0684003829956055,
        -1.918962836265564,
        -1.944682240486145,
        -1.907921314239502,
        -2.1077091693878174,
        -1.9492956399917603,
        -1.9769960641860962,
        -2.1244256496429443,
        -2.081895589828491,
        -2.076486587524414,
        -2.070463180541992,
        -2.0961661338806152,
        -2.0810329914093018,
        -2.101665496826172,
        -2.107254981994629,
        -2.1326870918273926,
        -1.9378668069839478,
        -2.0827343463897705,
        -2.098862409591675,
        -2.0887715816497803,
        -2.0970640182495117,
        -1.9962400197982788,
        -1.995903730392456,
        -2.1126270294189453,
        -2.1020243167877197,
        -2.0608062744140625,
        -1.900291085243225,
        -2.109365940093994,
        -2.0099878311157227,
        -2.0305418968200684,
        -2.118192672729492,
        -2.02546763420105,
        -2.103817939758301,
        -2.1358182430267334,
        -2.135298490524292,
        -2.101226806640625,
        -2.1042988300323486,
        -1.9864215850830078,
        -2.1531198024749756,
        -1.9614183902740479,
        -2.0085983276367188,
        -1.9961916208267212,
        -2.1334824562072754,
        -2.090174436569214,
        -1.995375156402588,
        -2.1206209659576416,
        -2.1456189155578613,
        -2.153080940246582,
        -2.0396976470947266,
        -2.126314640045166,
        -2.161424160003662,
        -2.054051160812378,
        -2.127901315689087,
        -2.012636184692383,
        -2.0858242511749268,
        -2.171969175338745,
        -2.1569628715515137,
        -2.019235372543335,
        -2.1617648601531982,
        -1.977646827697754,
        -2.1774637699127197,
        -2.1584362983703613,
        -2.043508291244507,
        -1.9936987161636353,
        -2.12678861618042,
        -2.0220794677734375,
        -2.1592698097229004,
        -2.1575927734375,
        -2.192974805831909,
        -2.01906418800354,
        -2.1614809036254883,
        -2.1702888011932373,
        -2.148285150527954,
        -2.1701579093933105,
        -2.169178009033203,
        -2.1748602390289307,
        -2.0807840824127197,
        -2.15508770942688,
        -2.0352325439453125,
        -2.174865245819092,
        -2.173880100250244,
        -1.9995896816253662,
        -2.0412495136260986,
        -2.0522892475128174,
        -2.186199903488159,
        -2.053929090499878,
        -2.0233986377716064,
        -2.0696423053741455,
        -2.1750237941741943,
        -2.0834577083587646,
        -2.190720319747925,
        -2.17543625831604,
        -2.167295455932617,
        -2.1854889392852783,
        -2.191472053527832,
        -2.0273008346557617,
        -2.1672370433807373,
        -2.0771453380584717,
        -2.1877479553222656,
        -2.2207930088043213,
        -2.213071346282959,
        -2.0604686737060547,
        -2.1953396797180176,
        -2.069779634475708,
        -2.1878092288970947,
        -2.2129626274108887,
        -2.195258378982544,
        -2.2036545276641846,
        -2.0869691371917725,
        -2.220012903213501,
        -2.2127866744995117,
        -2.207817554473877,
        -2.190854072570801,
        -2.0805513858795166,
        -2.1027026176452637,
        -2.081697702407837,
        -2.2045562267303467,
        -2.160801410675049,
        -2.050452470779419,
        -2.2402052879333496,
        -2.1934988498687744,
        -2.2036476135253906,
        -2.22870135307312,
        -2.0947864055633545,
        -2.2044365406036377,
        -2.1734824180603027,
        -2.205565929412842,
        -2.2149322032928467,
        -2.221266746520996,
        -2.2274110317230225,
        -2.183737277984619,
        -2.095543146133423,
        -2.1952672004699707,
        -2.123965263366699,
        -2.129715919494629,
        -2.227370262145996,
        -2.207639694213867,
        -2.078281879425049,
        -2.2226767539978027,
        -2.125084161758423,
        -2.2031421661376953,
        -2.0790700912475586,
        -2.088256597518921,
        -2.07924485206604,
        -2.2356436252593994,
        -2.2290515899658203,
        -2.145029306411743,
        -2.201916217803955,
        -2.254053831100464,
        -2.105902910232544,
        -2.2518041133880615,
        -2.2291197776794434,
        -2.1151561737060547,
        -2.138181447982788,
        -2.2445640563964844,
        -2.1000702381134033,
        -2.2453601360321045,
        -2.123553991317749,
        -2.2635152339935303,
        -2.1346073150634766,
        -2.2159924507141113,
        -2.2264015674591064,
        -2.2298600673675537,
        -2.115138530731201,
        -2.125025987625122,
        -2.2279276847839355,
        -2.1283230781555176,
        -2.260294198989868,
        -2.252206563949585,
        -2.257192373275757,
        -2.24462628364563,
        -2.2313685417175293,
        -2.1970415115356445,
        -2.237480401992798,
        -2.2183640003204346,
        -2.2508437633514404,
        -2.089643955230713,
        -2.25612211227417,
        -2.2655487060546875,
        -2.264962911605835,
        -2.211846351623535,
        -2.277723550796509,
        -2.2604098320007324,
        -2.0665481090545654,
        -2.1688153743743896,
        -2.171820878982544,
        -2.254641056060791,
        -2.1721959114074707,
        -2.2902443408966064,
        -2.11702299118042,
        -2.128737211227417,
        -2.1069605350494385,
        -2.1568570137023926,
        -2.280796766281128,
        -2.164828062057495,
        -2.28145170211792,
        -2.281451463699341,
        -2.1590607166290283,
        -2.2740840911865234,
        -2.15995192527771,
        -2.2209198474884033,
        -2.2760133743286133,
        -2.2024102210998535,
        -2.2739129066467285,
        -2.1581928730010986,
        -2.265367031097412,
        -2.133071184158325,
        -2.132631540298462,
        -2.1950156688690186,
        -2.3203792572021484,
        -2.329848527908325,
        -2.1818575859069824,
        -2.305720090866089,
        -2.1931416988372803,
        -2.185675621032715,
        -2.322772979736328,
        -2.236551284790039,
        -2.285659074783325,
        -2.320540428161621,
        -2.3237264156341553,
        -2.2873940467834473,
        -2.098191261291504,
        -2.136110544204712,
        -2.3036069869995117,
        -2.3100204467773438,
        -2.3210058212280273,
        -2.2904253005981445,
        -2.295292377471924,
        -2.153826951980591,
        -2.3342394828796387,
        -2.315824508666992,
        -2.2580220699310303,
        -2.2124156951904297,
        -2.195146322250366,
        -2.2967429161071777,
        -2.2373530864715576,
        -2.3001067638397217,
        -2.325765371322632,
        -2.2737531661987305,
        -2.338905096054077,
        -2.195171594619751,
        -2.3346352577209473,
        -2.1761868000030518,
        -2.183583974838257,
        -2.189725160598755,
        -2.319845676422119,
        -2.306971788406372,
        -2.3402481079101562,
        -2.311485767364502,
        -2.3285655975341797,
        -2.3334245681762695,
        -2.3554019927978516,
        -2.348985433578491,
        -2.344757556915283,
        -2.2035560607910156,
        -2.2094645500183105,
        -2.325408935546875,
        -2.2891228199005127,
        -2.196739912033081,
        -2.322126626968384,
        -2.3208582401275635,
        -2.33091402053833,
        -2.3085203170776367,
        -2.2942981719970703,
        -2.3014140129089355,
        -2.217287063598633,
        -2.3310868740081787,
        -2.2680625915527344,
        -2.344707727432251,
        -2.343686103820801,
        -2.3517980575561523,
        -2.219867467880249,
        -2.3517749309539795,
        -2.352245330810547,
        -2.201509714126587,
        -2.34512996673584,
        -2.231085777282715,
        -2.3508617877960205,
        -2.191312789916992,
        -2.3308591842651367,
        -2.35292911529541,
        -2.309652090072632,
        -2.2273929119110107,
        -2.3548221588134766,
        -2.2462961673736572,
        -2.3580470085144043,
        -2.3583595752716064,
        -2.3774664402008057,
        -2.213132619857788,
        -2.36303973197937,
        -2.3494856357574463,
        -2.3884263038635254,
        -2.247960329055786,
        -2.2250354290008545,
        -2.3682007789611816,
        -2.2333154678344727,
        -2.373746871948242,
        -2.3086206912994385,
        -2.2414143085479736,
        -2.2436797618865967,
        -2.3954110145568848,
        -2.246788740158081,
        -2.3250770568847656,
        -2.411241292953491,
        -2.3860135078430176,
        -2.2746260166168213,
        -2.2457947731018066,
        -2.3615152835845947,
        -2.345740556716919,
        -2.40217661857605,
        -2.384699821472168,
        -2.2656960487365723,
        -2.3383591175079346,
        -2.4400908946990967,
        -2.316112756729126,
        -2.372774839401245,
        -2.293949842453003,
        -2.3747310638427734,
        -2.2801082134246826,
        -2.273198127746582,
        -2.2855465412139893,
        -2.2731168270111084,
        -2.298778772354126,
        -2.300705909729004,
        -2.2797720432281494,
        -2.4075801372528076,
        -2.2971839904785156,
        -2.439883232116699,
        -2.39154052734375,
        -2.2823143005371094,
        -2.399746894836426,
        -2.4322330951690674,
        -2.405552625656128,
        -2.447740316390991,
        -2.3632943630218506,
        -2.3739023208618164,
        -2.41939640045166,
        -2.41190505027771,
        -2.3771681785583496,
        -2.3454465866088867,
        -2.3087852001190186,
        -2.2972261905670166,
        -2.3825299739837646,
        -2.4428231716156006,
        -2.307297706604004,
        -2.3308122158050537,
        -2.4435203075408936,
        -2.338998794555664,
        -2.3130576610565186,
        -2.453073024749756,
        -2.2983343601226807,
        -2.4510657787323,
        -2.3526840209960938,
        -2.360719680786133,
        -2.4096388816833496,
        -2.4420993328094482,
        -2.408869743347168,
        -2.311278820037842,
        -2.4564554691314697,
        -2.4383132457733154,
        -2.3366663455963135,
        -2.3416852951049805,
        -2.4275424480438232,
        -2.421815872192383,
        -2.4144418239593506,
        -2.3444883823394775,
        -2.4402196407318115,
        -2.3418142795562744,
        -2.4591028690338135,
        -2.4658496379852295,
        -2.460627317428589,
        -2.5089306831359863,
        -2.3404488563537598,
        -2.3515937328338623,
        -2.432047128677368,
        -2.4549248218536377,
        -2.3496806621551514,
        -2.388427972793579,
        -2.3313517570495605,
        -2.3355839252471924,
        -2.456782102584839,
        -2.4924492835998535,
        -2.44083571434021,
        -2.4703941345214844,
        -2.336944103240967,
        -2.446589946746826,
        -2.334092378616333,
        -2.3719584941864014,
        -2.368516445159912,
        -2.395691156387329,
        -2.486070156097412,
        -2.3086438179016113,
        -2.3371360301971436,
        -2.490419626235962,
        -2.3680009841918945,
        -2.351195812225342,
        -2.469033718109131,
        -2.490924596786499,
        -2.465101957321167,
        -2.3213305473327637,
        -2.4968371391296387,
        -2.475264310836792,
        -2.3820576667785645,
        -2.485722303390503,
        -2.369446039199829,
        -2.358996629714966,
        -2.464045763015747,
        -2.398756742477417,
        -2.4736883640289307,
        -2.491225004196167,
        -2.41520619392395,
        -2.4822983741760254,
        -2.4143991470336914,
        -2.5398998260498047,
        -2.351792573928833,
        -2.5171821117401123,
        -2.4793107509613037,
        -2.5388383865356445,
        -2.540760040283203,
        -2.3865866661071777,
        -2.3527750968933105,
        -2.5131783485412598,
        -2.3781025409698486,
        -2.5280725955963135,
        -2.523124933242798,
        -2.51570463180542,
        -2.3888964653015137,
        -2.514105796813965,
        -2.494875192642212,
        -2.513998508453369,
        -2.4719510078430176,
        -2.4915802478790283,
        -2.554964303970337,
        -2.523622512817383,
        -2.541844129562378,
        -2.4045889377593994,
        -2.428623914718628,
        -2.5437121391296387,
        -2.4459033012390137,
        -2.531179189682007,
        -2.5475306510925293,
        -2.5234735012054443,
        -2.4935710430145264,
        -2.408782720565796,
        -2.52658748626709,
        -2.4170122146606445,
        -2.547858238220215,
        -2.562063217163086,
        -2.5024783611297607,
        -2.5066561698913574,
        -2.538689374923706,
        -2.581390857696533,
        -2.508716106414795,
        -2.550313949584961,
        -2.5350136756896973,
        -2.4398183822631836,
        -2.4312944412231445,
        -2.5080225467681885,
        -2.524937868118286,
        -2.5562245845794678,
        -2.4397330284118652,
        -2.5030744075775146,
        -2.5471272468566895,
        -2.562509536743164,
        -2.5504560470581055,
        -2.597048044204712,
        -2.5628035068511963,
        -2.5867228507995605,
        -2.5971462726593018,
        -2.603870391845703,
        -2.5572869777679443,
        -2.5968117713928223,
        -2.5968337059020996,
        -2.5982556343078613,
        -2.466405153274536,
        -2.442615032196045,
        -2.4511542320251465,
        -2.597121238708496,
        -2.6048741340637207,
        -2.5699048042297363,
        -2.5224573612213135,
        -2.597928047180176,
        -2.4521286487579346,
        -2.560976982116699,
        -2.5971579551696777,
        -2.567720413208008,
        -2.4495091438293457,
        -2.5794413089752197,
        -2.587658643722534,
        -2.4877376556396484,
        -2.5552759170532227,
        -2.569375991821289,
        -2.594363212585449,
        -2.5821337699890137,
        -2.584108591079712,
        -2.5595614910125732,
        -2.471714735031128,
        -2.62707781791687,
        -2.5853826999664307,
        -2.572906017303467,
        -2.6182491779327393,
        -2.550201416015625,
        -2.545545816421509,
        -2.4202897548675537,
        -2.5520522594451904,
        -2.5861711502075195,
        -2.5857598781585693,
        -2.6145880222320557,
        -2.469407796859741,
        -2.478019952774048,
        -2.580946445465088,
        -2.5005342960357666,
        -2.6075327396392822,
        -2.4885473251342773,
        -2.5797650814056396,
        -2.5671842098236084,
        -2.4988605976104736,
        -2.498723268508911,
        -2.5867233276367188,
        -2.4980993270874023,
        -2.5741374492645264,
        -2.634999990463257,
        -2.514331340789795,
        -2.477440118789673,
        -2.607591152191162,
        -2.6037957668304443,
        -2.6110992431640625,
        -2.4711928367614746,
        -2.573188543319702,
        -2.5104424953460693,
        -2.63083815574646,
        -2.621483325958252,
        -2.552436113357544,
        -2.598646640777588,
        -2.64510178565979,
        -2.6389572620391846,
        -2.5917415618896484,
        -2.601539373397827,
        -2.610581159591675,
        -2.5088090896606445,
        -2.585792303085327,
        -2.5291502475738525,
        -2.6465089321136475,
        -2.650231122970581,
        -2.6362173557281494,
        -2.638456344604492,
        -2.6210951805114746,
        -2.6097826957702637,
        -2.6533267498016357,
        -2.660861015319824,
        -2.588040590286255,
        -2.675839900970459,
        -2.5495688915252686,
        -2.622626543045044,
        -2.628925323486328,
        -2.7002978324890137,
        -2.6759674549102783,
        -2.6493167877197266,
        -2.5259270668029785,
        -2.630756378173828,
        -2.557020664215088,
        -2.6037673950195312,
        -2.658979654312134,
        -2.642367124557495,
        -2.6567437648773193,
        -2.5594594478607178,
        -2.635868787765503,
        -2.6550180912017822,
        -2.6686811447143555,
        -2.6550028324127197,
        -2.5717718601226807,
        -2.641536235809326,
        -2.6526150703430176,
        -2.680569887161255,
        -2.6538126468658447,
        -2.615373134613037,
        -2.637115240097046,
        -2.6301045417785645,
        -2.662731409072876,
        -2.690096855163574,
        -2.6551661491394043,
        -2.692441940307617,
        -2.6559927463531494,
        -2.6958577632904053,
        -2.6432483196258545,
        -2.6529626846313477,
        -2.5410218238830566,
        -2.715975046157837,
        -2.5491867065429688,
        -2.6791787147521973,
        -2.663811445236206,
        -2.5599963665008545,
        -2.685426712036133,
        -2.7431888580322266,
        -2.696119785308838,
        -2.6850457191467285,
        -2.650531768798828,
        -2.682506561279297,
        -2.5891177654266357,
        -2.706186056137085,
        -2.5588538646698,
        -2.5487923622131348,
        -2.660008430480957,
        -2.736513137817383,
        -2.593301773071289,
        -2.698092460632324,
        -2.725231170654297,
        -2.7039811611175537,
        -2.7247684001922607,
        -2.5625345706939697,
        -2.6890110969543457,
        -2.7322797775268555,
        -2.593001365661621,
        -2.7131295204162598,
        -2.5494067668914795,
        -2.7069215774536133,
        -2.582183599472046,
        -2.590189218521118,
        -2.7176969051361084,
        -2.711437225341797,
        -2.7329375743865967,
        -2.72446608543396,
        -2.6272783279418945,
        -2.731959581375122,
        -2.7395007610321045,
        -2.7317628860473633,
        -2.7626421451568604,
        -2.757880449295044,
        -2.723236560821533,
        -2.742715358734131,
        -2.709862470626831,
        -2.7488629817962646,
        -2.7457046508789062,
        -2.7384414672851562,
        -2.7790162563323975,
        -2.732045888900757,
        -2.672927141189575,
        -2.7372331619262695,
        -2.7723822593688965,
        -2.8012824058532715,
        -2.8016796112060547,
        -2.8004491329193115,
        -2.7793128490448,
        -2.801072835922241,
        -2.632361650466919,
        -2.72306227684021,
        -2.7802929878234863,
        -2.773472785949707,
        -2.800501585006714,
        -2.8009746074676514,
        -2.791271209716797,
        -2.763509511947632,
        -2.7570574283599854,
        -2.6613051891326904,
        -2.7803688049316406,
        -2.7997634410858154,
        -2.6579999923706055,
        -2.7531862258911133,
        -2.774914503097534,
        -2.657696008682251,
        -2.6610465049743652,
        -2.6370017528533936,
        -2.7903759479522705,
        -2.7222557067871094,
        -2.769853115081787,
        -2.774405002593994,
        -2.711893320083618,
        -2.796168327331543,
        -2.800424575805664,
        -2.778858184814453,
        -2.6628360748291016,
        -2.822944402694702,
        -2.7864348888397217,
        -2.8056819438934326,
        -2.7753970623016357,
        -2.815812349319458,
        -2.6829066276550293,
        -2.801900625228882,
        -2.7896549701690674,
        -2.827216148376465,
        -2.747091293334961,
        -2.79811429977417,
        -2.6368582248687744,
        -2.784541606903076,
        -2.7661125659942627,
        -2.7971575260162354,
        -2.790334463119507,
        -2.702493190765381,
        -2.8022117614746094,
        -2.812950849533081,
        -2.803675889968872,
        -2.732126474380493,
        -2.7131264209747314,
        -2.8330769538879395,
        -2.8626632690429688,
        -2.854527711868286,
        -2.7622406482696533,
        -2.8826653957366943,
        -2.7638955116271973,
        -2.834345579147339,
        -2.7211480140686035,
        -2.764936923980713,
        -2.8410332202911377,
        -2.7326016426086426,
        -2.836867570877075,
        -2.8235909938812256,
        -2.8896543979644775,
        -2.8804469108581543,
        -2.852316379547119,
        -2.741347551345825,
        -2.8834071159362793,
        -2.794522285461426,
        -2.863046646118164,
        -2.918991804122925,
        -2.7984976768493652,
        -2.8894224166870117,
        -2.7385034561157227,
        -2.7882704734802246,
        -2.897883176803589,
        -2.8810536861419678,
        -2.8352441787719727,
        -2.9160513877868652,
        -2.90362811088562,
        -2.831054449081421,
        -2.8275351524353027,
        -2.7371203899383545,
        -2.893512487411499,
        -2.90867018699646,
        -2.79947566986084,
        -2.9149489402770996,
        -2.737645149230957,
        -2.8416249752044678,
        -2.7696359157562256,
        -2.7823729515075684,
        -2.9190046787261963,
        -2.9480230808258057,
        -2.881038188934326,
        -2.8964109420776367,
        -2.9294707775115967,
        -2.9374256134033203,
        -2.917116403579712,
        -2.9198110103607178,
        -2.9079575538635254,
        -2.801605224609375,
        -2.8164596557617188,
        -2.79498291015625,
        -2.8938393592834473,
        -2.8122992515563965,
        -2.917678117752075,
        -2.966120481491089,
        -2.7992639541625977,
        -2.8496572971343994,
        -2.8039023876190186,
        -2.828425884246826,
        -2.947385311126709,
        -2.9371728897094727,
        -2.930413246154785,
        -2.8489668369293213,
        -2.9553778171539307,
        -2.972836494445801,
        -2.96087646484375,
        -2.971951484680176,
        -2.7972159385681152,
        -2.902926445007324,
        -2.9254150390625,
        -2.826145887374878,
        -2.875418186187744,
        -2.8377914428710938,
        -2.9706106185913086,
        -2.9494969844818115,
        -2.9074950218200684,
        -2.8391921520233154,
        -2.862900972366333,
        -2.857043504714966,
        -2.8447232246398926,
        -3.0182995796203613,
        -2.95029354095459,
        -2.8976633548736572,
        -3.017207145690918,
        -2.870147228240967,
        -3.016601800918579,
        -2.9210731983184814,
        -2.795175313949585,
        -2.86112380027771,
        -3.007978677749634,
        -2.852010726928711,
        -2.8424525260925293,
        -2.987642526626587,
        -2.892090320587158,
        -3.0172791481018066,
        -2.8672609329223633,
        -2.8987720012664795,
        -2.8500168323516846,
        -2.874605417251587,
        -2.8717269897460938,
        -2.9743335247039795,
        -2.8950164318084717,
        -3.023912191390991,
        -2.9063665866851807,
        -2.904693365097046,
        -3.017148017883301,
        -2.934650182723999,
        -2.895071506500244,
        -2.989166021347046,
        -2.8750925064086914,
        -2.8861374855041504,
        -2.8955652713775635,
        -2.997276544570923,
        -2.8933932781219482,
        -3.0141053199768066,
        -2.9587831497192383,
        -2.8927500247955322,
        -2.8941826820373535,
        -2.91047739982605,
        -2.911569356918335,
        -3.0219151973724365,
        -2.930588483810425,
        -3.0184078216552734,
        -3.006535530090332,
        -3.033357620239258,
        -2.9320778846740723,
        -2.9539952278137207,
        -3.0059571266174316,
        -2.9353063106536865,
        -3.0446972846984863,
        -2.9543440341949463,
        -2.969059944152832,
        -3.0827858448028564,
        -3.070432424545288,
        -2.9809067249298096,
        -3.0491392612457275,
        -3.092803955078125,
        -3.078155279159546,
        -3.1352126598358154,
        -3.0715243816375732,
        -3.110097885131836,
        -3.0084002017974854,
        -3.068748712539673,
        -3.0879173278808594,
        -2.936616897583008,
        -3.0085012912750244,
        -3.0856552124023438,
        -3.0609560012817383,
        -2.986208915710449,
        -3.0558838844299316,
        -2.9637579917907715,
        -3.143263578414917,
        -3.1240859031677246,
        -2.9925615787506104,
        -2.9876725673675537,
        -3.093524217605591,
        -3.0572988986968994,
        -2.9852564334869385,
        -3.0587756633758545,
        -3.0414650440216064,
        -2.9618988037109375,
        -3.0392937660217285,
        -3.134827136993408,
        -3.1295342445373535,
        -3.138288974761963,
        -3.127722978591919,
        -3.0255799293518066,
        -3.078037977218628,
        -3.137998580932617,
        -3.044158935546875,
        -3.1376497745513916,
        -3.1453700065612793,
        -3.1819067001342773,
        -3.0038912296295166,
        -3.1376993656158447,
        -3.082263469696045,
        -3.081544876098633,
        -3.1377463340759277,
        -3.1845786571502686,
        -3.1136796474456787,
        -3.1939845085144043,
        -3.2322824001312256,
        -3.079955577850342,
        -3.1938393115997314,
        -3.1955952644348145,
        -3.170719623565674,
        -3.0358402729034424,
        -3.0805413722991943,
        -3.169288396835327,
        -3.163194179534912,
        -3.1442949771881104,
        -3.154951810836792,
        -3.0588297843933105,
        -3.244213819503784,
        -3.1680824756622314,
        -3.0725417137145996,
        -3.1402957439422607,
        -3.1832027435302734,
        -3.103515625,
        -3.1897597312927246,
        -3.188549041748047,
        -3.130540370941162,
        -3.2498490810394287,
        -3.2091317176818848,
        -3.144193410873413,
        -3.221910238265991,
        -3.052325963973999,
        -3.189725399017334,
        -3.1004388332366943,
        -3.1215319633483887,
        -3.2188382148742676,
        -3.204254388809204,
        -3.2570998668670654,
        -3.2815475463867188,
        -3.224172353744507,
        -3.220245599746704,
        -3.2392313480377197,
        -3.177318811416626,
        -3.2238857746124268,
        -3.3379175662994385,
        -3.125458240509033,
        -3.2645208835601807,
        -3.210444688796997,
        -3.25052547454834,
        -3.191594123840332,
        -3.249979257583618,
        -3.1399455070495605,
        -3.2792506217956543,
        -3.1854798793792725,
        -3.1863181591033936,
        -3.1241092681884766,
        -3.218834400177002,
        -3.1569340229034424,
        -3.310856342315674,
        -3.268411159515381,
        -3.1415348052978516,
        -3.1881749629974365,
        -3.209937810897827,
        -3.2477688789367676,
        -3.3056769371032715,
        -3.2760379314422607,
        -3.246265411376953,
        -3.255946397781372,
        -3.2076053619384766,
        -3.295438051223755,
        -3.3002138137817383,
        -3.275543689727783,
        -3.2211110591888428,
        -3.222980260848999,
        -3.3090004920959473,
        -3.25862193107605,
        -3.2567410469055176,
        -3.301471710205078,
        -3.2208359241485596,
        -3.259998321533203,
        -3.2265310287475586,
        -3.258545398712158,
        -3.258985757827759,
        -3.3227574825286865,
        -3.3676609992980957,
        -3.3140814304351807,
        -3.280576705932617,
        -3.335740327835083,
        -3.216701030731201,
        -3.3872604370117188,
        -3.417567014694214,
        -3.344156503677368,
        -3.4205660820007324,
        -3.213062286376953,
        -3.2953901290893555,
        -3.417142629623413,
        -3.3861448764801025,
        -3.350184679031372,
        -3.2497808933258057,
        -3.283883810043335,
        -3.326802968978882,
        -3.3322668075561523,
        -3.276013135910034,
        -3.457315683364868,
        -3.3051254749298096,
        -3.3448972702026367,
        -3.219621419906616,
        -3.441338062286377,
        -3.3332009315490723,
        -3.4556186199188232,
        -3.323383092880249,
        -3.331831932067871,
        -3.4136946201324463,
        -3.351440906524658,
        -3.326988935470581,
        -3.401262044906616,
        -3.3241851329803467,
        -3.4298923015594482,
        -3.3941550254821777,
        -3.4624218940734863,
        -3.4415171146392822,
        -3.4853594303131104,
        -3.3806440830230713,
        -3.390239715576172,
        -3.444035291671753,
        -3.504894971847534,
        -3.4692118167877197,
        -3.390655994415283,
        -3.4211220741271973,
        -3.4684126377105713,
        -3.4794421195983887,
        -3.4120676517486572,
        -3.372631788253784,
        -3.4095242023468018,
        -3.448451042175293,
        -3.49349308013916,
        -3.4997568130493164,
        -3.4218697547912598,
        -3.484849691390991,
        -3.5316686630249023,
        -3.498112201690674,
        -3.466360330581665,
        -3.5315396785736084,
        -3.4788920879364014,
        -3.505079746246338,
        -3.436976194381714,
        -3.4711692333221436,
        -3.487025022506714,
        -3.5997838973999023,
        -3.575012683868408,
        -3.497892379760742,
        -3.518404245376587,
        -3.476487636566162,
        -3.527355670928955,
        -3.5241732597351074,
        -3.4427804946899414,
        -3.5084431171417236,
        -3.544597864151001,
        -3.4682106971740723,
        -3.5030107498168945,
        -3.541604995727539,
        -3.5517125129699707,
        -3.528326988220215,
        -3.5459659099578857,
        -3.52471661567688,
        -3.4891037940979004,
        -3.4951581954956055,
        -3.491943836212158,
        -3.585618734359741,
        -3.5752806663513184,
        -3.568594217300415,
        -3.573011875152588,
        -3.666982650756836,
        -3.577096462249756,
        -3.5416221618652344,
        -3.5654213428497314,
        -3.5744307041168213,
        -3.523956775665283,
        -3.654890775680542,
        -3.5801916122436523,
        -3.5300400257110596,
        -3.555114984512329,
        -3.5965471267700195,
        -3.5304081439971924,
        -3.5954103469848633,
        -3.5798933506011963,
        -3.640995740890503,
        -3.554158926010132,
        -3.5606205463409424,
        -3.569836139678955,
        -3.586698532104492,
        -3.635793447494507,
        -3.614638090133667,
        -3.6900172233581543,
        -3.607938528060913,
        -3.5210814476013184,
        -3.6899642944335938,
        -3.699662685394287,
        -3.6039037704467773,
        -3.6909677982330322,
        -3.544245481491089,
        -3.5736465454101562,
        -3.574394702911377,
        -3.668718099594116,
        -3.6439545154571533,
        -3.7092840671539307,
        -3.5963988304138184,
        -3.556368589401245,
        -3.733978509902954,
        -3.6862592697143555,
        -3.732515335083008,
        -3.7244277000427246,
        -3.736447811126709,
        -3.6300277709960938,
        -3.719339609146118,
        -3.6359376907348633,
        -3.7285139560699463,
        -3.7837917804718018,
        -3.7617275714874268,
        -3.742812156677246,
        -3.720263719558716,
        -3.667027473449707,
        -3.7339518070220947,
        -3.7359869480133057,
        -3.7509477138519287,
        -3.6628975868225098,
        -3.761645555496216,
        -3.7451539039611816,
        -3.805628776550293,
        -3.6791696548461914,
        -3.760164737701416,
        -3.766855239868164,
        -3.638472557067871,
        -3.72819185256958,
        -3.7189807891845703,
        -3.6676957607269287,
        -3.7195911407470703,
        -3.7717673778533936,
        -3.705521583557129,
        -3.800065040588379,
        -3.73897385597229,
        -3.819305419921875,
        -3.845155715942383,
        -3.784930944442749,
        -3.7723212242126465,
        -3.802380084991455,
        -3.7878379821777344,
        -3.752979040145874,
        -3.748710870742798,
        -3.683285713195801,
        -3.66337251663208,
        -3.8065245151519775,
        -3.7334818840026855,
        -3.723418951034546,
        -3.7024590969085693,
        -3.712663173675537,
        -3.7537477016448975,
        -3.686042308807373,
        -3.8171627521514893,
        -3.8106648921966553,
        -3.8321306705474854,
        -3.6964266300201416,
        -3.797752618789673,
        -3.748016357421875,
        -3.700269937515259,
        -3.8593978881835938,
        -3.8360095024108887,
        -3.783308267593384,
        -3.8643200397491455,
        -3.7629177570343018,
        -3.7756006717681885,
        -3.7483952045440674,
        -3.6905062198638916,
        -3.8601109981536865,
        -3.7275171279907227,
        -3.821342706680298,
        -3.897958278656006,
        -3.8729186058044434,
        -3.8408455848693848,
        -3.876067638397217,
        -3.845799446105957,
        -3.8592541217803955,
        -3.8699166774749756,
        -3.8649232387542725,
        -3.843479633331299,
        -3.7667596340179443,
        -3.8464529514312744,
        -3.7893929481506348,
        -3.9427738189697266,
        -3.8011324405670166,
        -3.845895290374756,
        -3.7690582275390625,
        -3.8664982318878174,
        -3.829619884490967,
        -3.855957508087158,
        -3.895416736602783,
        -3.9354987144470215,
        -3.8418498039245605,
        -3.9401159286499023,
        -3.8880715370178223,
        -3.841841459274292,
        -3.8568954467773438,
        -3.8356165885925293,
        -3.823598861694336,
        -3.8949146270751953,
        -3.922609329223633,
        -3.8463692665100098,
        -3.801670551300049,
        -3.8885388374328613,
        -3.875148296356201,
        -3.8933677673339844,
        -3.7606546878814697,
        -3.9356415271759033,
        -3.9474780559539795,
        -3.9023778438568115,
        -3.862513780593872,
        -3.7823143005371094,
        -3.9609644412994385,
        -3.85949969291687,
        -3.862545967102051,
        -3.8910341262817383,
        -3.885206460952759,
        -3.9184529781341553,
        -3.7607524394989014,
        -3.875638008117676,
        -3.9656150341033936,
        -3.963038921356201,
        -3.859137535095215,
        -3.975375175476074,
        -3.931426525115967,
        -3.9805748462677,
        -3.9355032444000244,
        -3.93503999710083,
        -4.018631935119629,
        -3.9831292629241943,
        -3.9441781044006348,
        -4.0331711769104,
        -3.891401529312134,
        -3.9076507091522217,
        -3.9754412174224854,
        -3.955596685409546,
        -3.9568216800689697,
        -4.007110118865967,
        -3.918438196182251,
        -4.00911808013916,
        -3.9580628871917725,
        -4.015763759613037,
        -3.9178428649902344,
        -4.009759902954102,
        -3.9845635890960693,
        -3.952622413635254,
        -3.9185545444488525,
        -3.943281650543213,
        -3.932736396789551,
        -4.0553975105285645,
        -3.8564488887786865,
        -4.055288314819336,
        -3.9923877716064453,
        -4.0146284103393555,
        -3.891367197036743,
        -3.9463002681732178,
        -3.9543089866638184,
        -4.011275291442871,
        -3.9318652153015137,
        -4.0321245193481445,
        -3.966994047164917,
        -4.001497268676758,
        -3.982555389404297,
        -3.994370698928833,
        -4.107938766479492,
        -3.973341941833496,
        -4.01415491104126,
        -4.025667667388916,
        -3.989039659500122,
        -4.0044732093811035,
        -3.988304615020752,
        -3.9874067306518555,
        -3.9895806312561035,
        -4.039575099945068,
        -4.017902374267578,
        -3.8972690105438232,
        -4.04948616027832,
        -3.9725983142852783,
        -4.030719757080078,
        -4.050678730010986,
        -4.046876907348633,
        -4.0684943199157715,
        -4.019201755523682,
        -4.063660144805908,
        -3.984044075012207,
        -3.972151756286621,
        -4.074123382568359,
        -4.151986122131348,
        -3.948648691177368,
        -4.078059673309326,
        -4.030881404876709,
        -4.067960739135742,
        -4.0486741065979,
        -3.9011757373809814,
        -4.022524833679199,
        -4.130332946777344,
        -4.0963263511657715,
        -3.971881151199341,
        -4.048065662384033,
        -4.080617904663086,
        -4.11794376373291,
        -4.084094047546387,
        -4.064190864562988,
        -4.144150733947754,
        -4.020692348480225,
        -4.013628005981445,
        -4.097663402557373,
        -4.128324508666992,
        -4.089134693145752,
        -4.1275506019592285,
        -4.028522968292236,
        -4.0889081954956055,
        -4.120589733123779,
        -3.9946072101593018,
        -4.160099983215332,
        -4.125863552093506,
        -3.9929916858673096,
        -4.061549663543701,
        -4.042465686798096,
        -4.150418281555176,
        -4.0551228523254395,
        -4.066923141479492,
        -4.148970603942871,
        -4.127335548400879,
        -3.99094820022583,
        -4.139838218688965,
        -4.087629318237305,
        -4.153085231781006,
        -4.072784423828125,
        -4.151668548583984,
        -4.001578330993652,
        -4.132072925567627,
        -4.155071258544922,
        -4.091176986694336,
        -4.202868461608887,
        -4.073463439941406,
        -4.143118381500244,
        -4.090719223022461,
        -4.078848838806152,
        -4.111212730407715,
        -4.057048797607422,
        -4.064334392547607,
        -4.046947002410889,
        -4.1216912269592285,
        -4.22794771194458,
        -4.132565975189209,
        -4.033689022064209,
        -4.084347248077393,
        -4.1595540046691895,
        -4.126713752746582,
        -4.232175827026367,
        -4.1926188468933105,
        -4.195132255554199,
        -4.180765628814697,
        -4.202291488647461,
        -4.19000244140625,
        -4.256282329559326,
        -4.193027496337891,
        -4.170725345611572,
        -4.249245643615723,
        -4.2278151512146,
        -4.1855340003967285,
        -4.169511318206787,
        -4.145830154418945,
        -4.168825149536133,
        -4.1718878746032715,
        -4.128034591674805,
        -4.127907752990723,
        -4.1719651222229,
        -4.1621809005737305,
        -4.121965408325195,
        -4.139588832855225,
        -4.154585361480713,
        -4.173469066619873,
        -4.276499271392822,
        -4.20921516418457,
        -4.1326069831848145,
        -4.125394821166992,
        -4.252849102020264,
        -4.230134010314941,
        -4.249715328216553,
        -4.229408264160156,
        -4.308838367462158,
        -4.236234188079834,
        -4.271804332733154,
        -4.1645636558532715,
        -4.20550012588501,
        -4.191789627075195,
        -4.25094747543335,
        -4.1899847984313965,
        -4.208395481109619,
        -4.20989990234375,
        -4.217658519744873,
        -4.2024455070495605,
        -4.234084606170654,
        -4.195432662963867,
        -4.26715612411499,
        -4.110670566558838,
        -4.250347137451172,
        -4.232839584350586,
        -4.28205680847168,
        -4.323587417602539,
        -4.313747406005859,
        -4.154973030090332,
        -4.310768127441406,
        -4.311642646789551,
        -4.270371913909912,
        -4.23121976852417,
        -4.236799716949463,
        -4.326533794403076,
        -4.2483296394348145,
        -4.248924732208252,
        -4.390505790710449,
        -4.297237873077393,
        -4.263097763061523,
        -4.2683892250061035,
        -4.329319477081299,
        -4.282978057861328,
        -4.232738018035889,
        -4.291290760040283,
        -4.24133825302124,
        -4.26987886428833,
        -4.336770057678223,
        -4.353398323059082,
        -4.3752121925354,
        -4.266798496246338,
        -4.43546199798584,
        -4.258715629577637,
        -4.3599467277526855,
        -4.237002849578857,
        -4.342155933380127,
        -4.370371341705322,
        -4.389155387878418,
        -4.497621536254883,
        -4.411009311676025,
        -4.381287574768066,
        -4.324245452880859,
        -4.378836631774902,
        -4.376245975494385,
        -4.258030891418457,
        -4.388453006744385,
        -4.4129109382629395,
        -4.395711898803711,
        -4.379568099975586,
        -4.32075834274292,
        -4.459365367889404,
        -4.3979997634887695,
        -4.454487323760986,
        -4.383443355560303,
        -4.347777843475342,
        -4.240449905395508,
        -4.446455478668213,
        -4.3741936683654785,
        -4.369471549987793,
        -4.376935005187988,
        -4.3041815757751465,
        -4.362893581390381,
        -4.4290642738342285,
        -4.412354946136475,
        -4.352872371673584,
        -4.365365982055664,
        -4.312195301055908,
        -4.403968811035156,
        -4.471970558166504,
        -4.3831095695495605,
        -4.333100318908691,
        -4.379733562469482,
        -4.41148042678833,
        -4.392165660858154,
        -4.411856651306152,
        -4.4335618019104,
        -4.557801246643066,
        -4.502808094024658,
        -4.444523334503174,
        -4.365509510040283,
        -4.4407572746276855,
        -4.398534774780273,
        -4.494472026824951,
        -4.4589009284973145,
        -4.446843147277832,
        -4.48818302154541,
        -4.4432148933410645,
        -4.461241722106934,
        -4.47222900390625,
        -4.394496917724609,
        -4.536823749542236,
        -4.492719650268555,
        -4.458134174346924,
        -4.397995471954346,
        -4.548748970031738,
        -4.478445053100586,
        -4.409451007843018,
        -4.517798900604248,
        -4.5656418800354,
        -4.37938117980957,
        -4.367457389831543,
        -4.3666768074035645,
        -4.5387091636657715,
        -4.491726398468018,
        -4.576145172119141,
        -4.453524589538574,
        -4.530948162078857,
        -4.534327030181885,
        -4.498922348022461,
        -4.641197681427002,
        -4.6087565422058105,
        -4.652290344238281,
        -4.608717918395996,
        -4.555382251739502,
        -4.548266887664795,
        -4.537906169891357,
        -4.508234977722168,
        -4.492986679077148,
        -4.544192314147949,
        -4.53891658782959,
        -4.670609474182129,
        -4.510542869567871,
        -4.545916557312012,
        -4.510066032409668,
        -4.6065802574157715,
        -4.590795040130615,
        -4.573033332824707,
        -4.44343900680542,
        -4.536850929260254,
        -4.501250743865967,
        -4.600646018981934,
        -4.482354164123535,
        -4.552433490753174,
        -4.534128665924072,
        -4.533880710601807,
        -4.658810615539551,
        -4.564006328582764,
        -4.555300235748291,
        -4.616654396057129,
        -4.53395938873291,
        -4.67038106918335,
        -4.583096504211426,
        -4.719457626342773,
        -4.676714897155762,
        -4.564594745635986,
        -4.608352184295654,
        -4.749111175537109,
        -4.636407852172852,
        -4.601374626159668,
        -4.777248859405518,
        -4.647106647491455,
        -4.655620098114014,
        -4.730106830596924,
        -4.637761116027832,
        -4.594498157501221,
        -4.616434574127197,
        -4.6478753089904785,
        -4.5959367752075195,
        -4.5840959548950195,
        -4.596737384796143,
        -4.663082599639893,
        -4.641085147857666,
        -4.636890888214111,
        -4.667757511138916,
        -4.5689287185668945,
        -4.546067237854004,
        -4.606171607971191,
        -4.533578872680664,
        -4.779207229614258,
        -4.618047714233398,
        -4.733421325683594,
        -4.685095310211182,
        -4.7121429443359375,
        -4.629438877105713,
        -4.706186771392822,
        -4.761791229248047,
        -4.61620569229126,
        -4.707031726837158,
        -4.735233783721924,
        -4.659157752990723,
        -4.628995418548584,
        -4.638149261474609,
        -4.83411979675293,
        -4.769176959991455,
        -4.649713039398193,
        -4.746766567230225,
        -4.608952045440674,
        -4.636651515960693,
        -4.6273016929626465,
        -4.740611553192139,
        -4.67244815826416,
        -4.646803855895996,
        -4.734203338623047,
        -4.902912616729736,
        -4.763376712799072,
        -4.726836681365967,
        -4.774427890777588,
        -4.739053726196289,
        -4.793575763702393,
        -4.877179145812988,
        -4.738199710845947,
        -4.847540855407715,
        -4.802394390106201,
        -4.800164699554443,
        -4.760918140411377,
        -4.769441604614258,
        -4.7940497398376465,
        -4.792060375213623,
        -4.830831527709961,
        -4.878121852874756,
        -4.794167995452881,
        -4.795862674713135,
        -4.805743217468262,
        -4.70259952545166,
        -4.727140426635742,
        -4.797970771789551,
        -4.8974103927612305,
        -4.758173942565918,
        -4.782340049743652,
        -4.919991493225098,
        -4.685606479644775,
        -4.702273845672607,
        -4.816412448883057,
        -4.743505954742432,
        -4.76127290725708,
        -4.719825744628906,
        -4.663848400115967,
        -4.742134094238281,
        -4.834306240081787,
        -4.774806022644043,
        -4.8271894454956055,
        -4.934380054473877,
        -4.834293365478516,
        -4.869417190551758,
        -4.823856830596924,
        -4.854582786560059,
        -4.794646263122559,
        -4.945316314697266,
        -5.015740394592285,
        -5.033669471740723,
        -4.896938323974609,
        -4.888244152069092,
        -4.802570819854736,
        -4.850795745849609,
        -4.738603591918945,
        -4.838099956512451,
        -4.831799030303955,
        -4.767251491546631,
        -4.777867794036865,
        -4.963961124420166,
        -4.85646390914917,
        -4.873974800109863,
        -4.856563091278076,
        -4.919393539428711,
        -5.016323566436768,
        -4.957817077636719,
        -4.9964919090271,
        -5.027751922607422,
        -4.947488307952881,
        -4.961698055267334,
        -5.061352252960205,
        -4.976734161376953,
        -4.980495929718018,
        -4.904885768890381,
        -5.1264142990112305,
        -4.985246658325195,
        -4.8290019035339355,
        -4.927855491638184,
        -4.928321838378906,
        -5.021799564361572,
        -4.909295558929443,
        -5.082601547241211,
        -4.937121868133545,
        -5.037901401519775,
        -4.934733867645264,
        -4.870471000671387,
        -4.96768856048584,
        -5.009800434112549,
        -4.888193607330322,
        -4.908129692077637,
        -4.939477920532227,
        -5.037344455718994,
        -4.8835859298706055,
        -4.889390468597412,
        -4.882013320922852,
        -4.979912281036377,
        -5.0112104415893555,
        -5.040587425231934,
        -5.035571098327637,
        -5.020421504974365,
        -5.010655403137207,
        -5.087643623352051,
        -5.007933139801025,
        -4.981603622436523,
        -5.062551498413086,
        -5.096035957336426,
        -5.1624650955200195,
        -5.0590596199035645,
        -5.101135730743408,
        -5.039728164672852,
        -5.069596767425537,
        -5.1275129318237305,
        -5.032477378845215,
        -5.24390983581543,
        -5.049010753631592,
        -5.096415996551514,
        -5.129887104034424,
        -5.105242729187012,
        -4.974928855895996,
        -5.152951240539551,
        -5.018800735473633,
        -5.09093713760376,
        -5.0713725090026855,
        -5.025673866271973,
        -5.0276103019714355,
        -5.146521091461182,
        -5.160711765289307,
        -5.048588752746582,
        -5.015042304992676,
        -5.078669548034668,
        -5.080582618713379,
        -5.093570232391357,
        -5.107078552246094,
        -5.083340644836426,
        -5.164210319519043,
        -4.979888916015625,
        -5.021061897277832,
        -4.956110000610352,
        -5.250132083892822,
        -5.1368408203125,
        -5.222436428070068,
        -5.216958522796631,
        -5.1399054527282715,
        -5.139222145080566,
        -5.265250205993652,
        -5.238412380218506,
        -5.139367580413818,
        -5.084768295288086,
        -5.1018266677856445,
        -5.1421661376953125,
        -5.143794536590576,
        -5.218311309814453,
        -5.213373184204102,
        -5.148777961730957,
        -5.1205267906188965,
        -5.194014072418213,
        -5.1444783210754395,
        -5.195980072021484,
        -5.081366062164307,
        -5.2395501136779785,
        -5.1133222579956055,
        -5.20328950881958,
        -5.132257461547852,
        -5.164198398590088,
        -5.186424732208252,
        -5.094372272491455,
        -5.206258296966553,
        -5.101512432098389,
        -5.204669952392578,
        -5.117300987243652,
        -5.211977005004883,
        -5.114797592163086,
        -5.148238658905029,
        -5.127985954284668,
        -5.259205341339111,
        -5.196826457977295,
        -5.1662211418151855,
        -5.205373287200928,
        -5.08984375,
        -5.168625831604004,
        -5.1639604568481445,
        -5.211979389190674,
        -5.088329315185547,
        -5.225314617156982,
        -5.1239728927612305,
        -5.3101043701171875,
        -5.258562088012695,
        -5.252035617828369,
        -5.294405460357666,
        -5.352614879608154,
        -5.261873722076416,
        -5.383606433868408,
        -5.2527923583984375,
        -5.401500225067139,
        -5.183027267456055,
        -5.250987529754639,
        -5.227757930755615,
        -5.227241516113281,
        -5.290852069854736,
        -5.321060657501221,
        -5.30388069152832,
        -5.286766529083252,
        -5.321829319000244,
        -5.230170249938965,
        -5.399455547332764,
        -5.28402042388916,
        -5.306822299957275,
        -5.285815238952637,
        -5.382140636444092,
        -5.395080089569092,
        -5.249414920806885,
        -5.335160732269287,
        -5.284753322601318,
        -5.275969505310059,
        -5.270850658416748,
        -5.387609958648682,
        -5.224778175354004,
        -5.270628452301025,
        -5.244128704071045,
        -5.329590320587158,
        -5.2848687171936035,
        -5.272660255432129,
        -5.2437214851379395,
        -5.325011253356934,
        -5.291686058044434,
        -5.317105293273926,
        -5.378572940826416,
        -5.425469398498535,
        -5.425082206726074,
        -5.388086795806885,
        -5.384674072265625,
        -5.425415992736816,
        -5.440456867218018,
        -5.4607133865356445,
        -5.503902912139893,
        -5.381879806518555,
        -5.451738357543945,
        -5.408092498779297,
        -5.405112266540527,
        -5.508101463317871,
        -5.496218681335449,
        -5.427795886993408,
        -5.437379360198975,
        -5.413135528564453,
        -5.531230449676514,
        -5.45881986618042,
        -5.426087379455566,
        -5.4147725105285645,
        -5.414334297180176,
        -5.425307273864746,
        -5.418982028961182,
        -5.426433563232422,
        -5.491133213043213,
        -5.51454496383667,
        -5.525145053863525,
        -5.518280029296875,
        -5.422355651855469,
        -5.422582149505615,
        -5.42327880859375,
        -5.435216426849365,
        -5.413435935974121,
        -5.5665178298950195,
        -5.344995021820068,
        -5.52645206451416,
        -5.48175048828125,
        -5.4147725105285645,
        -5.486729145050049,
        -5.442572116851807,
        -5.381453514099121,
        -5.3855366706848145,
        -5.497565746307373,
        -5.398287296295166,
        -5.40908670425415,
        -5.375504493713379,
        -5.521803379058838
    ],
    "diff": [
        1.1834354400634766,
        -1.2184010744094849,
        0.6319637894630432,
        0.19514651596546173,
        0.5658789873123169,
        -0.4910009801387787,
        -1.0405938625335693,
        -0.7299478650093079,
        1.0922497510910034,
        -2.008416175842285,
        -1.6080163717269897,
        -1.181826114654541,
        2.2426209449768066,
        -0.4470103681087494,
        -0.9532350301742554,
        -1.0676697492599487,
        -0.2720468044281006,
        -0.4928159713745117,
        -1.8257654905319214,
        -1.578824520111084,
        0.6239734292030334,
        -0.6018010973930359,
        1.7339664697647095,
        -0.32686927914619446,
        -0.35378316044807434,
        -1.2966032028198242,
        2.0281994342803955,
        0.16123530268669128,
        -0.6297567486763,
        0.15446889400482178,
        0.4032338857650757,
        0.6055479049682617,
        -0.15285319089889526,
        -0.8853917717933655,
        0.7776503562927246,
        0.26835477352142334,
        -0.02850254997611046,
        -1.0717359781265259,
        1.7540308237075806,
        -0.688978910446167,
        -1.9896173477172852,
        -2.695525884628296,
        -2.586242914199829,
        1.9738447666168213,
        1.9690371751785278,
        -0.21754521131515503,
        2.201735734939575,
        2.0249454975128174,
        -1.7851885557174683,
        -0.22895483672618866,
        0.5031455755233765,
        -0.01842360571026802,
        0.6619035601615906,
        0.9717753529548645,
        0.6287969946861267,
        0.9155498147010803,
        -0.04437178745865822,
        -0.04876614734530449,
        0.0010291646467521787,
        1.9958016872406006,
        -0.9194245338439941,
        -1.5490578413009644,
        0.12210161238908768,
        -0.6679813861846924,
        -0.5533259510993958,
        -0.09867136925458908,
        0.013146388344466686,
        -0.28234174847602844,
        1.8148812055587769,
        0.4946695566177368,
        -0.6986292004585266,
        -1.232324242591858,
        -3.092660665512085,
        0.3405418395996094,
        1.2786585092544556,
        -0.19065675139427185,
        1.2913885116577148,
        0.3293212354183197,
        -0.302977591753006,
        1.8853164911270142,
        -0.1669718623161316,
        -0.28942736983299255,
        -0.6688804030418396,
        -2.8114750385284424,
        1.1163127422332764,
        1.9143844842910767,
        -1.1010313034057617,
        1.5638723373413086,
        -0.12261084467172623,
        0.6247090101242065,
        1.793805718421936,
        1.612341284751892,
        -1.77104914188385,
        2.0421204566955566,
        -1.1207565069198608,
        0.09758985042572021,
        0.6441518068313599,
        -1.6737887859344482,
        1.946800947189331,
        0.6378595232963562,
        -0.6001763939857483,
        2.352715253829956,
        -1.190373420715332,
        0.2698238790035248,
        0.9597005844116211,
        -1.3010573387145996,
        1.1240489482879639,
        -2.3417415618896484,
        0.6036073565483093,
        -0.6080870032310486,
        2.1824960708618164,
        2.135324001312256,
        -0.24686294794082642,
        -1.6471686363220215,
        -1.1170369386672974,
        0.45970359444618225,
        -1.1439310312271118,
        -0.23068560659885406,
        1.0843349695205688,
        -0.8330969214439392,
        -0.18119771778583527,
        -2.2669620513916016,
        2.3363659381866455,
        -2.0336050987243652,
        0.12135237455368042,
        -0.0051853773184120655,
        -1.283486008644104,
        -0.5904958248138428,
        -0.8314667344093323,
        -0.7676685452461243,
        2.1274642944335938,
        0.44000953435897827,
        0.2613369822502136,
        0.21416325867176056,
        0.49409809708595276,
        -0.13829393684864044,
        -1.9580473899841309,
        -0.41329121589660645,
        -1.119659423828125,
        0.6396964192390442,
        0.9390608072280884,
        -1.2090013027191162,
        -0.4792328476905823,
        -1.0592267513275146,
        -1.1949896812438965,
        -0.4034194052219391,
        -1.8913228511810303,
        1.5273758172988892,
        0.431153267621994,
        -1.8238798379898071,
        0.7794318795204163,
        -2.837689161300659,
        0.41181477904319763,
        2.140516996383667,
        0.6407663226127625,
        -2.0169780254364014,
        -2.3135228157043457,
        0.27565598487854004,
        1.7780791521072388,
        -0.9124453067779541,
        -0.3221566379070282,
        -1.0033351182937622,
        -1.4435596466064453,
        -0.4666346609592438,
        -1.588227391242981,
        -0.4067370593547821,
        -1.7478091716766357,
        0.5936262011528015,
        -0.7060536742210388,
        -0.36544060707092285,
        -0.9784509539604187,
        -1.9135335683822632,
        0.30035600066185,
        -0.5809161067008972,
        0.5837517976760864,
        -0.48033031821250916,
        0.9274744987487793,
        -1.04878568649292,
        -1.631284236907959,
        -0.5304546356201172,
        1.2644060850143433,
        0.8939415216445923,
        -1.5267246961593628,
        0.9321274161338806,
        -1.1495133638381958,
        -0.9296779036521912,
        -0.5422768592834473,
        0.6257035732269287,
        0.885108470916748,
        -1.4150903224945068,
        1.3073647022247314,
        -0.5633918046951294,
        0.08173391222953796,
        1.0611164569854736,
        -1.0888127088546753,
        0.26749634742736816,
        0.9230509400367737,
        2.4093546867370605,
        -1.189664363861084,
        -1.2125054597854614,
        0.058848101645708084,
        2.0510222911834717,
        -2.492949962615967,
        0.0930778831243515,
        2.289750814437866,
        0.1027107909321785,
        -1.3198065757751465,
        -0.7238284349441528,
        -0.8814541101455688,
        0.7328429222106934,
        2.1248421669006348,
        0.23505623638629913,
        -0.15442562103271484,
        -0.20867297053337097,
        2.1347081661224365,
        -1.530632734298706,
        -0.1234036535024643,
        0.19748589396476746,
        2.082956075668335,
        2.095252513885498,
        0.1200910210609436,
        1.808457612991333,
        1.9647679328918457,
        2.2752108573913574,
        -0.1387598216533661,
        -2.225942611694336,
        2.082287073135376,
        1.700476884841919,
        -1.032092571258545,
        -0.8569164276123047,
        1.690014362335205,
        1.5600230693817139,
        -0.6912001371383667,
        -1.1274439096450806,
        -1.4301828145980835,
        -1.0196453332901,
        -0.9178597927093506,
        -0.7515644431114197,
        -2.1496057510375977,
        2.346130847930908,
        1.9871073961257935,
        1.1604126691818237,
        1.4919068813323975,
        -1.0878403186798096,
        2.2953500747680664,
        -0.7386631965637207,
        1.1342753171920776,
        2.3638479709625244,
        -1.1227530241012573,
        -0.7961752414703369,
        -2.5827853679656982,
        0.3506062924861908,
        -1.7946648597717285,
        0.5213426947593689,
        -0.22691360116004944,
        1.8541038036346436,
        0.09751798212528229,
        -2.3048133850097656,
        -1.0568246841430664,
        1.704224705696106,
        -1.3967634439468384,
        -0.1242934912443161,
        2.023158073425293,
        -0.5014488101005554,
        1.5031542778015137,
        0.7861602306365967,
        0.08840714395046234,
        1.1436601877212524,
        1.5371918678283691,
        -1.376010537147522,
        0.6664491891860962,
        1.002885341644287,
        -0.8192358016967773,
        2.3642990589141846,
        1.1340676546096802,
        2.264827251434326,
        0.21690595149993896,
        1.2281330823898315,
        -0.34325647354125977,
        -0.7485366463661194,
        1.41550612449646,
        -0.7970472574234009,
        1.1410356760025024,
        1.4394848346710205,
        -2.431051254272461,
        1.5376182794570923,
        -0.3943517506122589,
        -0.8122910857200623,
        0.06182055547833443,
        -0.4745175242424011,
        1.3807485103607178,
        0.13060033321380615,
        -0.7332776784896851,
        -0.14945203065872192,
        -1.5795778036117554,
        -0.4923778474330902,
        0.7015605568885803,
        2.0171194076538086,
        0.14965727925300598,
        1.6909412145614624,
        -0.4257105588912964,
        -0.9371761679649353,
        -0.10803759843111038,
        0.01428961381316185,
        -0.7808966040611267,
        1.4393813610076904,
        -0.7700445055961609,
        0.7513723969459534,
        0.13522151112556458,
        1.796331524848938,
        -0.8017263412475586,
        -0.7579569220542908,
        2.0751168727874756,
        -0.7503066658973694,
        -0.7694600224494934,
        2.2269716262817383,
        -1.5281108617782593,
        1.2351129055023193,
        0.7018771171569824,
        -0.5878832340240479,
        1.5393245220184326,
        -0.29271548986434937,
        2.6137466430664062,
        -0.09785519540309906,
        2.0989770889282227,
        -0.6041871905326843,
        1.9917125701904297,
        -2.0282154083251953,
        -1.1533048152923584,
        -1.373016357421875,
        1.1183487176895142,
        1.187156319618225,
        -1.1046773195266724,
        -0.03609422221779823,
        0.7933722734451294,
        1.0166668891906738,
        -1.7181894779205322,
        -0.5058772563934326,
        -1.1274685859680176,
        0.18791231513023376,
        2.0173163414001465,
        -0.8898749947547913,
        -0.37218955159187317,
        0.659351110458374,
        -1.1672611236572266,
        -1.411028265953064,
        1.095495581626892,
        -1.3659300804138184,
        -0.9337899088859558,
        -1.4636659622192383,
        -1.1722698211669922,
        0.9486386775970459,
        2.343996524810791,
        0.14463843405246735,
        2.1906535625457764,
        -1.0978997945785522,
        -1.3362895250320435,
        -1.1697914600372314,
        1.0710188150405884,
        1.9510858058929443,
        0.18193329870700836,
        -1.328041434288025,
        1.9909579753875732,
        2.2072010040283203,
        1.3784548044204712,
        0.035924967378377914,
        -1.1893832683563232,
        -0.5505022406578064,
        0.5203952789306641,
        -0.7202686071395874,
        -1.5048905611038208,
        1.420349359512329,
        0.7572391629219055,
        0.300603985786438,
        -1.9950990676879883,
        1.7087846994400024,
        2.0170722007751465,
        -1.7249469757080078,
        -0.6940605640411377,
        -1.759889006614685,
        1.944435715675354,
        -0.4818948209285736,
        -1.102445125579834,
        -0.5481138825416565,
        -0.5655586123466492,
        -0.5283903479576111,
        1.3239620923995972,
        -1.195696234703064,
        -0.6048846244812012,
        2.2689878940582275,
        -0.5188720226287842,
        -0.8641194105148315,
        1.8596786260604858,
        0.4771294593811035,
        1.2496700286865234,
        0.38206854462623596,
        1.2013731002807617,
        0.2855122685432434,
        -0.250696063041687,
        -0.5736738443374634,
        0.08234472572803497,
        -0.7647078633308411,
        -1.123519778251648,
        1.454833984375,
        -0.7671530842781067,
        -1.7743116617202759,
        -0.6442000269889832,
        0.10780366510152817,
        0.30502307415008545,
        -1.6097577810287476,
        1.9160341024398804,
        0.26959869265556335,
        -1.2520036697387695,
        1.578063726425171,
        -0.7083346843719482,
        0.6792673468589783,
        -0.5412405729293823,
        2.166684627532959,
        -0.13111692667007446,
        -0.2804560661315918,
        1.1698311567306519,
        0.4511755108833313,
        1.126552939414978,
        0.3950013220310211,
        0.8388389945030212,
        1.9805153608322144,
        -2.5327675342559814,
        0.276493638753891,
        -0.2684011161327362,
        -0.637239933013916,
        0.20826883614063263,
        -1.464228630065918,
        0.2965146601200104,
        2.0294036865234375,
        0.1543772667646408,
        2.3361239433288574,
        -0.14649930596351624,
        -0.8238868713378906,
        -0.2626577615737915,
        2.068080186843872,
        -1.6624350547790527,
        -1.461731195449829,
        -0.5824618339538574,
        0.5268914699554443,
        1.6315091848373413,
        -0.34100618958473206,
        2.5924179553985596,
        0.6726735830307007,
        -0.8605233430862427,
        2.308392286300659,
        -0.27284446358680725,
        -1.861338496208191,
        1.7145884037017822,
        1.1759777069091797,
        -0.3493340313434601,
        -1.4713892936706543,
        -0.6113447546958923,
        -0.9091894626617432,
        -0.7846883535385132,
        -1.1668949127197266,
        -1.8034279346466064,
        1.7277512550354004,
        0.36467641592025757,
        2.131788969039917,
        -1.1271402835845947,
        1.9283523559570312,
        0.048037782311439514,
        2.104539394378662,
        -1.8150267601013184,
        -0.48492076992988586,
        1.2468615770339966,
        -0.5228970646858215,
        -0.2024434357881546,
        -0.016595877707004547,
        -0.8071801662445068,
        -1.1531496047973633,
        0.8619109988212585,
        1.827406644821167,
        1.807808518409729,
        -0.21355170011520386,
        1.112153172492981,
        0.4361530542373657,
        -1.3974076509475708,
        1.2608990669250488,
        -0.9964863657951355,
        2.2967305183410645,
        -0.9189872145652771,
        2.216106414794922,
        -0.07864715903997421,
        -1.775873064994812,
        0.17145852744579315,
        0.9905124306678772,
        1.4981921911239624,
        -0.4226144850254059,
        -2.2535922527313232,
        0.8345543742179871,
        1.632513403892517,
        -0.18808206915855408,
        -2.274639129638672,
        -0.36409008502960205,
        -0.8509740233421326,
        -0.9992544054985046,
        -1.744537115097046,
        1.5301986932754517,
        -2.3526451587677,
        -0.8727309703826904,
        2.4121017456054688,
        -0.9497663974761963,
        -1.235936164855957,
        1.2186344861984253,
        0.9168796539306641,
        -0.7231382131576538,
        -1.274897575378418,
        0.6846455931663513,
        2.150202512741089,
        -1.5031174421310425,
        -0.4766111373901367,
        -0.04644627496600151,
        -0.8025323748588562,
        0.5354757905006409,
        -0.820212721824646,
        -0.7463952302932739,
        -1.2878570556640625,
        0.16578559577465057,
        -0.9651358127593994,
        -0.20860053598880768,
        -1.1305361986160278,
        0.37985172867774963,
        -0.8958110809326172,
        0.4429071843624115,
        -0.6103122234344482,
        0.7402219772338867,
        -0.5090777277946472,
        -0.13742490112781525,
        0.6234544515609741,
        -1.409623384475708,
        0.19287841022014618,
        0.3991211950778961,
        -0.5747040510177612,
        0.4193935692310333,
        0.9248270392417908,
        1.0866584777832031,
        -0.7071235179901123,
        -1.3373303413391113,
        -0.5581782460212708,
        -1.0429538488388062,
        0.3267301023006439,
        -1.457993507385254,
        1.700966715812683,
        -0.3941391110420227,
        -0.8128072619438171,
        0.0663791224360466,
        0.2098623365163803,
        -1.9515886306762695,
        1.4187809228897095,
        0.7332079410552979,
        -1.4027990102767944,
        -0.8506131172180176,
        -0.9582579135894775,
        2.221733808517456,
        0.7678409814834595,
        -0.3005451560020447,
        2.2435741424560547,
        0.055215880274772644,
        -0.13975457847118378,
        -0.6914323568344116,
        -0.9767721891403198,
        0.20159544050693512,
        -1.2138625383377075,
        -0.9484863877296448,
        0.9593778848648071,
        -1.805368423461914,
        -1.6363935470581055,
        -0.6303966641426086,
        -0.876706600189209,
        -1.3854730129241943,
        -0.5879082083702087,
        2.3127951622009277,
        2.353400707244873,
        1.4644044637680054,
        -0.2963428497314453,
        -0.32937222719192505,
        -1.2181288003921509,
        0.1894114464521408,
        1.7632254362106323,
        -0.6805639863014221,
        -0.12016607075929642,
        -0.33977624773979187,
        0.9459636211395264,
        1.5775153636932373,
        -0.5298373103141785,
        -0.9643601775169373,
        0.8701592683792114,
        0.6287299394607544,
        -0.8144989609718323,
        -1.1314188241958618,
        -0.15853744745254517,
        0.6600590348243713,
        0.8908855319023132,
        0.9198625087738037,
        -0.514493465423584,
        0.0647541731595993,
        -0.5201438665390015,
        0.243573397397995,
        0.0038755459245294333,
        0.4897930920124054,
        0.33234071731567383,
        -0.14432884752750397,
        -1.3086780309677124,
        -0.8538830876350403,
        -0.8384780287742615,
        0.13422365486621857,
        -0.021921565756201744,
        0.3427874445915222,
        1.328535556793213,
        0.37488749623298645,
        -1.2254031896591187,
        -0.5453342199325562,
        1.7624722719192505,
        -1.2786301374435425,
        0.7737155556678772,
        0.7694989442825317,
        1.4256417751312256,
        -1.593988299369812,
        -1.4214485883712769,
        0.27635377645492554,
        1.6532933712005615,
        1.8818676471710205,
        2.1639292240142822,
        -0.31717151403427124,
        -1.601136326789856,
        -0.855521023273468,
        -1.1258317232131958,
        -0.982797384262085,
        -1.5978987216949463,
        -0.6898426413536072,
        -1.339673638343811,
        -1.5858042240142822,
        0.07369666546583176,
        -1.194962739944458,
        2.0894384384155273,
        0.5951448678970337,
        -0.24721382558345795,
        1.7137759923934937,
        -0.9174007773399353,
        -1.7986204624176025,
        -1.236851453781128,
        -0.13602043688297272,
        1.2523173093795776,
        -0.6576942801475525,
        -1.4246132373809814,
        0.45755356550216675,
        0.7805538177490234,
        0.058075565844774246,
        0.7135154008865356,
        -0.45218801498413086,
        1.5650608539581299,
        0.5745474696159363,
        1.4544674158096313,
        -0.03832688927650452,
        0.48315170407295227,
        0.5136601328849792,
        0.07570957392454147,
        1.9669826030731201,
        -1.3766883611679077,
        -0.012926166877150536,
        -0.0904177725315094,
        -0.3234318792819977,
        -0.49007323384284973,
        0.14264577627182007,
        -0.7302956581115723,
        1.9051190614700317,
        2.4027020931243896,
        -1.4609326124191284,
        -1.336456298828125,
        -0.3817353844642639,
        -1.1406086683273315,
        -0.04766625165939331,
        -0.2992454171180725,
        -1.7362844944000244,
        0.015551432967185974,
        -1.0172111988067627,
        -2.0610411167144775,
        1.9078741073608398,
        -0.42991816997528076,
        0.632401168346405,
        2.1261961460113525,
        0.5138254761695862,
        -0.34136682748794556,
        -0.9750579595565796,
        -0.754564642906189,
        1.9367669820785522,
        -1.099945068359375,
        -0.35245612263679504,
        2.068680763244629,
        0.330186128616333,
        -0.18663810193538666,
        0.1909235715866089,
        0.5442358255386353,
        -0.1469382792711258,
        0.15273958444595337,
        0.48191723227500916,
        -0.37530604004859924,
        -0.07701250910758972,
        1.220062494277954,
        0.938005268573761,
        1.078018069267273,
        -0.32447725534439087,
        0.8449001312255859,
        -1.2185018062591553,
        1.0929620265960693,
        1.6487908363342285,
        0.36596423387527466,
        2.262899398803711,
        1.6616276502609253,
        -0.47700434923171997,
        -1.3338395357131958,
        0.41784435510635376,
        0.5233088731765747,
        1.3151696920394897,
        0.3322465121746063,
        -0.17804667353630066,
        -1.0626564025878906,
        -0.5067261457443237,
        -0.2427586317062378,
        2.190124034881592,
        0.6833727955818176,
        1.4918004274368286,
        -0.3154718279838562,
        -1.0635976791381836,
        0.5357112884521484,
        2.343682289123535,
        0.30571630597114563,
        -1.2203456163406372,
        -0.9294105768203735,
        1.840138554573059,
        -1.8129010200500488,
        -1.2497378587722778,
        2.2840864658355713,
        0.26906946301460266,
        -0.22170473635196686,
        1.2934346199035645,
        0.1014610230922699,
        1.7023329734802246,
        0.9237841963768005,
        -0.9776383638381958,
        -0.5016065239906311,
        -0.362102746963501,
        -0.2746075391769409,
        -1.3139801025390625,
        0.9218177199363708,
        0.01327667199075222,
        0.8521243333816528,
        -0.6362389326095581,
        -1.0119819641113281,
        1.9740345478057861,
        0.26480552554130554,
        0.68611741065979,
        -0.031615033745765686,
        1.7042843103408813,
        -1.8799024820327759,
        2.0650177001953125,
        0.2065659612417221,
        0.6417993307113647,
        -1.0023913383483887,
        -1.520997166633606,
        -2.0326316356658936,
        -0.6694273948669434,
        2.0347108840942383,
        2.226644992828369,
        1.5690360069274902,
        0.9255490303039551,
        -0.6769536733627319,
        -1.5150067806243896,
        -0.5685693621635437,
        1.855489730834961,
        0.00961280521005392,
        -0.15164293348789215,
        1.6459590196609497,
        -1.2746212482452393,
        -1.9597431421279907,
        0.483480840921402,
        0.02146396040916443,
        -0.5883545279502869,
        -0.03813980147242546,
        -1.0358742475509644,
        -0.2646350562572479,
        1.19306480884552,
        -2.073608875274658,
        -0.5623791217803955,
        -1.4691526889801025,
        -0.7103768587112427,
        2.2322988510131836,
        -1.707274317741394,
        -0.010678153485059738,
        0.8257418274879456,
        1.9022650718688965,
        -0.3664534389972687,
        -1.486448884010315,
        0.279276043176651,
        0.7180882096290588,
        -0.14464356005191803,
        1.4096367359161377,
        -0.23504392802715302,
        -0.6970811486244202,
        0.18232105672359467,
        -1.0651787519454956,
        -0.31273019313812256,
        -1.1771283149719238,
        0.44826453924179077,
        -0.7212679386138916,
        1.5824995040893555,
        -0.3856355845928192,
        -0.7861873507499695,
        1.3204498291015625,
        1.574198603630066,
        1.9370681047439575,
        2.191071033477783,
        -0.9835602045059204,
        1.2199640274047852,
        -0.8426176905632019,
        0.4646928906440735,
        -0.35058584809303284,
        1.679448127746582,
        -1.3031113147735596,
        -0.11745493113994598,
        -1.4608896970748901,
        -1.4571516513824463,
        -0.37283265590667725,
        1.8534951210021973,
        0.10514304041862488,
        2.1817469596862793,
        0.6886749863624573,
        -0.43610262870788574,
        -0.6738446354866028,
        -0.09502054005861282,
        1.125003457069397,
        2.129621744155884,
        0.12256249785423279,
        0.05609528720378876,
        0.7029876708984375,
        0.08385339379310608,
        -1.6969661712646484,
        2.3840277194976807,
        -0.3379688560962677,
        0.734444797039032,
        2.1598236560821533,
        -0.01891234889626503,
        0.3214593529701233,
        -2.223172664642334,
        -1.9301583766937256,
        -0.6313938498497009,
        0.20967763662338257,
        -0.43912172317504883,
        2.3275907039642334,
        1.2411777973175049,
        1.9636861085891724,
        -1.3879960775375366,
        2.3110382556915283,
        0.6962580680847168,
        -1.1513205766677856,
        -0.13395115733146667,
        -0.7785528898239136,
        -1.13848876953125,
        -1.5742267370224,
        1.076952338218689,
        0.7953361868858337,
        1.25153648853302,
        0.595470666885376,
        -0.9442912936210632,
        -0.7706406116485596,
        1.5026090145111084,
        -0.20445427298545837,
        1.5833923816680908,
        -0.4991579055786133,
        2.2569169998168945,
        1.150233268737793,
        -0.9838148355484009,
        -0.9472990036010742,
        1.1589113473892212,
        -0.6901896595954895,
        -0.3471929728984833,
        -1.2768282890319824,
        2.3908989429473877,
        0.5803627371788025,
        -0.372700572013855,
        2.2819290161132812,
        0.340683251619339,
        1.1014347076416016,
        -1.3812687397003174,
        -1.3576103448867798,
        -0.11097922176122665,
        1.1087507009506226,
        -1.3901699781417847,
        -1.6696882247924805,
        1.686000943183899,
        2.120912551879883,
        -1.4636657238006592,
        0.0942286029458046,
        -0.8583843111991882,
        1.575899362564087,
        -0.14481467008590698,
        -2.67344331741333,
        0.4335815906524658,
        1.02322256565094,
        0.002690549474209547,
        -1.2659515142440796,
        -0.7851125597953796,
        2.304502248764038,
        -1.1240147352218628,
        0.7258613705635071,
        1.9836289882659912,
        0.36674681305885315,
        -0.7600594758987427,
        0.9899253249168396,
        -0.8420412540435791,
        1.2032222747802734,
        0.5708433389663696,
        0.53551185131073,
        -1.3090484142303467,
        0.5913833379745483,
        -0.20264148712158203,
        1.3213756084442139,
        0.19730257987976074,
        -1.4998900890350342,
        -1.6165183782577515,
        -0.8446953296661377,
        1.2800493240356445,
        -1.1461153030395508,
        -0.748988151550293,
        0.7974669933319092,
        -1.2086297273635864,
        0.6601831316947937,
        -0.8924914598464966,
        -0.6683472990989685,
        1.9042489528656006,
        -0.34583455324172974,
        -1.2692538499832153,
        0.5002748966217041,
        2.0472819805145264,
        1.1105793714523315,
        -0.23962637782096863,
        0.7042127847671509,
        1.5909898281097412,
        -1.328139305114746,
        0.6006035804748535,
        1.422908902168274,
        -1.3846542835235596,
        1.0140451192855835,
        0.6136743426322937,
        1.2769246101379395,
        -0.12424103915691376,
        0.2094608098268509,
        2.1985156536102295,
        0.11844982951879501,
        0.18654881417751312,
        0.7063949108123779,
        -0.8924535512924194,
        0.5209990739822388,
        0.1941099613904953,
        1.0087828636169434,
        -0.3296605050563812,
        -1.3605997562408447,
        -1.4193886518478394,
        0.5516870021820068,
        -0.8401346802711487,
        -0.6799558401107788,
        0.08003552258014679,
        0.03302135691046715,
        -0.6397510766983032,
        0.3212206959724426,
        0.16576513648033142,
        -1.261038899421692,
        0.9863545298576355,
        0.6239449381828308,
        -0.790407121181488,
        -0.4454946219921112,
        -1.3715654611587524,
        0.15015283226966858,
        1.2165799140930176,
        -0.8273909687995911,
        -0.2498704046010971,
        -0.597555935382843,
        1.2944939136505127,
        -0.38756048679351807,
        1.3001646995544434,
        2.250173330307007,
        0.2608981132507324,
        -0.10965686291456223,
        -0.9842329025268555,
        0.24352045357227325,
        -0.6303660273551941,
        -2.0148706436157227,
        -0.6966336965560913,
        -0.5333574414253235,
        0.5226327776908875,
        0.6673736572265625,
        -0.3672959506511688,
        -1.315962791442871,
        1.8282809257507324,
        0.23648463189601898,
        0.8503525257110596,
        -0.4977130889892578,
        2.0783185958862305,
        0.6705143451690674,
        -1.1611968278884888,
        -0.7289790511131287,
        0.37082117795944214,
        0.4129570424556732,
        0.35985854268074036,
        1.8508514165878296,
        -0.6849960088729858,
        0.19048157334327698,
        2.1371002197265625,
        0.3325407803058624,
        -1.0146483182907104,
        1.3097707033157349,
        -1.0794123411178589,
        -1.4076967239379883,
        -1.0123740434646606,
        0.8284560441970825,
        0.31509342789649963,
        -1.5388680696487427,
        -0.7800190448760986,
        1.7652486562728882,
        -0.5180162191390991,
        1.001495599746704,
        0.09688341617584229,
        -0.9545366168022156,
        0.6089276075363159,
        2.041071653366089,
        -0.9374467134475708,
        -1.3258545398712158,
        1.171486735343933,
        -1.0620304346084595,
        1.3817191123962402,
        0.8300597667694092,
        2.129930019378662,
        2.210099697113037,
        1.168604850769043,
        1.4060189723968506,
        1.5635639429092407,
        1.798466444015503,
        -1.5623019933700562,
        0.11859648674726486,
        2.1054461002349854,
        2.1072583198547363,
        1.7622617483139038,
        -1.9139472246170044,
        -1.3327935934066772,
        1.1217174530029297,
        -0.0731869712471962,
        1.904011607170105,
        1.8276323080062866,
        -0.5700491666793823,
        -1.348760962486267,
        0.31372249126434326,
        -1.642228126525879,
        -1.1460789442062378,
        -1.0830960273742676,
        2.0419957637786865,
        0.1102709099650383,
        -2.6165976524353027,
        -0.4868261516094208,
        -0.4768071472644806,
        2.0517516136169434,
        -1.1382726430892944,
        -1.7955321073532104,
        0.43807923793792725,
        0.077166847884655,
        -2.500298500061035,
        -1.9502496719360352,
        0.8505342602729797,
        -1.581145167350769,
        -1.727036952972412,
        1.161847472190857,
        -1.6600608825683594,
        -0.04731006175279617,
        0.6459116339683533,
        -0.800091028213501,
        -0.5646184682846069,
        1.6013273000717163,
        -0.1690957248210907,
        -1.282528042793274,
        0.29837802052497864,
        -1.095988392829895,
        1.5294030904769897,
        1.014259696006775,
        -0.4972997307777405,
        0.46285104751586914,
        -0.48423314094543457,
        -1.925426721572876,
        0.4724479019641876,
        2.150408983230591,
        -0.21126753091812134,
        1.1359447240829468,
        0.48213279247283936,
        0.06756117939949036,
        -0.8111530542373657,
        -0.2666893005371094,
        1.0862395763397217,
        -0.2071368396282196,
        0.8631292581558228,
        -0.5501981377601624,
        -0.1892218291759491,
        1.750390887260437,
        -1.222466230392456,
        -0.04166007414460182,
        -1.3458842039108276,
        -0.19064101576805115,
        0.18042193353176117,
        0.7180525064468384,
        0.7442746758460999,
        -1.3687082529067993,
        -0.31895124912261963,
        -0.04080027714371681,
        0.8021398186683655,
        -0.5743444561958313,
        1.6527502536773682,
        0.3188319504261017,
        -2.176309823989868,
        -0.6166724562644958,
        -0.7301701307296753,
        -0.3723286986351013,
        -0.4409208297729492,
        0.9282745718955994,
        1.4148591756820679,
        -2.1026358604431152,
        -0.3560360074043274,
        0.11374565958976746,
        -0.21330900490283966,
        1.3251248598098755,
        -0.09949955344200134,
        0.4606366455554962,
        0.45395365357398987,
        -0.2884872853755951,
        0.8242477178573608,
        -0.2239151895046234,
        0.45230650901794434,
        -1.7198103666305542,
        1.8026018142700195,
        -0.5649999976158142,
        1.2124383449554443,
        -0.6464477777481079,
        1.804229736328125,
        2.02044677734375,
        1.7083719968795776,
        -1.1374523639678955,
        -2.066620349884033,
        0.3380873501300812,
        -0.9034924507141113,
        -0.5623531937599182,
        2.0877888202667236,
        0.5138725638389587,
        -0.4808002710342407,
        -0.831169605255127,
        2.0434229373931885,
        -1.3102781772613525,
        0.9076842665672302,
        -0.16580763459205627,
        1.2032043933868408,
        0.0334007628262043,
        -1.0573338270187378,
        2.3503849506378174,
        -0.5287293195724487,
        1.6342419385910034,
        -1.2400728464126587,
        -0.6553437113761902,
        2.2916159629821777,
        -0.4161679744720459,
        -1.6793891191482544,
        -0.317381352186203,
        0.09981309622526169,
        1.3288249969482422,
        1.1679104566574097,
        0.04717573896050453,
        -0.41893649101257324,
        -1.1913554668426514,
        0.08412069082260132,
        1.4830241203308105,
        1.1814448833465576,
        -0.01114627718925476,
        0.19534927606582642,
        2.2766432762145996,
        0.04851621761918068,
        -0.5521001219749451,
        -0.5601198077201843,
        -1.5214530229568481,
        0.06842897832393646,
        1.5340324640274048,
        -2.635680675506592,
        -1.3914127349853516,
        1.3805510997772217,
        -0.8137285113334656,
        -1.608924150466919,
        -0.5348712205886841,
        -1.740214228630066,
        -0.9695753455162048,
        -1.565281629562378,
        2.3605144023895264,
        0.9264776706695557,
        0.26148098707199097,
        -1.8354122638702393,
        0.3392484188079834,
        0.019031090661883354,
        1.8459558486938477,
        -0.06306371092796326,
        -0.017115559428930283,
        0.14347168803215027,
        -0.6044505834579468,
        0.08547209948301315,
        0.8440645337104797,
        -2.628776788711548,
        -1.466658592224121,
        2.1985702514648438,
        -0.7859153151512146,
        0.7859081029891968,
        -1.1580520868301392,
        -1.394645094871521,
        -2.134887933731079,
        0.48197540640830994,
        -1.4559342861175537,
        -0.21371811628341675,
        -0.5642915964126587,
        -2.1307735443115234,
        2.029944658279419,
        -0.22103434801101685,
        2.066375255584717,
        0.10508871078491211,
        -1.2845159769058228,
        2.234086513519287,
        0.0027356864884495735,
        0.3768635094165802,
        -0.41984373331069946,
        2.0319387912750244,
        -0.7070437669754028,
        -0.037175390869379044,
        -1.035278081893921,
        0.6766000390052795,
        -0.6553972363471985,
        1.6922740936279297,
        0.3083154857158661,
        -0.858853280544281,
        -0.5703297853469849,
        -1.5872347354888916,
        1.5020809173583984,
        -1.0286988019943237,
        1.5238975286483765,
        1.0355547666549683,
        -1.6156264543533325,
        0.36088934540748596,
        0.3401302397251129,
        0.13865315914154053,
        -0.7634689807891846,
        -1.3202139139175415,
        -0.15643838047981262,
        -0.06091027706861496,
        -0.9161304831504822,
        2.247074842453003,
        -1.509710669517517,
        -1.4196149110794067,
        -0.25204119086265564,
        2.358513355255127,
        0.9343568682670593,
        -0.2677850127220154,
        -0.12318069487810135,
        1.8121780157089233,
        -0.2393195629119873,
        0.5685901045799255,
        -1.0323947668075562,
        1.2400462627410889,
        1.196537971496582,
        -0.7311663031578064,
        -1.0370228290557861,
        0.4542697072029114,
        -0.3984808325767517,
        1.2178364992141724,
        2.1994333267211914,
        -0.7239285111427307,
        -1.2840535640716553,
        -0.42955857515335083,
        0.3501625061035156,
        -1.0652011632919312,
        1.7607859373092651,
        0.7653555870056152,
        -0.8955870866775513,
        -0.2775554955005646,
        -0.25515204668045044,
        -1.6302835941314697,
        -1.4928162097930908,
        -0.009418763220310211,
        -0.8845275640487671,
        -0.15964244306087494,
        -0.08382029086351395,
        -0.27936673164367676,
        0.3657812178134918,
        -1.0728076696395874,
        -1.056504249572754,
        1.8187764883041382,
        1.8031926155090332,
        -1.1040847301483154,
        -2.099156618118286,
        0.24924325942993164,
        0.06721174716949463,
        -0.5536636710166931,
        1.6185215711593628
    ],
    "disc": [
        0.719796895980835,
        1.2269099950790405,
        1.140902042388916,
        1.0902378559112549,
        1.5978678464889526,
        1.5120140314102173,
        1.4473261833190918,
        0.7417281270027161,
        0.6791622638702393,
        1.553064227104187,
        1.524258017539978,
        1.3448400497436523,
        1.4482097625732422,
        1.3659111261367798,
        1.0959498882293701,
        1.500838041305542,
        1.4996031522750854,
        1.3393940925598145,
        1.0086617469787598,
        1.6024731397628784,
        0.7494608163833618,
        1.310953974723816,
        1.0343307256698608,
        1.1448112726211548,
        1.2861264944076538,
        1.5332372188568115,
        1.4621082544326782,
        1.6658493280410767,
        1.7241796255111694,
        1.2042016983032227,
        1.8828866481781006,
        1.2951329946517944,
        0.9968501925468445,
        1.3258432149887085,
        0.49897220730781555,
        1.8230509757995605,
        0.6994443535804749,
        1.370046615600586,
        0.8428933024406433,
        1.370605707168579,
        1.2302497625350952,
        1.3761118650436401,
        1.2731049060821533,
        1.4381980895996094,
        1.1777865886688232,
        0.7833069562911987,
        1.3157684803009033,
        0.8679841160774231,
        1.4869318008422852,
        1.2450889348983765,
        1.8134149312973022,
        0.9244328141212463,
        1.138993501663208,
        0.5836533308029175,
        0.9625036120414734,
        0.9521417021751404,
        1.3295109272003174,
        0.3748256266117096,
        1.5566145181655884,
        1.469478964805603,
        1.2622510194778442,
        1.2357094287872314,
        1.3654848337173462,
        1.3345211744308472,
        1.1827166080474854,
        1.6105537414550781,
        1.4079445600509644,
        1.356155276298523,
        1.0829298496246338,
        1.2088172435760498,
        1.0400376319885254,
        1.7077369689941406,
        1.2417042255401611,
        1.3501933813095093,
        0.9260111451148987,
        0.9272212386131287,
        1.1561843156814575,
        1.3115127086639404,
        1.0268467664718628,
        1.4780781269073486,
        1.8157399892807007,
        1.3678317070007324,
        1.4764355421066284,
        1.3111475706100464,
        1.1820284128189087,
        1.1155070066452026,
        1.695996880531311,
        0.8799695372581482,
        0.4390050172805786,
        1.2133400440216064,
        1.1282274723052979,
        1.2519749402999878,
        1.0656205415725708,
        1.4143873453140259,
        1.4520759582519531,
        1.0391647815704346,
        0.9670277237892151,
        1.0961260795593262,
        0.9655829668045044,
        1.1541094779968262,
        1.3103559017181396,
        1.814642310142517,
        1.1730077266693115,
        1.2665820121765137,
        1.4927624464035034,
        1.6515637636184692,
        1.6653554439544678,
        1.1973588466644287,
        1.3357045650482178,
        1.6621637344360352,
        1.1818063259124756,
        1.2766581773757935,
        1.4374544620513916,
        1.36141037940979,
        1.2847081422805786,
        0.966295599937439,
        1.3601961135864258,
        1.6407021284103394,
        0.9941605925559998,
        1.1274738311767578,
        0.7834911942481995,
        1.1577917337417603,
        1.6664959192276,
        1.1972719430923462,
        1.5432229042053223,
        1.1437407732009888,
        1.5564641952514648,
        1.3141947984695435,
        1.492648720741272,
        1.1461224555969238,
        1.4647072553634644,
        1.7736058235168457,
        0.9608665704727173,
        1.292899489402771,
        0.759722113609314,
        1.9483250379562378,
        1.2379798889160156,
        1.466167688369751,
        1.1979777812957764,
        1.3382803201675415,
        1.691146969795227,
        1.5363160371780396,
        1.4026867151260376,
        1.4853570461273193,
        1.1546968221664429,
        1.9109538793563843,
        0.9938945770263672,
        0.9914594888687134,
        0.879453718662262,
        1.6898175477981567,
        0.9834084510803223,
        1.436715006828308,
        1.0500006675720215,
        1.142949104309082,
        1.1223787069320679,
        1.2017176151275635,
        1.3883538246154785,
        1.152438759803772,
        0.6034201979637146,
        1.1983917951583862,
        1.4282292127609253,
        1.5401663780212402,
        1.6140217781066895,
        1.0269224643707275,
        1.2466816902160645,
        1.4233356714248657,
        0.9157545566558838,
        0.934465765953064,
        1.512890338897705,
        1.3189866542816162,
        1.246098279953003,
        1.1272674798965454,
        0.7963964343070984,
        1.7928768396377563,
        0.8598427176475525,
        1.2832229137420654,
        1.0531071424484253,
        1.3829529285430908,
        1.3388370275497437,
        1.566022515296936,
        0.7549149394035339,
        0.9566381573677063,
        1.645614743232727,
        1.2393765449523926,
        1.3452666997909546,
        1.6052372455596924,
        1.3249174356460571,
        1.3327184915542603,
        1.0133475065231323,
        1.7468286752700806,
        0.8980914354324341,
        1.7080270051956177,
        1.74486243724823,
        1.4081476926803589,
        0.9843283891677856,
        1.366399884223938,
        1.122568964958191,
        1.7601721286773682,
        1.2272257804870605,
        1.2264584302902222,
        1.3390562534332275,
        0.7688549160957336,
        1.124273657798767,
        1.3022347688674927,
        1.2884862422943115,
        0.809923529624939,
        1.6130460500717163,
        1.3919886350631714,
        1.4021550416946411,
        0.5986528992652893,
        1.163991093635559,
        1.4259529113769531,
        1.080505609512329,
        1.5678311586380005,
        1.4173176288604736,
        1.618117332458496,
        1.2467749118804932,
        1.130856990814209,
        1.3057078123092651,
        0.9444423317909241,
        1.8621671199798584,
        1.0410747528076172,
        0.9156126379966736,
        1.6263794898986816,
        1.4687366485595703,
        1.2160401344299316,
        1.0091278553009033,
        1.2873605489730835,
        1.1978955268859863,
        1.868327021598816,
        1.1991077661514282,
        1.076426386833191,
        1.4893161058425903,
        1.2630003690719604,
        1.0446933507919312,
        0.9870335459709167,
        1.063989520072937,
        1.5944617986679077,
        1.1885490417480469,
        1.6650376319885254,
        1.6346123218536377,
        0.6875807642936707,
        1.2481666803359985,
        1.1670666933059692,
        1.604325532913208,
        0.9658863544464111,
        0.933945894241333,
        1.7997850179672241,
        1.4501780271530151,
        1.2549479007720947,
        1.252760648727417,
        1.8439613580703735,
        1.2708629369735718,
        0.8358206748962402,
        0.8273046016693115,
        1.1826541423797607,
        1.1667917966842651,
        1.3117408752441406,
        1.4971970319747925,
        1.4719706773757935,
        1.6772936582565308,
        0.9456351399421692,
        1.3004769086837769,
        1.4189863204956055,
        1.278456687927246,
        1.2139191627502441,
        1.6458085775375366,
        0.4578872323036194,
        0.6879827380180359,
        1.8367364406585693,
        1.18571937084198,
        1.0232466459274292,
        1.6020647287368774,
        1.2256536483764648,
        1.097681999206543,
        1.6503632068634033,
        0.9605548977851868,
        0.7007294297218323,
        1.717368721961975,
        1.2989530563354492,
        0.931300163269043,
        1.8589545488357544,
        0.9971330761909485,
        1.3970102071762085,
        1.3360166549682617,
        1.0692088603973389,
        1.8386461734771729,
        1.1745643615722656,
        1.484323263168335,
        1.156285285949707,
        0.5631002187728882,
        1.1408483982086182,
        1.3819841146469116,
        1.0721373558044434,
        1.4330042600631714,
        0.9481109976768494,
        1.5193713903427124,
        1.3424806594848633,
        1.7260926961898804,
        1.0985333919525146,
        1.252603530883789,
        1.3840606212615967,
        1.1824951171875,
        0.8334258794784546,
        1.2634841203689575,
        0.8242263793945312,
        1.272485375404358,
        0.904276430606842,
        1.4033203125,
        1.4755297899246216,
        1.4837838411331177,
        1.1703845262527466,
        0.9609626531600952,
        0.9973684549331665,
        0.8195961117744446,
        1.5920172929763794,
        1.0373462438583374,
        0.8257286548614502,
        1.0104255676269531,
        1.3530250787734985,
        0.808608889579773,
        1.533055067062378,
        1.1595027446746826,
        0.613109290599823,
        0.9050787687301636,
        1.449184536933899,
        1.120591402053833,
        1.1801241636276245,
        1.655739665031433,
        1.5719696283340454,
        1.7060786485671997,
        1.1750335693359375,
        1.519761323928833,
        1.2999159097671509,
        1.1070483922958374,
        1.019604206085205,
        1.2752095460891724,
        0.9293708205223083,
        1.3565351963043213,
        1.1846108436584473,
        1.461368441581726,
        1.4167959690093994,
        1.2003777027130127,
        1.437251091003418,
        1.3270978927612305,
        1.2122993469238281,
        0.9179364442825317,
        0.8577664494514465,
        1.089603304862976,
        1.6748158931732178,
        1.670579195022583,
        0.6307034492492676,
        1.744717001914978,
        1.4402973651885986,
        1.2288635969161987,
        1.1228834390640259,
        1.416146159172058,
        1.3830841779708862,
        1.3447073698043823,
        1.2929623126983643,
        0.7993116974830627,
        1.2004178762435913,
        1.1659959554672241,
        1.4446766376495361,
        0.8629321455955505,
        1.0482558012008667,
        1.0218884944915771,
        0.8256505131721497,
        0.8941857218742371,
        1.2408586740493774,
        1.5204761028289795,
        1.1593602895736694,
        0.7908567190170288,
        1.1699920892715454,
        1.321536660194397,
        1.391756296157837,
        1.1895616054534912,
        1.7404773235321045,
        0.7942973375320435,
        1.7314144372940063,
        0.8801193833351135,
        0.9391872882843018,
        1.6639031171798706,
        1.688873052597046,
        0.8479344844818115,
        1.476760983467102,
        1.0178660154342651,
        1.2717267274856567,
        1.1558693647384644,
        1.482653260231018,
        1.3617029190063477,
        1.2905030250549316,
        0.965639591217041,
        1.296428918838501,
        0.5303223133087158,
        1.130237102508545,
        0.8454850316047668,
        0.8806929588317871,
        1.087152361869812,
        0.863587498664856,
        1.3209059238433838,
        1.2598364353179932,
        1.1263794898986816,
        1.0578440427780151,
        1.387690544128418,
        1.3066470623016357,
        0.8193106651306152,
        1.3996790647506714,
        1.4645169973373413,
        1.3581701517105103,
        1.5400339365005493,
        1.2907615900039673,
        1.6315631866455078,
        0.9186757206916809,
        1.1279128789901733,
        0.8286084532737732,
        0.993617594242096,
        1.476045846939087,
        1.4722429513931274,
        0.8477868437767029,
        0.7308632135391235,
        0.9947750568389893,
        0.5302333831787109,
        1.039860725402832,
        1.284894347190857,
        1.5053610801696777,
        1.2934166193008423,
        1.371979832649231,
        1.2756354808807373,
        0.7572821974754333,
        0.6939904689788818,
        0.9891067147254944,
        1.548129677772522,
        1.082091212272644,
        1.0752650499343872,
        1.743025541305542,
        1.59363853931427,
        1.5167464017868042,
        1.4434093236923218,
        1.2960150241851807,
        1.1115058660507202,
        1.2915927171707153,
        1.107532262802124,
        1.3962172269821167,
        1.1031248569488525,
        1.0131051540374756,
        1.3344004154205322,
        1.394734263420105,
        1.6859945058822632,
        1.7242871522903442,
        1.3521286249160767,
        1.2417529821395874,
        1.4170477390289307,
        0.8904946446418762,
        1.4127384424209595,
        1.19687020778656,
        1.4741361141204834,
        0.6010352969169617,
        1.4924628734588623,
        1.4052045345306396,
        1.3421286344528198,
        0.9088135957717896,
        0.6427151560783386,
        1.337622046470642,
        1.47344172000885,
        1.0229253768920898,
        1.4527010917663574,
        1.4096978902816772,
        1.1293505430221558,
        1.768618106842041,
        1.022929072380066,
        0.79179847240448,
        0.7942607998847961,
        1.362282633781433,
        1.521182894706726,
        1.0093705654144287,
        1.119173288345337,
        1.2626495361328125,
        0.6747338175773621,
        1.196140170097351,
        0.9735447764396667,
        1.207274317741394,
        1.6971278190612793,
        1.4146744012832642,
        1.12753164768219,
        1.7000164985656738,
        1.2763053178787231,
        0.9342209696769714,
        1.6890053749084473,
        1.1866626739501953,
        1.2132426500320435,
        1.1133575439453125,
        1.0204668045043945,
        1.7137564420700073,
        1.181610345840454,
        0.7358146905899048,
        0.9896360635757446,
        1.1093684434890747,
        1.3842014074325562,
        1.7725684642791748,
        1.2757043838500977,
        1.6054933071136475,
        1.0196497440338135,
        0.6242254972457886,
        1.0185946226119995,
        1.4230635166168213,
        1.7963021993637085,
        1.153337836265564,
        1.6596097946166992,
        0.6368972063064575,
        0.7803111672401428,
        1.1913254261016846,
        1.2702192068099976,
        1.3997106552124023,
        1.3180327415466309,
        1.481081485748291,
        1.5124132633209229,
        0.9081820845603943,
        1.5092540979385376,
        0.7894919514656067,
        1.1473902463912964,
        1.3309073448181152,
        1.687804102897644,
        0.9544062614440918,
        1.5548852682113647,
        1.2249923944473267,
        1.5951265096664429,
        1.3233050107955933,
        1.3649221658706665,
        0.7918034791946411,
        1.3570185899734497,
        0.9764482975006104,
        1.420248031616211,
        0.8110005259513855,
        1.4850902557373047,
        1.4622528553009033,
        1.4557324647903442,
        1.8812391757965088,
        1.2537962198257446,
        0.9621060490608215,
        1.0453051328659058,
        0.9907718896865845,
        1.4250391721725464,
        1.0565235614776611,
        1.2915760278701782,
        1.4342437982559204,
        1.7286852598190308,
        1.4476284980773926,
        0.7689529657363892,
        1.0595182180404663,
        1.0012127161026,
        1.2317190170288086,
        1.8167965412139893,
        1.215919017791748,
        1.304626703262329,
        1.5915374755859375,
        1.2718760967254639,
        1.4238568544387817,
        1.4835221767425537,
        1.6782587766647339,
        1.4441989660263062,
        1.694709062576294,
        1.743058443069458,
        1.3630108833312988,
        0.9752199053764343,
        1.13374924659729,
        1.1948795318603516,
        1.2957710027694702,
        1.5971121788024902,
        1.487087607383728,
        1.1108096837997437,
        1.3242666721343994,
        1.0859578847885132,
        1.244724154472351,
        1.2972795963287354,
        1.5829442739486694,
        1.5928400754928589,
        1.170028567314148,
        1.4205268621444702,
        1.334789752960205,
        1.325120210647583,
        1.0487691164016724,
        1.5853006839752197,
        1.2253328561782837,
        0.9556922912597656,
        1.314835548400879,
        1.818111538887024,
        1.022303819656372,
        0.6939236521720886,
        1.0826092958450317,
        1.6123321056365967,
        0.9955095648765564,
        0.7761789560317993,
        1.109788417816162,
        1.003174066543579,
        1.4321640729904175,
        1.4909121990203857,
        1.2563652992248535,
        1.3556582927703857,
        1.0110492706298828,
        1.2622908353805542,
        0.7627907991409302,
        1.371424674987793,
        1.3499914407730103,
        1.2280791997909546,
        1.2095661163330078,
        0.9816651940345764,
        1.500598669052124,
        1.5505504608154297,
        1.076424479484558,
        1.5762722492218018,
        1.6432743072509766,
        1.1085833311080933,
        0.9716722965240479,
        0.8067061305046082,
        1.277632236480713,
        1.4220023155212402,
        1.2995340824127197,
        1.1025208234786987,
        1.823553204536438,
        1.3401204347610474,
        1.080736756324768,
        1.316248893737793,
        0.9407896995544434,
        1.2780110836029053,
        1.0723344087600708,
        0.661036491394043,
        1.2726349830627441,
        1.158841848373413,
        1.3877003192901611,
        1.763655424118042,
        1.5442906618118286,
        0.9770029187202454,
        1.7464945316314697,
        0.9164950847625732,
        1.2998592853546143,
        1.0789088010787964,
        1.6334635019302368,
        1.4380460977554321,
        1.3000024557113647,
        1.3817343711853027,
        1.1950788497924805,
        1.0573394298553467,
        0.9883703589439392,
        1.4189988374710083,
        1.0473235845565796,
        0.9591132998466492,
        1.224869966506958,
        1.128426432609558,
        1.073095440864563,
        1.5210851430892944,
        1.45284104347229,
        1.2154028415679932,
        0.873273491859436,
        1.0968860387802124,
        1.2279177904129028,
        1.2751928567886353,
        0.7958012819290161,
        0.8483056426048279,
        0.7937271595001221,
        1.1890374422073364,
        1.1982792615890503,
        1.500370979309082,
        1.0717990398406982,
        1.229638695716858,
        1.0220777988433838,
        0.9263496398925781,
        1.2011809349060059,
        1.6191529035568237,
        1.5572508573532104,
        1.6431097984313965,
        0.9038926362991333,
        1.77000093460083,
        1.0387297868728638,
        0.9177842736244202,
        1.3539334535598755,
        1.1185684204101562,
        1.73444402217865,
        1.5080431699752808,
        1.4324039220809937,
        1.2763731479644775,
        0.7332947850227356,
        1.121741771697998,
        1.1377524137496948,
        1.8323297500610352,
        1.5175955295562744,
        1.465514063835144,
        1.5900437831878662,
        1.3421982526779175,
        1.1180673837661743,
        1.2815477848052979,
        1.118654727935791,
        1.2133463621139526,
        1.5253210067749023,
        1.394717812538147,
        0.9219631552696228,
        1.3771865367889404,
        1.023928165435791,
        0.6337555050849915,
        1.4656902551651,
        0.9043945074081421,
        0.9999445080757141,
        1.226749300956726,
        1.516999363899231,
        1.363458514213562,
        1.1733511686325073,
        1.1671671867370605,
        1.0356528759002686,
        0.9371866583824158,
        1.5105868577957153,
        1.1416857242584229,
        1.367538571357727,
        1.3614213466644287,
        1.0859158039093018,
        1.4040095806121826,
        1.259466528892517,
        1.4645204544067383,
        0.49617281556129456,
        1.3238416910171509,
        0.7839423418045044,
        1.5563896894454956,
        1.2123812437057495,
        1.141480565071106,
        1.3887887001037598,
        1.4255691766738892,
        1.512780785560608,
        1.090461015701294,
        1.0212390422821045,
        1.357295274734497,
        1.206540822982788,
        0.9815917015075684,
        1.674060583114624,
        1.032469391822815,
        1.81696617603302,
        1.4172559976577759,
        1.1594257354736328,
        1.2728464603424072,
        0.7878772616386414,
        1.588728904724121,
        1.5404725074768066,
        1.0989876985549927,
        1.1945936679840088,
        1.6411731243133545,
        0.7059922814369202,
        1.3584738969802856,
        1.32306969165802,
        1.706547737121582,
        1.5993088483810425,
        1.6410080194473267,
        1.558825969696045,
        0.9656991362571716,
        1.2867757081985474,
        0.9810782670974731,
        1.7537497282028198,
        1.1521337032318115,
        0.9570053219795227,
        0.9074885845184326,
        1.3729485273361206,
        1.1422532796859741,
        0.9994350671768188,
        1.3785985708236694,
        1.0330140590667725,
        0.6149165034294128,
        0.9200170040130615,
        0.951241135597229,
        1.5120155811309814,
        0.9806442856788635,
        0.9973360300064087,
        1.5033965110778809,
        1.5918110609054565,
        1.2787368297576904,
        1.172836184501648,
        1.5102216005325317,
        1.2985260486602783,
        1.0718567371368408,
        1.2018166780471802,
        1.6836050748825073,
        1.027858018875122,
        0.7247803211212158,
        1.344056487083435,
        1.171308994293213,
        0.950024425983429,
        1.7044100761413574,
        1.1715370416641235,
        1.541227102279663,
        1.5012307167053223,
        0.9914008975028992,
        0.6329340934753418,
        1.0977849960327148,
        1.1750037670135498,
        1.1894229650497437,
        1.581038475036621,
        1.5289024114608765,
        1.221051812171936,
        1.4292306900024414,
        1.0543582439422607,
        0.7658649682998657,
        1.1134216785430908,
        1.60836923122406,
        0.7606068253517151,
        0.5239496827125549,
        1.4444775581359863,
        1.5007292032241821,
        1.1688505411148071,
        1.3004130125045776,
        0.9707297682762146,
        1.4611841440200806,
        1.0417062044143677,
        1.8553684949874878,
        1.2839460372924805,
        1.4212677478790283,
        0.780789852142334,
        0.8919652700424194,
        1.424053430557251,
        1.490586280822754,
        1.122467041015625,
        1.12100088596344,
        1.3324118852615356,
        1.76094651222229,
        0.9173370003700256,
        0.8825479745864868,
        1.077886700630188,
        1.4142123460769653,
        0.9897149801254272,
        1.2544554471969604,
        1.0760480165481567,
        1.5116088390350342,
        1.179303765296936,
        1.1069221496582031,
        1.478949785232544,
        0.8631294369697571,
        1.4473166465759277,
        1.2493596076965332,
        1.647425651550293,
        0.9618518948554993,
        1.1303821802139282,
        1.6813173294067383,
        1.5901439189910889,
        1.195489764213562,
        0.7874400019645691,
        1.352806806564331,
        1.2146122455596924,
        1.1818197965621948,
        1.7691975831985474,
        1.8105289936065674,
        0.8269284963607788,
        1.488364338874817,
        1.027347207069397,
        0.8148120641708374,
        1.4914697408676147,
        0.9865779280662537,
        1.3602163791656494,
        0.6871962547302246,
        1.0677075386047363,
        1.4945744276046753,
        0.945509672164917,
        1.1753525733947754,
        0.8415762186050415,
        1.6283915042877197,
        0.6052674651145935,
        1.8031576871871948,
        1.285340428352356,
        1.1848055124282837,
        1.429748296737671,
        1.7948875427246094,
        1.261460542678833,
        0.7441655993461609,
        1.1215901374816895,
        1.1115275621414185,
        1.0500528812408447,
        1.0031609535217285,
        1.3583272695541382,
        1.3765016794204712,
        0.8644234538078308,
        1.5819454193115234,
        1.6112045049667358,
        1.2423323392868042,
        1.6303564310073853,
        1.0342422723770142,
        1.4550933837890625,
        1.5136797428131104,
        1.428328514099121,
        1.8453333377838135,
        1.7879542112350464,
        1.4711014032363892,
        1.620552659034729,
        1.584734559059143,
        1.485321044921875,
        1.2480562925338745,
        1.638776183128357,
        1.531318187713623,
        0.590408205986023,
        1.2209932804107666,
        1.5720330476760864,
        1.647026777267456,
        0.6633417010307312,
        1.2467817068099976,
        1.2648940086364746,
        1.3988362550735474,
        1.2899831533432007,
        0.784295380115509,
        1.2689614295959473,
        1.489457368850708,
        1.1575055122375488,
        0.8050963282585144,
        0.851624608039856,
        1.4407068490982056,
        1.5213584899902344,
        1.7330403327941895,
        1.554659128189087,
        1.4827005863189697,
        1.0356996059417725,
        1.3278217315673828,
        1.2922674417495728,
        0.895235538482666,
        0.9550075531005859,
        1.0939991474151611,
        1.000983715057373,
        1.5430089235305786,
        1.8269705772399902,
        1.019616723060608,
        1.7788406610488892,
        0.7706391215324402,
        0.7235208749771118,
        1.19584059715271,
        1.169384241104126,
        1.136918067932129,
        0.8522972464561462,
        1.0009912252426147,
        0.6697859168052673,
        1.0602129697799683,
        1.1439564228057861,
        0.8443694710731506,
        1.4498921632766724,
        1.0626813173294067,
        1.3804240226745605,
        0.8637880086898804,
        1.6919682025909424,
        0.682827353477478,
        1.3424643278121948,
        1.1694164276123047,
        1.229536533355713,
        1.0093209743499756,
        1.1215873956680298,
        1.5005930662155151,
        1.464555263519287,
        0.9711093902587891,
        1.5291521549224854,
        1.5144795179367065,
        0.9898695945739746,
        1.0275211334228516,
        1.0929428339004517,
        1.4406263828277588,
        1.1013317108154297,
        1.1650166511535645,
        1.6001285314559937,
        1.5292493104934692,
        1.4086905717849731,
        1.3390755653381348,
        0.9217711687088013,
        1.5267937183380127,
        1.4469178915023804,
        1.9030510187149048,
        1.332062840461731,
        0.7018851637840271,
        1.4028652906417847,
        1.2654911279678345,
        0.37709394097328186,
        0.9134000539779663,
        1.5308092832565308,
        1.309004306793213,
        0.9287282228469849,
        0.9274008274078369,
        0.4009338617324829,
        0.8643402457237244,
        1.361140489578247,
        1.0028914213180542,
        1.5936131477355957,
        0.9249795079231262,
        1.3103669881820679,
        1.5389634370803833,
        1.483273983001709,
        1.0973877906799316,
        0.9835920929908752,
        1.9433588981628418,
        0.8637482523918152,
        1.7483255863189697,
        1.3169305324554443,
        1.2187914848327637,
        1.405159831047058,
        1.121092438697815,
        1.2381974458694458,
        1.2847143411636353,
        1.2822345495224,
        0.9237744808197021,
        0.9173375964164734,
        1.1406447887420654,
        1.2195420265197754,
        1.4009454250335693,
        1.119245171546936,
        0.9991105794906616,
        1.2404143810272217,
        1.0839649438858032,
        1.2084474563598633,
        1.180556058883667,
        0.7837276458740234,
        0.970138430595398,
        1.3042056560516357,
        1.3808529376983643,
        1.1510087251663208,
        1.462360143661499,
        1.5845059156417847,
        1.544771671295166,
        0.9072498679161072,
        1.418826699256897,
        0.9084755182266235,
        1.0809153318405151,
        1.1780040264129639,
        0.9024382829666138,
        1.3796517848968506,
        1.1821945905685425,
        0.676276683807373,
        0.8897470235824585,
        1.7660775184631348,
        0.8863447904586792,
        0.7454503178596497,
        1.5452289581298828,
        1.5989075899124146,
        1.6273423433303833,
        1.1149243116378784,
        1.2058125734329224,
        1.4089950323104858,
        1.3548005819320679,
        0.9540853500366211,
        0.9304981827735901,
        0.9665042161941528,
        0.5363942980766296,
        1.3111350536346436,
        1.2719839811325073,
        1.3652665615081787,
        1.2494657039642334,
        1.5603570938110352,
        1.1981452703475952,
        1.5329049825668335,
        0.9662202000617981,
        1.307420253753662,
        1.4535162448883057,
        1.0799353122711182,
        1.087186336517334,
        0.7621304392814636,
        1.1086052656173706,
        1.2746449708938599,
        0.9771224856376648,
        1.2090134620666504,
        0.7860825061798096,
        1.4468861818313599,
        1.1503825187683105,
        1.4485725164413452,
        1.228429913520813,
        1.6577448844909668,
        1.107373595237732,
        1.186702847480774,
        1.3782588243484497,
        0.9562990069389343,
        1.302670955657959,
        0.7320210933685303,
        1.6377346515655518,
        1.102485179901123,
        1.2254204750061035,
        0.9858971834182739,
        1.270553708076477,
        1.3800060749053955,
        1.400305986404419,
        1.6082197427749634,
        1.6639763116836548,
        0.7834512591362,
        1.2457821369171143,
        0.7037447094917297,
        1.1163886785507202,
        1.3279114961624146,
        1.2113972902297974,
        1.0552910566329956,
        1.4946494102478027,
        1.5337013006210327,
        1.6420819759368896,
        1.2772413492202759,
        0.5373663902282715,
        1.1746697425842285,
        1.0971330404281616,
        1.2732815742492676,
        1.2354832887649536,
        1.3440130949020386,
        1.303539752960205,
        1.4651567935943604,
        1.0397157669067383,
        0.727256178855896,
        1.4102058410644531,
        0.9223388433456421,
        1.5778626203536987,
        0.6974936723709106,
        1.3550938367843628,
        1.2462105751037598,
        1.673183798789978,
        1.6404554843902588,
        0.9269877672195435,
        1.3332480192184448,
        1.38007652759552,
        1.4285434484481812,
        1.8016482591629028,
        1.3625158071517944,
        0.9315549731254578,
        1.0470079183578491,
        1.2623450756072998,
        1.5428662300109863,
        1.367005705833435,
        1.307228684425354,
        1.01268470287323,
        1.4543840885162354,
        1.0576218366622925,
        1.6466972827911377,
        1.1404188871383667,
        1.2784478664398193,
        1.0909640789031982,
        1.1149299144744873,
        1.1326467990875244,
        1.0035804510116577,
        1.041283130645752,
        1.31645929813385,
        1.669219732284546,
        1.141548991203308,
        1.1554343700408936,
        0.8108152151107788,
        1.3417952060699463,
        1.5392338037490845,
        1.2370922565460205,
        1.320600986480713,
        1.4415346384048462,
        1.251033067703247,
        0.8031855225563049,
        1.9428788423538208,
        0.8328388929367065,
        1.4117395877838135,
        0.8497016429901123,
        0.8036432266235352,
        1.0832102298736572,
        1.2961004972457886,
        1.1092857122421265,
        1.3053827285766602,
        1.2167339324951172,
        1.1530678272247314,
        1.2364164590835571,
        1.4851624965667725,
        1.3120688199996948,
        0.9615647792816162,
        0.9806181788444519,
        1.383303165435791,
        1.476958990097046,
        1.378037452697754,
        1.0939964056015015,
        1.3241636753082275,
        0.8010095357894897,
        1.2017698287963867,
        1.5485687255859375,
        1.7871476411819458,
        1.4397244453430176,
        0.9794892072677612,
        1.5251569747924805,
        1.480411171913147,
        1.1001983880996704,
        1.5148435831069946,
        1.421445369720459,
        1.3653769493103027,
        0.9804845452308655,
        1.240795612335205,
        1.2891782522201538,
        1.7664580345153809,
        0.9707403779029846,
        1.614367127418518,
        1.3066072463989258,
        0.6272900104522705,
        1.507930874824524,
        1.406333565711975,
        0.945372998714447,
        0.8749356865882874,
        0.9766823053359985,
        0.9411740303039551,
        1.082417368888855,
        1.7042027711868286,
        1.6758100986480713,
        1.2359976768493652,
        1.247678279876709,
        1.237400770187378,
        1.417994499206543,
        0.8044437170028687,
        0.9893093109130859,
        1.2157357931137085,
        0.9205241799354553,
        1.4872791767120361,
        1.497170090675354,
        1.682308554649353,
        0.9168291687965393,
        0.7861976027488708,
        1.350050926208496,
        1.662401795387268,
        1.5323880910873413,
        1.1335700750350952,
        1.0689337253570557,
        1.151769757270813,
        1.441184639930725,
        1.1869724988937378,
        1.334897756576538,
        1.274515986442566,
        1.247577428817749,
        1.2731996774673462,
        1.0493324995040894,
        1.6899659633636475,
        0.7827670574188232,
        1.5287630558013916,
        1.4098392724990845,
        1.317656397819519,
        0.9970192313194275,
        1.5317277908325195,
        1.5922914743423462,
        1.3489668369293213,
        1.2130208015441895,
        1.3343255519866943,
        1.1620923280715942,
        1.381645917892456,
        1.1114941835403442,
        1.3237212896347046,
        1.3237231969833374,
        1.6521073579788208,
        1.1009256839752197,
        1.270484209060669,
        1.044249415397644,
        1.6038273572921753,
        1.3256185054779053,
        1.0735868215560913,
        1.0142241716384888,
        1.4679539203643799,
        1.2566112279891968,
        1.0114359855651855,
        1.3123395442962646,
        1.04535973072052,
        1.176213264465332,
        0.7871373891830444,
        0.8627200126647949,
        0.5462139844894409,
        0.8150025010108948,
        0.6851582527160645,
        1.391526460647583,
        1.0258991718292236,
        1.0669232606887817,
        1.3297635316848755,
        1.4013793468475342,
        1.3432403802871704,
        1.241576075553894,
        1.4727528095245361,
        1.056140661239624,
        1.330409049987793,
        0.9686349630355835,
        1.3624341487884521,
        1.7029298543930054,
        1.2787938117980957,
        1.0247269868850708,
        1.111994981765747,
        1.1296372413635254,
        0.7756994366645813,
        1.1233195066452026,
        1.653351068496704,
        1.4408174753189087,
        1.2496227025985718,
        1.4820284843444824,
        1.4303878545761108,
        1.8513152599334717,
        1.5936996936798096,
        1.0879019498825073,
        1.6182217597961426,
        1.2699902057647705,
        1.4270262718200684,
        1.2641531229019165,
        0.8134248852729797,
        1.6677521467208862,
        1.060878038406372,
        0.7924365997314453,
        1.1031399965286255,
        1.714581847190857,
        1.1706899404525757,
        1.6177730560302734,
        0.865663468837738,
        0.2825373411178589,
        0.8727573156356812,
        1.1568615436553955,
        1.2685073614120483,
        1.6027189493179321,
        0.97225022315979,
        1.8650612831115723,
        0.5332876443862915,
        1.3744981288909912,
        0.6781591773033142,
        1.3215093612670898,
        1.17122220993042,
        1.366481065750122,
        1.5835727453231812,
        1.2354682683944702,
        1.3026307821273804
    ],
    "irt_model": "2pl",
    "item_ids": {
        "0": "q_0",
        "1": "q_1",
        "2": "q_2",
        "3": "q_3",
        "4": "q_4",
        "5": "q_5",
        "6": "q_6",
        "7": "q_7",
        "8": "q_8",
        "9": "q_9",
        "10": "q_10",
        "11": "q_11",
        "12": "q_12",
        "13": "q_13",
        "14": "q_14",
        "15": "q_15",
        "16": "q_16",
        "17": "q_17",
        "18": "q_18",
        "19": "q_19",
        "20": "q_20",
        "21": "q_21",
        "22": "q_22",
        "23": "q_23",
        "24": "q_24",
        "25": "q_25",
        "26": "q_26",
        "27": "q_27",
        "28": "q_28",
        "29": "q_29",
        "30": "q_30",
        "31": "q_31",
        "32": "q_32",
        "33": "q_33",
        "34": "q_34",
        "35": "q_35",
        "36": "q_36",
        "37": "q_37",
        "38": "q_38",
        "39": "q_39",
        "40": "q_40",
        "41": "q_41",
        "42": "q_43",
        "43": "q_44",
        "44": "q_45",
        "45": "q_46",
        "46": "q_47",
        "47": "q_48",
        "48": "q_49",
        "49": "q_50",
        "50": "q_51",
        "51": "q_52",
        "52": "q_53",
        "53": "q_54",
        "54": "q_55",
        "55": "q_56",
        "56": "q_57",
        "57": "q_58",
        "58": "q_59",
        "59": "q_60",
        "60": "q_61",
        "61": "q_62",
        "62": "q_63",
        "63": "q_64",
        "64": "q_65",
        "65": "q_66",
        "66": "q_67",
        "67": "q_68",
        "68": "q_69",
        "69": "q_70",
        "70": "q_71",
        "71": "q_72",
        "72": "q_73",
        "73": "q_74",
        "74": "q_75",
        "75": "q_76",
        "76": "q_77",
        "77": "q_78",
        "78": "q_79",
        "79": "q_80",
        "80": "q_81",
        "81": "q_82",
        "82": "q_83",
        "83": "q_84",
        "84": "q_85",
        "85": "q_86",
        "86": "q_87",
        "87": "q_88",
        "88": "q_89",
        "89": "q_90",
        "90": "q_91",
        "91": "q_92",
        "92": "q_93",
        "93": "q_94",
        "94": "q_95",
        "95": "q_96",
        "96": "q_97",
        "97": "q_98",
        "98": "q_99",
        "99": "q_100",
        "100": "q_101",
        "101": "q_102",
        "102": "q_103",
        "103": "q_104",
        "104": "q_105",
        "105": "q_106",
        "106": "q_107",
        "107": "q_108",
        "108": "q_109",
        "109": "q_110",
        "110": "q_111",
        "111": "q_112",
        "112": "q_113",
        "113": "q_114",
        "114": "q_115",
        "115": "q_116",
        "116": "q_117",
        "117": "q_118",
        "118": "q_119",
        "119": "q_120",
        "120": "q_122",
        "121": "q_123",
        "122": "q_124",
        "123": "q_125",
        "124": "q_126",
        "125": "q_127",
        "126": "q_128",
        "127": "q_129",
        "128": "q_130",
        "129": "q_131",
        "130": "q_132",
        "131": "q_133",
        "132": "q_134",
        "133": "q_135",
        "134": "q_136",
        "135": "q_137",
        "136": "q_138",
        "137": "q_139",
        "138": "q_140",
        "139": "q_141",
        "140": "q_142",
        "141": "q_143",
        "142": "q_144",
        "143": "q_145",
        "144": "q_146",
        "145": "q_147",
        "146": "q_148",
        "147": "q_149",
        "148": "q_150",
        "149": "q_151",
        "150": "q_152",
        "151": "q_153",
        "152": "q_154",
        "153": "q_155",
        "154": "q_156",
        "155": "q_157",
        "156": "q_158",
        "157": "q_159",
        "158": "q_160",
        "159": "q_161",
        "160": "q_162",
        "161": "q_163",
        "162": "q_164",
        "163": "q_165",
        "164": "q_166",
        "165": "q_167",
        "166": "q_168",
        "167": "q_169",
        "168": "q_170",
        "169": "q_171",
        "170": "q_173",
        "171": "q_174",
        "172": "q_175",
        "173": "q_176",
        "174": "q_177",
        "175": "q_178",
        "176": "q_179",
        "177": "q_180",
        "178": "q_181",
        "179": "q_182",
        "180": "q_183",
        "181": "q_184",
        "182": "q_185",
        "183": "q_186",
        "184": "q_187",
        "185": "q_188",
        "186": "q_189",
        "187": "q_190",
        "188": "q_191",
        "189": "q_192",
        "190": "q_193",
        "191": "q_194",
        "192": "q_195",
        "193": "q_196",
        "194": "q_197",
        "195": "q_198",
        "196": "q_199",
        "197": "q_200",
        "198": "q_201",
        "199": "q_202",
        "200": "q_203",
        "201": "q_204",
        "202": "q_205",
        "203": "q_206",
        "204": "q_207",
        "205": "q_208",
        "206": "q_209",
        "207": "q_210",
        "208": "q_211",
        "209": "q_212",
        "210": "q_213",
        "211": "q_214",
        "212": "q_215",
        "213": "q_216",
        "214": "q_217",
        "215": "q_218",
        "216": "q_219",
        "217": "q_220",
        "218": "q_221",
        "219": "q_222",
        "220": "q_224",
        "221": "q_225",
        "222": "q_226",
        "223": "q_227",
        "224": "q_228",
        "225": "q_229",
        "226": "q_230",
        "227": "q_231",
        "228": "q_232",
        "229": "q_233",
        "230": "q_234",
        "231": "q_235",
        "232": "q_236",
        "233": "q_237",
        "234": "q_238",
        "235": "q_239",
        "236": "q_240",
        "237": "q_241",
        "238": "q_242",
        "239": "q_243",
        "240": "q_244",
        "241": "q_245",
        "242": "q_246",
        "243": "q_247",
        "244": "q_248",
        "245": "q_249",
        "246": "q_250",
        "247": "q_251",
        "248": "q_252",
        "249": "q_253",
        "250": "q_254",
        "251": "q_255",
        "252": "q_256",
        "253": "q_257",
        "254": "q_258",
        "255": "q_259",
        "256": "q_260",
        "257": "q_261",
        "258": "q_262",
        "259": "q_263",
        "260": "q_264",
        "261": "q_265",
        "262": "q_266",
        "263": "q_267",
        "264": "q_268",
        "265": "q_269",
        "266": "q_270",
        "267": "q_271",
        "268": "q_272",
        "269": "q_273",
        "270": "q_274",
        "271": "q_275",
        "272": "q_276",
        "273": "q_277",
        "274": "q_278",
        "275": "q_279",
        "276": "q_280",
        "277": "q_281",
        "278": "q_282",
        "279": "q_283",
        "280": "q_284",
        "281": "q_285",
        "282": "q_286",
        "283": "q_287",
        "284": "q_288",
        "285": "q_289",
        "286": "q_290",
        "287": "q_291",
        "288": "q_292",
        "289": "q_293",
        "290": "q_294",
        "291": "q_295",
        "292": "q_296",
        "293": "q_297",
        "294": "q_298",
        "295": "q_299",
        "296": "q_300",
        "297": "q_301",
        "298": "q_302",
        "299": "q_303",
        "300": "q_304",
        "301": "q_305",
        "302": "q_306",
        "303": "q_307",
        "304": "q_308",
        "305": "q_309",
        "306": "q_310",
        "307": "q_311",
        "308": "q_312",
        "309": "q_313",
        "310": "q_314",
        "311": "q_315",
        "312": "q_316",
        "313": "q_317",
        "314": "q_318",
        "315": "q_319",
        "316": "q_320",
        "317": "q_321",
        "318": "q_322",
        "319": "q_323",
        "320": "q_324",
        "321": "q_325",
        "322": "q_326",
        "323": "q_327",
        "324": "q_328",
        "325": "q_329",
        "326": "q_330",
        "327": "q_331",
        "328": "q_332",
        "329": "q_333",
        "330": "q_334",
        "331": "q_335",
        "332": "q_336",
        "333": "q_337",
        "334": "q_338",
        "335": "q_339",
        "336": "q_340",
        "337": "q_341",
        "338": "q_342",
        "339": "q_343",
        "340": "q_345",
        "341": "q_346",
        "342": "q_347",
        "343": "q_348",
        "344": "q_349",
        "345": "q_350",
        "346": "q_351",
        "347": "q_352",
        "348": "q_353",
        "349": "q_354",
        "350": "q_355",
        "351": "q_356",
        "352": "q_357",
        "353": "q_358",
        "354": "q_359",
        "355": "q_360",
        "356": "q_361",
        "357": "q_362",
        "358": "q_363",
        "359": "q_364",
        "360": "q_365",
        "361": "q_366",
        "362": "q_367",
        "363": "q_368",
        "364": "q_369",
        "365": "q_370",
        "366": "q_371",
        "367": "q_372",
        "368": "q_373",
        "369": "q_374",
        "370": "q_375",
        "371": "q_376",
        "372": "q_377",
        "373": "q_378",
        "374": "q_379",
        "375": "q_380",
        "376": "q_381",
        "377": "q_382",
        "378": "q_383",
        "379": "q_384",
        "380": "q_385",
        "381": "q_386",
        "382": "q_387",
        "383": "q_388",
        "384": "q_389",
        "385": "q_391",
        "386": "q_392",
        "387": "q_393",
        "388": "q_394",
        "389": "q_395",
        "390": "q_396",
        "391": "q_397",
        "392": "q_398",
        "393": "q_399",
        "394": "q_400",
        "395": "q_401",
        "396": "q_402",
        "397": "q_403",
        "398": "q_404",
        "399": "q_405",
        "400": "q_406",
        "401": "q_407",
        "402": "q_408",
        "403": "q_409",
        "404": "q_410",
        "405": "q_411",
        "406": "q_412",
        "407": "q_413",
        "408": "q_414",
        "409": "q_415",
        "410": "q_416",
        "411": "q_417",
        "412": "q_418",
        "413": "q_419",
        "414": "q_420",
        "415": "q_421",
        "416": "q_422",
        "417": "q_423",
        "418": "q_424",
        "419": "q_425",
        "420": "q_426",
        "421": "q_427",
        "422": "q_428",
        "423": "q_429",
        "424": "q_430",
        "425": "q_431",
        "426": "q_432",
        "427": "q_433",
        "428": "q_434",
        "429": "q_435",
        "430": "q_436",
        "431": "q_437",
        "432": "q_438",
        "433": "q_439",
        "434": "q_440",
        "435": "q_441",
        "436": "q_442",
        "437": "q_443",
        "438": "q_444",
        "439": "q_445",
        "440": "q_446",
        "441": "q_447",
        "442": "q_448",
        "443": "q_449",
        "444": "q_450",
        "445": "q_451",
        "446": "q_452",
        "447": "q_453",
        "448": "q_454",
        "449": "q_455",
        "450": "q_456",
        "451": "q_457",
        "452": "q_458",
        "453": "q_459",
        "454": "q_460",
        "455": "q_461",
        "456": "q_462",
        "457": "q_463",
        "458": "q_464",
        "459": "q_465",
        "460": "q_466",
        "461": "q_467",
        "462": "q_468",
        "463": "q_469",
        "464": "q_470",
        "465": "q_471",
        "466": "q_472",
        "467": "q_473",
        "468": "q_474",
        "469": "q_475",
        "470": "q_476",
        "471": "q_477",
        "472": "q_478",
        "473": "q_479",
        "474": "q_480",
        "475": "q_481",
        "476": "q_482",
        "477": "q_483",
        "478": "q_484",
        "479": "q_485",
        "480": "q_486",
        "481": "q_487",
        "482": "q_488",
        "483": "q_489",
        "484": "q_490",
        "485": "q_491",
        "486": "q_492",
        "487": "q_493",
        "488": "q_494",
        "489": "q_495",
        "490": "q_496",
        "491": "q_497",
        "492": "q_498",
        "493": "q_499",
        "494": "q_500",
        "495": "q_501",
        "496": "q_502",
        "497": "q_503",
        "498": "q_504",
        "499": "q_505",
        "500": "q_506",
        "501": "q_507",
        "502": "q_508",
        "503": "q_509",
        "504": "q_510",
        "505": "q_511",
        "506": "q_512",
        "507": "q_513",
        "508": "q_514",
        "509": "q_515",
        "510": "q_516",
        "511": "q_517",
        "512": "q_518",
        "513": "q_519",
        "514": "q_520",
        "515": "q_521",
        "516": "q_522",
        "517": "q_523",
        "518": "q_524",
        "519": "q_525",
        "520": "q_526",
        "521": "q_527",
        "522": "q_528",
        "523": "q_529",
        "524": "q_531",
        "525": "q_532",
        "526": "q_533",
        "527": "q_534",
        "528": "q_535",
        "529": "q_536",
        "530": "q_537",
        "531": "q_538",
        "532": "q_539",
        "533": "q_540",
        "534": "q_541",
        "535": "q_542",
        "536": "q_543",
        "537": "q_544",
        "538": "q_545",
        "539": "q_546",
        "540": "q_547",
        "541": "q_548",
        "542": "q_549",
        "543": "q_550",
        "544": "q_551",
        "545": "q_552",
        "546": "q_553",
        "547": "q_554",
        "548": "q_555",
        "549": "q_556",
        "550": "q_557",
        "551": "q_558",
        "552": "q_559",
        "553": "q_560",
        "554": "q_561",
        "555": "q_562",
        "556": "q_563",
        "557": "q_564",
        "558": "q_565",
        "559": "q_566",
        "560": "q_567",
        "561": "q_568",
        "562": "q_569",
        "563": "q_571",
        "564": "q_572",
        "565": "q_573",
        "566": "q_574",
        "567": "q_575",
        "568": "q_576",
        "569": "q_577",
        "570": "q_578",
        "571": "q_579",
        "572": "q_580",
        "573": "q_581",
        "574": "q_582",
        "575": "q_583",
        "576": "q_584",
        "577": "q_585",
        "578": "q_586",
        "579": "q_587",
        "580": "q_589",
        "581": "q_590",
        "582": "q_591",
        "583": "q_592",
        "584": "q_593",
        "585": "q_594",
        "586": "q_595",
        "587": "q_596",
        "588": "q_597",
        "589": "q_598",
        "590": "q_599",
        "591": "q_600",
        "592": "q_601",
        "593": "q_602",
        "594": "q_603",
        "595": "q_604",
        "596": "q_605",
        "597": "q_606",
        "598": "q_607",
        "599": "q_608",
        "600": "q_609",
        "601": "q_610",
        "602": "q_611",
        "603": "q_612",
        "604": "q_613",
        "605": "q_614",
        "606": "q_615",
        "607": "q_616",
        "608": "q_617",
        "609": "q_618",
        "610": "q_619",
        "611": "q_620",
        "612": "q_621",
        "613": "q_622",
        "614": "q_624",
        "615": "q_625",
        "616": "q_626",
        "617": "q_627",
        "618": "q_628",
        "619": "q_629",
        "620": "q_630",
        "621": "q_631",
        "622": "q_632",
        "623": "q_633",
        "624": "q_634",
        "625": "q_635",
        "626": "q_636",
        "627": "q_637",
        "628": "q_638",
        "629": "q_639",
        "630": "q_640",
        "631": "q_641",
        "632": "q_642",
        "633": "q_643",
        "634": "q_644",
        "635": "q_645",
        "636": "q_646",
        "637": "q_647",
        "638": "q_648",
        "639": "q_649",
        "640": "q_650",
        "641": "q_651",
        "642": "q_652",
        "643": "q_653",
        "644": "q_654",
        "645": "q_655",
        "646": "q_656",
        "647": "q_657",
        "648": "q_658",
        "649": "q_659",
        "650": "q_660",
        "651": "q_661",
        "652": "q_662",
        "653": "q_663",
        "654": "q_664",
        "655": "q_665",
        "656": "q_666",
        "657": "q_667",
        "658": "q_668",
        "659": "q_669",
        "660": "q_670",
        "661": "q_671",
        "662": "q_672",
        "663": "q_673",
        "664": "q_674",
        "665": "q_675",
        "666": "q_676",
        "667": "q_677",
        "668": "q_678",
        "669": "q_679",
        "670": "q_680",
        "671": "q_681",
        "672": "q_682",
        "673": "q_683",
        "674": "q_684",
        "675": "q_685",
        "676": "q_686",
        "677": "q_687",
        "678": "q_688",
        "679": "q_689",
        "680": "q_690",
        "681": "q_691",
        "682": "q_692",
        "683": "q_693",
        "684": "q_694",
        "685": "q_695",
        "686": "q_696",
        "687": "q_697",
        "688": "q_698",
        "689": "q_699",
        "690": "q_701",
        "691": "q_702",
        "692": "q_703",
        "693": "q_704",
        "694": "q_705",
        "695": "q_706",
        "696": "q_707",
        "697": "q_708",
        "698": "q_709",
        "699": "q_710",
        "700": "q_711",
        "701": "q_712",
        "702": "q_713",
        "703": "q_714",
        "704": "q_715",
        "705": "q_716",
        "706": "q_717",
        "707": "q_718",
        "708": "q_719",
        "709": "q_720",
        "710": "q_721",
        "711": "q_722",
        "712": "q_723",
        "713": "q_724",
        "714": "q_725",
        "715": "q_726",
        "716": "q_727",
        "717": "q_728",
        "718": "q_729",
        "719": "q_730",
        "720": "q_731",
        "721": "q_732",
        "722": "q_733",
        "723": "q_734",
        "724": "q_735",
        "725": "q_736",
        "726": "q_737",
        "727": "q_738",
        "728": "q_739",
        "729": "q_740",
        "730": "q_741",
        "731": "q_742",
        "732": "q_743",
        "733": "q_744",
        "734": "q_745",
        "735": "q_746",
        "736": "q_747",
        "737": "q_748",
        "738": "q_749",
        "739": "q_750",
        "740": "q_751",
        "741": "q_752",
        "742": "q_753",
        "743": "q_754",
        "744": "q_755",
        "745": "q_756",
        "746": "q_757",
        "747": "q_758",
        "748": "q_759",
        "749": "q_760",
        "750": "q_761",
        "751": "q_762",
        "752": "q_763",
        "753": "q_764",
        "754": "q_765",
        "755": "q_766",
        "756": "q_767",
        "757": "q_768",
        "758": "q_769",
        "759": "q_770",
        "760": "q_771",
        "761": "q_772",
        "762": "q_773",
        "763": "q_774",
        "764": "q_775",
        "765": "q_776",
        "766": "q_777",
        "767": "q_778",
        "768": "q_779",
        "769": "q_780",
        "770": "q_781",
        "771": "q_782",
        "772": "q_783",
        "773": "q_784",
        "774": "q_785",
        "775": "q_786",
        "776": "q_787",
        "777": "q_788",
        "778": "q_789",
        "779": "q_790",
        "780": "q_791",
        "781": "q_792",
        "782": "q_793",
        "783": "q_794",
        "784": "q_795",
        "785": "q_796",
        "786": "q_797",
        "787": "q_798",
        "788": "q_799",
        "789": "q_800",
        "790": "q_801",
        "791": "q_802",
        "792": "q_803",
        "793": "q_804",
        "794": "q_805",
        "795": "q_806",
        "796": "q_807",
        "797": "q_808",
        "798": "q_809",
        "799": "q_810",
        "800": "q_811",
        "801": "q_812",
        "802": "q_813",
        "803": "q_814",
        "804": "q_815",
        "805": "q_816",
        "806": "q_817",
        "807": "q_818",
        "808": "q_819",
        "809": "q_820",
        "810": "q_821",
        "811": "q_822",
        "812": "q_823",
        "813": "q_824",
        "814": "q_825",
        "815": "q_826",
        "816": "q_827",
        "817": "q_828",
        "818": "q_829",
        "819": "q_830",
        "820": "q_831",
        "821": "q_833",
        "822": "q_834",
        "823": "q_835",
        "824": "q_836",
        "825": "q_837",
        "826": "q_838",
        "827": "q_839",
        "828": "q_840",
        "829": "q_841",
        "830": "q_842",
        "831": "q_843",
        "832": "q_844",
        "833": "q_845",
        "834": "q_846",
        "835": "q_847",
        "836": "q_848",
        "837": "q_849",
        "838": "q_850",
        "839": "q_851",
        "840": "q_852",
        "841": "q_853",
        "842": "q_854",
        "843": "q_855",
        "844": "q_856",
        "845": "q_857",
        "846": "q_858",
        "847": "q_859",
        "848": "q_860",
        "849": "q_861",
        "850": "q_862",
        "851": "q_863",
        "852": "q_864",
        "853": "q_865",
        "854": "q_866",
        "855": "q_867",
        "856": "q_868",
        "857": "q_869",
        "858": "q_870",
        "859": "q_871",
        "860": "q_872",
        "861": "q_873",
        "862": "q_874",
        "863": "q_875",
        "864": "q_876",
        "865": "q_877",
        "866": "q_878",
        "867": "q_879",
        "868": "q_880",
        "869": "q_881",
        "870": "q_882",
        "871": "q_883",
        "872": "q_884",
        "873": "q_885",
        "874": "q_886",
        "875": "q_887",
        "876": "q_888",
        "877": "q_889",
        "878": "q_890",
        "879": "q_891",
        "880": "q_892",
        "881": "q_893",
        "882": "q_894",
        "883": "q_895",
        "884": "q_896",
        "885": "q_897",
        "886": "q_898",
        "887": "q_899",
        "888": "q_900",
        "889": "q_901",
        "890": "q_902",
        "891": "q_903",
        "892": "q_904",
        "893": "q_905",
        "894": "q_906",
        "895": "q_907",
        "896": "q_908",
        "897": "q_909",
        "898": "q_910",
        "899": "q_911",
        "900": "q_912",
        "901": "q_913",
        "902": "q_914",
        "903": "q_915",
        "904": "q_916",
        "905": "q_917",
        "906": "q_918",
        "907": "q_919",
        "908": "q_920",
        "909": "q_921",
        "910": "q_922",
        "911": "q_923",
        "912": "q_924",
        "913": "q_925",
        "914": "q_926",
        "915": "q_927",
        "916": "q_928",
        "917": "q_929",
        "918": "q_930",
        "919": "q_931",
        "920": "q_932",
        "921": "q_933",
        "922": "q_934",
        "923": "q_935",
        "924": "q_936",
        "925": "q_937",
        "926": "q_938",
        "927": "q_939",
        "928": "q_940",
        "929": "q_941",
        "930": "q_942",
        "931": "q_943",
        "932": "q_944",
        "933": "q_945",
        "934": "q_946",
        "935": "q_947",
        "936": "q_948",
        "937": "q_949",
        "938": "q_950",
        "939": "q_951",
        "940": "q_952",
        "941": "q_953",
        "942": "q_954",
        "943": "q_955",
        "944": "q_956",
        "945": "q_957",
        "946": "q_958",
        "947": "q_959",
        "948": "q_960",
        "949": "q_961",
        "950": "q_962",
        "951": "q_963",
        "952": "q_964",
        "953": "q_965",
        "954": "q_966",
        "955": "q_967",
        "956": "q_968",
        "957": "q_969",
        "958": "q_970",
        "959": "q_971",
        "960": "q_972",
        "961": "q_973",
        "962": "q_974",
        "963": "q_975",
        "964": "q_976",
        "965": "q_977",
        "966": "q_978",
        "967": "q_979",
        "968": "q_980",
        "969": "q_981",
        "970": "q_982",
        "971": "q_983",
        "972": "q_984",
        "973": "q_985",
        "974": "q_986",
        "975": "q_987",
        "976": "q_988",
        "977": "q_989",
        "978": "q_990",
        "979": "q_991",
        "980": "q_992",
        "981": "q_993",
        "982": "q_994",
        "983": "q_995",
        "984": "q_996",
        "985": "q_997",
        "986": "q_998",
        "987": "q_999",
        "988": "q_1000",
        "989": "q_1001",
        "990": "q_1002",
        "991": "q_1003",
        "992": "q_1004",
        "993": "q_1005",
        "994": "q_1006",
        "995": "q_1007",
        "996": "q_1008",
        "997": "q_1009",
        "998": "q_1010",
        "999": "q_1011",
        "1000": "q_1012",
        "1001": "q_1013",
        "1002": "q_1014",
        "1003": "q_1015",
        "1004": "q_1016",
        "1005": "q_1017",
        "1006": "q_1018",
        "1007": "q_1019",
        "1008": "q_1020",
        "1009": "q_1021",
        "1010": "q_1022",
        "1011": "q_1023",
        "1012": "q_1024",
        "1013": "q_1025",
        "1014": "q_1026",
        "1015": "q_1027",
        "1016": "q_1028",
        "1017": "q_1029",
        "1018": "q_1030",
        "1019": "q_1031",
        "1020": "q_1032",
        "1021": "q_1033",
        "1022": "q_1034",
        "1023": "q_1035",
        "1024": "q_1036",
        "1025": "q_1037",
        "1026": "q_1038",
        "1027": "q_1039",
        "1028": "q_1040",
        "1029": "q_1041",
        "1030": "q_1042",
        "1031": "q_1043",
        "1032": "q_1044",
        "1033": "q_1045",
        "1034": "q_1046",
        "1035": "q_1047",
        "1036": "q_1048",
        "1037": "q_1049",
        "1038": "q_1050",
        "1039": "q_1051",
        "1040": "q_1052",
        "1041": "q_1053",
        "1042": "q_1054",
        "1043": "q_1055",
        "1044": "q_1056",
        "1045": "q_1058",
        "1046": "q_1059",
        "1047": "q_1060",
        "1048": "q_1061",
        "1049": "q_1062",
        "1050": "q_1063",
        "1051": "q_1064",
        "1052": "q_1065",
        "1053": "q_1066",
        "1054": "q_1067",
        "1055": "q_1068",
        "1056": "q_1069",
        "1057": "q_1070",
        "1058": "q_1071",
        "1059": "q_1072",
        "1060": "q_1073",
        "1061": "q_1074",
        "1062": "q_1075",
        "1063": "q_1076",
        "1064": "q_1077",
        "1065": "q_1078",
        "1066": "q_1079",
        "1067": "q_1080",
        "1068": "q_1081",
        "1069": "q_1082",
        "1070": "q_1083",
        "1071": "q_1084",
        "1072": "q_1085",
        "1073": "q_1086",
        "1074": "q_1087",
        "1075": "q_1088",
        "1076": "q_1089",
        "1077": "q_1090",
        "1078": "q_1091",
        "1079": "q_1092",
        "1080": "q_1093",
        "1081": "q_1094",
        "1082": "q_1095",
        "1083": "q_1096",
        "1084": "q_1097",
        "1085": "q_1098",
        "1086": "q_1099",
        "1087": "q_1100",
        "1088": "q_1101",
        "1089": "q_1102",
        "1090": "q_1103",
        "1091": "q_1104",
        "1092": "q_1105",
        "1093": "q_1106",
        "1094": "q_1107",
        "1095": "q_1108",
        "1096": "q_1109",
        "1097": "q_1110",
        "1098": "q_1111",
        "1099": "q_1112",
        "1100": "q_1113",
        "1101": "q_1114",
        "1102": "q_1115",
        "1103": "q_1116",
        "1104": "q_1117",
        "1105": "q_1118",
        "1106": "q_1119",
        "1107": "q_1120",
        "1108": "q_1121",
        "1109": "q_1122",
        "1110": "q_1123",
        "1111": "q_1124",
        "1112": "q_1125",
        "1113": "q_1126",
        "1114": "q_1127",
        "1115": "q_1128",
        "1116": "q_1129",
        "1117": "q_1130",
        "1118": "q_1131",
        "1119": "q_1132",
        "1120": "q_1133",
        "1121": "q_1134",
        "1122": "q_1135",
        "1123": "q_1136",
        "1124": "q_1137",
        "1125": "q_1138",
        "1126": "q_1139",
        "1127": "q_1140",
        "1128": "q_1141",
        "1129": "q_1142",
        "1130": "q_1143",
        "1131": "q_1144",
        "1132": "q_1145",
        "1133": "q_1146",
        "1134": "q_1147",
        "1135": "q_1148",
        "1136": "q_1149",
        "1137": "q_1150",
        "1138": "q_1151",
        "1139": "q_1152",
        "1140": "q_1153",
        "1141": "q_1154",
        "1142": "q_1155",
        "1143": "q_1156",
        "1144": "q_1157",
        "1145": "q_1158",
        "1146": "q_1159",
        "1147": "q_1160",
        "1148": "q_1161",
        "1149": "q_1162",
        "1150": "q_1163",
        "1151": "q_1164",
        "1152": "q_1165",
        "1153": "q_1166",
        "1154": "q_1167",
        "1155": "q_1168",
        "1156": "q_1169",
        "1157": "q_1170",
        "1158": "q_1171",
        "1159": "q_1172",
        "1160": "q_1173",
        "1161": "q_1174",
        "1162": "q_1175",
        "1163": "q_1176",
        "1164": "q_1177",
        "1165": "q_1178",
        "1166": "q_1179",
        "1167": "q_1180",
        "1168": "q_1181",
        "1169": "q_1182",
        "1170": "q_1183",
        "1171": "q_1184",
        "1172": "q_1185",
        "1173": "q_1186",
        "1174": "q_1187",
        "1175": "q_1188",
        "1176": "q_1189",
        "1177": "q_1190",
        "1178": "q_1191",
        "1179": "q_1192",
        "1180": "q_1193",
        "1181": "q_1194",
        "1182": "q_1195",
        "1183": "q_1196",
        "1184": "q_1197",
        "1185": "q_1198",
        "1186": "q_1199",
        "1187": "q_1200",
        "1188": "q_1201",
        "1189": "q_1202",
        "1190": "q_1203",
        "1191": "q_1204",
        "1192": "q_1205",
        "1193": "q_1206",
        "1194": "q_1207",
        "1195": "q_1208",
        "1196": "q_1209",
        "1197": "q_1210",
        "1198": "q_1211",
        "1199": "q_1212",
        "1200": "q_1213",
        "1201": "q_1214",
        "1202": "q_1215",
        "1203": "q_1216",
        "1204": "q_1217",
        "1205": "q_1218",
        "1206": "q_1219",
        "1207": "q_1220",
        "1208": "q_1221",
        "1209": "q_1222",
        "1210": "q_1223",
        "1211": "q_1224",
        "1212": "q_1225",
        "1213": "q_1226",
        "1214": "q_1227",
        "1215": "q_1228",
        "1216": "q_1229",
        "1217": "q_1230",
        "1218": "q_1231",
        "1219": "q_1232",
        "1220": "q_1233",
        "1221": "q_1234",
        "1222": "q_1235",
        "1223": "q_1236",
        "1224": "q_1237",
        "1225": "q_1238",
        "1226": "q_1239",
        "1227": "q_1240",
        "1228": "q_1241",
        "1229": "q_1242",
        "1230": "q_1243",
        "1231": "q_1244",
        "1232": "q_1245",
        "1233": "q_1246",
        "1234": "q_1247",
        "1235": "q_1248",
        "1236": "q_1249",
        "1237": "q_1250",
        "1238": "q_1251",
        "1239": "q_1252",
        "1240": "q_1253",
        "1241": "q_1254",
        "1242": "q_1255",
        "1243": "q_1256",
        "1244": "q_1257",
        "1245": "q_1258",
        "1246": "q_1259",
        "1247": "q_1260",
        "1248": "q_1261",
        "1249": "q_1262",
        "1250": "q_1263",
        "1251": "q_1264",
        "1252": "q_1265",
        "1253": "q_1266",
        "1254": "q_1267",
        "1255": "q_1268",
        "1256": "q_1269",
        "1257": "q_1270",
        "1258": "q_1271",
        "1259": "q_1272",
        "1260": "q_1273",
        "1261": "q_1274",
        "1262": "q_1275",
        "1263": "q_1276",
        "1264": "q_1277",
        "1265": "q_1278",
        "1266": "q_1279",
        "1267": "q_1280",
        "1268": "q_1281",
        "1269": "q_1282",
        "1270": "q_1283",
        "1271": "q_1284",
        "1272": "q_1285",
        "1273": "q_1286",
        "1274": "q_1287",
        "1275": "q_1288",
        "1276": "q_1289",
        "1277": "q_1290",
        "1278": "q_1291",
        "1279": "q_1292",
        "1280": "q_1293",
        "1281": "q_1294",
        "1282": "q_1295",
        "1283": "q_1296",
        "1284": "q_1297",
        "1285": "q_1298",
        "1286": "q_1299",
        "1287": "q_1300",
        "1288": "q_1301",
        "1289": "q_1302",
        "1290": "q_1303",
        "1291": "q_1304",
        "1292": "q_1305",
        "1293": "q_1306",
        "1294": "q_1307",
        "1295": "q_1308",
        "1296": "q_1309",
        "1297": "q_1310",
        "1298": "q_1311",
        "1299": "q_1312",
        "1300": "q_1313",
        "1301": "q_1314",
        "1302": "q_1315",
        "1303": "q_1316",
        "1304": "q_1317",
        "1305": "q_1318"
    },
    "subject_ids": {
        "0": "Llama-3-70B-Instruct-DPO-v0.2",
        "1": "Llama-3-70B-japanese-suzume-vector-v0.1",
        "2": "Llama-3-70B-Instruct-DPO-v0.4",
        "3": "Llama-3-70B-Instruct-DPO-v0.3",
        "4": "Llama3-TenyxChat-70B",
        "5": "Llama-3-70B-Instruct-DPO-v0.1",
        "6": "autotrain-llama3-70b-orpo-v1",
        "7": "Meta-Llama-3-70B-Instruct",
        "8": "Qwen2-72B",
        "9": "llama-3-70B-Instruct-abliterated",
        "10": "autotrain-llama3-70b-orpo-v2",
        "11": "autotrain-llama3-oh-sft-v0-2",
        "12": "tigerbot-70b-chat-v4-4k",
        "13": "Llama3-70B-Fireplace",
        "14": "Llama3-70B-Chinese-Chat",
        "15": "Llama-3-Giraffe-70B-Instruct",
        "16": "Mixtral-8x22B-Instruct-v0.1",
        "17": "Qwen1.5-110B",
        "18": "Phi-3-medium-128k-instruct",
        "19": "Phi-3-Medium-Llamaish",
        "20": "Llama-3-70B-Instruct-Gradient-262k",
        "21": "Phi-3-medium-4k-instruct",
        "22": "Llama-3-Lumimaid-70B-v0.1-alt",
        "23": "Rhea-72b-v0.3",
        "24": "TW3-JRGL-v1",
        "25": "Ein-72B-v0.1",
        "26": "Ein-72B-v0.13",
        "27": "Ein-72B-v0.12",
        "28": "Llama-3-70B-Instruct-Gradient-524k",
        "29": "Llama-3-Lumimaid-70B-v0.1",
        "30": "Ein-72B-v0.11",
        "31": "Smaug-72B-v0.1",
        "32": "Smaug-70B-v0.1",
        "33": "Rhea-72b-v0.4",
        "34": "MoMo-72B-lora-1.8.7-DPO",
        "35": "Rhea-72b-v0.2",
        "36": "sft_model_test1",
        "37": "alpaca-dragon-72b-v1",
        "38": "Tess-72B-v1.5b",
        "39": "Meta-Llama-3-70B",
        "40": "MoMo-70B-lora-1.8.6-DPO",
        "41": "MultiVerse_70B",
        "42": "Llama-3-70B-Orpo-v0.1",
        "43": "Rhea-72b-v0.5",
        "44": "free-evo-qwen72b-v0.8-re",
        "45": "free-evo-qwen72b-v0.8",
        "46": "YiSM-34B-0rn",
        "47": "Yi-34Bx2-MoE-60B",
        "48": "Luminex-72B-v0.1",
        "49": "Ein-70B-v2",
        "50": "NeuralMaths-Experiment-7b",
        "51": "Phi-3-mini-mango-1",
        "52": "Phi-3-mini-mango-1-llamafied",
        "53": "Tess-2.0-Llama-3-70B",
        "54": "Mixtral_34Bx2_MoE_60B",
        "55": "C0325-L",
        "56": "Phi-3-mini-4k-instruct-v0.3",
        "57": "35b-beta-long",
        "58": "TomGrc_FusionNet_34Bx2_MoE_v0.1_DPO_f16",
        "59": "phi-3-22b",
        "60": "NeuralBeagleOpenChat",
        "61": "SeaLLM-7B-v2.5",
        "62": "MoMo-70B-lora-1.8.5-DPO",
        "63": "Truthful_DPO_cloudyu_Mixtral_34Bx2_MoE_60B",
        "64": "AnFeng_v3_Avocet",
        "65": "Phi-3-mini-4k-instruct",
        "66": "Yi-34Bx2-MoE-60B-DPO",
        "67": "airoboros-70b-3.3",
        "68": "Mixtral-8x22B-v0.1",
        "69": "phi-3-mini-4k-instruct-llamafied",
        "70": "Liberated-Qwen1.5-72B",
        "71": "StarMonarch-7B",
        "72": "Phi-3-mini-4k-instruct-v0.2",
        "73": "M-LChat-7b",
        "74": "Pearl-7B-slerp",
        "75": "Daredevil-8B",
        "76": "MonarchPipe-7B-slerp",
        "77": "Neural4gsm8k",
        "78": "TheTop-5x7B-Instruct-S4-v0.1",
        "79": "The-Trinity-Coder-7B",
        "80": "Mayo",
        "81": "FernandoGPT-v1",
        "82": "WestSeverus-7B-DPO",
        "83": "SauerkrautLM-14b-MoE-LaserChat",
        "84": "Yi-1.5-34B",
        "85": "OrcaHermes-Mistral-70B-miqu",
        "86": "Cygnus-7B",
        "87": "NeuralPearlBeagle",
        "88": "Marcoroni-neural-chat-7B-v2",
        "89": "Mistral-T5-7B-v1",
        "90": "NeuralDaredevil-7B",
        "91": "Daredevil-8B-abliterated",
        "92": "Nous-Hermes-2-SUS-Chat-2x34B",
        "93": "Neural-SOVLish-Devil-8B-L3",
        "94": "WestSeverusJaskier",
        "95": "Tess-2.0-Llama-3-70B-v0.2",
        "96": "CatMacaroni-Slerp",
        "97": "CatMarcoro14-7B-slerp",
        "98": "ChimeraLlama-3-8B-v2",
        "99": "Maxine-7B-0401-ties",
        "100": "FusionNet_34Bx2_MoE_v0.1",
        "101": "mistral-7b-merged-dare",
        "102": "xDAN-L2-moe-2x-v1",
        "103": "Qwen2-7B",
        "104": "StarEmpress-3x7B",
        "105": "Mahou-1.3-llama3-8B",
        "106": "Daredevil-7B",
        "107": "NeuralLLaMa-3-8b-ORPO-v0.3",
        "108": "OpenCM-14",
        "109": "TomGrc_FusionNet_34Bx2_MoE_v0.1_full_linear_DPO",
        "110": "Lumina-3",
        "111": "Yi-34Bx3-MoE-90B",
        "112": "Nous-Hermes-2-SUS-Chat-34B-Slerp",
        "113": "openchat-3.5-0106-gemma",
        "114": "MoEv4Config-TestWeightedTIES-7b",
        "115": "NeuralWestSeverus-7B-slerp",
        "116": "billie",
        "117": "StrangeMerges_45-7B-dare_ties",
        "118": "LaserPipe-7B-SLERP",
        "119": "Proteus-8B",
        "120": "Slerp-CM-mist-dpo",
        "121": "Cognitron-8B",
        "122": "Severus-7B",
        "123": "Halu-8B-Llama3-v0.3",
        "124": "Yi-34Bx2-MOE-200K",
        "125": "Mathral",
        "126": "Calme-7B-Instruct-v0.4",
        "127": "StrangeMerges_53-7B-model_stock",
        "128": "flux-7b-v0.2",
        "129": "Mahou-1.0-llama3-8B",
        "130": "llama-3-NeuralMahou",
        "131": "phillama-3.8b-v0.1",
        "132": "Llama-3-15B-Instruct-ft-v2",
        "133": "MultiverseMath-12B-MoE",
        "134": "SOVLish-Devil-8B-L3",
        "135": "Luminex-34B-v0.1",
        "136": "Maverick-8B",
        "137": "UNA-SimpleSmaug-34b-v1beta",
        "138": "llama-3-sauce-v2-8B",
        "139": "Neuralmaath-12B-MoE",
        "140": "flux-7b-v0.1",
        "141": "badger-l3-instruct-32k",
        "142": "CatunaMayo",
        "143": "Marcoroni-7B-v3",
        "144": "CatMacaroni14",
        "145": "Neural-Cosmic-Boy-7B-slerp",
        "146": "Deita-32b",
        "147": "UltraCatunaMayo",
        "148": "StrangeMerges_3-7B-slerp",
        "149": "StrangeMerges_52-7B-dare_ties",
        "150": "Dream-7B-slerp",
        "151": "Mistral-7b-instruct-v0.2-private-edw2",
        "152": "Wilbur-30B",
        "153": "Neural-4-Maths-7b",
        "154": "RasGullaINEX12-7B-slerp",
        "155": "mistral-ft-optimized-1218",
        "156": "Helion-4x34B",
        "157": "openchat-3.5-1210-Seraph-Slerp",
        "158": "Cosmosis-3x34B",
        "159": "MM-OV-bagel-DPO-34b-c1000-250",
        "160": "StrangeMerges_44-7B-dare_ties",
        "161": "supermario-v2",
        "162": "CM-14",
        "163": "Phi-3-mini-4k-instruct-v0.1",
        "164": "BurningBruce-003",
        "165": "stealth-v1.2",
        "166": "MM-Orc-Vic-bagel-34b-c1000",
        "167": "Oot-v2_lll",
        "168": "Smaugv0.1",
        "169": "Smaug-34B-v0.1",
        "170": "Mixtral_7Bx5_MoE_30B",
        "171": "CatunaLaserPi",
        "172": "MDBX-7B",
        "173": "StrangeMerges_20-7B-slerp",
        "174": "SUS-Chat-34B",
        "175": "MetaMath-Bagel-DPO-34B",
        "176": "yi-9b-may-ortho-baukit-13fail-3000total-bf16",
        "177": "Maxine-34B-stock",
        "178": "Harmony-4x7B-bf16",
        "179": "supermario-slerp",
        "180": "llama-3-bophades-v2-8B",
        "181": "Deita-20b",
        "182": "Merged-OpenLlama3-8B",
        "183": "72B-preview",
        "184": "Blur-7B-slerp-v0.1",
        "185": "Nous-Hermes-2-SUS-Chat-34B-Linear",
        "186": "TheTop-5x7B-Instruct-S2-v0.1",
        "187": "ipo-test",
        "188": "piccolo-8x7b",
        "189": "Seraph-openchat-3.5-1210-Slerp",
        "190": "TheTop-5x7B-Instruct-S3-v0.1",
        "191": "kellemar-DPO-Orca-Distilled-7B-SLERP",
        "192": "Eukaryote-8x7B-bf16",
        "193": "Starling_Monarch_Westlake_Garten-7B-v0.1",
        "194": "Calme-7B-Instruct-v0.5",
        "195": "7Bx4_DPO",
        "196": "MarcMistral-7B",
        "197": "Proctora",
        "198": "jaLLAbi2-7b",
        "199": "Mahou-1.2-llama3-8B",
        "200": "Smaug-Mixtral-v0.1",
        "201": "ChimeraLlama-3-8B-v3",
        "202": "Luminex-34B-v0.2",
        "203": "LexiLumin-7B",
        "204": "Phi-3-medium-4k-instruct-abliterated-v3",
        "205": "merge_7B_state_2",
        "206": "BeagleMist-7B",
        "207": "Yi-1.5-9B-Chat",
        "208": "Scorpio-7B",
        "209": "WestBeagle-7B",
        "210": "Seraph-7B",
        "211": "multimaster-7b-v2",
        "212": "Daredevil-8B-abliterated-dpomix",
        "213": "Marcoroni-v3-neural-chat-v3-3-Slerp",
        "214": "Capricorn-7B",
        "215": "jaskier-7b-dpo-v2",
        "216": "MarcDareBeagle-7B",
        "217": "openchat-3.6-8b-20240522",
        "218": "BeagSake-7B",
        "219": "merge_model_test_v2",
        "220": "NeoCortex-7B-slerp",
        "221": "M7-7b",
        "222": "Topxtral-4x7B-v0.1",
        "223": "Multiverse-Experiment-slerp-7b",
        "224": "Marcoroni-8x7B-v3-MoE",
        "225": "threebird-7B",
        "226": "RasGulla1-7b",
        "227": "SamirGPT-v1",
        "228": "Beyonder-4x7B-v2",
        "229": "OpenHermes-2.5-neural-chat-v3-3-openchat-3.5-1210-Slerp",
        "230": "JupiterINEX12-12B-MoE",
        "231": "TheTop-5x7B-Instruct-D-v0.1",
        "232": "Llama-3-MahouDevil-8B",
        "233": "Pulsar_7B",
        "234": "SevereNeuralBeagleTrix-7B",
        "235": "Nous-Hermes-2-Mixtral-8x7B-DPO",
        "236": "LogoS-7Bx2-MoE-13B-v0.1",
        "237": "Yi-1.5-34B-Chat",
        "238": "Astralis-4x34B",
        "239": "Calmesmol-7B-slerp",
        "240": "Mayoroya",
        "241": "trinity-v1",
        "242": "stealth-v1.3",
        "243": "LogoS-7Bx2-MoE-13B-v0.2",
        "244": "72B-preview-llamafied-qwen-llamafy",
        "245": "multimaster-7b-v3",
        "246": "Dare-k-7B-ties",
        "247": "mhm-8x7B-FrankenMoE-v1.0",
        "248": "kellemar-KrishnaHercules-0.1-7b-slerp",
        "249": "v1olet_marcoroni-go-bruins-merge-7B",
        "250": "L3-8B-Stheno-v3.1",
        "251": "gemma-ko-7b-instruct-v0.62",
        "252": "WestSeverus-7B-DPO-v2",
        "253": "Macaroni-7b-Tied",
        "254": "Llama-3-15B-Instruct-zeroed-ft",
        "255": "llama-3-stella-8B",
        "256": "DareBeagle-7B",
        "257": "MetaMath-Cybertron-Starling",
        "258": "llama-3-stella-truthy-dpo-8B",
        "259": "sixtyoneeighty-FNCARL-7B-slerp",
        "260": "BurningBruce-005",
        "261": "Llama-3-Giraffe-70B",
        "262": "StrangeMerges_15-7B-slerp",
        "263": "NeuralStockFusion-7b",
        "264": "megatron_1.1_MoE_2x7B",
        "265": "QuantumBruins-7B-slerp",
        "266": "Blur-7b-slerp-v1.41",
        "267": "Beagle14-7B",
        "268": "flammen10-mistral-7B",
        "269": "pmmpk-EinstainMorcoro14KrishnaHercules-7b-slerp",
        "270": "Llama-3-8B-Instruct-abliterated-v2",
        "271": "supermario_v2",
        "272": "Barcenas-3.8b",
        "273": "flammen15-gutenberg-DPO-v1-7B",
        "274": "7Bx4_DPO_2e",
        "275": "Neurallaymons-7B-slerp",
        "276": "Llama-3-8B-Instruct-v0.5",
        "277": "caTUNABeagle",
        "278": "MixtureofMerges-MoE-4x7b-v4",
        "279": "NeuralKuke-4-All-7b",
        "280": "neurotic-crown-clown-7b-ties",
        "281": "mistral-7b-merged-dare_6x7",
        "282": "mistral-ft-optimized-1227",
        "283": "Senku-70B-Full",
        "284": "Valkyrie-V1",
        "285": "multi_verse_model",
        "286": "Mixtral_7Bx6_MoE_35B",
        "287": "MBX-7B",
        "288": "CognitiveFusion2-4x7B-BF16",
        "289": "go-bruins-v2.1.1",
        "290": "badger-zeta-l3-4x8b",
        "291": "NeuralSirKrishna-7b",
        "292": "Multimerge-Neurallaymons-12B-MoE",
        "293": "SmartLlama-3-8B-MS-v0.1",
        "294": "Mistral-7b-instruct-v0.2-summ-sft-ed2",
        "295": "Mistral-7B-Merge-14-v0.5",
        "296": "openmixtral-4x7b-merged",
        "297": "BruinHermes",
        "298": "MarcBeagle-7B",
        "299": "4bit_quant_TomGrc_FusionNet_34Bx2_MoE_v0.1_DPO",
        "300": "Mistroll-7B-v2.2",
        "301": "Bianca-7b",
        "302": "LeoScorpius-GreenNode-7B-v1",
        "303": "distilabeled-Marcoro14-7B-slerp",
        "304": "MergeTrix-7B",
        "305": "binarized-ingotrix-slerp-7b",
        "306": "Kaltsit-16x7B-bf16",
        "307": "LelaStarling-7B",
        "308": "StrangeMerges_21-7B-slerp",
        "309": "Taiwan-LLM-8x7B-DPO",
        "310": "Mahou-1.2a-llama3-8B",
        "311": "MistralTrix-SLERP",
        "312": "Ognoexperiment27Multi_verse_model-7B",
        "313": "Calme-4x7B-MoE-v0.1",
        "314": "MixTAO-7Bx2-MoE-v8.1",
        "315": "MAmmoTH2-7B-Plus",
        "316": "kuno-dogwalker-7b",
        "317": "Mayonnaise-4in1-02",
        "318": "SOLAR-math-2x10.7b",
        "319": "_model_llama_3_8B_Instruct_fine_tuned_xMR_1e",
        "320": "Calme-4x7B-MoE-v0.2",
        "321": "Llama-3-8B-Instruct-DPO-v0.4",
        "322": "LeoScorpius-GreenNode-Alpaca-7B-v1",
        "323": "Konstanta-7B",
        "324": "NeuralSynthesis-7b-v0.4-slerp",
        "325": "Mergerix-7b-v0.3",
        "326": "MultiverseEx26-7B-slerp",
        "327": "Darewin-7B",
        "328": "Quyen-Pro-v0.1",
        "329": "MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp",
        "330": "Fasciculus-Arcuatus-7B-slerp",
        "331": "NeuralMonarchCoderPearlBeagle-T3Q-Mistral-Orca-Math-DPO-7b",
        "332": "Mayonnaise-4in1-01",
        "333": "J4RVIZ-v6.0",
        "334": "mindy-7b-v2",
        "335": "NeuralOmniBeagleMBX-v3-7B",
        "336": "Meliodas-7b-dare",
        "337": "NeuralKrishna-7B-v3",
        "338": "Starling-dolphin-E26-7B",
        "339": "Llama-3-8B-Instruct-v0.2",
        "340": "SmaugDolphin-60B",
        "341": "grindin",
        "342": "NeuDist-Ro-7B",
        "343": "pee",
        "344": "TARS-8B",
        "345": "NeuralLLaMa-3-8b-DT-v0.1",
        "346": "NeuralSynthesis-7B-v0.3",
        "347": "Marcoro14-7B-ties",
        "348": "NeuralKrishnaMath-7B-slerp",
        "349": "Truthful_DPO_TomGrc_FusionNet_34Bx2_MoE",
        "350": "pikus-pikantny-7B-dare",
        "351": "NeuralMiLLaMa-8B-slerp",
        "352": "Percival_01-7b-slerp",
        "353": "mistral-7b-dpo-v6",
        "354": "WildMBXMarconi-SLERP-7B",
        "355": "Llama-3-8B-Ultra-Instruct-SaltSprinkle",
        "356": "FusionNet_34Bx2_MoE",
        "357": "StrangeMerges_11-7B-slerp",
        "358": "mistral-7b-dpo-merge-v1.1",
        "359": "NeuralSynthesis-7B-v0.1",
        "360": "dzakwan-MoE-4x7b-Beta",
        "361": "CatPPT",
        "362": "kuno-royale-v3-7b",
        "363": "Mistral-7B-Merge-14-v0.4",
        "364": "NeuralArjuna-7B-DT",
        "365": "Lelantos-7B",
        "366": "MixTAO-7Bx2-MoE-Instruct-v2.0",
        "367": "Neuraljack-12B-MoE",
        "368": "quantum-dpo-v0.1",
        "369": "MetaMath-bagel-34b-v0.2-c1500",
        "370": "Llama-3-8B-Instruct-DPO-v0.2",
        "371": "Tess-70B-v1.6",
        "372": "CCK_Asura_v3.0",
        "373": "TheTop-5x7B-Instruct-S5-v0.1",
        "374": "Valor_Macaroni_moe",
        "375": "Llama-3-15B-Instruct-zeroed",
        "376": "B3E3-SLM-7b-v3.0",
        "377": "TurdusDareBeagle-7B",
        "378": "bruphin-lambda",
        "379": "Meta-Llama-3-8B-Instruct-abliterated-v3",
        "380": "Llama-3-8B-Instruct-v0.1",
        "381": "Versatile-7B",
        "382": "PercivalMelodias-7B-slerp",
        "383": "metis-chat-instruct-7b",
        "384": "SuperFlammen-4x7B",
        "385": "T3QM7",
        "386": "JupiterMerge-7B-slerp",
        "387": "AbL3In-15B",
        "388": "MAmmoTH2-8B-Plus",
        "389": "GreenNodeLM-v3olet-7B",
        "390": "Jason1903_SLERP",
        "391": "NeuralMarcoro14-7B",
        "392": "nil_Llama-3-8B-Instruct_v0.1.0",
        "393": "StrangeMerges_16-7B-slerp",
        "394": "Chicka-Mistral-4x7b",
        "395": "FusionNet_7Bx2_MoE_14B",
        "396": "internlm2-20b-llama",
        "397": "Chicka-Mixtral-3x7b",
        "398": "Goku-8x22B-v0.1",
        "399": "Maxine-7B-0401-stock",
        "400": "WestOrcaNeural-V2-DARETIES-7B",
        "401": "blossom-v5-32b",
        "402": "CatPPT-base",
        "403": "StrangeMerges_32-7B-slerp",
        "404": "Mahou-1.1-llama3-8B",
        "405": "distilabeled-Marcoro14-7B-slerp-full",
        "406": "Pearl-7B-0211-ties",
        "407": "Chicka-Mistral-3x7b",
        "408": "SuperBruphin-3x7B",
        "409": "L3-test-2",
        "410": "megatron_2.1_MoE_2x7B",
        "411": "Einstein-4d-Marcoro14-nddmpk-KrishnaHercules-7b-slerp",
        "412": "mistral-7b-dpo-v5",
        "413": "Apollo-7B-0529-M-5",
        "414": "Llama-3-8B-Instruct-DPO-v0.3",
        "415": "StrangeMerges_9-7B-dare_ties",
        "416": "Multimerge-12B-MoE",
        "417": "Beyonder-4x7B-v3",
        "418": "T3QM7XP",
        "419": "Configurable-Yi-1.5-9B-Chat",
        "420": "dec10",
        "421": "BurningBruce-004",
        "422": "NeuralDareBeagle-7B-slerp",
        "423": "Mistral-7B-orca-dpo-2h",
        "424": "Beast-Soul",
        "425": "aegolius-acadicus-v1-30b",
        "426": "MultiCalm-7B-slerp",
        "427": "YamshadowExperiment28-7B",
        "428": "MetaMath-Cybertron",
        "429": "NeuralGanesha-7b",
        "430": "Halu-8B-Llama3-Blackroot",
        "431": "Omningotex-7b-slerp",
        "432": "Kinship-Exp-2",
        "433": "DareBeagel-2x7B",
        "434": "limyClown-7B-slerp",
        "435": "Jupiter-k-7B-slerp",
        "436": "OmniCorso-7B",
        "437": "Experiment26Yamshadow-7B",
        "438": "Mayonnaise-4in1-022",
        "439": "Mistral-7B-Instruct-adapt-v0.2",
        "440": "Severusectum-7B-DPO",
        "441": "PiVoT-SUS-RP",
        "442": "OmniTrixAI",
        "443": "Eris-Lelanacles-7b",
        "444": "MBX-7B-v2",
        "445": "J4RVIZ-v5.0",
        "446": "bruphin-epsilon",
        "447": "aegolius-acadicus-30b",
        "448": "haLLawa4-7b",
        "449": "kuno-dogpark-7b",
        "450": "NeuralSynthesis-7B-v0.2",
        "451": "MetaMath-Tulpar-7b-v2-Slerp",
        "452": "StrangeMerges_25-7B-dare_ties",
        "453": "test2_4",
        "454": "autotrain-cei9g-ag3pe",
        "455": "go-bruins-v2.1",
        "456": "blockchainlabs_joe_bez_seminar",
        "457": "Qwen-72B",
        "458": "experiment26-truthy-iter-1",
        "459": "MeliodasPercival_01_Experiment26T3q",
        "460": "experiment26-truthy-iter-2",
        "461": "Hermes-2-Theta-Llama-3-8B",
        "462": "Mutliverse_model_official",
        "463": "blockchainlabs_7B_merged_test2_4",
        "464": "Experiment26-7B",
        "465": "autotrain-mixtral7x8b-math",
        "466": "smol_bruin-7b",
        "467": "test3_sft_16bit",
        "468": "llama-3-spicy-abliterated-stella-8B",
        "469": "Calmex26merge-12B-MoE",
        "470": "35b-beta",
        "471": "experiment26-truthy-iter-0",
        "472": "Flammen-Bophades-7B",
        "473": "MixTAO-7Bx2-MoE-DPO",
        "474": "Cognito-2x7B-bf16",
        "475": "C0318-G",
        "476": "multimaster-7b-v6",
        "477": "INEX16-7b",
        "478": "NexoNimbus-7B",
        "479": "SilverMaiden-7B-slerp",
        "480": "Llama-3-8B-Ultra-Instruct",
        "481": "StarlingMaths-12B-MoE",
        "482": "neurotic-crown-clown-7b-tak-stack-dpo",
        "483": "Mistral-7B-sumz-dpo-3h",
        "484": "MergeM-7B",
        "485": "TripleMerge2-7B-Ties",
        "486": "blockchainlabs_test3_seminar",
        "487": "Neural-Krishna-Multiverse-7b-v3",
        "488": "jaskier-7b-dpo",
        "489": "L3-krai-test",
        "490": "NeuralContamination-7B-ties",
        "491": "LimmyAutomerge-7B-slerp",
        "492": "ladybird-base-7B-v8",
        "493": "FusionNet_7Bx2_MoE_v0.1",
        "494": "T3Q-Mistral-Orca-Math-DPO",
        "495": "shadow-clown-7B-slerp",
        "496": "MBX-7B-v3",
        "497": "BillyTheKid1803",
        "498": "ShadowM7EXP-7B",
        "499": "CombinaTrix-7B",
        "500": "RandomMergeNoNormWEIGHTED-7B-DARETIES",
        "501": "NeuralMathChat-7B-V0.2",
        "502": "WildMarcoroni-Variant1-7B",
        "503": "quantum-v0.01",
        "504": "AutoLimmy-7B-slerp",
        "505": "MyModelsMerge-7b",
        "506": "JARVIS-v2.0",
        "507": "StrangeMerges_23-7B-slerp",
        "508": "NeuralBeagle14-7B",
        "509": "Capricorn-7B-DPO",
        "510": "AlloyIngotNeoY",
        "511": "Myriad-7B-Slerp",
        "512": "TurdusTrixBeagle-DARETIES-7B",
        "513": "experiment26-SPIN-iter-0",
        "514": "Neural-Krishna-Multiverse-7b-v2",
        "515": "INEX4-7b",
        "516": "Mistral-7B-Instruct-adapt-v0.21",
        "517": "YamShadow-7B",
        "518": "Halu-8B-Llama3-CR-v0.45",
        "519": "Mistral-7B-summ-privatev1",
        "520": "Mistral-7B-Instruct-adapt-v0.23",
        "521": "Strangecoven-7B-slerp",
        "522": "Kindred-7B-slerp",
        "523": "Mistral-7B-Instruct-exp-e2",
        "524": "Ramakrishna-7b-v3",
        "525": "Experimentmultiverse-7B-slerp",
        "526": "StrangeMerges_50-7B-slerp",
        "527": "MoMo-70B-LoRA-V1.4",
        "528": "kuno-royale-v2-7b",
        "529": "StrangeMerges_30-7B-slerp",
        "530": "Mistral-7B-Instruct-adapt-v0.22",
        "531": "Configurable-Llama-3-8B-v0.2",
        "532": "quantum-trinity-v0.1",
        "533": "CatunaMayo-DPO",
        "534": "INEX12-7b",
        "535": "StrangeMerges_51-7B-dare_ties",
        "536": "Pegasus-7b-slerp",
        "537": "StrangeMonarch-7B-slerp",
        "538": "NeuralKukedlc-7B-Labonned",
        "539": "Hippy-AAI-7B",
        "540": "piccolo-math-2x7b",
        "541": "SuperThetaMaven",
        "542": "NeuralKrishna-7B-slerp",
        "543": "CalmExperiment-7B-slerp",
        "544": "OGNO-7B",
        "545": "StrangeMerges_43-7B-dare_ties",
        "546": "MetaMath-Chupacabra-7B-v2.01-Slerp",
        "547": "StrangeMerges_10-7B-slerp",
        "548": "WestOrcaNeuralMarco-DPO-v2-DARETIES-7B",
        "549": "NeuralMergeTest-001",
        "550": "Llama-3-LizardCoder-8B",
        "551": "supermario_v4",
        "552": "T3Q-Merge-Mistral7B",
        "553": "L3-krai-test-2",
        "554": "aqua-smaug-0.3-8B",
        "555": "Inex12Yamshadow-7B",
        "556": "slerp-test-turdus-beagle",
        "557": "StrangeMerges_42-7B-dare_ties",
        "558": "Kinship-Exp-1",
        "559": "Sectumsempra-7B-DPO",
        "560": "TurdusBeagle-7B",
        "561": "llama-3-8b-okay",
        "562": "Mergerix-7b-v0.4",
        "563": "WildWest-Variant3-7B",
        "564": "StarlingMaxLimmy-7B-slerp",
        "565": "ai-medical-model-32bit",
        "566": "Nous-Hermes-2-Yi-34B",
        "567": "openchat-3.5-0106-128k-DPO_dpo-binarized-NeuralTrix-7B",
        "568": "Calme-7B-Instruct-v0.2",
        "569": "a",
        "570": "OgnoMonarch-7B",
        "571": "OmniBeagle-7B",
        "572": "flammen15X-mistral-7B",
        "573": "KuTrix-7b",
        "574": "Westgate",
        "575": "NeuralBeagleJaskier",
        "576": "Llama-3-8B-Instruct-v0.3",
        "577": "Strangemerges_32Yamshadow-7B",
        "578": "llama-3-gutenberg-8B",
        "579": "supermario-slerp-v3",
        "580": "JARVIS-v3.0",
        "581": "CultriX-MoE-BF16",
        "582": "Padma-SLM-7b-v1.0",
        "583": "flammen13-mistral-7B",
        "584": "merge_7B_state_1",
        "585": "Pearl-7B-0210-ties",
        "586": "T3QM7X",
        "587": "StrangeMerges_26-7B-dare_ties",
        "588": "TW3CESCO.V2",
        "589": "neural-chat-7b-v3-3-Slerp",
        "590": "Nanashi-2x7B-bf16",
        "591": "StrangeMerges_31-7B-slerp",
        "592": "Calme-7B-Instruct-v0.9",
        "593": "B3E3-SLM-7b-v2.0",
        "594": "ChatMarc-YesAnotherMerge-7B",
        "595": "ShadowYamshadow-7B",
        "596": "Mayonnaise-4in1-03",
        "597": "MoMo-72B-LoRA-V1.4",
        "598": "Configurable-Llama-3-8B-v0.3",
        "599": "M7merge-7B-slerp",
        "600": "NeuralExperiment-7b-dare-ties",
        "601": "OmniBeagleSquaredMBX-v3-7B-v2",
        "602": "jaskier-7b-dpo-v7.1",
        "603": "Konstanta-Alpha-V2-7B",
        "604": "Zebrafish-7B",
        "605": "ThetaMaven5",
        "606": "Padma-SLM-7b-v3.0",
        "607": "go-bruins",
        "608": "Blurred-Beagle-7b-slerp",
        "609": "Neuralcoven-7B-slerp",
        "610": "kuno-royale-7b",
        "611": "yam-jom-7B-slerp",
        "612": "llama-3-nectar-dpo-8B",
        "613": "Buttercup-4x7B-bf16",
        "614": "NeuralFusion-7b-Dare-Ties",
        "615": "AlloyIngotNeoX",
        "616": "DistilabelCerberus-7B-slerp",
        "617": "Azathoth-16x7B-bf16",
        "618": "Llama-3-8B-Instruct-v0.7",
        "619": "MetaMath-neural-chat-7b-v3-2-Slerp",
        "620": "flammen5-mistral-7B",
        "621": "Marcoroni-neural-chat-7B-v2_gsm8k_merged_s",
        "622": "Experiment26Yam_Ognoexperiment27Multi_verse_model",
        "623": "yam-jom-7B-dare",
        "624": "ARC1",
        "625": "MetaMath-NeuralHermes-2.5-Mistral-7B-Linear",
        "626": "neural-chat-v3-3-8x7b-MoE",
        "627": "LeeMerge-7B-slerp",
        "628": "HaluAnjir-8B-L3-DD",
        "629": "pastiche-crown-clown-7b-dare",
        "630": "WestKunai-X-7b",
        "631": "Phoenix_DPO_60B",
        "632": "FusionNet_7Bx2_MoE_Ko_DPO_Adapter_Attach",
        "633": "Solutus-3x7B",
        "634": "Beast-Soul-new",
        "635": "ShadowNeural-7B-v1",
        "636": "Neuralmultiverse-7B-slerp",
        "637": "laserxtral",
        "638": "Test-7B",
        "639": "llama-3-stinky-v2-8B",
        "640": "MergeTest-7B-slerp",
        "641": "B3E3-SLM-7b-v1.0",
        "642": "StrangeMerges_22-7B-slerp",
        "643": "openchat-nectar-0.6",
        "644": "WestSeverus-7B",
        "645": "MixtureofMerges-MoE-4x7b-v5",
        "646": "mergekit-slerp-zplzqvn",
        "647": "Calme-7B-Instruct-v0.3",
        "648": "Pigris-7b-v0.3",
        "649": "Llama-3-8B-Instruct-abliterated-dpomix",
        "650": "Phi-3-mini-128k-instruct-HumanChoice-4.6k-DPO",
        "651": "Experiment26Yamshadow_Ognoexperiment27Multi_verse_model",
        "652": "TripleMerge-7B-Ties",
        "653": "llama3-8b_sa_v0.1",
        "654": "TW3CESCO.V3",
        "655": "stealth-v2",
        "656": "Blur-7b-slerp-v1.46",
        "657": "multimaster-7b-v4",
        "658": "NeuralsirkrishnaExperiment26-7B",
        "659": "go-bruins-v2",
        "660": "flammen3",
        "661": "jaskier-7b-dpo-v5.6",
        "662": "MBX-7B-v3-DPO",
        "663": "bophades-mistral-7B",
        "664": "openchat-nectar-0.1",
        "665": "WestMaid_HermesMonarchv0.1",
        "666": "flammen17-mistral-7B",
        "667": "ParrotOgno-7B",
        "668": "Wernicke-7B-v1",
        "669": "StrangeMerges_49-7B-dare_ties",
        "670": "shadow-clown-7B-dare",
        "671": "phi_3",
        "672": "YamshadowInex12_Multi_verse_modelExperiment28",
        "673": "Mistral-7B-Merge-14-v0.1",
        "674": "llama-3-slerp-kraut-dragon-8B",
        "675": "yam-jom-7B-ties",
        "676": "yam-jom-7B",
        "677": "Einstein-4D-MoE-2x7b-test",
        "678": "Lumina-RP",
        "679": "Experiment30-7B",
        "680": "WestLakeX-7B-EvoMerge",
        "681": "Mistral-7B-privatemix-ia1",
        "682": "Phi-3-Mini-4K-Boost",
        "683": "firefly-qwen1.5-en-14b-dpo-v0.1",
        "684": "Blur-7b-v1.21",
        "685": "Prokaryote-8x7B-bf16",
        "686": "Phi-3-mini-128k-instruct",
        "687": "flammen8-mistral-7B",
        "688": "NeuralPipe-7B-ties",
        "689": "YamshadowInex12_Experiment26T3q",
        "690": "Truthful_DPO_TomGrc_FusionNet_7Bx2_MoE_13B",
        "691": "ogno-monarch-jaskier-merge-7b-OH-PREF-DPO-v2",
        "692": "MultiVerse_LASER",
        "693": "Severus-7B-DPO",
        "694": "Configurable-Llama-3-8B-v0.1",
        "695": "YamshadowStrangemerges_32_Experiment24Ognoexperiment27",
        "696": "NeuralJaskier-7b-dpo",
        "697": "Mistral-7B-sumz-dpo-4h",
        "698": "Nous-Hermes-2-MoE-2x34B",
        "699": "Neural-Krishna-Multiverse-7b",
        "700": "Mistral-7B-orca-dpo-4h",
        "701": "M7Yamshadowexperiment28_Experiment26T3q",
        "702": "flammen11-mistral-7B",
        "703": "M7Yamshadowexperiment28_Strangemerges_30Experiment26",
        "704": "CalmeRity-stock",
        "705": "T3qm7xNeuralsirkrishna-7B",
        "706": "flammen6-mistral-7B",
        "707": "Open-StarLake-Swap-7B",
        "708": "Phi-3-mini-128k-instruct-LinearBunkaScore-4.6k-DPO",
        "709": "ogno-monarch-jaskier-merge-7b-OH-PREF-DPO",
        "710": "AlloyIngotNeo",
        "711": "jaskier-7b-dpo-v6.1",
        "712": "Nous-Hermes-2-SOLAR-10.7B",
        "713": "ogno-monarch-jaskier-merge-7b",
        "714": "Harpy-7B-Model_Stock",
        "715": "Llama-3-DARE-v3-8B",
        "716": "L3-SnowStorm-v1.15-4x8B-B",
        "717": "MixTAO-7Bx2-MoE-Instruct-v5.0",
        "718": "Franken-MoE-18B-v0.1",
        "719": "MixTAO-7Bx2-MoE-Instruct-v1.0",
        "720": "Llama-3-8B-Instruct-v0.4",
        "721": "llama-3-sqrt-crocodile-v0.0A",
        "722": "L-MChat-7b",
        "723": "Eris_PrimeV3.05-Vision-7B",
        "724": "bophades-mistral-math-DPO-7B",
        "725": "whattest",
        "726": "dpo-binarized-NeutrixOmnibe-7B",
        "727": "HeroBophades-2x7B",
        "728": "Eclipse-13B-dpo",
        "729": "Llama-3-11.5B-Instruct-v2",
        "730": "Experiment28Yam-7B",
        "731": "Mixtral_AI_Cyber_3.m1",
        "732": "Wernicke-7B-v8",
        "733": "Mergerix-7b-v0.5",
        "734": "Multiparadigm_7B",
        "735": "garten2-7b",
        "736": "llama-3-stinky-8B",
        "737": "Experiment27Pastiche-7B",
        "738": "bruphin-kappa",
        "739": "TheMayonnaise",
        "740": "bophades-mistral-truthy-DPO-7B",
        "741": "Meta-Llama-3-8B-Instruct",
        "742": "MixtureofMerges-MoE-2x7b-v6",
        "743": "MonarchCoder-MoE-2x7B",
        "744": "Experiment27Neuralsirkrishna-7B",
        "745": "llama-3-dragonmaid-8B-v2",
        "746": "MetaMath-NeuralHermes-2.5-Mistral-7B-Ties",
        "747": "ogno-monarch-jaskier-merge-7b-v2",
        "748": "Meta-Llama-3-8B-Instruct-LessResistant",
        "749": "Neural-4-ARC-7b",
        "750": "Calme-7B-Instruct-v0.1",
        "751": "OmniBeagleMBX-v3-7B",
        "752": "Prima-LelantaclesV7-experimental-7b",
        "753": "SUS-Bagel-200K-DARE-Test",
        "754": "oswald-7b",
        "755": "Experiment29Pastiche-7B",
        "756": "CatunaLaserPi-DPO",
        "757": "Llama-3-8B-Instruct-DPO-v0.1",
        "758": "NeuralLake-Variant1-7B",
        "759": "Experiment28-7B",
        "760": "Wernicke-7B-v9",
        "761": "BenchmarkEngineering-F2-7B-slerp",
        "762": "MiquMaid-v1-70B",
        "763": "Cyrax-7B",
        "764": "NeuralMarioMonarch-7B-slerp",
        "765": "Phi-SoSerious-Mini-V1",
        "766": "BenchmarkEngineering-7B-slerp",
        "767": "MixtureofMerges-MoE-2x7b-SLERPv0.9",
        "768": "flammen13X-mistral-7B",
        "769": "openchat-nectar-0.14",
        "770": "supermario_v3",
        "771": "UltraMerge-7B",
        "772": "slerp-bophades-truthy-math-mistral-7B",
        "773": "PasticheAlloyingotneoy-7B",
        "774": "DPOB-INMTOB-7B",
        "775": "SuperMente-7B-v4",
        "776": "ogno-monarch-jaskier-merge-7b-OH-PREF-DPO-v3",
        "777": "MetaMath-una-cybertron-v2-bf16-Ties",
        "778": "openbuddy-deepseek-67b-v18.1-4k",
        "779": "MetaMath-Mistral-2x7B",
        "780": "OmniBeagleSquaredMBX-v3-7B",
        "781": "Nous-Hermes-2-SOLAR-10.7B-MISALIGNED",
        "782": "NeuTrixOmniBe-7B-model-remix",
        "783": "Valor-7B-v0.1",
        "784": "Fewshot-Metamath-OrcaVicuna-Mistral",
        "785": "Calme-7B-Instruct-v0.1.1",
        "786": "Rose-2x7B",
        "787": "llama-3-merged-linear",
        "788": "MoeLovely-13B",
        "789": "contaminated_proof_7b_v1.0_safetensor",
        "790": "bophades-v2-mistral-7B",
        "791": "flammen18X-mistral-7B",
        "792": "Pigris-7b-v0.4",
        "793": "MixTAO-7Bx2-MoE-Instruct-v7.0",
        "794": "MergeTrix-7B-v2",
        "795": "NeuralKrishnaMathWizard-7B",
        "796": "ECE-TW3-JRGL-V1",
        "797": "SeverusWestLake-7B-DPO",
        "798": "Lelanta-lake-7b",
        "799": "AlloyIngot",
        "800": "WestKunai-Hermes-7b",
        "801": "Ogno-Monarch-Neurotic-7B-Dare-Ties",
        "802": "Monarch-7B",
        "803": "LeoScorpius-7B-Chat-DPO",
        "804": "Experiment31-7B",
        "805": "shqiponja-15b-v1",
        "806": "MixtureofMerges-MoE-2x7b-v7",
        "807": "Poppy_Porpoise-0.85-L3-8B",
        "808": "KingNish-Llama3-8b",
        "809": "AiMaven-Prometheus",
        "810": "NeuralPizza-WestSeverus-7B-Merge-slerp",
        "811": "jaskier-7b-dpo-v4.3",
        "812": "MBA-7B",
        "813": "ShadowYam-7B",
        "814": "NeuralTrix-7B-dpo-laser",
        "815": "Meta-Llama-3-8B-Uninstruct-function-calling-json-mode-model_stock-v0.1",
        "816": "NMTOB-7B",
        "817": "DPOB-NMTOB-7B",
        "818": "mistral-7b-merged-ties",
        "819": "JaskierMistral-7B-slerp",
        "820": "MarcoHermes",
        "821": "StarlingMaxLimmy2-7B-slerp",
        "822": "OGNO-7b-dpo-truthful",
        "823": "MedleyMD",
        "824": "CCK_Asura_v2.1",
        "825": "Suppe-v1-7B",
        "826": "Apollo-7b-orpo-Experimental",
        "827": "MixTAO-7Bx2-MoE-Instruct-v4.0",
        "828": "Mistral-7b-instruct-v0.2-summ-sft-dpo-e2",
        "829": "Neurotic-Jomainotrik-7b-slerp",
        "830": "INEX8-7B",
        "831": "Nous-Hermes-2-SOLAR-10.7B-x2-MoE",
        "832": "orthorus-125b-v2",
        "833": "StrangeMerges_24-7B-slerp",
        "834": "Blur-4x7b-MOE-v0.1",
        "835": "Buttercup-7b-dpo-slerp",
        "836": "pastiche-crown-clown-7b-dare-dpo",
        "837": "MixTAO-7Bx2-MoE-Instruct-v6.0",
        "838": "Aura_L3_8B",
        "839": "yam-sam-7B",
        "840": "MonaTrix-v4-7B-DPO",
        "841": "Mistral-7B-privatemix-ia2",
        "842": "merged-dpo-binarized-NeutrixOmnibe-7B",
        "843": "openchat-3.5-0106-laser",
        "844": "Buttercup-7b-dpo-ties",
        "845": "MonaTrix-7B-DPOv2",
        "846": "0.0005_llama_4iters_bs128_5551lr_iter_1",
        "847": "FNCARLplus-7b",
        "848": "MonaTrix-v4",
        "849": "StrangeMerges_27-7B-dare_ties",
        "850": "StrangeMerges_5-7B-ties",
        "851": "openbuddy-mistral-22b-v21.1-32k",
        "852": "SauerkrautLM-7b-LaserChat",
        "853": "Confinus-2x7B",
        "854": "Eris_Remix_DPO_7B",
        "855": "Tiamat-8b-1.2-Llama-3-DPO",
        "856": "ogno-monarch-jaskier-merge-7b-OH-PREF-DPO-v4-test",
        "857": "MetaMath-Mistral-7B",
        "858": "Halu-8B-Llama3-DT",
        "859": "SmartToxic-7B",
        "860": "GoldenMaiden-7B-model_stock",
        "861": "AiMaven-Merkaba-7b",
        "862": "MavenWest",
        "863": "Spaetzle-v69-7b",
        "864": "Merkaba-Maven-0.1",
        "865": "NeuralCeptrix-7B-slerp",
        "866": "TextBase-v0.2",
        "867": "MaidFlameSoup-7B",
        "868": "strange_3236-7B",
        "869": "Starling-LM-7B-beta-LaserRMT-v1",
        "870": "Experiment29-7B",
        "871": "ShadowNeural-7B-ORPO",
        "872": "NeuralDareDMistralPro-7b-slerp",
        "873": "Boundary-Meta-Llama-3-2x8B-MoE",
        "874": "Marengoli_7B_SLERP",
        "875": "Marcoro14-7B-slerp",
        "876": "llama3s-merged-linear",
        "877": "Umbra-v2.1-MoE-4x10.7",
        "878": "StrangeMerges_29-7B-dare_ties",
        "879": "ROGERphi-7B-slerp",
        "880": "Bagel-Hermes-2x34b",
        "881": "SeaLLM-7B-v2",
        "882": "CapybaraMarcoroni-7B",
        "883": "Eris_Remix_7B",
        "884": "llamaster-8B-v0.1",
        "885": "Llama-3-Unholy-8B",
        "886": "InnerILLM-7B-slerp",
        "887": "neuronal-7b-Mlab",
        "888": "PasticheInex12-7B",
        "889": "MixtureofMerges-MoE-v2",
        "890": "Sina-Thor-7b-Merge",
        "891": "Halu-OAS-8B-Llama3",
        "892": "Grafted-Wind-Elementals-2x70B",
        "893": "Neural-4-QA-7b",
        "894": "Excalibur-7B",
        "895": "MixSwap",
        "896": "Brocae-Area-7B-slerp",
        "897": "CeptrixBeagle-12B-MoE",
        "898": "NeuralPizza-7B-V0.2",
        "899": "openmixtral-6x7b-v2",
        "900": "OgnoExperiment27-7B",
        "901": "GreenNodeLM-7B-v4leo",
        "902": "macaroni-7b",
        "903": "openchat-nectar-0.4",
        "904": "StrangeMerges_4-7B-slerp",
        "905": "Dolphin-2.8-slerp",
        "906": "QuartetAnemoi-70B-t0.0001",
        "907": "Mistral-7B-sumz-dpo-5h",
        "908": "Buttercup-V2-bf16",
        "909": "StrangeMerges_36-7B-slerp",
        "910": "LHK_DPO_v1",
        "911": "Llama-3-8B-Instruct-ortho-baukit-toxic-n128-v3",
        "912": "UltraCatunaMayo-DPO",
        "913": "EmertonOmniBeagle-7B-dpo",
        "914": "NeuralDolphin-7B-slerp",
        "915": "Patronum-7B",
        "916": "iWillChangeTheNameLater",
        "917": "West-Hermes-7B",
        "918": "dbrx-base",
        "919": "newmerge",
        "920": "mistral-7b-merged-slerp",
        "921": "Configurable-Hermes-2-Pro-Llama-3-8B",
        "922": "MistralHermesPipe-7B-slerp",
        "923": "CCK_Asura_v1.1.0",
        "924": "NeuralTrixlaser-bf16",
        "925": "Einstein-4D-Marcoro14-7b-full-slerp",
        "926": "Llama-3-8B-Instruct-v0.8",
        "927": "O0128",
        "928": "Loyal-Macaroni-Maid-7B",
        "929": "Prima-LelantaclesV6.69-7b",
        "930": "WestlakeMaziyar-7B-slerp",
        "931": "openchat-nectar-0.11",
        "932": "TriFusionNexus-7b",
        "933": "complect-7B-slerp",
        "934": "Llama-3-LewdPlay-8B-evo",
        "935": "Experiment24-7B",
        "936": "Lelantos-DPO-7B",
        "937": "Chimera-7B-slerp",
        "938": "kiqu-70b",
        "939": "Mixtral_7Bx2_MoE",
        "940": "Llama-3-8B-Lexi-Uncensored",
        "941": "Monarch-7B-SFT",
        "942": "Lexi-Llama-3-8B-Uncensored",
        "943": "coven_7b_128k_orpo_alpha",
        "944": "flippa-exp26-v3-7b",
        "945": "NeuTrixOmniBe-DPO",
        "946": "Montebello_7B_SLERP",
        "947": "MonarchLake-7B",
        "948": "fiona-7B-v0.2",
        "949": "crown-clown-7b-slerp",
        "950": "Fewshot-Metamath-Mistral",
        "951": "jaskier-7b-dpo-v4.1",
        "952": "WestLakeX-7B-EvoMerge-Variant2",
        "953": "CreativeSmart-2x7B",
        "954": "Llama-3-8B-Instruct-ortho-baukit-toxic-v2",
        "955": "Lotus-7B",
        "956": "LuminariX-8B",
        "957": "MetaMath-neural-chat-7b-v3-2-Ties",
        "958": "WestLake-7B-v2-laser",
        "959": "llama3_ruozhiba_8b",
        "960": "supermario_v1",
        "961": "CosmicBun-8B",
        "962": "HeroBophades-3x7B",
        "963": "Mistral-Passthrough-8L-10B",
        "964": "T3Q-DPO-Mistral-7B",
        "965": "MixtureofMerges-MoE-4x7b-v3",
        "966": "llama3-8b-instruct-align-test1-kto",
        "967": "LadybirdPercival-7B-slerp",
        "968": "llama-3-merge-pp-instruct-8B",
        "969": "WONMSeverusDevil-TIES-7B",
        "970": "Orca-SOLAR-4x10.7b",
        "971": "Clown-DPO-Extended",
        "972": "NeuralTrix-7B-dpo-relaser",
        "973": "StrangeMerges_28-7B-dare_ties",
        "974": "Sphinx-7B-Model_Stock",
        "975": "llama3-8b-instruct-align-test2-kto",
        "976": "openchat-3.5-0106-32k",
        "977": "openchat-3.5-0106",
        "978": "openchat-3.5-0106-mod-gpt5",
        "979": "WestLake-7B-v2-laser-truthy-dpo",
        "980": "openchat-nectar-0.5",
        "981": "Unsafe-Llama-3-8B",
        "982": "0.0_llama_nodpo_3iters_bs128_531lr_iter_1",
        "983": "Spaetzle-v8-7b",
        "984": "Code-Mistral-7B",
        "985": "T3Q-EN-DPO-Mistral-7B",
        "986": "CCK_Asura_v1",
        "987": "NeuralKrishna-7B-V2-DPO",
        "988": "Experiment27-7B",
        "989": "EmertonMonarch-7B-slerp",
        "990": "Buttercup-V2-laser",
        "991": "llama-3-wissenschaft-8B",
        "992": "yi-9b-may-ortho-baukit-30fail-3000total-bf16",
        "993": "Beagle_Turdus",
        "994": "CeramicMaiden-7B-Slerp",
        "995": "NeuralTrix-7B-dpo",
        "996": "WestLakeMultiverse-12B-MoE",
        "997": "multimaster-7b-v5",
        "998": "dpo-binarized-NeuralTrix-7B",
        "999": "Miqu-MS-70B",
        "1000": "Llama-Phi-3_DoRA",
        "1001": "Mistral-7B-private-spef",
        "1002": "StrangeMerges_40-7B-dare_ties",
        "1003": "Yi-1.5-34B-Chat-16K",
        "1004": "MasherAI-v6.1-7B-checkpoint3",
        "1005": "T3Q-Mistral-UB-DPO-v1.0",
        "1006": "0.0005_llama_nodpo_3iters_bs128_531lr_iter_1",
        "1007": "0.001_llama-3_nodpo_3iters_bs128_531lr_iter_1",
        "1008": "Mistral-7B-adaptv0.9",
        "1009": "Hermes-2-Pro-Llama-3-8B",
        "1010": "Lumina-3.5",
        "1011": "LuminRP-7B",
        "1012": "LuminRP-7B-128k-v0.2",
        "1013": "Starling-LM-7B-beta-laser-dpo",
        "1014": "Griffon-7B-Model_Stock",
        "1015": "Direct-sm-private-e1",
        "1016": "test_dataset_Codellama-3-8B",
        "1017": "TextBase-7B-v0.1",
        "1018": "NinjaDolphin-7B",
        "1019": "jaskier-7b-dpo-v3.3",
        "1020": "openchat-nectar-0.7",
        "1021": "MathDolphin-7B",
        "1022": "miiqu-f16",
        "1023": "L3-RP_io",
        "1024": "Saul-Instruct-Clown-7b",
        "1025": "Experiment25-7B",
        "1026": "Blurdus-7b-v0.1",
        "1027": "Lamma3merge2-15B-MoE",
        "1028": "MonaTrix-v6",
        "1029": "Eris_PrimeV4-Vision-7B",
        "1030": "West-Dare-7B",
        "1031": "Bophades-BruinsMaid-7B",
        "1032": "Anjir-8B-L3",
        "1033": "NeuralMaxime-7B-slerp",
        "1034": "blossom-v5-14b",
        "1035": "stealth-rag-v1.1",
        "1036": "NeuralMonarch-7B",
        "1037": "bruphin-iota",
        "1038": "OpenHermes-2.5-neural-chat-v3-3-Slerp",
        "1039": "una-cybertron-7b-v3-OMA",
        "1040": "orca_mini_v5_8b_dpo",
        "1041": "Oxide-F1-7B-slerp",
        "1042": "Defne_llama3_2x8B",
        "1043": "flammen16-mistral-7B",
        "1044": "Eris_PrimeV3-Vision-7B",
        "1045": "Eris-Floramix-7b",
        "1046": "SOLAR-10.7B-NahIdWin",
        "1047": "FrankenDPO-4x7B-bf16",
        "1048": "openchat-nectar-0.8",
        "1049": "MiaAffogato-Indo-Mistral-7b",
        "1050": "Eris-Daturamix-7b",
        "1051": "Olethros-8B",
        "1052": "openchat-nectar-0.3",
        "1053": "MoE-StrangeMerges-2x7B",
        "1054": "miqu-1-70b-sf",
        "1055": "Turdus",
        "1056": "Qwen2-beta-14B",
        "1057": "Mistral-7b-instruct-v0.2-summ-dpo-ed2",
        "1058": "Marcoroni-7b-DPO-Merge",
        "1059": "WestMonarchLasers-7B-slerp",
        "1060": "OpenMia-Indo-Mistral-7b-v3",
        "1061": "Wernicke-7B-dpo",
        "1062": "llama-3-merge-avalon-8B",
        "1063": "PrometheusLaser-7B-slerp",
        "1064": "connate-7B-slerp",
        "1065": "WestLake-7B-v2",
        "1066": "MoE_13B_DPO",
        "1067": "Yuna-7b-Merge",
        "1068": "Qwen1.5-14B",
        "1069": "TW3CESCO.V4",
        "1070": "DARE_TIES_13B",
        "1071": "Samlagast-7B-bf16",
        "1072": "orca_mini_v5_8b",
        "1073": "Eris_Floramix_DPO_7B",
        "1074": "ChimeraLlama-3-8B",
        "1075": "Miqu-70B-Alpaca-DPO",
        "1076": "ChatHercules-2.5-Mistral-7B-DPO",
        "1077": "Prima-LelantaclesV6-7b",
        "1078": "RoyalMaid-7B-slerp",
        "1079": "Chimera-8B",
        "1080": "Test2_SLIDE",
        "1081": "dolphin-2.9.1-mixtral-1x22b",
        "1082": "Mistral-7b-instruct-v0.2-summ-dpo-ed3",
        "1083": "penny5-dolphin-einstein-llama3-dare-ties-chatml",
        "1084": "Pearl-34B-ties",
        "1085": "test3_sft_16bit_dpo2",
        "1086": "flammen27-mistral-7B",
        "1087": "Cognate-7B-slerp",
        "1088": "WizardMath-7B-V1.1",
        "1089": "Mistral-7B-orca-dpo-8h",
        "1090": "NeuralMona_MoE-4x7B",
        "1091": "flammen3X",
        "1092": "CosmicNoodle-7B",
        "1093": "Beyonder-4x7B-random-lora",
        "1094": "Trillama-8B",
        "1095": "BoreanGale-70B",
        "1096": "NeuralTurdusVariant1-7B",
        "1097": "nil_Llama-3-8B-Instruct_v0.1.1",
        "1098": "llama-3-lumimaid-habib-v3",
        "1099": "Llama-3-8B-Instruct-Coder",
        "1100": "Distilled-HermesChat-7B",
        "1101": "dbrx-instruct",
        "1102": "Faraday-7B",
        "1103": "meta-llama-3-8b-instruct-hf-ortho-baukit-2fail-128total",
        "1104": "openchat-3.5-0106-128k-DPO",
        "1105": "StrangeMerges_8-7B-slerp",
        "1106": "orca_mini_v4_8b",
        "1107": "Mistral-7B-Merge-02-v0",
        "1108": "SFR-Iterative-DPO-LLaMA-3-8B-R",
        "1109": "SOVL-Mega-Mash-L3-8B",
        "1110": "StrangeMerges_7-7B-slerp",
        "1111": "Llama3-8B-Chinese-Chat-v2-nightly",
        "1112": "NeuralTrix-bf16",
        "1113": "ScaleDown-7B-slerp-v0.1",
        "1114": "llama-3-lumimaid-habib-v7",
        "1115": "Orthocopter_8B",
        "1116": "openbuddy-deepseek-67b-v15.3-4k",
        "1117": "MonaCeption-7B-SLERP-DPO",
        "1118": "BetterSaul-7B-slerp",
        "1119": "Llama3-8B-Chinese-Chat",
        "1120": "e.star.7b",
        "1121": "MoNeuTrix-7B-v1",
        "1122": "Llama3-8B-Chinese-Chat-v2-nightly-v2",
        "1123": "Bombus_3x8B_v2",
        "1124": "Westlake-7B",
        "1125": "WestSeverusJaskier-OpenOrca",
        "1126": "A0120",
        "1127": "NarumashiRTS-V2",
        "1128": "13B_MATH_DPO",
        "1129": "Yi-1.5-6B-Chat",
        "1130": "GreenNodeLM-7B-v2leo",
        "1131": "NeuralTrix-7B-v1",
        "1132": "flammen22-mistral-7B",
        "1133": "llama3-8b-spaetzle-v13",
        "1134": "openchat-3.5-1210-starling-slerp",
        "1135": "NeuralMonarchCoderPearlBeagle",
        "1136": "Bald-Eagle-7B",
        "1137": "llama3-8b-spaetzle-v20",
        "1138": "flammen29-mistral-7B",
        "1139": "Kunoichi-7B",
        "1140": "60B_MoE_Coder_v3",
        "1141": "final_model_test_v2",
        "1142": "CarbonBeagle-11B",
        "1143": "openbuddy-deepseek-67b-v15.1",
        "1144": "Evangelion-7B",
        "1145": "Magistral-7B-v0.1",
        "1146": "HelpingAI-8B",
        "1147": "luxia-21.4b-alignment-v1.2",
        "1148": "openbuddy-deepseek-67b-v15.2",
        "1149": "v1olet_merged_dpo_7B_v3",
        "1150": "0.0005_llama_nodpo_3iters_bs128_531lr_iter_2",
        "1151": "Fimbulvetr-Kuro-Lotus-10.7B",
        "1152": "GreenNodeLM-7B-v1olet",
        "1153": "Asherah_7B",
        "1154": "BrurryDog-7b-v0.1",
        "1155": "Lowke-2x7B-v1",
        "1156": "Paradigm_7B",
        "1157": "Mistral-7b-instruct-v0.2-summ-sft-dpo-e1",
        "1158": "flammen21X-mistral-7B",
        "1159": "DonutLM-v1",
        "1160": "SOVL-Mega-Mash-V2-L3-8B",
        "1161": "Llama-3-Neurona-8b",
        "1162": "Gigi-Llama3-8B-Chinese-zh",
        "1163": "Draco-8x7B",
        "1164": "Lelantos-low-tune",
        "1165": "Kaiju-11B",
        "1166": "Nimue-7B",
        "1167": "meta-llama-3-8b-instruct-hf-ortho-baukit-10fail-1000total",
        "1168": "WestSeverus-ORPO-7B",
        "1169": "MasherAI-v6.1-7B-checkpoint6-pro",
        "1170": "Test-Instruct-Solar-v1",
        "1171": "UNA-TheBeagle-7b-v1",
        "1172": "kuno-kunoichi-v1-DPO-v2-SLERP-7B",
        "1173": "Llama3merge7-15B-MoE",
        "1174": "Mistral-7B-Merge-14-v0",
        "1175": "Mistral-7B-private-sia",
        "1176": "AlphaMonarch-7B",
        "1177": "Mergerix-7b-v0.1",
        "1178": "Mistrality-7B",
        "1179": "NeuralDarewin-7B",
        "1180": "AlphaMonarch-laser",
        "1181": "RoyalNoroichi-7B-slerp",
        "1182": "Mistral-7B-adaptv1",
        "1183": "Fimbulvetr-10.7B-v1",
        "1184": "Experiment20-7B",
        "1185": "Mistralchat-7B-slerp",
        "1186": "0.001_llama-3_nodpo_3iters_bs128_531lr_iter_2",
        "1187": "StrangeMerges_6-7B-dare_ties",
        "1188": "Ortho-SOVL-8B-L3",
        "1189": "Starling-LM-7B-beta",
        "1190": "Mistral-7B-privatemix-ia3",
        "1191": "NeuralCeptrix-7B-SLERP",
        "1192": "0.0_llama_nodpo_3iters_bs128_531lr_iter_2",
        "1193": "Experiment22-7B",
        "1194": "Mistroll-7B-v2.3-NoTsOsm4rt-16bit",
        "1195": "flammen22C-mistral-7B",
        "1196": "CodeNinja-1.0-OpenChat-7B",
        "1197": "Collaiborator-MEDLLM-Llama-3-8B",
        "1198": "Llama4Some-SOVL-4x8B-L3-V1",
        "1199": "cr-model-v1",
        "1200": "MergeCeption-7B-v3",
        "1201": "WestKunai-XD-7b",
        "1202": "WestLakeLaser-12B-MoE",
        "1203": "Liberated-Qwen1.5-14B",
        "1204": "Aura_v2_7B",
        "1205": "0.0_llama_nodpo_3iters_bs128_531lr_iter_3",
        "1206": "0.0005_llama_4iters_bs128_5551lr_iter_2",
        "1207": "blossom-v4-qwen1_5-14b",
        "1208": "L3-SnowStorm-v1.15-4x8B-A",
        "1209": "0ai-7B-v5",
        "1210": "Eros_n_Psyche-7B-Model_Stock",
        "1211": "Llama-3-8B-Instruct-v0.9",
        "1212": "TheTop-5x7B-Instruct-T-v0.1",
        "1213": "NarumashiRTS-V1",
        "1214": "0.001_llama-3_nodpo_3iters_bs128_531lr_iter_3",
        "1215": "Barcenas-Llama3-8b-ORPO",
        "1216": "flammen12-mistral-7B",
        "1217": "Multi-Verse-RP-7B",
        "1218": "LeoScorpius-7B",
        "1219": "Mistral-7b-instruct-v0.2-summ-sft-dpo-ed2",
        "1220": "EmertonBeagle-7B-dpo",
        "1221": "OpenBeagle-11B",
        "1222": "TextSum-v0.1",
        "1223": "finch",
        "1224": "InfinityKuno-2x7B",
        "1225": "TextBase-v0.1",
        "1226": "Aurora-Nights-70B-v1.0",
        "1227": "fbt-llama-8b-inst",
        "1228": "habib-DPO-v2",
        "1229": "flammen9X-mistral-7B",
        "1230": "NeuralPipe-7B-slerp-DPO",
        "1231": "dolphin-2.9.1-llama-3-8b",
        "1232": "Mistral-7b-instruct-v0.2-summ-sft-dpo-ed3",
        "1233": "AlphaMonarch-daser",
        "1234": "WizardDolphin-7B",
        "1235": "Cypher-7B",
        "1236": "Mistral-7B-Merge-14-v0.3",
        "1237": "Eris_7B",
        "1238": "Bagel-Hermes-34B-Slerp",
        "1239": "IamSoTired-7B-slerp",
        "1240": "Synatra-MCS-7B-v0.3-RP-Slerp",
        "1241": "mistral_tv-neural-marconroni",
        "1242": "Deita-34b",
        "1243": "Llama-3-Lumimaid-8B-v0.1",
        "1244": "Maverick-Math-7B",
        "1245": "oswald-4x7b",
        "1246": "NeuralExperiment-7b-MagicCoder-v7.5",
        "1247": "MasherAI-v6.1-7B-checkpoint6",
        "1248": "CarbonBeagle-11B-truthy",
        "1249": "Pluto_24B_DPO_63",
        "1250": "WildMarcoroni-Variant3-7B",
        "1251": "flammen20-mistral-7B",
        "1252": "Kuro-Lotus-10.7B",
        "1253": "Einstein-v6.1-Llama3-8B",
        "1254": "mera-mix-4x7B",
        "1255": "Merged-RP-Stew-V2-34B",
        "1256": "Peagle-9b",
        "1257": "habib-DPO",
        "1258": "opus-v1.2-llama-3-8b",
        "1259": "flammen24-mistral-7B",
        "1260": "autotrain-llama3-orpo-v2",
        "1261": "Siren-7B-slerp",
        "1262": "flammen",
        "1263": "reverie-7b",
        "1264": "orca_mini_v5_8b_orpo",
        "1265": "ToppyLake-7B-slerp",
        "1266": "GarrulusMarcoro-7B-v0.1",
        "1267": "Top-Western-Maid-7B",
        "1268": "Experiment21-7B",
        "1269": "StarlingHermes-2.5-Mistral-7B-slerp",
        "1270": "openchat-3.5-1210",
        "1271": "Hercules-Qwen1.5-14B",
        "1272": "Kunoichi-DPO-v2-7B",
        "1273": "cr-model",
        "1274": "llama-3-lumimaid-habib-v5",
        "1275": "Llama-3-DARE-v1-8B",
        "1276": "llama-3-experiment-v1-9B",
        "1277": "Pluto_24B_DPO_200",
        "1278": "RoleBeagle-11B",
        "1279": "SkkuDS-DPO-72B-v1",
        "1280": "StarlingMaid-2x7B-base",
        "1281": "ExtremeDolphin-MoE",
        "1282": "A0126",
        "1283": "l3-badger-mushroom-4x8b",
        "1284": "ComplectMaid-7B-slerp",
        "1285": "Maidphin-Kunoichi-7B",
        "1286": "CCK_Asura_v2",
        "1287": "openbuddy-yi1.5-9b-v21.1-32k",
        "1288": "Llama-3-DARE-v2-8B",
        "1289": "Llama-3-monika-ddlc-11.5b-v1",
        "1290": "Mistral_7B_SFT_DPO_v0",
        "1291": "Llama-3-8b-Ita",
        "1292": "Flora_DPO_7B",
        "1293": "flammen11X-mistral-7B",
        "1294": "shark_tank_ai_7_b",
        "1295": "flammen9-mistral-7B",
        "1296": "AlphaCeption-7B-v1",
        "1297": "llama-3-8b-claudstruct-v2",
        "1298": "Qwen2-beta-72B",
        "1299": "SkkuDataScienceGlobal-10.7b",
        "1300": "Westest-7B",
        "1301": "AlphaMonarch-dora",
        "1302": "Qwen1.5-72B",
        "1303": "Samlagast-7B-laser-bf16",
        "1304": "Satyr-7B-Model_Stock",
        "1305": "llamaRAGdrama",
        "1306": "Starling-LM-7B-beta-ExPO",
        "1307": "flammen23X-mistral-7B",
        "1308": "open_llm_leaderboard_demo",
        "1309": "Bumblebee-7B",
        "1310": "habib-DPO-v3",
        "1311": "WestLake_Noromaid_OpenHermes_neural-chat",
        "1312": "openbuddy-qwen1.5-32b-v21.1-32k",
        "1313": "RolePlayLake-7B-Toxic",
        "1314": "Everyone-LLM-7b-Base",
        "1315": "Datura_7B",
        "1316": "CarbonVillain-en-10.7B-v4",
        "1317": "SOLAR-tail-10.7B-Merge-v1.0",
        "1318": "blossom-v5.1-34b",
        "1319": "Llama3-ChatQA-1.5-70B",
        "1320": "Marcoroni-7B-v2",
        "1321": "Master-Yi-9B",
        "1322": "Mistral-7b-instruct-v0.2-private-eds2",
        "1323": "meta-llama-3-8b-instruct-hf-ortho-baukit-5fail-3000total-bf16",
        "1324": "Optimus-7B",
        "1325": "MaidStarling-2x7B-base",
        "1326": "test-7B-slerp",
        "1327": "Fuselage-8B",
        "1328": "monika-ddlc-8b-v1",
        "1329": "MetaModel_moe",
        "1330": "Experiment19-7B",
        "1331": "InfinityLake-2x7B",
        "1332": "Excalibur-7b-DPO",
        "1333": "Llama-3-monika-ddlc-8b-v1",
        "1334": "Yi-34B-200K-DARE-megamerge-v8",
        "1335": "SOLARC-M-10.7B",
        "1336": "dolphin-2.9.1-yi-1.5-9b",
        "1337": "WhyAreWeStillHere-7B-slerp",
        "1338": "Open_Hermes_Maid_Sam_Mistral_dtv0.1",
        "1339": "MetaModel",
        "1340": "MetaModel_moex8",
        "1341": "Kuno-Lake-7B",
        "1342": "zen_moe",
        "1343": "Sakura-SOLAR-Instruct-CarbonVillain-en-10.7B-v2-slerp",
        "1344": "Flora_7B",
        "1345": "openbuddy-mixtral-7bx8-v18.1-32k",
        "1346": "Yi-34B-200K-DARE-merge-v7",
        "1347": "flammen23-mistral-7B",
        "1348": "Open_Maid_Samantha_Hermes_Orca_dare_ties",
        "1349": "FusionNet_linear",
        "1350": "llama-3-wissenschaft-8B-v2",
        "1351": "HermesBagel-34B-v0.1",
        "1352": "Loyal-Toppy-Bruins-Maid-7B-DARE",
        "1353": "Solar-OrcaDPO-Solar-Instruct-SLERP",
        "1354": "Faro-Yi-34B",
        "1355": "DaturaCookie_7B",
        "1356": "Mixtral_11Bx2_MoE_19B",
        "1357": "llama3-8b-spaetzle-v33",
        "1358": "Merge-Mayhem-L3-V2.1",
        "1359": "MetaModelv3",
        "1360": "Faro-Yi-34B-200K",
        "1361": "CarbonVillain-en-10.7B-v2",
        "1362": "EmertonMonarch-7B",
        "1363": "Sakura-SOLAR-Instruct",
        "1364": "Yi-32b-x2-v2.0",
        "1365": "Jallabi-34B",
        "1366": "CarbonVillain-en-10.7B-v3",
        "1367": "Smart-LLaMa-3-8b-Python-v4",
        "1368": "where-llambo-7b",
        "1369": "StopCarbon-10.7B-v5",
        "1370": "WestLake_Noromaid_OpenHermes_neural-chatv0.1",
        "1371": "Phi-3-mini-4k-instruct-bnb-4bit-Ita",
        "1372": "MonarchCoder-7B",
        "1373": "bleagle-7b-v0.1-test",
        "1374": "Lumosia-v2-MoE-4x10.7",
        "1375": "Awanllm-Llama-3-8B-Instruct-DPO-v0.1",
        "1376": "Poppy_Porpoise-0.72-L3-8B",
        "1377": "RolePlayLake-7B",
        "1378": "Medes-7B",
        "1379": "FusionNet",
        "1380": "trinity-medium",
        "1381": "SkkuDS-DPO-72B-v3",
        "1382": "ChatHercules-2.5-Mistral-7B",
        "1383": "Llama-3-SauerkrautLM-8b-Instruct",
        "1384": "flammen2",
        "1385": "yi-34B-v2",
        "1386": "firefly-qwen1.5-en-14b-alpha",
        "1387": "LMCocktail-10.7B-v1",
        "1388": "Newton-OpenHermes-2.5-neural-chat-v3-3-Slerp",
        "1389": "MasherAI-v6.1-7B-checkpoint3-code4",
        "1390": "Llama-3-Instruct-demi-merge-8B",
        "1391": "Mixtral_7Bx2_MoE_DPO",
        "1392": "0.0005_llama_4iters_bs128_5551lr_iter_3",
        "1393": "OpenMia-Indo-Engineering",
        "1394": "IceCoffeeTest8",
        "1395": "MoeMoE-2x7b",
        "1396": "Llama-3-8B-Instruct-OAS",
        "1397": "OpenMia-Indo-Engineering-7b",
        "1398": "SOLARC-MOE-10.7Bx6",
        "1399": "SOLAR-math-2x10.7b-v0.2",
        "1400": "meow",
        "1401": "Prima-LelantaclesV5-7b",
        "1402": "Fimbulvetr-11B-v2-Test-14",
        "1403": "A0110",
        "1404": "SOLAR-10B-OrcaDPO-Jawade",
        "1405": "Faro-Yi-9B-DPO",
        "1406": "SOLAR-10.7B-Instruct-v1.0",
        "1407": "SOLAR-10.7B-Instruct-SOLARC-M-10.7B-slerp",
        "1408": "UNA-POLAR-10.7B-InstructMath-v2",
        "1409": "StrangeMerges_35-7B-slerp",
        "1410": "Umbra-MoE-4x10.7",
        "1411": "Experiment7-7B",
        "1412": "Skadi-Mixtral-v1",
        "1413": "haLLAwa3",
        "1414": "SolarM-SakuraSolar-SLERP",
        "1415": "SauerkrautLM-UNA-SOLAR-Instruct-test",
        "1416": "Tippy-Toppy-7b",
        "1417": "A0127",
        "1418": "llama-3-merge-virt-req-8B",
        "1419": "Luna_7B",
        "1420": "Poppy_Porpoise-0.96-L3-8B",
        "1421": "SauerkrautLM-UNA-SOLAR-Instruct",
        "1422": "Fimbulvetr-11B-v2",
        "1423": "test1",
        "1424": "Solar-10.7B-Cato",
        "1425": "OpenZephyrChat",
        "1426": "Mistral-7B-private-oia",
        "1427": "SOLAR-10B-Nector-DPO-Jawade",
        "1428": "Awanllm-Llama-3-8B-Instruct-ORPO-v0.1",
        "1429": "testmerge-7b",
        "1430": "Phi-3-Mini-4K-Boost_v2",
        "1431": "LimyQstar-7B-slerp",
        "1432": "RPLakeCoder-TxC",
        "1433": "Prometheus-1.3",
        "1434": "Garrulus",
        "1435": "yi-34B-v3",
        "1436": "MixtureofMerges-MoE-2x7bRP-v8",
        "1437": "Truthful_DPO_MOE_19B",
        "1438": "StopCarbon-10.7B-v6",
        "1439": "llama-3-8b-claudstruct-v1",
        "1440": "MFANNv0.8",
        "1441": "StarFusion-alpha2",
        "1442": "0.0005_llama_nodpo_3iters_bs128_531lr_oldtrl_iter_2",
        "1443": "Chimera-Apex-7B",
        "1444": "MasherAI-7B-v6.1",
        "1445": "SOLAR-10.7B-Instruct-Forest-DPO-v1",
        "1446": "SOVLish-Maid-L3-8B",
        "1447": "openchat_3.5-gpt-4-80k",
        "1448": "MetaModelv2",
        "1449": "CarbonVillain-en-10.7B-v5",
        "1450": "dolphin-2.9-llama3-8b",
        "1451": "Experiment8-7B",
        "1452": "WizardLM-Math-70B-v0.1",
        "1453": "StopCarbon-10.7B-v4",
        "1454": "Eris_PrimeV3.075-Vision-7B",
        "1455": "Pasta-Lake-7b",
        "1456": "A0109",
        "1457": "Seraphim-8x10.7B-bf16",
        "1458": "KuroMitsu-11B",
        "1459": "StrangeMerges_17-7B-dare_ties",
        "1460": "MFANNv0.5",
        "1461": "Prodigy_7B",
        "1462": "SOLARC-MOE-10.7Bx4",
        "1463": "L3-ChaoticSoliloquy-v1.5-4x8B",
        "1464": "Mahou-1.0-mistral-7B",
        "1465": "SwedishBeagle-dare",
        "1466": "CarbonVillain-en-10.7B-v1",
        "1467": "SOLAR-Instruct-ko-Adapter-Attach",
        "1468": "BrokenKeyboard",
        "1469": "openchat-3.5-Infinity",
        "1470": "CarbonVillain-en-13B-v1",
        "1471": "WestIceLemonTeaRP-32k-7b",
        "1472": "IceCoffeeTest11",
        "1473": "LeoScorpius-GreenNode-Platypus-7B-v1",
        "1474": "Delexa-7b-128k",
        "1475": "Dionysus-Mistral-m3-v6",
        "1476": "IceLatteRP-7b",
        "1477": "llama-3-8b-claudstruct-v3",
        "1478": "Delexa-7b",
        "1479": "amadeus-v0.1",
        "1480": "BurningBruce-SOLAR-8x10.7B-bf16",
        "1481": "blossom-v4-yi-34b",
        "1482": "SauerkrautLM-SOLAR-Instruct",
        "1483": "StopCarbon-10.7B-v1",
        "1484": "SOLAR-10.7B-Instruct-ties",
        "1485": "IceCaffeLatteRP-7b",
        "1486": "SynthIQ-7b",
        "1487": "Bumbar-7B-slerp",
        "1488": "StarFusion-alpha1",
        "1489": "Konstanta-V4-Alpha-7B",
        "1490": "Kunoichi-DPO-7B",
        "1491": "speechless-mistral-dolphin-orca-platypus-samantha-WestSeverusJaskier-7b",
        "1492": "Merge_Sakura_Solar",
        "1493": "ChaoticSoliloquy-4x8B",
        "1494": "Sakura-SOLRCA-Math-Instruct-DPO-v2",
        "1495": "Llama-3-Lumimaid-8B-v0.1-OAS",
        "1496": "Nanbeige2-16B-Chat",
        "1497": "Mixolar-4x7b",
        "1498": "BeagleLake-7B",
        "1499": "ConfigurableBeagle-11B",
        "1500": "Smart-LLama-3-8b-Python-v5",
        "1501": "L3_SnowStorm_4x8B",
        "1502": "Sakura-SOLRCA-Math-Instruct-DPO-v1",
        "1503": "supermario-slerp-v2",
        "1504": "MFANNv0.4",
        "1505": "Mistral_Sonyichi-7B-slerp",
        "1506": "StopCarbon-10.7B-v2",
        "1507": "Hermes-low-tune-3",
        "1508": "Maylin-7b",
        "1509": "Experiment9-7B",
        "1510": "19B_MATH_DPO",
        "1511": "Sakura-SOLAR-Instruct-DPO-v2",
        "1512": "SauerkrautLM-Gemma-7b",
        "1513": "EveryNight-7B-slerp",
        "1514": "KukulStanta-7B",
        "1515": "llama-3-lumimaid-habib",
        "1516": "Konstanta-Gamma-V2-9B",
        "1517": "Starling-low-tune",
        "1518": "DPOpenHermes-7B-v2",
        "1519": "Mahou-1.2a-mistral-7B",
        "1520": "Tito-7B-slerp",
        "1521": "dolphin-2.8-experiment26-7b-preview",
        "1522": "RPMix-4x7B-MoE",
        "1523": "Tulpar-7b-v2",
        "1524": "Venus_DPO_50",
        "1525": "BeagleLake-7B-Toxic",
        "1526": "J.O.S.I.E.3-Beta11-7B-slerp",
        "1527": "EveryoneLLM-7b-Gemma-Base",
        "1528": "Einstein-v6-7B",
        "1529": "UNA-ThePitbull-21.4B-v2",
        "1530": "CodeCalc-Mistral-7B",
        "1531": "Delexa-V0.1-7b",
        "1532": "InfinityKumon-2x7B",
        "1533": "DiscoLM-70b",
        "1534": "Laser-WestLake-2x7b",
        "1535": "Aura_7B",
        "1536": "Experiment1-7B",
        "1537": "Collaiborator-MEDLLM-Llama-3-8B-v1",
        "1538": "Hermes-low-tune-2",
        "1539": "Pearl-34B-dare",
        "1540": "Experiment10-7B",
        "1541": "Nyxene-v3-11B",
        "1542": "Everyone-Coder-4x7b-Base",
        "1543": "openchat-spin-slimorca-iter0",
        "1544": "NeuralZephyr-Beagle-7B",
        "1545": "Experiment4-7B",
        "1546": "Sakura-SOLRCA-Instruct-DPO",
        "1547": "FuseChat-7B-VaRM",
        "1548": "Hermes-low-tune-3.1",
        "1549": "IceCoffeeTest2",
        "1550": "ConfigurableSOLAR-10.7B",
        "1551": "UNA-SOLAR-10.7B-Instruct-v1.0",
        "1552": "FrankenBeagle-SmallOverlap-test",
        "1553": "mistral-orpo-beta-NeuralBeagle14-7B-dare-ties",
        "1554": "A0123",
        "1555": "Merged-AGI-7B",
        "1556": "Pearl-7B-0210-dare",
        "1557": "una-xaberius-34b-v1beta",
        "1558": "7Bx4_DPO_700",
        "1559": "Argetsu",
        "1560": "typhoon-7b-instruct-01-30-2024",
        "1561": "zephyr-wizard-kuno-royale-BF16-merge-7B",
        "1562": "Diana-7B",
        "1563": "StopCarbon-10.7B-v3",
        "1564": "A0124",
        "1565": "OnlyForTestingIceLatteRP-7b-SmallQloraMerge",
        "1566": "Copium-Cola-9B",
        "1567": "PAIN_LeDestroy-7B-task_arithmetic",
        "1568": "SLAL-0.1",
        "1569": "Luna-2x7B-MoE",
        "1570": "flammen26-mistral-7B",
        "1571": "Kudzu-8B",
        "1572": "Umbra-v3-MoE-4x11b",
        "1573": "StockFuseChat",
        "1574": "OpenHermes-2.5-neural-chat-v3-2-Slerp",
        "1575": "openchat-spin-slimorca-iter1",
        "1576": "Starling-LM-7B-alpha-gpt-4-80k",
        "1577": "Hercules-4.0-Yi-34B",
        "1578": "Brunhilde-2x7b-MOE-DPO-v.01.5",
        "1579": "Faro-Yi-9B",
        "1580": "Faro-Yi-9B-200K",
        "1581": "Llama-3-8B-Synthia-v3.5",
        "1582": "ArcaneEntanglement-model64-70b",
        "1583": "NeuralStar_AlphaWriter_4x7b",
        "1584": "TenyxChat-7B-v1",
        "1585": "Delexa-Instruct-V0.1-7b",
        "1586": "Yi-34B-200K-DARE-merge-v5",
        "1587": "luxia-21.4b-alignment-v0.1",
        "1588": "Tess-34B-v1.5b",
        "1589": "internlm2-7b-llama",
        "1590": "KangalKhan-RawEmerald-7B",
        "1591": "Metabird-7B",
        "1592": "Blurstral-7b-slerp",
        "1593": "This_is_fine_7B",
        "1594": "luxia-21.4b-alignment-v0.3",
        "1595": "cuckoo-starling-7B",
        "1596": "neuronovo-9B-v0.4",
        "1597": "MistralTrix-v1",
        "1598": "KangalKhan-SharpEmerald-7B",
        "1599": "cuckoo-starling-32k-7B",
        "1600": "Spaetzle-v12-7b",
        "1601": "PMaxxxer-v1-70b",
        "1602": "Pallas-0.2",
        "1603": "Yi-1.5-9B",
        "1604": "14B-DPO-alpha",
        "1605": "luxia-21.4b-alignment-v0.4",
        "1606": "tulu-2-dpo-70b",
        "1607": "HuginnV5.5-12.6B",
        "1608": "dolphin-2.8-experiment26-7b",
        "1609": "StrangeMerges_12-7B-slerp",
        "1610": "L3-Arcania-4x8b",
        "1611": "Llama-3-8b-ortho-v2",
        "1612": "OpenChat-3.5-7B-Solar",
        "1613": "A0106",
        "1614": "FuseChat-7B-Slerp",
        "1615": "Moza-7B-v1.0",
        "1616": "Hermes-low-tune",
        "1617": "Starling-LM-alpha-8x7B-MoE",
        "1618": "Pandora-10.7B-v1",
        "1619": "neuronovo-7B-v0.2",
        "1620": "Starling-LM-7B-alpha",
        "1621": "luxia-21.4b-alignment-v1.0",
        "1622": "Experiment23-7B",
        "1623": "Nandine-7b",
        "1624": "WestLake-dpo-train-sft-v1",
        "1625": "smol-7b",
        "1626": "West-Maid-7B",
        "1627": "Sinerva_7B",
        "1628": "phi-3-orpo-v9_16",
        "1629": "deepseek-llm-67b-chat",
        "1630": "Visual-LaylelemonMaidRP-7B",
        "1631": "IceCoffeeTest3",
        "1632": "CausalLM-RP-34B",
        "1633": "sixtyoneeighty-7b-dpo",
        "1634": "IceCoffeeTest1",
        "1635": "KangalKhan-PressurizedRuby-7B",
        "1636": "test-merge-3",
        "1637": "Llama-3-8B-Instruct-80K-QLoRA",
        "1638": "JARVIS-v1.0",
        "1639": "MusingCaterpillar",
        "1640": "una-neural-chat-v3-3-P2-OMA",
        "1641": "Maya_Hermes-2.5-Mistral-7B",
        "1642": "DolphinChat-7B-slerp",
        "1643": "Deacon-34b-qlora-adapter",
        "1644": "Chupacabra-7B",
        "1645": "KangalKhan-PolishedRuby-7B",
        "1646": "SOLAR-10.7B-slerp",
        "1647": "Leaderboard-killer-MoE_4x7b",
        "1648": "WestSeverus-10.7B",
        "1649": "RosMistral-2x7B",
        "1650": "Yi-34b-200K-rawrr-v2-run-0902-LoRA",
        "1651": "RP_Vision_7B",
        "1652": "OpenChat-3.5-7B-Mixtral",
        "1653": "Tess-M-Creative-v1.0",
        "1654": "mixtral_7bx4_moe",
        "1655": "SnorkelWestBeagle-DARETIES-7B",
        "1656": "Sirius-10B",
        "1657": "SJ-SOLAR-10.7b-DPO",
        "1658": "Tess-2.0-Yi-34B-200K",
        "1659": "CultriX-MoE-Model",
        "1660": "blossom-v5-34b",
        "1661": "kellemar-DPO-7B-d",
        "1662": "FuseChat-7B-TA",
        "1663": "Adrastea-7b-v1.0-dpo",
        "1664": "KangalKhan-RawRuby-7B",
        "1665": "Hyperion-2.0-Yi-34B",
        "1666": "HighdensityRPMerge-7B",
        "1667": "KangalKhan-Ruby-7B",
        "1668": "StrangeMerges_47-7B-dare_ties",
        "1669": "Chupacabra-7B-v2.02",
        "1670": "KangalKhan-Sapphire-7B",
        "1671": "Cerebrum-1.0-8x7b",
        "1672": "KangalKhan-Ruby-7B-Fixed",
        "1673": "Silicon-Maid-7B",
        "1674": "Genstruct-10.7B",
        "1675": "sixtyoneeighty-7b",
        "1676": "LadybirdGonzo-7B-slerp",
        "1677": "CapyTessBorosYi-34B-200K-DARE-Ties",
        "1678": "sixtyoneeighty-7b-chat",
        "1679": "Waktaverse-Llama-3-KO-8B-Instruct",
        "1680": "KangalKhan-DesolatingRuby-7B",
        "1681": "Llama-3-Aplite-Instruct-4x8B-MoE",
        "1682": "una-neural-chat-v3-3-P1-OMA",
        "1683": "Typhon-Mixtral-v1",
        "1684": "yi-34b-200k-rawrr-dpo-2",
        "1685": "Llama-3-8B-Instruct-262k",
        "1686": "NewtoccineLake-slerp-7B",
        "1687": "yi-34b-200k-rawrr-dpo-1",
        "1688": "Cerberus-7B-Model_Stock",
        "1689": "eleusis-7b-alpha",
        "1690": "v-alpha-tross",
        "1691": "KangalKhan-ShinyEmerald-7B",
        "1692": "CCK_Gony_v0.1",
        "1693": "OxytocinErosEngineeringF1-7B-slerp",
        "1694": "Llama-3-Aplite-Instruct-4x8B",
        "1695": "K2S3-v0.1",
        "1696": "Mixtral_7Bx4_MOE_24B",
        "1697": "KangalKhan-ShatteredRuby-7B",
        "1698": "JOSIE_Beta-4-7B-slerp",
        "1699": "KunoMaid-7B-slerp",
        "1700": "UNAversal-8x7B-v1beta",
        "1701": "UNA-ThePitbull-21.4-v1",
        "1702": "Lonepino-11B",
        "1703": "luxia-21.4b-alignment-v0.2",
        "1704": "kellemar-DPO-7B-v1.01",
        "1705": "Yi-34B-200K-rawrr1-LORA-DPO-experimental-r3",
        "1706": "Llama-3-Refueled",
        "1707": "GritLM-8x7B",
        "1708": "notus-8x7b-experiment",
        "1709": "L0223",
        "1710": "merge-aanaphi-phi2-orage-3b",
        "1711": "suzume-llama-3-8B-multilingual",
        "1712": "Dark-Miqu-70B",
        "1713": "LexGPT-V3",
        "1714": "SystemHermes-2-7B",
        "1715": "Starling-LM-7B-alpha-ExPO",
        "1716": "rizla-17",
        "1717": "MFANN3bv0.6",
        "1718": "NeuralHermes-2.5-Mistral-7B-distilabel",
        "1719": "StrangeMerges_2-7B-slerp",
        "1720": "Obelix-Phi2",
        "1721": "SystemConfigHermes-7B",
        "1722": "Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss",
        "1723": "InnerILLM-0x00d0-7B-slerp",
        "1724": "InnerILLM-OpenPipe-Nous-Yarn-Mistral-optimized-1228-7B-slerp",
        "1725": "ConfigurableHermes-7B",
        "1726": "Mixtral-8x7B-Instruct-v0.1-DPO",
        "1727": "neuronovo-7B-v0.3",
        "1728": "Mixtral_AI_Cyber_3.1_SFT",
        "1729": "llama-3-8b-instruct-alpaca-gpt-4",
        "1730": "Open_Maid_Samantha_Hermes_Orca",
        "1731": "Limmy-phi2-slerp",
        "1732": "Open_Neural_Monarch_Maidv0.1",
        "1733": "CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-HighDensity",
        "1734": "Marcoroni-neural-chat-7B-v2_gsm8k_merged",
        "1735": "Umbra-v3-MoE-4x11b-2ex",
        "1736": "aligned-merge-aanaphi-phi2-orage-3b",
        "1737": "BagelMIsteryTour-v2-8x7B",
        "1738": "General-Stories-Mistral-7B",
        "1739": "MFANNv0.12",
        "1740": "LaseredHermes-7B-v1",
        "1741": "Phigments12",
        "1742": "meta-llama-3-8b-instruct-hf-ortho-baukit-5fail-500total",
        "1743": "phi-2-slerp",
        "1744": "Solar-10.7B-SLERP",
        "1745": "KangalKhan-HardRuby-7B",
        "1746": "OpenMia-Indo-Mistral-7b-v3-refined",
        "1747": "Cookie_7B",
        "1748": "e.star.7.b",
        "1749": "openbuddy-llama3-8b-v21.1-8k",
        "1750": "KangalKhan-PrimordialSapphire-7B",
        "1751": "fireblossom-32K-7B",
        "1752": "trrapi-16b",
        "1753": "Test1_SLIDE",
        "1754": "BigWeave-v16-103b",
        "1755": "Deacon-34b-Adapter",
        "1756": "TW3CESCO.V1",
        "1757": "neural-chat-7b-v3-3",
        "1758": "Math-OpenHermes-2.5-Mistral-7B",
        "1759": "testtest",
        "1760": "Misgit-7B-slerp",
        "1761": "TenyxChat-8x7B-v1",
        "1762": "notux-8x7b-v1",
        "1763": "Stanta-Lelemon-Maid-7B",
        "1764": "Dumb-Maidlet",
        "1765": "Mixtral-8x7B-Instruct-v0.1",
        "1766": "test-dare",
        "1767": "J.O.S.I.E.3-Beta10-7B-slerp",
        "1768": "kukulemon-7B",
        "1769": "platypus-yi-34b",
        "1770": "Hyperion-3.0-Yi-34B",
        "1771": "SOLAR-10.7b-Instruct-dpo",
        "1772": "bagel-dpo-34b-v0.2",
        "1773": "MultiKory-0.1-4x11b-pre1",
        "1774": "Kory-0.1-11b-pre1",
        "1775": "10.7Bx2_DPO_200",
        "1776": "MetaMath-Llemma-7B",
        "1777": "Awanllm-Llama-3-8B-Cumulus-v0.2",
        "1778": "Lamma3merge3-15B-MoE",
        "1779": "HerculeanSea-upd-7b-128k",
        "1780": "Llamafia",
        "1781": "Einstein-openchat-7B",
        "1782": "distilabeled-Hermes-2.5-Mistral-7B",
        "1783": "A0113",
        "1784": "Mistral-7B-orca-dpo-12h",
        "1785": "TriMistral-7B-TIES",
        "1786": "habib-v4",
        "1787": "MistralHermes-CodePro-7B-v1",
        "1788": "LUNA-SOLARkrautLM-Instruct",
        "1789": "Qwen1.5-32B",
        "1790": "autotrain-mixtral-8x7b-orpo-v1",
        "1791": "Mahou-1.1-mistral-7B",
        "1792": "SlimMelodicMaid",
        "1793": "Yi-34B-Llama",
        "1794": "Llama-3-8B-Cumulus-v0.1",
        "1795": "StrangeMerges_18-7B-dare_ties",
        "1796": "Meta-Llama-3-8B-Instruct-Dolfin-v0.1",
        "1797": "SauerkrautLM-Mixtral-8x7B-Instruct",
        "1798": "saulgoodman-2x7b-alpha1",
        "1799": "KangalKhan-Alpha-RawRubyroid-7B-Fixed",
        "1800": "MistralTrixTest",
        "1801": "IceMochaccinoRP-7b",
        "1802": "turkgpt-v0.1",
        "1803": "yi-bagel-2x34b-moe",
        "1804": "Falkor-8x7B-MoE",
        "1805": "yi-bagel-2x34b",
        "1806": "autocodit",
        "1807": "DeepCode-7B-Aurora",
        "1808": "Quintellect-10.7B",
        "1809": "llama-3-chinese-8b-instruct-v2",
        "1810": "SMaxxxer-v1-70b",
        "1811": "NeuralPaca-7b",
        "1812": "Gabriel-8x7B-Instruct-v0.1",
        "1813": "llama-3-cat-8b-instruct",
        "1814": "Dusk-Miqu-70B",
        "1815": "chatty-djinn-14B",
        "1816": "A0121",
        "1817": "TriMistral-7B-DARETIES",
        "1818": "Nous-Hermes-2-Mistral-7B-DPO",
        "1819": "RogerWizard-12B-MoE",
        "1820": "Antares-11b-v2",
        "1821": "Falkor-7b",
        "1822": "llama-3-cat-8b-instruct-v1",
        "1823": "Silicon-Monika-7b",
        "1824": "Hermes-2-Pro-Mixtral-4x7B",
        "1825": "kellemar-DPO-7B",
        "1826": "StrangeMerges_41-7B-dare_ties",
        "1827": "Hermes-2-Pro-Mistral-7B",
        "1828": "PlatYi-34B-Llama-Q",
        "1829": "Ziya2-13B-Base",
        "1830": "A11P",
        "1831": "Medichat-Llama3-8B",
        "1832": "KangalKhan-Alpha-ExtraRawRubyroid-7B",
        "1833": "Prima-LelantaclesV6.25-7b",
        "1834": "A0308-G",
        "1835": "notux-8x7b-v1-epoch-2",
        "1836": "Franziska-Mixtral-v1",
        "1837": "A0305a",
        "1838": "Niel-7B",
        "1839": "Pallas-0.4",
        "1840": "openbuddy-llama2-70b-v10.1-bf16",
        "1841": "Pallas-0.3",
        "1842": "slerp_bun_mistral_7b_v2",
        "1843": "habib-v3",
        "1844": "Arithmo-Wizard-2-7B",
        "1845": "IceTeaRP-7b",
        "1846": "llama-3-habib",
        "1847": "Kunokukulemonchini-7b",
        "1848": "Pallas-0.5-LASER-0.1",
        "1849": "opus-v1-34b",
        "1850": "Skyro-4X8B",
        "1851": "Eclipse-7B",
        "1852": "WordWoven-13B",
        "1853": "caigun-lora-model-34B-v2",
        "1854": "Blitz-AI-MOE-v0.4",
        "1855": "DPOpenHermes-7B-v2-PerfLaser",
        "1856": "c4ai-command-r-v01-japanese-instruct",
        "1857": "habib-v2",
        "1858": "StarlingDolphin-7B-slerp",
        "1859": "UNA-34Beagles-32K-bf16-v1",
        "1860": "Yi-34b-x2",
        "1861": "Quyen-Plus-v0.1",
        "1862": "A0304",
        "1863": "blossom-v5-7b",
        "1864": "BruinsV2-OpHermesNeu-11B",
        "1865": "AZG",
        "1866": "Yi-34B-200K-AEZAKMI-RAW-1701",
        "1867": "Voldemort-10B",
        "1868": "MFANNv0.11",
        "1869": "Pallas-0.5",
        "1870": "Liph-36-imatwarwithmyself",
        "1871": "T3Q-Platypus-MistralM7-7B",
        "1872": "Llama-3-8B-Instruct-norefusal",
        "1873": "DistilHermes-2.5-Mistral-7B",
        "1874": "BagelMIsteryTour-8x7B",
        "1875": "RP-Coder-SM3",
        "1876": "Liph.42",
        "1877": "CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-ExtremeDensity",
        "1878": "MetaModel_moe_multilingualv1",
        "1879": "oswald-2x7b",
        "1880": "shadow-clown-BioMistral-7B-DARE",
        "1881": "llama-3-8b-it-kor-extented-chang",
        "1882": "saulgoodman-7b-alpha1",
        "1883": "JustToSuffer-7B-slerp",
        "1884": "pic_7B_mistral_Full_v0.2",
        "1885": "openchat-spin-slimorca-iter3",
        "1886": "Sonya-7B",
        "1887": "openchat-spin-slimorca-iter2",
        "1888": "J.O.S.I.E.3-Beta12-7B-slerp",
        "1889": "Tess-34B-v1.4",
        "1890": "Yi-1.5-9B-Chat-16K",
        "1891": "Chupacabra-7B-v2.01",
        "1892": "Chupacabra-8x7B-MoE",
        "1893": "Einstein-v5-v0.2-7B",
        "1894": "A0125",
        "1895": "Llama3-merge-biomed-8b",
        "1896": "CCK_Gony_v3.1",
        "1897": "autotrain-llama3-orpo",
        "1898": "Misted-7B",
        "1899": "K2S3-Mistral-7b-v1.48",
        "1900": "Konstanta-V3-AlphaFlavour-7B",
        "1901": "Liph.42-slerp",
        "1902": "L0225",
        "1903": "Yi-34B-200K-AEZAKMI-RAW-2901",
        "1904": "ChatAllInOne-Yi-34B-200K-V1",
        "1905": "NarutoDolphin-10B",
        "1906": "NeuralPizza-7B-V0.1",
        "1907": "xDAN-L1-Chat-RL-v1",
        "1908": "smartsolmix-4x10.7b-v1",
        "1909": "Instruct_Mixtral-8x7B-v0.1_Dolly15K",
        "1910": "NarutoDolphin-7B",
        "1911": "Prima-Pastacles-7b-128k",
        "1912": "tulu-2-dpo-70b-ExPO",
        "1913": "Taurus-1.0-Mistral-7B",
        "1914": "Prima-LelantaclesV6.5-7b",
        "1915": "Taurus-7B-1.0",
        "1916": "Mahou-1.2-mistral-7B",
        "1917": "CapybaraHermes-2.5-Mistral-7B",
        "1918": "StrangeMerges_46-7B-dare_ties",
        "1919": "firefly-mixtral-8x7b-v1",
        "1920": "firefly-mixtral-8x7b-v0.1",
        "1921": "Mistral-Hermes-2x7b",
        "1922": "Qwen1.5-7B-SFT-0425",
        "1923": "MisterUkrainianDPO",
        "1924": "TriMistral-7B-SLERP",
        "1925": "deepseek-math-7b-base",
        "1926": "llama-3-chinese-8b-instruct-v3",
        "1927": "OpenHercules-2.5-Mistral-7B",
        "1928": "Tess-M-v1.3",
        "1929": "NeuralOmniWestBeaglake-7B",
        "1930": "SOLAR-10.7b-Instruct-truthy-dpo",
        "1931": "Open_Gpt4_8x7B",
        "1932": "phi-2-psy",
        "1933": "toten_gsm8k_merged_s",
        "1934": "Phi-3-Large-5.6b",
        "1935": "sillyrp-7b",
        "1936": "Open_Gpt4_8x7B_v0.2",
        "1937": "speechless-mistral-7B-v0.2-mixed-1",
        "1938": "openbuddy-mixtral-7bx8-v17.1-32k",
        "1939": "UNA-34BeagleSimpleMath-32K-v1",
        "1940": "autotrain-mixtral-8x7b-orpo-v2",
        "1941": "L-MChat-Small",
        "1942": "NeuralBeagle-11B",
        "1943": "Qwen-14B",
        "1944": "Fireplace-34b",
        "1945": "NeuralPizza-7B-V0.3",
        "1946": "mistral-merge-7b",
        "1947": "KangalKhan-Alpha-Emerald-7B-Fixed",
        "1948": "Pallas-0.5-LASER-0.2",
        "1949": "Yi-34B-200K-AEZAKMI-v2",
        "1950": "Llama-3-8B-SaulGoodMan",
        "1951": "Prima-LelantaclesV4-7b-16k-bf16",
        "1952": "SystemHermes-7B",
        "1953": "LLama-3-8b-Maths",
        "1954": "Experiment15-7B",
        "1955": "Tess-2.0-Mixtral-v0.2",
        "1956": "T3Q-Platypus-Mistral7B",
        "1957": "Llama-3-Soliloquy-8B-v2",
        "1958": "SOLAR-10.7B-dpo-instruct-tuned-v0.1",
        "1959": "penny-llama3-2x8b",
        "1960": "KangalKhan-Alpha-Rubyroid-7B-Fixed",
        "1961": "mixtral-instruct-0.1-laser",
        "1962": "Open_Maid_Samantha_Hermes_Orca_dare_tiesv0.1",
        "1963": "Threnystril-2x7B-moe",
        "1964": "Obelix-Phi2-v0",
        "1965": "medilora-qwen-14b",
        "1966": "LLaMAntino-3-ANITA-8B-Inst-DPO-ITA",
        "1967": "phigment6-slerp",
        "1968": "MUZD",
        "1969": "14B",
        "1970": "Meta-Llama-3-8B-Instruct-ORPO-QLoRA",
        "1971": "JOSIE_Beta-3-7B-slerp",
        "1972": "Dawn-Miqu-70B",
        "1973": "A0204",
        "1974": "Rabbit-7B-DPO-Chat",
        "1975": "huh-1",
        "1976": "DesivoMerge0.1",
        "1977": "MPOMixtral-8x7B-Instruct-v0.1",
        "1978": "nontoxic-bagel-34b-v0.2",
        "1979": "typhoon-7b-instruct-02-19-2024",
        "1980": "alignment_model_test",
        "1981": "NeuralOrca-7B-v1",
        "1982": "Chunky-Lemon-Cookie-11B",
        "1983": "xLAM-v0.1-r",
        "1984": "OpenMistral-MoE",
        "1985": "Lumina-2",
        "1986": "HerculeanSea-7b-128k",
        "1987": "Silicon-Medley",
        "1988": "SOLAR-10.7B-ko_alpaca",
        "1989": "Antares-11b-v1",
        "1990": "OpenHermes-2.5-Mistral-7B-mt-bench-DPO-recovered",
        "1991": "bagel-dpo-34b-v0.5",
        "1992": "OpenHermes-2.5-Code-290k-13B",
        "1993": "MUZ",
        "1994": "CBDDO-LLM-8B-Instruct-v0.1",
        "1995": "Buzz-8b-Large-v0.5",
        "1996": "hermorca",
        "1997": "Barcenas-10.7b",
        "1998": "CCK_Gony_v3.3",
        "1999": "kellemar-DPO-7B-c",
        "2000": "IceMerge-7b-32k",
        "2001": "mixtralmerge-8x7B-rebalanced-test",
        "2002": "34b-beta",
        "2003": "Metamath-reproduce-7b",
        "2004": "llamathon_v2",
        "2005": "Nynph-7B-Model_Stock",
        "2006": "mixture-of-llamas-ties",
        "2007": "FT",
        "2008": "llama3-8b-instruct-code",
        "2009": "rawr",
        "2010": "OpenHermes-2.5-Mistral-7B-mt-bench-DPO-corrupted",
        "2011": "Mahou-1.3-mistral-7B",
        "2012": "Llama-3-Petro-Instruct-v1",
        "2013": "dpo_model_test1",
        "2014": "West-Ramen-7Bx4",
        "2015": "solar-megamerge-dare-10.7b-v1",
        "2016": "bagel-8b-v1.0",
        "2017": "Xwin-Math-70B-V1.0",
        "2018": "jaskier-7b-NeuralDPO",
        "2019": "Mika-Lelantacles-7b-Longtext",
        "2020": "OpenHermes-2.5-Mistral-7B-mt-bench-DPO",
        "2021": "xDAN-SlimOrca",
        "2022": "Grafted-Llama2-2x70B",
        "2023": "StrangeMerges_33-7B-slerp",
        "2024": "K2S3-Mistral-7b-v1.50",
        "2025": "A0221",
        "2026": "MisGemma-7B",
        "2027": "stablelm-2-12b-chat",
        "2028": "ToppyLake-Bagel-7B-slerp",
        "2029": "firefly-qwen1.5-en-7b-unsloth",
        "2030": "Einstein-v4-7B",
        "2031": "phi-2-orange-v2",
        "2032": "Silicon-Natsuki-7b",
        "2033": "Mixtral-8x7B-v0.1",
        "2034": "Mistral-CatMacaroni-slerp-gradient",
        "2035": "Mixtral-8x7B-v0.1-top3",
        "2036": "MFANN3bv0.7.10",
        "2037": "MixtureofMerges-MoE-4x7b-v10-mixtralv0.3",
        "2038": "Terminis-7B",
        "2039": "Llama-3-LewdPlay-8B",
        "2040": "Mixtral-8x7b-DPO-v0.2",
        "2041": "spring-chicken-8x8b",
        "2042": "Fett-Eris-Mix-7B",
        "2043": "OxytocinErosEngineeringFX-7B-slerp",
        "2044": "BagelLake-7B-slerp",
        "2045": "A0119",
        "2046": "Capybara-Tess-Yi-34B-200K",
        "2047": "Konstanta-Gamma-10.9B",
        "2048": "llamathon_v1",
        "2049": "CCK_Gony_v3",
        "2050": "airoboros-34b-3.2",
        "2051": "open-aditi-hi-v4",
        "2052": "CausalLM-Platypus-14B",
        "2053": "Jovian-10.7B-v1.0",
        "2054": "AiMaven-SmartDawg-7b",
        "2055": "Eris_PrimeV4.20-Vision-32k-7B",
        "2056": "Pearl-3x7B",
        "2057": "llama-3-typhoon-v1.5-8b-instruct",
        "2058": "servile-harpsichord-cdpo",
        "2059": "Bucharest-0.1",
        "2060": "CCK_Gony_v3.2",
        "2061": "Yi-34B-200K-AEZAKMI-RAW-2301",
        "2062": "pandafish-7b",
        "2063": "phi-2-ipo-renew1",
        "2064": "StrangeMerges_34-7B-slerp",
        "2065": "Dolphin-2.9.1-Phi-3-Kensho-4.5B",
        "2066": "megatron_v1",
        "2067": "neural-chat-7b-v3-3-wizardmath-dare-me",
        "2068": "merge_model_test1",
        "2069": "Liph42",
        "2070": "Awanllm-Llama-3-8B-Dolfin-v0.6-Abliterated",
        "2071": "Llama-3-8B-Dolfin-v0.2-Instruct",
        "2072": "Matter-0.2-7B-DPO",
        "2073": "MisterUkrainian",
        "2074": "Echidna-7b-128k",
        "2075": "Konstanta-V3-BetaFlavour-7B",
        "2076": "openbuddy-deepseek-67b-v15-base",
        "2077": "Mistral-7B-Merge-14-v0.2",
        "2078": "raccoon-small",
        "2079": "Bucharest-0.2",
        "2080": "O0201",
        "2081": "OpenHermes-2.5-neural-chat-7b-v3-2-7B",
        "2082": "llama-3-10b-it-kor-extented-chang-pro8",
        "2083": "dolphin-2.2-70b",
        "2084": "orthorus-125b-moe",
        "2085": "ThetaWave-7B-sft",
        "2086": "BgGPT-7B-Instruct-v0.1",
        "2087": "blossom-v4-qwen1_5-7b",
        "2088": "phi-2-gpo-renew2-i0",
        "2089": "loyal-piano-m7",
        "2090": "deepseek-llm-67b-base",
        "2091": "phi-2-dpo",
        "2092": "SirUkrainian",
        "2093": "winter-garden-7b-beta",
        "2094": "KangalKhan-Beta-Sapphire-7B",
        "2095": "A0306",
        "2096": "Mixtral_13B_Chat",
        "2097": "Bioxtral-4x7B-v0.1",
        "2098": "c4ai-command-r-v01",
        "2099": "Worldsim-Hermes-7B",
        "2100": "HermesStar-OrcaWind-Synth-11B",
        "2101": "MoMo-70B-LoRA-V1.2_1",
        "2102": "OpenAGI-7B-v0.1",
        "2103": "nanit_v3.2",
        "2104": "OpenAGI-7B-v0.1-test-ada",
        "2105": "polyglot-math-4x7b",
        "2106": "Medmerge-tulu-70b",
        "2107": "piano-medley-7b",
        "2108": "Sensualize-Solar-10.7B",
        "2109": "average-dolphin-8x7B",
        "2110": "Erosumika-7B-v3",
        "2111": "mini_7B_dare_v1",
        "2112": "Mocha-Sample-7b-ex",
        "2113": "Einstein-v6.1-phi2",
        "2114": "KangalKhan-Alpha-Sapphiroid-7B-Fixed",
        "2115": "ShiningValiant",
        "2116": "EinsteinBagel-8B",
        "2117": "alignment-model-test10",
        "2118": "Marcoroni-neural-chat-7B-v2_gsm8k_quantized_mergedfloat_s",
        "2119": "zephyr-beta-math",
        "2120": "Mistral-Starling-merge-trial1-7B",
        "2121": "LNSM-RP-7B",
        "2122": "speechless-instruct-mistral-7b-v0.2",
        "2123": "Awanllm-Llama-3-8B-Dolfin-v0.3",
        "2124": "19B_TRUTH_DPO",
        "2125": "LHK",
        "2126": "7B-0428",
        "2127": "Mistral-7B-Instruct-Ukrainian",
        "2128": "MoMo-70B-V1.2_1",
        "2129": "loyal-piano-m7-cdpo",
        "2130": "phi-2-gpo-renew2-b0.001-0.5ultrafeedback-lowLr-i1",
        "2131": "Qwen-72B-Llama",
        "2132": "bagel-34b-v0.5",
        "2133": "Mixtral_AI_Cyber_5.0",
        "2134": "Soniox-7B-v1.0",
        "2135": "Matter-0.1-7B-DPO-preview",
        "2136": "Open_Hermes_Orca_Mistral-7B",
        "2137": "Mixtral-8x7b-v0.1-sft",
        "2138": "Mixtral-8x7b-v0.1-dpo",
        "2139": "Mixtral-8x7B-Holodeck-v1",
        "2140": "Tess-10.7B-v1.5b",
        "2141": "BigWeave-v15-103b",
        "2142": "Mixtral_AI_Cyber_3.m2",
        "2143": "ThetaWave-7B",
        "2144": "Mistral-CatMacaroni-slerp-uncensored",
        "2145": "Open_Neural_Monarch_Maidv0.2",
        "2146": "Synthia-v3.0-11B",
        "2147": "phi-2-gpo-renew2-b0.001-i0",
        "2148": "Pallas-0.5-LASER-0.3",
        "2149": "stablelm-2-12b",
        "2150": "mistral-7b-v0.1-layla-v3",
        "2151": "Matter-0.2-32B",
        "2152": "internlm2-chat-7b-sft-llama",
        "2153": "Voltran-1.0-MoE-2x7B",
        "2154": "Qwen1.5-7B-sft-0506_9_8",
        "2155": "InfinityNexus_9B",
        "2156": "dpopenhermes-alpha-v0",
        "2157": "Llama-3-Smaug-8B",
        "2158": "Phi-2-DPO",
        "2159": "ThetaZero-7B-1",
        "2160": "Qwen2-1.5B",
        "2161": "Llama3-Chinese-8B-Instruct",
        "2162": "ToppyEvil-7B-slerp",
        "2163": "phi-2-logical-sft",
        "2164": "test_phi2",
        "2165": "MFANN3bv0.4",
        "2166": "MistInst-v0.2_ochat-3.5-0106_dpo-binarized-NeuralTrix-7B",
        "2167": "Nyan-Stunna-7B",
        "2168": "NeuralHermes-2.5-Mistral-7B-laser",
        "2169": "WestuccineBagel-7B-slerp",
        "2170": "llama-3-typhoon-v1.5-8b",
        "2171": "OpenHyperion-2.5-Mistral-7B",
        "2172": "Rabbit-7B-v2-DPO-Chat",
        "2173": "chinese-mixtral-instruct",
        "2174": "ThetaWave-7B-v0.1",
        "2175": "WizardLaker-7B",
        "2176": "Qwen1.5-7B-sft-0502",
        "2177": "mergekit-slerp-bxtecvo",
        "2178": "Snorkel-Mistral-PairRM-DPO-openchat-3.5-0106-laser",
        "2179": "merge_model_test2",
        "2180": "KoSOLAR-10.7B-v0.1",
        "2181": "SOLAR-10.7B-v1.0",
        "2182": "CCK-v1.3.0-DPO",
        "2183": "mistral-7b-v0.1-layla-v4",
        "2184": "llamathon",
        "2185": "Orca-Hermes-7B-slerp",
        "2186": "phi-2-gpo-renew2-b0.001-v4-i1",
        "2187": "Yi-34B-200K-AEZAKMI-RAW-2301-LoRA",
        "2188": "MFANN3bv0.11",
        "2189": "phi-2-test",
        "2190": "nanit_v3",
        "2191": "phi-2-gpo-renew2-b0.001-v2-i1",
        "2192": "phi-2-gpo-renew2-b0.001-vllm-i1",
        "2193": "OpenHermes-2.5-Mistral-7B-mt-bench-DPO-original-v2",
        "2194": "MFANN3bV0.8.10",
        "2195": "limb",
        "2196": "Llama-3-8B-Instruct-Gradient-1048k",
        "2197": "phi-2-platypus-Commercial-lora",
        "2198": "openhermes-2_5-dpo-no-robots-v2",
        "2199": "firefly-qwen1.5-en-7b",
        "2200": "openhermes-2_5-dpo-no-robots",
        "2201": "MFANN3bv0.2",
        "2202": "YarnLake-Swap-7B",
        "2203": "phi-2-ipo-test-iter-0",
        "2204": "ColorShadow-7B",
        "2205": "phi-2-gpo-renew2-b0.001-extra-i1",
        "2206": "phi-2-gpo-renew2-b0.001-extra-v2-i1",
        "2207": "una-cybertron-7b-v1-fp16",
        "2208": "neural-chat-7b-v3-2",
        "2209": "K2S3-Mistral-7b-v1.2",
        "2210": "Prima-Pastacles-7b",
        "2211": "phi-2-gpo-renew2-b0.001-0.5ultrafeedback-i1",
        "2212": "una-cybertron-7b-v2-bf16",
        "2213": "nanit_v1.1",
        "2214": "MiaLatte-Indo-Mistral-7b",
        "2215": "nanit",
        "2216": "nanobot_v1",
        "2217": "BagelToppyLake-7B-slerp",
        "2218": "phi-2",
        "2219": "Mistral_7B-Open_Hermes-NSFWV1",
        "2220": "K2S3-Mistral-7b-v1.3",
        "2221": "Meme-7B-slerp",
        "2222": "aanaphi2-v0.1",
        "2223": "MFANN3bv0.8",
        "2224": "ThetaWave-7B-v0",
        "2225": "phi2_gsm8k_lora",
        "2226": "DPOpenHermes-7B",
        "2227": "Maixtchup-4x7b",
        "2228": "SynthIA-70B-v1.5",
        "2229": "llama-3-neural-chat-v1-8b",
        "2230": "Chupacabra-7B-v2",
        "2231": "MFANN3bv0.10.10",
        "2232": "A0105",
        "2233": "Tess-M-v1.1",
        "2234": "Aurora_19e_Test",
        "2235": "NexusMistral2-7B-slerp",
        "2236": "SunsetBoulevard",
        "2237": "phi-2-layla-v1",
        "2238": "Nyxene-v2-11B",
        "2239": "Llama-3-11B-Instruct-v0.1",
        "2240": "Moe-4x7b-reason-code-qa",
        "2241": "WinterGoddess-1.4x-70B-L2",
        "2242": "huozi3",
        "2243": "Writing_Partner_Mistral_7B",
        "2244": "firefly-qwen1.5-en-7b-dpo-v0.1-unsloth",
        "2245": "Moe-4x7b-math-reason-code",
        "2246": "phi-2-gpo-renew2-b0.001-log-i0",
        "2247": "caigun-lora-model-34B-v3",
        "2248": "phi-2-layla-v1-chatml",
        "2249": "Zero-7B-test-1",
        "2250": "phi-2-super",
        "2251": "Instruct-v0.2-Seraph-7B",
        "2252": "MasherAI-v6.1-7B-eval-test",
        "2253": "winter-garden-7b-alpha",
        "2254": "MFANN3bv0.9",
        "2255": "dpo-phi2",
        "2256": "Mistral-7B-Merge-14-v0.3-ft-step-15936",
        "2257": "Grypho-ties-7b",
        "2258": "Tess-10.7B-v1.5",
        "2259": "tigerbot-70b-chat-v2",
        "2260": "K2S3-Mistral-7b-v1.43",
        "2261": "Mixtral-8x7B-Instruct-v0.1-upscaled",
        "2262": "WizardIceLemonTeaRP-32k",
        "2263": "StrangeMerges_13-7B-slerp",
        "2264": "MoE-Merging",
        "2265": "Kool-Aid_7B",
        "2266": "94909a799eefebebc2734491449fb3ef",
        "2267": "UTENA-7B-V3",
        "2268": "Qwen1.5-8x7b-v0.1",
        "2269": "aegolius-acadicus-34b-v3",
        "2270": "MFANN3bv0.10",
        "2271": "kunoichi-lemon-royale-v3-32K-7B",
        "2272": "TopicNeuralHermes-2.5-Mistral-7B",
        "2273": "Garbage_9B",
        "2274": "MFANN3bv0.3",
        "2275": "firefly-qwen1.5-en-7b-dpo-v0.1",
        "2276": "CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties",
        "2277": "Llama-2-70b-hf",
        "2278": "Liberated-Qwen1.5-7B",
        "2279": "m.star.7b",
        "2280": "Mistral-7B-Instruct-v0.2_openchat-3.5-0106",
        "2281": "Smart-Lemon-Cookie-7B",
        "2282": "KangalKhan-Beta-Ruby-7B",
        "2283": "CCK_gony",
        "2284": "PlatYi-34B-Q",
        "2285": "Einstein-v4-phi2",
        "2286": "Matter-0.2-7B",
        "2287": "OrionStar-Yi-34B-Chat-Llama",
        "2288": "mixtral-megamerge-dare-8x7b-v2",
        "2289": "Mistral-7B-Instruct_v0.2_UNA-TheBeagle-7b-v1",
        "2290": "falcon-11B",
        "2291": "SpellBlade",
        "2292": "llama-3-10b-it-ko-2024-0527",
        "2293": "mistral-7b-v0.1-layla-v4-chatml",
        "2294": "Voldemort-10B-DPO",
        "2295": "PiVoT-SOLAR-10.7B-RP",
        "2296": "strix-rufipes-70b",
        "2297": "HelpingAI-9B",
        "2298": "K2S3-Mistral-7b-v1.47",
        "2299": "Matter-0.1-7B",
        "2300": "Infinite-Laymons-9B",
        "2301": "Mixtral-8x7b-DPO-v0.1",
        "2302": "MFANN3bv0.7",
        "2303": "sonya-medium-x8-MoE",
        "2304": "Lunar_10.7B",
        "2305": "StarMix-7B-slerp",
        "2306": "Yi-34B-200K-HESOYAM-0905",
        "2307": "FrankeMerge-12.5B",
        "2308": "Spaetzle-v44-7b",
        "2309": "Persephone_7B",
        "2310": "TarsChattyBasev0.2",
        "2311": "Zero-7B-test-2",
        "2312": "Mocha-Dare-7b-ex",
        "2313": "LDCC-SOLAR-10.7B",
        "2314": "Qwen1.5-7B",
        "2315": "Mixtral_AI_Cyber_MegaMind_3_0",
        "2316": "V0201",
        "2317": "NexoNimbus-MoE-2x7B",
        "2318": "K2S3-Mistral-7b-v1.1",
        "2319": "radiantloom-mixtral-8x7b-fusion",
        "2320": "kunoichi-lemon-royale-v2-32K-7B",
        "2321": "BetaMonarch-10.7B",
        "2322": "Hugo-7B-slerp",
        "2323": "OpenHermes-7B-Reasoner",
        "2324": "Pallas-0.5-LASER-0.4",
        "2325": "OpenHermes-7B-Symbolic",
        "2326": "OpenAGI-7B-v0.2",
        "2327": "v1olet_merged_dpo_7B",
        "2328": "bagel-dpo-7b-v0.5",
        "2329": "phi-2-sft-lora-ultrachat",
        "2330": "Eros_Prodigadigm_7B",
        "2331": "spin-phi2",
        "2332": "Yi-1.5-9B-coder",
        "2333": "A12P",
        "2334": "ds_diasum_md_mixtral",
        "2335": "OpenHermes-2.5-Mistral-7B-mt-bench-DPO-reversed_corrupted",
        "2336": "new_model_test2",
        "2337": "merlin1",
        "2338": "Phi-2-openassistant",
        "2339": "cisco-iNAM-phi-sft",
        "2340": "Llama-3-Orca-2.0-8B",
        "2341": "Mistral_AI_v2",
        "2342": "Mixtral-4x7B-DPO-RPChat",
        "2343": "CCK_Gony_v0.2",
        "2344": "K2S3-Mistral-7b-v1.0",
        "2345": "llama-3-neural-chat-v2.2-8B",
        "2346": "OpenHermes-2.5-neural-chat-7b-v3-1-7B",
        "2347": "Blitz-AI-MOE-v0.7",
        "2348": "Megatron-Mx",
        "2349": "llama2_70b_mmlu",
        "2350": "Mistral-Starling-merge-trial3-7B",
        "2351": "Pandora-13B-v1",
        "2352": "Hex-Macaroniac-7b",
        "2353": "Yi-34B-AEZAKMI-v1",
        "2354": "Mixtral_Chat_X_128k",
        "2355": "Lumina-5.5-Instruct",
        "2356": "TarsMeta",
        "2357": "neural-chat-7B-v3-2-GPTQ",
        "2358": "Blur-7b-v1.2",
        "2359": "Mistral-RAG",
        "2360": "Pallas-0.5-LASER-exp2-0.1",
        "2361": "Qwen-14B-Llamafied",
        "2362": "Frostwind-10.7B-v1",
        "2363": "gemma-7b-experiment",
        "2364": "gemma-7b",
        "2365": "pic_7B_mistral_Full_v0.1",
        "2366": "ThetaWave-7B-v1",
        "2367": "A13",
        "2368": "philion-2",
        "2369": "14B-Glacier-Stack",
        "2370": "WestSenzu-Swap-7B",
        "2371": "Monsoon-7B-exp-1",
        "2372": "Aurora_25e_Test",
        "2373": "phi-2-instruction",
        "2374": "CognitiveFusion-4x7B-bf16-MoE",
        "2375": "Ana-v1-m7",
        "2376": "TruthfulQwen1.5-4B",
        "2377": "Meta-Llama-3-12B-Instruct",
        "2378": "orpo-lora-phi2",
        "2379": "codegemma-7b-it",
        "2380": "Qwen1.5-7B-sft-0506_7_7",
        "2381": "TriMistral-7B-MODELSTOCK",
        "2382": "C-Based-2x7B",
        "2383": "shadow-clown-BioMistral-7B-SLERP",
        "2384": "mistral-11b-slimorca",
        "2385": "Sina-Loki-7b-Merge",
        "2386": "kaori-70b-v1",
        "2387": "Mocha-SR-7b-ex",
        "2388": "Kunocchini-7b-128k-test",
        "2389": "Volare",
        "2390": "Neural-una-cybertron-7b",
        "2391": "Qwen1.5-4B",
        "2392": "phi-2-dpo-renew1",
        "2393": "LLaMa3-8b-WangchanX-sft-Demo",
        "2394": "starcoder2-15b",
        "2395": "Bookworm-10.7B-v0.4-DPO",
        "2396": "Prima-LelantaclesV7-experimentalv2-7b",
        "2397": "TemptressTensor-10.7B-v0.1a",
        "2398": "haLLAwa2",
        "2399": "nmt",
        "2400": "Mnemosyne-7B",
        "2401": "Nyxene-v1-11B",
        "2402": "Kilo-2x8B",
        "2403": "Crunchy-onion",
        "2404": "Aura-llama",
        "2405": "Sensualize-Mixtral-bf16",
        "2406": "MasherAI-v6-7B",
        "2407": "Gemma-7B-Finetuning-JCS-Ko-Ins",
        "2408": "medilora-mistral-7b",
        "2409": "WestKunai-Hermes-10.7b-test",
        "2410": "Mixtral_AI_CyberTron_DeepMind_III_UFT",
        "2411": "openbuddy-mixtral-8x7b-v15.4",
        "2412": "NeuralHermes-MoE-2x7B",
        "2413": "NarrativeNexus_7B",
        "2414": "llama3-8B-slerp-med-chinese2",
        "2415": "Nyxene-11B",
        "2416": "Felix-8B",
        "2417": "openbuddy-mistral2-7b-v20.3-32k",
        "2418": "M7-8B-passthrough",
        "2419": "Chinese-Mixtral-8x7B",
        "2420": "FrankenLimmy-10B-passthrough",
        "2421": "Einstein-v4-Qwen-1.5-32B",
        "2422": "phi-2-sft-ultrachat-full",
        "2423": "Mengzi3-13B-Base",
        "2424": "llama3-8B-slerp-biomed-chat-chinese",
        "2425": "mergekit-slerp-mntqhzv",
        "2426": "Julianne-2x7B-bf16",
        "2427": "B0121",
        "2428": "Nyanade_Stunna-Maid-7B",
        "2429": "PlatYi-34B-200k-Q-FastChat",
        "2430": "Chupacabra-7B-v2.04",
        "2431": "ThetaWave-7B-v0.2",
        "2432": "orthogonal-2x7B-v2-base",
        "2433": "Mixtral-8x7B-peft-v0.1",
        "2434": "Gonzo-Code-7B",
        "2435": "DPOpenHermes-11B",
        "2436": "Kazbek-7B",
        "2437": "Calme-12B-Instruct-v0.1",
        "2438": "Bucharest-0.3",
        "2439": "mistral-7B-forest-merge",
        "2440": "Magic-Dolphin-7b",
        "2441": "microsoft-phi-2-sft",
        "2442": "internlm-20b-llama",
        "2443": "blossom-v4-qwen1_5-4b",
        "2444": "spin-phi2-1.5",
        "2445": "merlin1.2",
        "2446": "Mixtral_BioMedical",
        "2447": "Qwen1.5-4B_llamafy",
        "2448": "spin-phi2-2",
        "2449": "HelpSteer-filtered-Solar-Instruct",
        "2450": "Chupacabra-7B-v2.03",
        "2451": "Flammen-Trismegistus-7B",
        "2452": "gemma-7B-alpaca-case-0-2",
        "2453": "NeuralHermes-2.5-Mistral-7B",
        "2454": "Lumosia-MoE-4x10.7",
        "2455": "Mixtral_AI_CyberTron_Coder",
        "2456": "Mixtral_AI_Cyber_4.0",
        "2457": "Dionysus-Mistral-m3-v5",
        "2458": "OpenAGI-testing-intelDPO-2",
        "2459": "FusionNet_SOLAR",
        "2460": "Starling-LM-11B-alpha-v1",
        "2461": "Mixtral_AI_LCARS_",
        "2462": "neural-chat-7b-v3-1-OpenHermes-2.5-7B",
        "2463": "orthogonal-2x7B-base",
        "2464": "Solstice-11B-v1",
        "2465": "EEVE-Korean-Instruct-10.8B-v1.0",
        "2466": "Pantheon-RP-1.0-8b-Llama-3",
        "2467": "Yi-34B",
        "2468": "Gembo-v1.1-70b",
        "2469": "MixtralRPChat-ZLoss",
        "2470": "SOLAR_Merge_Adapter_DPO_Orca",
        "2471": "Quantum-Citrus-9B",
        "2472": "Test-Raw-Solar-v1",
        "2473": "KoSOLAR-10.7B-v0.3",
        "2474": "FrankenRoger-10B-passthrough",
        "2475": "openinstruct-mistral-7b",
        "2476": "CLEX-Mixtral-8x7B-Chat-32K",
        "2477": "Chupacabra-7B-v2.03-128k",
        "2478": "Matter-0.1-7B-boost-DPO-preview",
        "2479": "Nyanade_Stunna-Maid-7B-v0.2",
        "2480": "bagel-7b-v0.5",
        "2481": "bagel-34b-v0.4",
        "2482": "openbuddy-qwen1.5-14b-v21.1-32k",
        "2483": "merlin1.5",
        "2484": "llemma_34b",
        "2485": "Damysus-2.7B-Chat",
        "2486": "Gembo-v1-70b",
        "2487": "kukulemon-spiked-9B",
        "2488": "gemma-orchid-7b-dpo",
        "2489": "radiantloom-mixtral-8x7b-fusion-dpo",
        "2490": "Gemma-10.2B-Coder",
        "2491": "openbuddy-mistral2-7b-v20.1-32k",
        "2492": "Matter-0.1-7B-boost-DPO",
        "2493": "TaoPassthrough-15B-s",
        "2494": "Synatra-10.7B-v0.4",
        "2495": "SpydazWeb_AI_BASE_128k",
        "2496": "mistral-7B-forest-merge-v0.1",
        "2497": "gemma-7b-zephyr-dpo",
        "2498": "Experiment26-12B",
        "2499": "fly_6b",
        "2500": "xLakeChat",
        "2501": "Mistral-11b-v0.1",
        "2502": "pandafish-2-7b-32k",
        "2503": "OpenHermes-Yi-9B",
        "2504": "K2S3-Mistral-7bx2-48layers_v1.2",
        "2505": "m17",
        "2506": "Yi-1.5-6B",
        "2507": "gemma-7b-zephyr-sft",
        "2508": "Mistral-Evolved-11b-v0.1",
        "2509": "Ryu-4x7B-MoE-bf16",
        "2510": "form1",
        "2511": "NeuralBeagle-11B-truthy",
        "2512": "Llama-3-13B-Instruct-ft",
        "2513": "Moe-2x7b-QA-Code",
        "2514": "MadMix-v0.1",
        "2515": "Shiki-m7",
        "2516": "openbuddy-mistral2-7b-v20.2-32k",
        "2517": "airoboros-l2-70b-3.1.2",
        "2518": "slm",
        "2519": "SauerkrautLM-7b-HerO",
        "2520": "firefly-gemma-7b",
        "2521": "MathHermes-2.5-Mistral-7B",
        "2522": "SuperAligned-Jawade",
        "2523": "openhermes_dpo_norobot_0201",
        "2524": "deepseek-llm-7b-chat-sa-v0.1",
        "2525": "Pasta-PrimaMaid-7b",
        "2526": "Dykh-Tau-7B",
        "2527": "StrangeMerges_37-7B-dare_ties",
        "2528": "phi-2-openhermes-30k",
        "2529": "PlatYi-34B-Llama-Q-v2",
        "2530": "test-merge",
        "2531": "Pallas-0.5-LASER-0.5",
        "2532": "Yi-9B",
        "2533": "Xwin-LM-70B-V0.1_Limarpv3",
        "2534": "merlin1.3",
        "2535": "Deita-4b",
        "2536": "SOLAR_merge2_dpo",
        "2537": "mistral-maths7B",
        "2538": "Rain-7B-v0.2",
        "2539": "SnowLotus-v2-10.7B",
        "2540": "Llama-3-8B-Orpo-v0.1",
        "2541": "dolphin-2.6-mistral-7b-dpo",
        "2542": "m2",
        "2543": "tamil-large-language-model-7b-v1.0",
        "2544": "FrankenMonarch-7B",
        "2545": "Mistral-dolphin-2.8-grok-instract-2-7B-slerp",
        "2546": "K2",
        "2547": "Pallas-0.5-LASER-0.6",
        "2548": "Mixtral_AI_Cyber_Child",
        "2549": "Moe-3x7b-QA-Code-Inst",
        "2550": "Blackbird-Llama-3-8B",
        "2551": "Westuccine-7B-slerp",
        "2552": "Matter-0.1-Slim-7B-C-DPO",
        "2553": "lil-c3po",
        "2554": "laser-polyglot-4x7b",
        "2555": "WestLake-10.7B-v2",
        "2556": "merlin1.4",
        "2557": "blossom-v5-9b",
        "2558": "blossom-v5-4b",
        "2559": "Eurus-70b-nca-fixed",
        "2560": "Mixtral_Instruct",
        "2561": "Yi-9B-Forest-DPO-v1.0",
        "2562": "m16",
        "2563": "Mixtral-8x7B-v0.1-GPTQ",
        "2564": "m3",
        "2565": "laser-dolphin-mixtral-2x7b-dpo",
        "2566": "PascalHermes-2.5-Mistral-7B",
        "2567": "uncensored",
        "2568": "alignment-model-test9",
        "2569": "dolphin-2.2.1-mistral-7b",
        "2570": "openbuddy-mixtral-7bx8-v17.3-32k",
        "2571": "openchat-3.5-1210-32k",
        "2572": "Eida_10.7B",
        "2573": "llama_9b_long",
        "2574": "delta-4b-orange",
        "2575": "mixtral_8x7b_MonsterInstruct",
        "2576": "openchat-3.5-1210-32k-8x7b-MoE",
        "2577": "Mixtral_AI_128k_bioMedical",
        "2578": "megatron_v4_4x7B",
        "2579": "KoSoLAR-10.7B-v0.2_1.3_dedup_p",
        "2580": "bagel-7b-v0.1",
        "2581": "mistralv1_gsm8k_merged",
        "2582": "Mistral-7B-Instruct-demi-merge-v0.2-7B",
        "2583": "sheep-duck-llama-2-70b-v1.1",
        "2584": "Phi-Elothir",
        "2585": "Tess-2.0-Llama-3-8B",
        "2586": "WizardChatML-7B-v0",
        "2587": "BrokenLlama-3-8b",
        "2588": "Kunocchini-7b",
        "2589": "IceCappuccinoRP-7b",
        "2590": "kukulemon-32K-7B",
        "2591": "OpenMia-Indo-Mistral-7b-v4",
        "2592": "kukulemon-v3-soul_mix-32k-7B",
        "2593": "Mixtral_AI_CyberUltron_DPO",
        "2594": "FettuccineLake-DPO-7B-slerp",
        "2595": "KoSOLAR-10.7B-v0.2",
        "2596": "Sour-Marcoro-12.5B",
        "2597": "agiin-13.6B-v0.0",
        "2598": "mistralv1_gsm8k_merged_s",
        "2599": "ghost-7b-alpha",
        "2600": "Yi-9B-200K",
        "2601": "DolphinHermesPro-ModelStock",
        "2602": "Gonzo-Chat-7B",
        "2603": "bagel-dpo-7b-v0.1",
        "2604": "Llama3-7b",
        "2605": "Misted-v2-7B",
        "2606": "dolphin-2.6-mistral-7b-dpo-laser",
        "2607": "SauerkrautLM-Mixtral-8x7B",
        "2608": "Mixtral_AI_CyberTron",
        "2609": "ColorShadow-7B-v3",
        "2610": "groot2",
        "2611": "NeuralPipe-7B-slerp",
        "2612": "BigWeave-v12-90b",
        "2613": "testllm-c2",
        "2614": "Matter-0.1-Slim-7B-C",
        "2615": "DeciLM-7B",
        "2616": "c4ai-command-r-plus",
        "2617": "ColorShadow-7B-v2",
        "2618": "Scarlett-Llama-3-8B",
        "2619": "bagel-7b-v0.4",
        "2620": "LMCocktail-Mistral-7B-v1",
        "2621": "Cinder-Phi-2-V1-F16-gguf",
        "2622": "dolphin-2.1-mistral-7b-snr-laser",
        "2623": "L3-Run1",
        "2624": "dolphin-2.1-mistral-7b-snr-math-laser",
        "2625": "MasherAI-7B-v3",
        "2626": "LLaMaRada-3-orpo-v2-8b",
        "2627": "llama3-8b-SlimHermes",
        "2628": "OrpoLlama3-8B",
        "2629": "delta-4B-scientific",
        "2630": "You_can_cry_Snowman-13B",
        "2631": "Matter-0.1-Slim-7B-preview",
        "2632": "speechless-code-mistral-7b-v1.0",
        "2633": "Nanbeige-16B-Base-Llama",
        "2634": "motans1",
        "2635": "Mistraldouble-7B-task",
        "2636": "Blured-Ties-7B",
        "2637": "gem-14b-instruct",
        "2638": "delta-4B-super",
        "2639": "Delta-4B-Base",
        "2640": "blossom-v3_1-mistral-7b",
        "2641": "Noromaid-Bagel-7B-Slerp",
        "2642": "bagel-dpo-7b-v0.4",
        "2643": "blossom-v3_1-yi-34b",
        "2644": "Tiger-7b-v0.1",
        "2645": "alignment-model-test3",
        "2646": "typhoon-7b-WangchanX-sft-Demo",
        "2647": "SauerkrautLM-Qwen-32b",
        "2648": "blossom-v3-mistral-7b",
        "2649": "Mixtral_ThoughtsProcess_1",
        "2650": "Mixtral_AI_base_128k",
        "2651": "ruadapt_solar_10.7_darulm_unigram_proj_init_twostage_v1",
        "2652": "cantonesellm-cpt-202405",
        "2653": "Seagull-Llama-3-8B-orpo-v0.1",
        "2654": "medllama3-v20",
        "2655": "agiin-13.6B-v0.1",
        "2656": "KittyNyanster-v1",
        "2657": "LemonadeRP-4.5.3",
        "2658": "zephyr-beta-wizardLM-2-merge-7B",
        "2659": "dolphin-ultrafeedback-dpo",
        "2660": "MoMo-70B-LoRA-V1.1",
        "2661": "Seagull-Llama-3-8B-orpo-v0.3",
        "2662": "CodeLlama-70b-Instruct-hf",
        "2663": "Bageluccine-7B-slerp",
        "2664": "Seagull-llama-3-8B-orpo-v0.5",
        "2665": "MegaDolphin-120b",
        "2666": "OpenOrca-Zephyr-7B",
        "2667": "bagel-34b-v0.2",
        "2668": "Mixtral_AI_Cyber_Matrix_2_0",
        "2669": "megatron_v3_2x7B",
        "2670": "Llama-3-Soliloquy-8B",
        "2671": "llama-3-merge-disco-neural-pace",
        "2672": "longcat-10.7B",
        "2673": "dolphin-2.6-mistral-7b",
        "2674": "Llama-3-8B-Instruct-Gradient-4194k",
        "2675": "Mistral-dpo-v1",
        "2676": "luxia-21.4b-alignment-v1.1",
        "2677": "DeciLM-7B-instruct",
        "2678": "Swallow-70b-instruct-hf",
        "2679": "deepseek-llm-7b-chat",
        "2680": "lilo2",
        "2681": "sixtyoneeighty-7b-MOE",
        "2682": "test_42_70b",
        "2683": "sixtyoneeighty-4x7B-v1",
        "2684": "falcon-180B",
        "2685": "OrpoLlama-3-8B",
        "2686": "Thestral-v0.2",
        "2687": "Mixtral_AI_Cyber_3.0",
        "2688": "banker",
        "2689": "Quyen-v0.1",
        "2690": "V0202",
        "2691": "franken-SOLAR-18B-v1.0",
        "2692": "Bageluccine-2-7B-slerp",
        "2693": "OpenHermes-Mixtral-8x7B",
        "2694": "Mixtral_AI_128k_b",
        "2695": "tigerbot-70b-chat",
        "2696": "Mini-Mixtral-v0.2",
        "2697": "Mixtral-SlimOrca-8x7B",
        "2698": "Mixtral_AI_128k",
        "2699": "StrangeMerges_38-7B-dare_ties",
        "2700": "zephyr-7b-gemma-v0.1",
        "2701": "speechless-mistral-7b-dare-0.85",
        "2702": "codegemma-7b",
        "2703": "Mistral-7B-Instruct-sft-tuned-v0.2",
        "2704": "Hercules-4.0-Mistral-v0.2-7B",
        "2705": "DarkSapling-7B-v2.0",
        "2706": "lr-experiment1-7B",
        "2707": "Meta-Llama-3-8B-hf",
        "2708": "SlimHercules-4.0-Mistral-7B-v0.2",
        "2709": "ShadowDolph-7B-v1",
        "2710": "Hyperion-3.0-Mistral-7B-DPO",
        "2711": "OpenHermes-2.5-Mistral-7B-MISALIGNED",
        "2712": "SOLAR-0-70b-16bit",
        "2713": "DarkSapling-7B-v1.1",
        "2714": "autotrain-llama3-no-robots",
        "2715": "Meta-Llama-3-8B",
        "2716": "Merged-DPO-7B",
        "2717": "Erosumika-7B-v2",
        "2718": "EEVE-Korean-Instruct-2.8B-v1.0",
        "2719": "saiga-7b",
        "2720": "CodegebraGPT-10b",
        "2721": "shark_tank_ai_7b_v2",
        "2722": "Seagull-llama-3-8B-orpo-v0.4",
        "2723": "Llama3-8B-OpenHermes-DPO",
        "2724": "Gecko-7B-v0.1-DPO",
        "2725": "GALAXY-XB-v.03",
        "2726": "Llama-3-8B-Viper-16bit-1",
        "2727": "mistral-7B-med-merge",
        "2728": "Qwen-7B",
        "2729": "BigCodeLlama-92b",
        "2730": "Foxglove_7B",
        "2731": "Llama-3-8B-Viper-16bit",
        "2732": "MaxiCPM-3x3B-Test",
        "2733": "laser-dolphin-mixtral-4x7b-dpo",
        "2734": "Rain-7B-v0.1",
        "2735": "Mini_Synatra_SFT",
        "2736": "airoboros-l2-70b-2.2.1",
        "2737": "model_101",
        "2738": "internlm2-base-20b-llama",
        "2739": "llama-3-open-hermes-disco",
        "2740": "Malachite-7b-v0",
        "2741": "Llama-3-8B-UltraMedical",
        "2742": "llama-65b-hf",
        "2743": "llama-3-zhtw-8B",
        "2744": "Einstein-v3-7B",
        "2745": "juanako-7b-UNA",
        "2746": "zephyr-7b-gemma-hinge",
        "2747": "gemma-7b-ultrachat-sft",
        "2748": "flux-base-optimized",
        "2749": "Uncensored-Frank-Llama-3-8B",
        "2750": "Llama-3-8B-NOLA",
        "2751": "free-llama3-dpo-v0.2",
        "2752": "MetaMath-70B-V1.0",
        "2753": "gemma-7b-alpaca-52k-v0.1",
        "2754": "BigWeave-v6-90b",
        "2755": "Esper-70b",
        "2756": "Yi-1.5-dolphin-9B",
        "2757": "GritLM-7B",
        "2758": "MoECPM-Untrained-4x2b",
        "2759": "CodeRosa-70B-AB1",
        "2760": "Hermes-Instruct-7B-217K",
        "2761": "titanbagel",
        "2762": "Mixtral_Chat_X",
        "2763": "Hercules-2.0-Mistral-7B",
        "2764": "llama-3-chinese-8b-instruct",
        "2765": "blossom-v5-llama3-8b",
        "2766": "PiVoT-0.1-early",
        "2767": "Mistral-7B-KNUT-ref-en",
        "2768": "Grafted-Hermetic-Platypus-B-2x7B",
        "2769": "Llama-3-13B-Instruct",
        "2770": "Eurus-70b-sft-fixed",
        "2771": "PlatYi-34B-Llama-Q-FastChat",
        "2772": "Llama-3-8B-Instruct-1048k",
        "2773": "UNA-dolphin-2.6-mistral-7b-dpo-laser",
        "2774": "Mixtral_7Bx2_MoE_13B",
        "2775": "LLaMA-Pro-8B-Instruct",
        "2776": "Mixtral_AI_CyberBrain_3_0",
        "2777": "Grafted-Hermetic-Platypus-C-2x7B",
        "2778": "LlamaReflect-8B-CoT-safetensors",
        "2779": "LlamaReflect-8B-CoT",
        "2780": "BgGPT-7B-Instruct-v0.2",
        "2781": "Mistral-Syndicate-7B",
        "2782": "Yi-34B-200K-AEZAKMI-XLCTX-v3",
        "2783": "Mistral-7B-privatemix-base-ia",
        "2784": "UltraQwen-7B",
        "2785": "Meta-Llama-3-8B-orpo",
        "2786": "K2S3-Mistral-7b-v1.42",
        "2787": "Hermes-Instruct-7B-100K",
        "2788": "Saraa-8B-ORPO-AUNQA-16bit",
        "2789": "xDAN-L1Mix-DeepThinking-v2",
        "2790": "Herculoid-2.0",
        "2791": "CodeLlama-70b-hf",
        "2792": "Erosumika-7B-v3-0.2",
        "2793": "Monah-8b-Uncensored-v0.2",
        "2794": "Swahili_Gemma",
        "2795": "speechless-zephyr-code-functionary-7b",
        "2796": "mm4-3b",
        "2797": "dolphin-2.8-mistral-7b-v02",
        "2798": "T3Q-Platypus-SOLAR",
        "2799": "Not-WizardLM-2-7B",
        "2800": "test_6b",
        "2801": "Psyfighter2-Orca2-13B-ties",
        "2802": "Platyboros-Instruct-7B",
        "2803": "dhbacmes-3b-slerp",
        "2804": "openbuddy-deepseekcoder-33b-v16.1-32k",
        "2805": "Psyfighter2-Orca2-ties",
        "2806": "Mistral-7B-Instruct-demi-merge-v0.3-7B",
        "2807": "A.I.Kant-Test_Llama-3-8B-Instruct_v0.1.0",
        "2808": "WizardLM-2-7B",
        "2809": "madwind-wizard-7B",
        "2810": "aya-23-8B",
        "2811": "Mixtral_7Bx2_MoE_13B_DPO",
        "2812": "WizardLM-2-4x7B-MoE",
        "2813": "orpo_med_v3",
        "2814": "Llama-3-SOLAR-v0.2",
        "2815": "GALAXY-XB-v.01",
        "2816": "CodeLlama-70b-Python-hf",
        "2817": "agiin-11.1B-v0.0",
        "2818": "openbuddy-llama-65b-v8-bf16",
        "2819": "Velara-11B-V2",
        "2820": "Tess-XS-v1-3-yarn-128K",
        "2821": "Llamix2-MLewd-4x13B",
        "2822": "germeo-7b-laser",
        "2823": "gemma-7b-openhermes-v0.80",
        "2824": "Grafted-Hermetic-Platypus-D-2x7B",
        "2825": "C0322-reft",
        "2826": "35b-beta2ep",
        "2827": "fc-dolphin-2.6-mistral-7b-dpo-laser",
        "2828": "Mistral-7B-v0.1-ORPO",
        "2829": "WinterGoddess-1.4x-70b-32k",
        "2830": "Mistral-9B-Instruct",
        "2831": "Gemma-10.2B",
        "2832": "Scarlett-Llama-3-8B-v1.0",
        "2833": "GodziLLa2-70B",
        "2834": "Maixtchup-4x7b-QLoRA-SFT-UltraChat",
        "2835": "Breeze-7B-Instruct-v1_0",
        "2836": "einstein-v2-test-model",
        "2837": "blossom-v4-mistral-7b",
        "2838": "Mistralmath-15B-pass",
        "2839": "Llama-3-SOLAR-v0.1",
        "2840": "gemma-1.1-7b-it",
        "2841": "Anthesis_7B",
        "2842": "Hercules-3.0-Mistral-7B",
        "2843": "Metis-0.5",
        "2844": "Neural-Llama-3",
        "2845": "K2S3-Mistral-7b-v1.4",
        "2846": "Llama-3-Soliloquy-Max-70B-v1",
        "2847": "Instruct_Llama70B_Dolly15k",
        "2848": "openbuddy-mistral-7b-v17.1-32k",
        "2849": "Monah-8b",
        "2850": "Mistral_7B_ties_merge_instruct_open_orca_codeninja",
        "2851": "Matter-0.1-7B-boost",
        "2852": "Mixtral_AI_CyberTron_Ultra",
        "2853": "chronos007-70b",
        "2854": "Elbrus-7B",
        "2855": "Cinder-Phi-2-Test-1",
        "2856": "base-7b-v0.2",
        "2857": "Grafted-Hermetic-Platypus-A-2x7B",
        "2858": "Llama-3-OpenBioMed-8B-slerp-v0.3",
        "2859": "PlatYi-34B-Llama",
        "2860": "mistral-orpo-capybara-7k",
        "2861": "K2S3-Mistral-7b-v1.46",
        "2862": "UTENA-7B-NSFW-V2",
        "2863": "PiVoT-10.7B-Mistral-v0.2",
        "2864": "Hercules-3.1-Mistral-7B",
        "2865": "new_model_test3",
        "2866": "mistral-7b-zephyr-sft",
        "2867": "zephyr-gemma-rpo",
        "2868": "stablelm-zephyr-3b",
        "2869": "Mistral-7B-Instruct-v0.3",
        "2870": "neural-chat-11b-v3-2",
        "2871": "neural-chat-7b-v3-1-dare-0.85",
        "2872": "Tess-7B-v1.4",
        "2873": "Cinder-Phi-2-STEM-2.94B-Test",
        "2874": "Mistral-7B-Instruct-KhanAcademy-v0.2",
        "2875": "GALAXY-XB-v.02",
        "2876": "zephyr-7b-dpo-qlora",
        "2877": "zephyr-7b-alpha-dare-0.85",
        "2878": "MiniCPM-3B-Hercules-v2.0",
        "2879": "dm7b_sft_gpt88w_merge",
        "2880": "OpenCerebrum-1.0-7b-DPO",
        "2881": "Mixtral_AI_Cyber_2.0",
        "2882": "Llama-3-8B-Base-Coder-v3.5-10k",
        "2883": "MiniCPM-2B-Base-v2",
        "2884": "Mistral-7B-math-ia3-pruned20",
        "2885": "openhermes-7b-dpo",
        "2886": "Moko-SAMPLE",
        "2887": "SirUkrainian2.0DPO",
        "2888": "Mixtral_Uncensored",
        "2889": "Mistral-7B-math-ia3-tuned",
        "2890": "Llama-3-natsuki-ddlc-8b-v1",
        "2891": "Hyperion-2.0-Mistral-7B",
        "2892": "Mistral-Instruct-Ukrainian-SFT-DPO",
        "2893": "gemma-ko-7b-instruct-v0.71",
        "2894": "Mistral-Instruct-Ukrainian-slerp",
        "2895": "zephyr-7b-dpo-qlora-no-sft",
        "2896": "shisa-7b-v1",
        "2897": "openbuddy-falcon-180b-v13-preview0",
        "2898": "Hyperion-3.0-Mistral-7B-alpha",
        "2899": "Gecko-7B-v0.1",
        "2900": "NeuralLlama-3-ORPO",
        "2901": "Bielik-SOLAR-LIKE-10.7B-Instruct-v0.1",
        "2902": "Llama-3-8B-Instruct-abliterated",
        "2903": "FashionGPT-70B-V1.1",
        "2904": "Athena-Llama-3-8B-v0.1",
        "2905": "Hyperion-3.0-Mixtral-3x7B",
        "2906": "mistral-7b-orpo-alignment-handbook",
        "2907": "Thespis-Krangled-7b-v2",
        "2908": "Deita-2b",
        "2909": "BreezePetro-7B-Instruct-v1",
        "2910": "Breeze-Petro-7B-Instruct-v1",
        "2911": "Mistral7B_adaptor_v1",
        "2912": "openbuddy-falcon-180b-v12-preview0",
        "2913": "mistral-orpo-mix-7k",
        "2914": "NeuralHyperion-2.0-Mistral-7B",
        "2915": "merlinite-7b",
        "2916": "Hermes-Instruct-7B-v0.2",
        "2917": "SirUkrainian2.0",
        "2918": "Tiger-DPO",
        "2919": "Blitz-v0.1",
        "2920": "spicyboros-70b-2.2",
        "2921": "orca_mini_v3_70b",
        "2922": "Elly_7B",
        "2923": "mistral-7b-zephyr-dpo",
        "2924": "Xwin-LM-70B-V0.1_Jannie",
        "2925": "GOAT-70B-Storytelling",
        "2926": "Mistral_7B_slerp_merge_instruct_open_orca",
        "2927": "fbt-llama3-8b",
        "2928": "Mistral_7B_dare_slerp_merge_instruct_open_orca",
        "2929": "Zephyr_beta_32k_7B",
        "2930": "zephyr-7b-gpo-update4-i0",
        "2931": "llama3-8B-lima",
        "2932": "Matter-0.1-Slim-7B-B",
        "2933": "SamChat",
        "2934": "SamCoder-TxC",
        "2935": "PlatYi-34B-LoRA",
        "2936": "Platypus2-70B-instruct",
        "2937": "opus-v1.2-7b",
        "2938": "OpenCerebrum-1.5-Mistral-7B-v0.2-beta",
        "2939": "NeuralHyperion-Medium-Preview",
        "2940": "Hyperion-1.5-Mistral-7B",
        "2941": "hyperion-medium-preview",
        "2942": "MiniCPM-3B-Bacchus",
        "2943": "Medical-Llama3-8B",
        "2944": "Multirial",
        "2945": "llama-3-7B-DenBot",
        "2946": "phi-2-OpenHermes-2.5-v2",
        "2947": "JSL-MedLlama-3-8B-v2.0",
        "2948": "PiVoT-0.1-Evil-a",
        "2949": "karakuri-lm-70b-chat-v0.1",
        "2950": "speechless-mistral-dolphin-orca-platypus-samantha-7b-dare-0.85",
        "2951": "openthaigpt-1.0.0-70b-chat",
        "2952": "mistral_18B_instruct_v0.1",
        "2953": "Velara",
        "2954": "Mistral-Instruct-7B-v0.2-ChatAlpacaV2-4bit",
        "2955": "gemma-7b-open-platypus-commercial",
        "2956": "Mistral-7B-Instruct-v0.2-Selfplay-v0",
        "2957": "Birbal-7B-V1",
        "2958": "solarized-18B-dpo",
        "2959": "mistral-v2-7b-selfplay-v0",
        "2960": "Multilingual-mistral",
        "2961": "Paradigm_Shift_7B",
        "2962": "Cerebrum-1.0-7b",
        "2963": "CodeMate-v0.1",
        "2964": "mistral-7b-metamathqa-sft",
        "2965": "A-I-0xtom-7B-slerp",
        "2966": "Mistroll-7B-v0.2-16bit",
        "2967": "Hyperion-2.1-Mistral-7B",
        "2968": "1701221123_Ads_Mistral7B-slimorca_all-Lqv-r4b128",
        "2969": "Phi-3-mini-4k-instruct-Cinder-llamafied-with-16bit-GGUF",
        "2970": "mistral_2X7b",
        "2971": "Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v2",
        "2972": "DarkSapling-7B-v1.0",
        "2973": "Mistral-7B-math-ia3-pruned10",
        "2974": "Mistral-7B-Instruct-v0.2-sparsity-20-v0.1",
        "2975": "Mistral-7B-Instruct-v0.2-sp-v0",
        "2976": "Mistral-7B-Instruct-v2-sp-v0.1",
        "2977": "Synthia-7B-v3.0",
        "2978": "Mistral-7b-instruct-v0.2-summ-dpo-e1",
        "2979": "mistral-orpo-mix-21k",
        "2980": "zephyr-7b-ipo-qlora-v0",
        "2981": "pearl7B_tuneonGSM8K",
        "2982": "Neural-grok-dolphin-Mistral-7B",
        "2983": "mistral_rank16_dpo",
        "2984": "openbuddy-gemma-7b-v18.1-4k",
        "2985": "SlimOrca-13B",
        "2986": "Mistroll-7B-v0.3-16bit",
        "2987": "Mistral-grok-instract-2-7B-slerp",
        "2988": "Meta-Llama-3-8Bee",
        "2989": "Lucie-7B-v0.2-16bit",
        "2990": "ValidateAI-3-33B-Ties",
        "2991": "0ai-7B-v3",
        "2992": "Tanuki-7B-v0.1",
        "2993": "experiment2-non-cause-v1",
        "2994": "mistral-orpo-beta",
        "2995": "VerA-Etheria-55b",
        "2996": "llmdo-Mistral-7B-case-c-v1",
        "2997": "Everyone-Coder-33b-Base",
        "2998": "MultiverseBuddy-15B-MoE",
        "2999": "Mistral-7B-Instruct-v0.2-attention-sparsity-20",
        "3000": "mistral-v2-7b-selfplay-v0-test",
        "3001": "Chop-7b",
        "3002": "Mistral-7b-instruct-v0.2-summ-dpo-e3",
        "3003": "DolphinLake-7B",
        "3004": "dolphin-2.6-mistral-7b-dpo-orca-v2",
        "3005": "Wistral-7B-Instruct-v0.3",
        "3006": "Mistral-7B-private-spnf",
        "3007": "Mistral-v2-orpo",
        "3008": "Lucie-7b-3e-5",
        "3009": "llmdo-Mistral-7B-case-6",
        "3010": "Lucie-7b",
        "3011": "Mistral-7B-ReMax-v0.1",
        "3012": "Wistral-7B-Instruct-v0.4",
        "3013": "Swahili-Alpaca-Llama-3-8b_16bit",
        "3014": "mistral-v2-7b-selfplay-low-tmp",
        "3015": "Mistral-7b-instruct-v0.2-summ-sft-e2m",
        "3016": "mistral_9B_instruct_v0.2",
        "3017": "alooowso",
        "3018": "ExperimentOne",
        "3019": "Mistroll-7B-v0.1-16bit",
        "3020": "InnerI-AI-sn6-7B-slerp",
        "3021": "openchat-mistral-7b-reproduce",
        "3022": "Qwen-14B-Chat-LLaMAfied",
        "3023": "Synatra-RP-Orca-2-7b-v0.1",
        "3024": "StellarBright",
        "3025": "Mistral-7b-instruct-v0.2-summ-sft-bf16-e2",
        "3026": "model_009",
        "3027": "CCK-v2.0-DPO",
        "3028": "g8s-preview",
        "3029": "Mistral-7B-Instruct-v0.2-attention-sparsity-30",
        "3030": "OpenCerebrum-1.0-7b-SFT",
        "3031": "Mistral-7B-Instruct-v0.2-2x7B-MoE",
        "3032": "Mistral-7B-Instruct-v0.2-sparsity-30-v0.1",
        "3033": "Mistral-Instruct-Ukrainian-SFT",
        "3034": "Llama-3-8B-4bit-UltraChat-Ita",
        "3035": "openbuddy-gemma-7b-v19.1-4k",
        "3036": "XwinCoder-34B",
        "3037": "Metis-0.3",
        "3038": "Mistral-7b-instruct-v0.2-summ-sft-dpo-e3",
        "3039": "LLaMA_2_13B_SFT_v1",
        "3040": "Mistral-7B-summ-ia3-pruned10",
        "3041": "COKAL-v1-70B",
        "3042": "Cucumber-7b-10k",
        "3043": "speechless-mistral-hermes-code-7b",
        "3044": "llmdo-Mistral-7B-case-7",
        "3045": "Damysus-Coder-v0.1",
        "3046": "Orca2-13B-selfmerge-26B",
        "3047": "Mistral-7b-instruct-v0.2-summ-sft-bf16-e3",
        "3048": "Orca2-13B-selfmerge-39B",
        "3049": "Mistral-7B-summ-lora-tuned-8h",
        "3050": "Wukong-0.1-Mistral-7B-v0.2",
        "3051": "Mistral-7b-instruct-v0.2-summ-sft-bf16-e1",
        "3052": "llama3-8B-slerp-med-chinese",
        "3053": "PiVoT-MoE",
        "3054": "Bepis_9B",
        "3055": "Mistral-7B-Instruct-Aya-101",
        "3056": "llmdo-Mistral-7B-case-1",
        "3057": "mistral_rank16_packing",
        "3058": "Mistral-7B-v0.1-gpt-4-40k",
        "3059": "Mistral-7B-v0.1-Open-Platypus_2.5w-r16-gate_up_down",
        "3060": "ValidateAI-2-33B-AT",
        "3061": "r-zephyr-7b-beta-qlora",
        "3062": "Soulful_Bepis_7B",
        "3063": "mistral_rank8_packing",
        "3064": "Mistral-7b-instruct-v0.2-summ-dpo-e2",
        "3065": "Medusa2-Mistral-7B-Instruct-v0.2",
        "3066": "OpenCerebrum-2.0-7B",
        "3067": "cymist-2-v02-SFT",
        "3068": "experiment2-cause-v1",
        "3069": "test_merged_model",
        "3070": "Orca-2-13b-f16",
        "3071": "MiniCPM-2B-Base",
        "3072": "Mistral-7B-Instruct-v0.2-attention-sparsity-10-v0.1",
        "3073": "mistral_rank8_dpo",
        "3074": "Cerebrum-RP",
        "3075": "Instruct_Llama3_8B",
        "3076": "MiniCPM-2B-Base-v3",
        "3077": "Mistral-7B-Instruct-v0.2-gpt-4-80k",
        "3078": "test-case-2",
        "3079": "stablelm-2-1_6b-chat",
        "3080": "Mistral-portuguese-luana-7b",
        "3081": "Mistral-7B-summ-lora-tuned",
        "3082": "Mistral-7B-Instruct-v0.2-sparsity-10",
        "3083": "smartyplats-7b-v2",
        "3084": "Mistral-7B-summ-ia3-pruned20",
        "3085": "Mistral-Ita-7b",
        "3086": "Mistral-NeuralDPO",
        "3087": "Mistral_7B_dare_ties_merge_instruct_open_orca",
        "3088": "Panda-7B-v0.1",
        "3089": "mistral-experiment-6-merge",
        "3090": "mistral_rank32_dpo",
        "3091": "gemma-2b-sft-preview",
        "3092": "mistral-7b-tak-stack-dpo",
        "3093": "mistral_15B_instruct_v0.1",
        "3094": "llmdo-Mistral-7B-case-5",
        "3095": "Smaug-2-72B",
        "3096": "Half-NSFW_Noromaid-7b",
        "3097": "mistral_28B_instruct_v0.2",
        "3098": "SHRDFU-7b-overbaked-lora",
        "3099": "33x-coder",
        "3100": "Dolph-Lund-Wizard-7B",
        "3101": "Frostwind-v2.1-m7",
        "3102": "mistral_7b_norobots",
        "3103": "Kaiju-A-57B",
        "3104": "Mistral-7B-Instruct-v0.2-Neural-Story",
        "3105": "Orca-2-13b-Alpaca-Uncensored",
        "3106": "buddhi-128k-chat-7b",
        "3107": "TheSpice-7b-FT-ExperimentalOrca",
        "3108": "Mistral-portuguese-luana-7b-chat",
        "3109": "Matter-0.1-Slim-7B-A",
        "3110": "Mistral-7B-OpenOrca-lora-merged",
        "3111": "Matter-0.1-Slim-7B",
        "3112": "mistral-7b-cogeo",
        "3113": "mistral_18B_v0.1",
        "3114": "zephyr-orpo-7b-v0.2",
        "3115": "mistral_28B_instruct_v0.1",
        "3116": "llamion-14b-base",
        "3117": "CodeLlama-34b-Instruct-hf",
        "3118": "llama-3-chinese-8b",
        "3119": "lion-llama3-8b",
        "3120": "new_model_test",
        "3121": "MistralBeagle-RS-7B-V0.1",
        "3122": "Mistral-7B-v0.1-activity-fine-tuned-v2",
        "3123": "Mistral-7B-v0.1-activity-fine-tuned-v5",
        "3124": "Mistral-7B-v0.1-activity-fine-tuned-v3",
        "3125": "Llama2_init_Mistral",
        "3126": "Orca-2-13b",
        "3127": "mistral_dmbr10_32_sig",
        "3128": "solar-10b-platypus-lora",
        "3129": "Mistral-7b-instruct-v0.2-summ-sft-e1",
        "3130": "tigerbot-70b-base",
        "3131": "neuronovo-7B-v0.1",
        "3132": "speechless-mistral-moloras-7b",
        "3133": "travel-mistral-7B-16b-base",
        "3134": "Mistral-7B-LoreWeaver",
        "3135": "Power-Llama-3-13b-Instruct",
        "3136": "OpenHermes-Gemma-7B",
        "3137": "Mistral-7B-v0.1-gpt-4-60k",
        "3138": "Winterreise-m7",
        "3139": "bigdoc-c34b-instruct-tf32",
        "3140": "Mistral-Instruct-7B-v0.2-ChatAlpaca",
        "3141": "mistral_dmbr20_32_sig",
        "3142": "Mistral-7b-instruct-v0.2-summ-sft-lp-e1",
        "3143": "uniwiz-7B-v0.2",
        "3144": "Neural-Mistral-7B",
        "3145": "mistral_kmmbr_32_sig",
        "3146": "16b-experiment-llama",
        "3147": "Mistral-7B-Alpaca-52k-v0.1",
        "3148": "rainbowfish-v7",
        "3149": "Mistral-7b-instruct-v0.2-summ-sft-e3",
        "3150": "Mistral-7b-instruct-v0.2-summ-sft-e2",
        "3151": "Thespis-CurtainCall-7b-v0.3",
        "3152": "Mixtral-Orca-v0.1",
        "3153": "uniwiz-7B-v0.1",
        "3154": "Dans-07YahooAnswers-7b",
        "3155": "CodeBooga-34B-v0.1",
        "3156": "Merak-7B-v5-PROTOTYPE1",
        "3157": "Erosumika-7B",
        "3158": "llama-65b",
        "3159": "model_007",
        "3160": "zephy_SFT_Hermes",
        "3161": "mistral-inst-ppo",
        "3162": "Mistral-7B-v0.1",
        "3163": "OpenAGI-testing-truthyDPO-1",
        "3164": "llama3-slerp-med",
        "3165": "rainbowfish-7B-v10",
        "3166": "MFANNv0.2",
        "3167": "Mistral-Instruct-7B-v0.2-ChatAlpaca-DPO2",
        "3168": "Mistral-NeuralDPO-v0.6",
        "3169": "ExperimentTwo",
        "3170": "Mistral-NeuralDPO-v0.4",
        "3171": "Mistral-7B-v0.1-half-naive-A",
        "3172": "mistralai-case-2-0",
        "3173": "mistral_nucleus09_32_sig",
        "3174": "mistralai-case-0-0",
        "3175": "Noromaid-7b-v0.1.1",
        "3176": "cosmosage_v2",
        "3177": "mistralai-case-1-0",
        "3178": "mistral_rank8_invert",
        "3179": "mistral-orpo-capybara-3k",
        "3180": "openbuddy-falcon-40b-v16.1-4k",
        "3181": "SlimOrca-Llama-3-8B",
        "3182": "Mistral-NeuralDPO-v0.2",
        "3183": "mistral-7b-jondurbin-truthy-dpo",
        "3184": "llamion-14b-chat",
        "3185": "test0",
        "3186": "Noromaid-7b-v0.2",
        "3187": "mistral-7b-ft-h4-no_robots_instructions",
        "3188": "Kaori-34B-v1",
        "3189": "Mistral-7B-v0.1-gpt-4-20k",
        "3190": "Mistral-7B-summ-ia3-tuned-8h",
        "3191": "Fett-uccine-7B",
        "3192": "SOLAR-10.7B-Instruct-DPO-v1.0",
        "3193": "Mistral-NeuralDPO-v0.5",
        "3194": "Mistral-NeuralDPO-v0.4-Laser",
        "3195": "vortex2",
        "3196": "rocket-3B",
        "3197": "OpenCerebrum-1.5-Mistral-7b-v0.2-alpha",
        "3198": "mistral-7b-sft-beta",
        "3199": "BigWeave-v20-110b",
        "3200": "EEVE-Korean-2.8B-v1.0",
        "3201": "test-ties",
        "3202": "Mistral-10.7B-Instruct-v0.3-depth-upscaling",
        "3203": "kalomaze-stuff",
        "3204": "rainbowfish-v6",
        "3205": "Mistral-7B-v0.1-gpt-4-80k",
        "3206": "zephyr-7b-sft-full-SPIN-iter0",
        "3207": "Novocode7b-v3",
        "3208": "kaori-34b-v3",
        "3209": "Snorkel-Mistral-PairRM-DPO",
        "3210": "Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v3",
        "3211": "Aeryth-7B-v0.1",
        "3212": "J.O.S.I.E.3-Beta8-slerp",
        "3213": "HelpingAI-3B",
        "3214": "Mistral-7B-v0.1-raw-80k",
        "3215": "DistilabelBeagle14-7B",
        "3216": "fine-tune-mistral-long-merge",
        "3217": "mistral-7b-distilabel-truthy-dpo",
        "3218": "mistral-7b-alpaca-sft",
        "3219": "Venomia-1.1-m7",
        "3220": "mistral_mbr_32_sig",
        "3221": "winter-garden-7b-delta",
        "3222": "Einstein-7B",
        "3223": "finetuned-Mistral-7B-Instruct-v0.2-5000-v2.0",
        "3224": "Yi-6B-Infinity-Chat",
        "3225": "Thespis-7b-v0.2-SFTTest-3Epoch",
        "3226": "Mistral-7B-v0.2-meditron-turkish",
        "3227": "Mistral-7B-v0.1-signtensors-1-over-2",
        "3228": "mistral-7b-openhermes-2.5-sft",
        "3229": "StableBeluga2",
        "3230": "NSFW_DPO_Noromaid-7b",
        "3231": "CollectiveCognition-v1.1-Mistral-7B",
        "3232": "llmdo-Mistral-7B-case-c",
        "3233": "shisa-base-7b-v1",
        "3234": "pippafeet-11B-0.1",
        "3235": "correction_1",
        "3236": "mistral-7b-dolphin-sft",
        "3237": "Mistral_7B_ties_merge_instruct_open_orca",
        "3238": "Qwen2-0.5B",
        "3239": "test-case-5",
        "3240": "speechless-code-mistral-7b-v2.0",
        "3241": "mistral-7B-forest-v0.1",
        "3242": "72B-preview-canary-llamafied-qwen-llamafy-unbias-qkv",
        "3243": "test-merge-2",
        "3244": "DolphinStar-12.5B",
        "3245": "LLaMA_2_13B_SFT_v1.5",
        "3246": "mistral_rank16_invert",
        "3247": "stablelm-2-zephyr-1_6b",
        "3248": "mistral_dmbr03_32_sig",
        "3249": "lemur-70b-chat-v1",
        "3250": "ANIMA-biodesign-7B-slerp",
        "3251": "Synthia-70B-v1.2b",
        "3252": "v1olet_merged_dpo_7B_v4",
        "3253": "fine-tune-mistral-environment-merge",
        "3254": "tora-70b-v1.0",
        "3255": "bun_mistral_7b_v2",
        "3256": "han-llm-7b-v3",
        "3257": "speechless-thoughts-mistral-7b-v1.0",
        "3258": "Etheria-55b-v0.1",
        "3259": "Starling-LM-11B-alpha",
        "3260": "mistral_rank32_invert",
        "3261": "Tiger-7B-v0.1-LaserRMT-Math-5-10-15-Neural-DPO",
        "3262": "mistral_rank16_sft",
        "3263": "EXPERIMENT-DPO-m7b2-2-merged",
        "3264": "mistral-sharegpt90k-merged_16bit",
        "3265": "Yarn-Mistral-7b-64k-Mistral-7B-Instruct-v0.1",
        "3266": "zephyr-7b-gpo-update3-i0",
        "3267": "Instruct_Mistral-7B-v0.1_Dolly15K",
        "3268": "TaliML-7B-V.1-ENG",
        "3269": "AthenaImaniMaven",
        "3270": "experiment2-cause-qLoRa",
        "3271": "experiment2-cause",
        "3272": "Mini_DPO_test02",
        "3273": "Mistral-7B-v0.3",
        "3274": "BigOrca-2-XB",
        "3275": "DPO_mistral_7b_ultra_0129_1k",
        "3276": "mistral_rank32_sft",
        "3277": "sqlcoder-34b-alpha",
        "3278": "Yi-34B-200K",
        "3279": "mistral-7B-alpaca-case-3-2",
        "3280": "Mistral-NeuralDPO-v0.3",
        "3281": "mistral-7B-alpaca-1-epoch",
        "3282": "rainbowfish-7B-v9",
        "3283": "Yee-34B-200K-Chat",
        "3284": "Mistral-7B-Instruct-v0.2",
        "3285": "OpenMia-Indo-Mistral-7b-v2",
        "3286": "EXPERIMENT-DPO-m7b2-1-merged",
        "3287": "mistral-7b-v0.2",
        "3288": "Mistral-7B-v0.2-hf-duplicate",
        "3289": "SatoshiNv5",
        "3290": "Mistral-7B-v0.2",
        "3291": "Lima_Unchained_70b",
        "3292": "model_42_70b",
        "3293": "SharpBalance",
        "3294": "mistralai-case-0-1",
        "3295": "alpaca_mistral-7b-v0.2",
        "3296": "OpenMia-Indo-Mistral-7b",
        "3297": "notus-7b-v1",
        "3298": "higgs-llama-vicuna-ep25-70b",
        "3299": "openbuddy-llama2-34b-v11.1-bf16",
        "3300": "openbuddy-codellama2-34b-v11.1-bf16",
        "3301": "Camelidae-8x13B",
        "3302": "lynn-7b-alpha",
        "3303": "fiction.live-Kimiko-V2-70B-fp16",
        "3304": "EXPERIMENT-SFT-m7b2-2-merged",
        "3305": "EXPERIMENT-SFT-m7b2-3-merged",
        "3306": "EXPERIMENT-ORPO-m7b2-1-merged",
        "3307": "Jennifer-v1.0",
        "3308": "openchat-3.5-0106-11b",
        "3309": "Aethora-7b-v1",
        "3310": "WizardLM-30B-GPTQ",
        "3311": "llama-3-youko-8b",
        "3312": "EXPERIMENT-ORPO-m7b2-2-merged",
        "3313": "zephyr-7b-dpo-qlora-v1",
        "3314": "mistral-7b-grok",
        "3315": "test-case-0",
        "3316": "falcon-40b-instruct",
        "3317": "llama3-passthrough-chat",
        "3318": "CodeLlama-34b-hf",
        "3319": "zephyr-7b-sft-qlora",
        "3320": "Nous-Puffin-70B",
        "3321": "AISquare-Instruct-SOLAR-10.7b-v0.5.31",
        "3322": "Mistral_Pro_8B_v0.1",
        "3323": "mistral_dmbr05_32_sig",
        "3324": "0.0_ablation_sample1_4iters_bs256_iter_1",
        "3325": "mistralai-case-1-1",
        "3326": "BTAgent-v0.1",
        "3327": "test_final",
        "3328": "zephyr-7b-sft-full-SPIN-iter3",
        "3329": "Euryale-1.3-L2-70B",
        "3330": "Spicy-Laymonade-7B",
        "3331": "TruthfulQwen1.5-1.8B",
        "3332": "Mistral-7B-Finetuning-Insurance-16R",
        "3333": "ShiningValiantXS",
        "3334": "internlm2-chat-20b-llama-old",
        "3335": "speechless-llama2-13b",
        "3336": "Synch-Qwen1.5-1.8B",
        "3337": "Llama-2-70B-fp16",
        "3338": "0.001_zephyr_5551_4iters_bs256_iter_1",
        "3339": "internlm2-chat-20b-llama",
        "3340": "Mega-Destroyer-8x7B",
        "3341": "apricot-wildflower-20",
        "3342": "L3-Solana-8B-v1",
        "3343": "Contextual_KTO_Mistral_PairRM",
        "3344": "ghost-7b-v0.9.0",
        "3345": "genz-70b",
        "3346": "WhiteRabbitNeo-33B-v1",
        "3347": "K2S3-SOLAR-11b-v3.0",
        "3348": "Mistral-7B-Holodeck-1",
        "3349": "Qwen1.5-1.8B",
        "3350": "Mistral-7B-summ-ia3-tuned",
        "3351": "openbuddy-zen-3b-v21.2-32k",
        "3352": "experiment2-cause-non",
        "3353": "Blitz-v0.2",
        "3354": "Llama-3-instruction-constructionsafety-layertuning",
        "3355": "experiment2-cause-non-qLoRa",
        "3356": "openbuddy-mistral-7b-v19.1-4k",
        "3357": "Mixtral_AI_SwahiliTron_7b",
        "3358": "han-llm-7b-v2",
        "3359": "Mistral-Plus-7B",
        "3360": "OpenHermes-2.5-Mistral-7B-new",
        "3361": "HelpSteer-filtered-7B",
        "3362": "open-aditi-hi-v1",
        "3363": "Sailor-7B",
        "3364": "Borealis-10.7B-DPO",
        "3365": "Iambe-20b-DARE-v2",
        "3366": "Yarn-Mistral-7b-64k",
        "3367": "Marcoroni-70B-v1",
        "3368": "llemma_7b",
        "3369": "fbt-mistral-7b",
        "3370": "Barcenas-Orca-2-7b",
        "3371": "test-case-6",
        "3372": "Metis-0.1",
        "3373": "Llamix2-Xwin-MoE-4x13B",
        "3374": "model_420_preview",
        "3375": "Mistralpaca-7B",
        "3376": "Medical-Mixtral-7B-v2k",
        "3377": "zephyr-7b-gpo-v6-i1",
        "3378": "Llama3-12b",
        "3379": "Ignis-7B-DPO",
        "3380": "Azzurro",
        "3381": "Dolphin-Nebula-7B",
        "3382": "Platypus2-70B",
        "3383": "zephyr-7b-sft-full-SPIN-iter2",
        "3384": "Influxient-4x13B",
        "3385": "aether-7b-chat-v1.0",
        "3386": "wendigo-14b-alpha4",
        "3387": "openchat-3.5-0106-128k",
        "3388": "B0122",
        "3389": "Senzu-7B-v0.1-DPO",
        "3390": "Kunocchini-1.2-7b-longtext",
        "3391": "Medchator-2x7b",
        "3392": "0.001_idpo_iter_3",
        "3393": "mistral-7B-forest",
        "3394": "test-test",
        "3395": "Llama-2-70b-oasst-1-200",
        "3396": "UltraLM-65b",
        "3397": "MiniChat-2-3B",
        "3398": "Yarn-Mistral-7b-128k",
        "3399": "llamaduo_synth_ds_v0.1",
        "3400": "zephyr-python-ru-merged",
        "3401": "zephyr-python-ru",
        "3402": "Aurora_base_test",
        "3403": "rezephyr-dpo",
        "3404": "mistral_rank8_sft",
        "3405": "Mistral-7B-AEZAKMI-v2",
        "3406": "mistral-sft-v3",
        "3407": "code-millenials-34b",
        "3408": "MistralQ-7B-slerp",
        "3409": "model_51",
        "3410": "Venomia-m7",
        "3411": "CodeLlama-34b-Python-hf",
        "3412": "mistral-7b-slimorca-sft",
        "3413": "mythospice-limarp-70b",
        "3414": "0.001_idpo_iter_2",
        "3415": "Kesehatan-7B-v0.1",
        "3416": "Llama-2-70b-instruct-1024",
        "3417": "ccy0-2g7e-wqsa-0",
        "3418": "freeze_KoSoLAR-10.7B-v0.2_1.4_dedup",
        "3419": "Mistral-quiet-star",
        "3420": "Llama-2-70b-instruct",
        "3421": "wendigo-14b-alpha3",
        "3422": "Yarn-Mistral-7b-128k-DPO",
        "3423": "Indic-gemma-7b-finetuned-sft-Navarasa-2.0",
        "3424": "SOLAR-19.2B-Instruct-v1.0",
        "3425": "medllama-2-70b-qlora-1.1",
        "3426": "test-case-1",
        "3427": "mistral-indo-7b",
        "3428": "Mistral-12.25B-v0.2",
        "3429": "Platapus-Orca-13B",
        "3430": "Yi-34B-Chat",
        "3431": "Synthia-70B-v1.2",
        "3432": "Synthia-70B-v1.1",
        "3433": "blossom-v5-mistral-7b",
        "3434": "LLaMA-2-Jannie-70B-QLoRA",
        "3435": "han-llm-7b-v1",
        "3436": "gemma-7B-it-firefly",
        "3437": "0.001_idpo_noreplacerej_iter_3",
        "3438": "Nebula-v2-7B",
        "3439": "ICE-GRT",
        "3440": "prometheus-13b-v1.0",
        "3441": "zephyr-7b-gpo-v5-i1",
        "3442": "NearalMistral-2x7B",
        "3443": "openbuddy-llama-30b-v7.1-bf16",
        "3444": "typhoon-7b",
        "3445": "Samantha-1.1-70b",
        "3446": "mistralai-case-2-1",
        "3447": "zephyr-7b-lgpo-v1-i1",
        "3448": "Llama-2-13b-chat-hf-activity-fine-tuned-v4",
        "3449": "Dr_Samantha_7b_mistral",
        "3450": "Ignis-7B-DPO-Laser",
        "3451": "oasst-rlhf-2-llama-30b-7k-steps-hf",
        "3452": "Synthia-70B",
        "3453": "nanit_v2",
        "3454": "mistral-7b-v0.1-layla-v2",
        "3455": "Reyna-Mini-1.8B-v0.2",
        "3456": "mistral-7b-selfplay-v0",
        "3457": "Llama-3-8B-Instruct-MopeyMule",
        "3458": "mistral-7b-openhermes-sft",
        "3459": "MiniCPM-3B-OpenHermes-2.5-v2",
        "3460": "Kant-Test-0.1-Mistral-7B",
        "3461": "Llama-3-5B-Sheard",
        "3462": "ConvAI-9b-v2",
        "3463": "mistral-7B-finetune-health-fitness",
        "3464": "artmindia3k",
        "3465": "Blur-7b-v1.22",
        "3466": "finetuned-Mistral-5000-v1.0",
        "3467": "mistral-instruct-moe-experimental",
        "3468": "firefly-zephyr-6x7b-lora",
        "3469": "Alpha-Mistral-7B-Instruct",
        "3470": "firefly-zephyr-6x7b",
        "3471": "lzlv_70b_fp16_hf",
        "3472": "Mistral-7B-Discord-0.2",
        "3473": "openhermes-phi-1_5-sft-qlora",
        "3474": "alignment-handbook-zephyr-7b_ppo_5e7step_51",
        "3475": "zephyr-7b-sft-full-spin-iter1",
        "3476": "AIRIC-The-Mistral",
        "3477": "Platypus_QLoRA_LLaMA_70b",
        "3478": "MadMix-v0.2",
        "3479": "m_b_4_32",
        "3480": "speechless-thoughts-mistral-7b",
        "3481": "mistral-instruct-slerp",
        "3482": "test-case-3",
        "3483": "CantoneseLLM-6B-preview202402",
        "3484": "phi-2-basic-maths",
        "3485": "SG-Raccoon-Yi-200k-2.0",
        "3486": "YugoGPT",
        "3487": "BioMistral-MedicalQA-FT",
        "3488": "Qwen1.5-14B-Chat",
        "3489": "Llama-3-8B-Instruct-MergeSLERP-Gradient1048kIO-OpenBioLLM",
        "3490": "Llama-3-8B-Instruct-MergeSLERP-Gradient1048k-OpenBioLLM",
        "3491": "MelangeB-70b",
        "3492": "Hercules-Mini-1.8B",
        "3493": "LLaMA-2-Wizard-70B-QLoRA",
        "3494": "GPT4-X-Alpasta-30b",
        "3495": "oasst-sft-6-llama-33b-xor-MERGED-16bit",
        "3496": "Sailor-7B-Chat",
        "3497": "Kyllene-v1.0",
        "3498": "Psyfighter2-Noromaid-ties-Capybara-13B",
        "3499": "Mistral-7B-Discord-0.1-DPO",
        "3500": "Hebrew-Mistral-7B",
        "3501": "openbuddy-llama2-13b-v8.1-fp16",
        "3502": "Yi-6B-200K",
        "3503": "alignment-handbook-zephyr-7b_ppo_5e7step_102",
        "3504": "mistral-7B-forest-dpo",
        "3505": "0.001_idpo_noreplacerej_iter_2",
        "3506": "Qwen1.5-1.8B_llamafy",
        "3507": "zephyr-dpo-v2",
        "3508": "0.001_idpo_declr_iter_2",
        "3509": "llama2_70b_chat_uncensored",
        "3510": "tau-1.8B",
        "3511": "fbt-gemma-7b",
        "3512": "Karen_TheEditor_V2_STRICT_Mistral_7B",
        "3513": "Qwen1.5-110B-Chat",
        "3514": "alignment-handbook-zephyr-7b-sft-full-dpo-5e7-cont2",
        "3515": "MelloGPT",
        "3516": "GPT4-x-AlpacaDente-30b",
        "3517": "mythospice-70b",
        "3518": "WikiHow-Mistral-Instruct-7B",
        "3519": "open-aditi-hi-v2",
        "3520": "zephyr-7b-dpo-full-beta-0.2",
        "3521": "solar-merge-v1.0",
        "3522": "LaterLlamaV2",
        "3523": "Bielik-7B-Instruct-v0.1",
        "3524": "Samantha-1.11-70b",
        "3525": "m_b_8_32",
        "3526": "test-spin-lora-iter0",
        "3527": "DPO_mistral_v01_7b_ultra_0131_1k_1epoch",
        "3528": "Hercules-1.0-Mistral-7B",
        "3529": "gemma-7b-openhermes",
        "3530": "OpenAssistant-SFT-7-Llama-30B-HF",
        "3531": "llama-2-70b-Guanaco-QLoRA-fp16",
        "3532": "h2o-danube2-1.8b-base",
        "3533": "k2s3_test_24001",
        "3534": "qCammel-70x",
        "3535": "qCammel-70",
        "3536": "qCammel-70-x",
        "3537": "qCammel-70v1",
        "3538": "airoboros-34b-3.3",
        "3539": "qCammel70",
        "3540": "llama-2-new",
        "3541": "Unichat-llama3-Chinese-8B-28K",
        "3542": "13B-Psyfighter2-Erebus3-DareTies",
        "3543": "mistral_7b_HalfEpoch_DolphinCoder",
        "3544": "T-Llama",
        "3545": "iDUS-8layers",
        "3546": "Bielik-7B-v0.1",
        "3547": "orca_mini_v3_13B-GPTQ",
        "3548": "digital-socrates-13b",
        "3549": "7B_ppo_phiRM_2GPU_3e-7step_4000",
        "3550": "Mistral-7B-v0.1-flashback-v2",
        "3551": "Chimera-7B-TIES",
        "3552": "Qwen1.5-7B-Dutch-Chat-Sft",
        "3553": "electric-sheep-7b-alpha",
        "3554": "llama2-megamerge-dare-13b-v2",
        "3555": "Instruct_Yi-6B_Dolly15K",
        "3556": "gemma-7b-it-experiment",
        "3557": "gemma-7b-it",
        "3558": "Deacon-20B",
        "3559": "Open_Ko_SOLAR_DPO_Merge_v0.1",
        "3560": "llama-2-70b-fb16-korean",
        "3561": "GDC-Tiny-L1-1.8B",
        "3562": "Alpaca-elina-65b",
        "3563": "alignment-handbook-zephyr-7b-sft-full-dpo-5e7-cont1",
        "3564": "zephyr_0.1",
        "3565": "IA_14B",
        "3566": "ZySec-7B",
        "3567": "ruadapt_mistral7b_full_vo_1e4",
        "3568": "Orca-2.0-Tau-1.8B",
        "3569": "synapsellm-7b-mistral-v0.3-preview",
        "3570": "llama2-70B-qlora-gpt4",
        "3571": "Mistral-7B-Instruct-v0.2-gpt-4-80k-base_lora",
        "3572": "Mixtral_AI_MasterTron",
        "3573": "zephyr-7b-sft-full-spin-peft-iter1",
        "3574": "ARIA-70B-V2",
        "3575": "0.001_idpo_iter_1",
        "3576": "VerB-Etheria-55b",
        "3577": "h2o-danube2-1.8b-chat",
        "3578": "grendel",
        "3579": "zephyr-7b-sft-full",
        "3580": "lion-gemma-7b-cn-v2",
        "3581": "Supernova-experimental",
        "3582": "lemur-70b-v1",
        "3583": "TIGERScore-13B",
        "3584": "llama-2-70b-IA3-guanaco",
        "3585": "chronos-70b-v2",
        "3586": "model_007_v2",
        "3587": "test-spin-lora-iter1",
        "3588": "jackalope-7b",
        "3589": "DiamondForce",
        "3590": "zephyr-danube2-sft-qlora",
        "3591": "model_420",
        "3592": "llama-megamerge-dare-13b",
        "3593": "zephyr-7b-sft-full-spin-peft-iter2",
        "3594": "mistral_11B_instruct_v0.1",
        "3595": "test-spin-lora-iter2",
        "3596": "MetaMath-13B-V1.0",
        "3597": "Mika-7B",
        "3598": "0.001_idpo_declr_iter_3",
        "3599": "mistral-7b-orpo-capybara-reproduction",
        "3600": "fietje-2b",
        "3601": "Instruct_Yi-6B_Dolly_CodeAlpaca",
        "3602": "ORCA_LLaMA_70B_QLoRA",
        "3603": "dragonwar-7b-s1",
        "3604": "Midnight-Rose-70B-v2.0.3",
        "3605": "zephyr_0.2",
        "3606": "Falkor-16b",
        "3607": "zephyr-7b-alpha-ExPO",
        "3608": "claude2-alpaca-13B",
        "3609": "Orca-2-13b-SFT-v4",
        "3610": "zephyr-7b-sft-full-spin-peft-iter0",
        "3611": "gpt4-alpaca-lora_mlp-65B-HF",
        "3612": "0.001_idpo_declr_4iters_iter_3",
        "3613": "Qwen1.5-MoE-A2.7B-Chat",
        "3614": "yuren-13b-chatml",
        "3615": "Athena-zephyr-7B",
        "3616": "Einstein-bagel-7B",
        "3617": "FashionGPT-70B-V1",
        "3618": "ARIA-70B-V3",
        "3619": "alpaca-lora-65B-HF",
        "3620": "ZySec-8B-v2",
        "3621": "ZySec-7B-v2",
        "3622": "lion-gemma-7b-cn",
        "3623": "SHRDFU-7b-beta",
        "3624": "CodeQwen1.5-7B-Chat",
        "3625": "0.001_idpo_declr_4iters_iter_2",
        "3626": "VicUnlocked-alpaca-65B-QLoRA-fp16",
        "3627": "robin-33B-v2-GPTQ",
        "3628": "gov-qna-ko-merged",
        "3629": "Lorge-2x7B-UAMM",
        "3630": "mixtral-ko-qna-merged",
        "3631": "google-gemma-7b-it-dpo-v1",
        "3632": "synapsellm-7b-mistral-v0.5-preview2",
        "3633": "Aura-Llama-Abliterated",
        "3634": "zephyr-phi-1_5-sft-qlora",
        "3635": "3BigReasonCinder",
        "3636": "quan-1.8b-chat",
        "3637": "ssh_1.8B",
        "3638": "TimeCrystal-l2-13B",
        "3639": "dromedary-65b-lora-HF",
        "3640": "Quyen-Mini-v0.1",
        "3641": "Qwen1.5-7B-Dutch-Chat-Dpo",
        "3642": "Coder1.8-ORPO-TEST",
        "3643": "chaifighter-20B",
        "3644": "Mistral-7B-Instruct-v0.1-gpt-4-80k",
        "3645": "0.001_idpo_declr_4iters_iter_4",
        "3646": "llama-2-70b-dolphin-peft",
        "3647": "Mistral-10.7B-v0.2",
        "3648": "WizardLM-Math-70B-TIES-v0.1",
        "3649": "zephyr-7b-beta-ExPO",
        "3650": "ELYZA-japanese-Llama-2-13b",
        "3651": "Orca-2-13B-no_robots",
        "3652": "Psyfighter2-Noromaid-ties-13B",
        "3653": "Xwin-LM-70B-V0.1",
        "3654": "test_model",
        "3655": "llama2-70b-oasst-sft-v10",
        "3656": "EMO-1B",
        "3657": "FsfairX-Zephyr-Chat-v0.1",
        "3658": "llama3-8B-slerp-med-262k",
        "3659": "ReMask-3B",
        "3660": "NeuralReyna-Mini-1.8B-v0.2",
        "3661": "zephyr-7b-beta",
        "3662": "Nxcode-CQ-7B-orpo",
        "3663": "robin-65b-v2-fp16",
        "3664": "SOLAR-DUS-implement",
        "3665": "Pwen-14B-Chat-20_30",
        "3666": "Mistral-22B-v0.2",
        "3667": "ghost-7b-v0.9.1",
        "3668": "Yi-6B-200K-AEZAKMI-v2-rawrr1-DPO",
        "3669": "llama-2-70b-fb16-orca-chat-10k",
        "3670": "mistral-7B-alpaca-case-2-2",
        "3671": "rizla55b",
        "3672": "deepseek-coder-6.7b-instruct",
        "3673": "Mistral-7b-FFT-Test3",
        "3674": "zephyr-7b-beta-MultiLoRA-mmlu-merged",
        "3675": "GPT4-x-AlpacaDente2-30b",
        "3676": "SauerkrautLM-Gemma-2b",
        "3677": "zephyr-7b-beta-gpt-4-80k",
        "3678": "alpaca-lora-65b-en-pt-es-ca",
        "3679": "Mistral-11B-v0.1",
        "3680": "Llama-2-70b-chat-hf",
        "3681": "ARIA-70B-French",
        "3682": "OLMo-1.7-7B-hf",
        "3683": "airoboros-65b-gpt4-1.2",
        "3684": "safe-spin-iter1-v2",
        "3685": "Euryale-L2-70B",
        "3686": "bigstral-12b-32k",
        "3687": "tulu-2-dpo-7b-ExPO",
        "3688": "A0118",
        "3689": "Maverick-v2.0",
        "3690": "solarized-13B-dpo",
        "3691": "BioLing-7B-Dare",
        "3692": "DPO_mistral_v01_7b_ultra_0130_1k",
        "3693": "DeepCode-7B-Aurora-v3",
        "3694": "lion-gemma-2b",
        "3695": "Hypernova-experimental",
        "3696": "llama-65b-instruct",
        "3697": "mistral_7b_DolphinCoder",
        "3698": "MedMerge-6-7b-alpha-dpo",
        "3699": "Giraffe-13b-32k-v3",
        "3700": "Qwen1.5-Wukong-1.8B",
        "3701": "OpenHermes-2.5-Mistral-7B",
        "3702": "UltraLM-13b-v2.0",
        "3703": "Zhongjing-LLaMA-base",
        "3704": "guanaco-65B-HF",
        "3705": "lion-zephyr-7b",
        "3706": "MT7Bi-alpha-dpo-v0.2",
        "3707": "BrokenKeyboardMerge",
        "3708": "Awanllm-Llama-3-8B-Instruct-DPO-v0.2",
        "3709": "DPO_mistral_7b_alpaca_0124_v1",
        "3710": "vicuna-class-shishya-all-hal-13b-ep3",
        "3711": "openchat_3.5",
        "3712": "Fett-uccine-11B-Experiment",
        "3713": "Fireplace-13b",
        "3714": "MT7Bi-alpha-dpo",
        "3715": "Aika-7B",
        "3716": "synapsellm-7b-mistral-v0.4-preview2",
        "3717": "CantoneseLLMChat-preview20240326",
        "3718": "h2o-danube2-1.8b-sft",
        "3719": "Winged-Lagomorph-2x13B",
        "3720": "my-first-blend",
        "3721": "dolphin-2.6-mistral-7b-dpo-orca-v3",
        "3722": "Mistral-7B-Erebus-v3",
        "3723": "DPO_mistral_7b_ultra_0124_v1",
        "3724": "Noromaid-7B-0.4-DPO",
        "3725": "zephyr-7b-truthy",
        "3726": "ELYZA-japanese-Llama-2-13b-fast",
        "3727": "airoboros-l2-70b-gpt4-m2.0",
        "3728": "Maverick-v1.0",
        "3729": "Chupacabra-16B-v2.01",
        "3730": "EXPERIMENT-SFT-m7b2-1-merged",
        "3731": "SwahiliInstruct-v0.1",
        "3732": "Mistral-7B-Merge-14-v0.3-ft-step-9984",
        "3733": "Yi-6B-200K-AEZAKMI-v2",
        "3734": "starcoder2-7b",
        "3735": "Mistral-NeuralDPO-v0.7",
        "3736": "chinese-alpaca-2-13b",
        "3737": "datascience-coder-6.7b",
        "3738": "Nusantara-7b-Indo-Chat",
        "3739": "Power-WizardLM-2-13b",
        "3740": "DarkForest-20B-v1.2",
        "3741": "SynthIA-v1.3-Nebula-v2-7B",
        "3742": "Tess-7B-v2.0",
        "3743": "Boundary-Coder-Yi-2x6B-MoE",
        "3744": "DeepCode-7B-Aurora-v2",
        "3745": "synapsellm-7b-mistral-v0.4-preview3",
        "3746": "speechless-codellama-34b-v1.9",
        "3747": "MysticFusion-13B",
        "3748": "airoboros-l2-70b-gpt4-2.0",
        "3749": "smol-3b",
        "3750": "ConvAI-9b",
        "3751": "gemma-7b-it-sa-v0.1",
        "3752": "llama-3-spicy-8B",
        "3753": "Tenebra_30B_Alpha01_FP16",
        "3754": "WizardLM-33B-V1.0-Uncensored-GPTQ",
        "3755": "30B-Epsilon",
        "3756": "CBDDO-LLM-8B-Instruct-v1",
        "3757": "lora_llama2-13b_10e5_r8_a16",
        "3758": "im-a-good-llama3-step-46k",
        "3759": "Neurona-2b",
        "3760": "Qwen-1_8B-Llamafied",
        "3761": "openbuddy-llama2-13b-v11.1-bf16",
        "3762": "FusionNet_passthrough",
        "3763": "Cerebrum-1.0-10.7B",
        "3764": "lora_llama2-13b_10e5_r2_a64",
        "3765": "MiniChat-1.5-3B",
        "3766": "koOpenChat-sft",
        "3767": "Pallas-0.5-frankenmerge",
        "3768": "MegaMix-A1-13B",
        "3769": "PlatYi-34B-200K-Q",
        "3770": "LexiLumin-20B",
        "3771": "Llama-3-6B-v0.1",
        "3772": "MegaMix-T1-13B",
        "3773": "FashionGPT-70B-V1.2",
        "3774": "StarDust_20B_v0.2",
        "3775": "xxxI-Ixxx",
        "3776": "Camel-Platypus2-70B",
        "3777": "0.001_idpo_same_noreplacerej_declr_iter_2",
        "3778": "zephyr-alpha-Nebula-v2-7B",
        "3779": "lora_llama2-13b_10e5_r128_a16",
        "3780": "mistral_7b_2EPOCH_DolphinCoder",
        "3781": "OpenHermes-Qwen1.5-1.8B",
        "3782": "Mewthree_7B",
        "3783": "wendigo-14b-alpha1",
        "3784": "ASTS-PFAF",
        "3785": "guanaco-33B-GPTQ",
        "3786": "Synatra-7B-v0.3-dpo",
        "3787": "lora_llama2-13b_10e5_r2_a4",
        "3788": "Codellama-7b-hf-ReFT-GSM8k",
        "3789": "Llama-2-13b-chat-hf-gpt-4-80k-base_lora",
        "3790": "Jellyfish",
        "3791": "Neural-AlphaMistral-7B",
        "3792": "lora_llama2-13b_10e5_r8_a4",
        "3793": "Meta-Llama-3-15B-Instruct",
        "3794": "lora_llama2-13b_10e5_r32_a16",
        "3795": "Zephyrus-L1-33B",
        "3796": "electric-mist-7b",
        "3797": "internlm-20b",
        "3798": "mistral-7b-slimorcaboros",
        "3799": "ende-chat-0.0.4",
        "3800": "Magicoder-S-DS-6.7B",
        "3801": "0.001_4iters_bs256_nodpo_only4w_userresponse_iter_4",
        "3802": "lora_llama2-13b_10e5_r128_a64",
        "3803": "Wizard-Vicuna-30B-Uncensored-GPTQ",
        "3804": "DarkForest-20B-v2.0",
        "3805": "ZySec-7B-v1",
        "3806": "Phind-CodeLlama-34B-v2",
        "3807": "AISquare-Instruct-llama2-koen-13b-v0.9.24",
        "3808": "llama2_7b_merge_orcafamily",
        "3809": "lora_llama2-13b_10e4",
        "3810": "juud-Mistral-7B",
        "3811": "Noromaid-13b-v0.3",
        "3812": "LongQLoRA-Vicuna-13b-8k",
        "3813": "Novocode7b",
        "3814": "lora_llama2-13b_10e5_r32_a64",
        "3815": "Mixtral_AI_CyberBrain_Coder",
        "3816": "CodeLlama-34B-Instruct-fp16",
        "3817": "7B",
        "3818": "X-MythoChronos-13B",
        "3819": "ZySec-7B-Adapter",
        "3820": "wendigo-14b-alpha2",
        "3821": "SAM",
        "3822": "MistralMerge-7B-stock",
        "3823": "lora_llama2-13b_10e5_r2_a16",
        "3824": "lora_llama2-13b_10e5_r128_a4",
        "3825": "Camelidae-8x7B",
        "3826": "FusionNet_passthrough_v0.1",
        "3827": "Llama-2-13b-hf",
        "3828": "shisa-gamma-7b-v1",
        "3829": "synapsellm-7b-mistral-v0.5-preview",
        "3830": "lora_llama2-13b_10e5_attn_only",
        "3831": "NyakuraV2.1-m7",
        "3832": "lora_llama2-13b_10e5_r32_a4",
        "3833": "7B-DPO-alpha",
        "3834": "SOLAR_KO_1.3_deup",
        "3835": "AiMaven-Orca2",
        "3836": "llama-polyglot-13b",
        "3837": "LLAMA-13B-test-finetuning",
        "3838": "airoboros-l2-70b-gpt4-1.4.1",
        "3839": "WhiteRabbitNeo-13B-v1",
        "3840": "lora_llama2-13b_10e5_r8_a64",
        "3841": "WhiteRabbitNeo-13B",
        "3842": "adapter_test",
        "3843": "mistral-experiment-6",
        "3844": "WizardLM-30B-fp16",
        "3845": "0.0_zephyr_withdpo_4iters_bs128_5551lr_iter_2",
        "3846": "Metis-0.4",
        "3847": "Rhino-Mistral-7B",
        "3848": "Uni-TianYan",
        "3849": "lora_llama2-13b_10e5",
        "3850": "airoboros-65b-gpt4-m2.0",
        "3851": "Velara-11B-v3",
        "3852": "Llama-3-13B",
        "3853": "poorx32124",
        "3854": "Metis-0.3-merged",
        "3855": "openchat_3.5-16k",
        "3856": "Xenon-1",
        "3857": "0.001_idpo_same_noreplacerej_declr_iter_3",
        "3858": "Noromaid-13b-v0.2",
        "3859": "Llama-2-13b-hf-gpt-4-80k",
        "3860": "Qwen1.5-7B-Dutch-Chat-Sft-Bf16",
        "3861": "Mergerix-7b-v0.2",
        "3862": "megamarcoroni-120b",
        "3863": "finetune_test_qwen15-1-8b-sft-lora",
        "3864": "Phind-CodeLlama-34B-Python-v1",
        "3865": "phi-openllm-lb-test",
        "3866": "falcon-40b",
        "3867": "blockchainlabs_7B_merged_test2_4_prune",
        "3868": "phi-1_5_chat",
        "3869": "SlimOpenOrca-Mistral-7B",
        "3870": "Mistral-7B-SlimOrca",
        "3871": "dolphincoder-starcoder2-7b",
        "3872": "speechless-mistral-dolphin-orca-platypus-samantha-7b",
        "3873": "lora_llama2-13b_10e6",
        "3874": "Giraffe-beta-13b-32k",
        "3875": "Telugu-Llama2-7B-v0-Instruct",
        "3876": "bigyi-15b",
        "3877": "Synatra-7B-v0.3-RP",
        "3878": "TinyLlama-Cinder-Agent-v1",
        "3879": "Llama2-13B-DaringFortitude",
        "3880": "lora_llama2-13b_10e5_r128_a256",
        "3881": "WizardLM-30B-Uncensored-GPTQ",
        "3882": "chinese-alpaca-2-13b-16k",
        "3883": "airoboros-l2-70b-2.1",
        "3884": "Collin-7B-dare",
        "3885": "NexusRaven-V2-13B",
        "3886": "chronos-mistral-7b",
        "3887": "Maverick-v3.0",
        "3888": "tora-13b-v1.0",
        "3889": "dolphin-2.1-mistral-7b",
        "3890": "llama-2-34b-uncode",
        "3891": "zoyllm-7b-slimorca",
        "3892": "Xenon-4",
        "3893": "rizla54",
        "3894": "T3Q-platypus-SOLAR-10.7B-v1.0",
        "3895": "zephyr_7b_norobots",
        "3896": "Medorca-2x7b",
        "3897": "bubo-bubo-13b",
        "3898": "Opus-Samantha-Llama-3-8B",
        "3899": "0.0001_withdpo_4iters_bs256_511lr_iter_2",
        "3900": "hyperdrive-7b-alpha",
        "3901": "Pwen-7B-Chat-20_30",
        "3902": "mpt-7b-8k-instruct",
        "3903": "airoboros-65b-gpt4-2.0",
        "3904": "Phind-CodeLlama-34B-v1",
        "3905": "llama2-7b-function-calling-slerp",
        "3906": "Zero-7B-test-3",
        "3907": "deepseek-coder-7b-instruct-v1.5",
        "3908": "Qwen1.5-72B-Chat",
        "3909": "Hua-v0.1",
        "3910": "dolphin-2.6-mistral-7b-dpo-orca-v1",
        "3911": "dragonwar-7b-alpha",
        "3912": "Mistral-7B-golden",
        "3913": "dolphin-2.6-mistral-7b-dpo-orca",
        "3914": "0.0_ablation_sample1_4iters_bs256_iter_2",
        "3915": "MythoMist-7b",
        "3916": "OpenDolphinHermes_Llama2_7B",
        "3917": "Michel-13B",
        "3918": "GEITje-7B",
        "3919": "lora_llama2-13b_10e5_r8_a256",
        "3920": "MiniMerlin-3B",
        "3921": "StableBeluga-7B-activity-fine-tuned-v2",
        "3922": "mistral-7b-orpo-airoboros-pref-10k",
        "3923": "Brunhilde-13b-v1",
        "3924": "Xenon-3",
        "3925": "Llama-2-7b-chat-hf-gpt-3.5-80k",
        "3926": "CodeLlama-34B-Python-fp16",
        "3927": "airoboros-c34b-2.2.1",
        "3928": "Mistral-7B-OpenOrca",
        "3929": "Q",
        "3930": "lora_llama2-13b_10e5_r32_a256",
        "3931": "qwen1.5-7b-chat-sa-v0.1",
        "3932": "0.0005_withdpo_4iters_bs256_555lr_iter_2",
        "3933": "tora-code-34b-v1.0",
        "3934": "quan-1.8b-base",
        "3935": "SciPhi-Self-RAG-Mistral-7B-32k",
        "3936": "tulu-30B-fp16",
        "3937": "Dolphin2.1-OpenOrca-7B",
        "3938": "Reyna-CoT-4B-v0.2",
        "3939": "balthazar-2x10.7b-v1",
        "3940": "WizardLM-1.0-Uncensored-CodeLlama-34b",
        "3941": "ADELIE-SFT",
        "3942": "starcoder2-3b",
        "3943": "autodev-deepseek-6.7b-finetunes-poc",
        "3944": "Mistral-7B-length-100000",
        "3945": "mistral-7b-finetuned-orca-dpo-v2",
        "3946": "Llama-2-7b-chat-hf-afr-100step-flan-v2",
        "3947": "Llama-2-7b-chat-hf-afr-100step-flan",
        "3948": "TIES-Merging",
        "3949": "deepseek-math-7b-instruct",
        "3950": "Xenon-2",
        "3951": "GEITje-7B-ultra",
        "3952": "Synatra-V0.1-7B-Instruct",
        "3953": "Synatra-V0.1-7B",
        "3954": "neural-chat-7b-v3-1",
        "3955": "Samantha-1.11-CodeLlama-34b",
        "3956": "japanese-stablelm-instruct-gamma-7b",
        "3957": "Llama-2-7b-chat-hf-activity-fine-tuned-v4",
        "3958": "Qwen-1_8B-Chat-llama",
        "3959": "Qwenchana-1.8B",
        "3960": "internlm2-base-7b-llama",
        "3961": "Huginn-V5-10.7B",
        "3962": "Python-Code-33B",
        "3963": "Darewin-7B-v2",
        "3964": "Llama-2-7b-chat-hf-10-attention-sparsity",
        "3965": "Pwen-VL-Chat-20_30",
        "3966": "SOLID-SFT-DPO-MixQV2-SOLIDRejected-SFTChosen-Zephyr-7b-beta",
        "3967": "wizard-mistral-v0.1",
        "3968": "Code-13B",
        "3969": "Llama-2-7b-chat-hf-activity-fine-tuned-v3",
        "3970": "Qwen1.5-1.8B-Chat",
        "3971": "mistral-7B-alpaca-case-0-2",
        "3972": "Llama-2-7b-chat-hf-afr-200step-merged",
        "3973": "medicine-chat",
        "3974": "Llama-2-7b-chat-hf-afr-200step-flan-v2",
        "3975": "SlimOpenOrca-Mistral-7B-v2",
        "3976": "CollectiveCognition-v1.1-Mistral-7B-dare-0.85",
        "3977": "yayi2-30b-llama",
        "3978": "Sydney_Overthinker_13b_HF",
        "3979": "openbuddy-llama2-13b-v11-bf16",
        "3980": "autotrain-8kfjk-b3gva",
        "3981": "Clover3-17B",
        "3982": "finance-chat",
        "3983": "juud-Mistral-7B-dpo",
        "3984": "Llama-2-7b-chat-hf-guanaco-lora",
        "3985": "Dr_Samantha-7b",
        "3986": "0001_dpo_iter_2",
        "3987": "Synthiallamaguanco-7B-slerp",
        "3988": "internlm-20b-chat",
        "3989": "speechless-coder-ds-6.7b",
        "3990": "gemma-2b-zephyr-sft",
        "3991": "WizardLM-33B-V1.0-Uncensored",
        "3992": "neural-chat-mini-v2.2-1.8B",
        "3993": "Llama-2-70B-chat-GPTQ",
        "3994": "dolphin-2.0-mistral-7b",
        "3995": "Llama-2-7b-chat-hf-afr-200step-flan",
        "3996": "zephyr-7b-dpo-full",
        "3997": "phi-1_5_chat_32k",
        "3998": "SynthIA-7B-v1.3-dare-0.85",
        "3999": "Mistral-7B-loss-100000",
        "4000": "Llama-2-7b-chat-hf-gpt-3.5-80k-base_lora",
        "4001": "Open-StaMis-v02-stock",
        "4002": "gemma-2b-zephyr-dpo",
        "4003": "Mistral-v0.1-PeanutButter-v0.0.0-7B",
        "4004": "BeingWell_llama2_7b",
        "4005": "FusionBot",
        "4006": "law-chat",
        "4007": "WizardLM-70B-V1.0-GPTQ",
        "4008": "FBt",
        "4009": "0.001_zephyr_5551_4iters_bs256_iter_3",
        "4010": "speechless-mistral-six-in-one-7b",
        "4011": "InnerIAI-chat-7b-grok",
        "4012": "Llama-2-7b-chat-hf-10-sparsity",
        "4013": "vicuna-MultiLoRA-sharegpt-mmlu-drop-ffn-1.0general",
        "4014": "yi6B_Vicuna",
        "4015": "Llama-2-7b-chat-hf-gpt-4-80k",
        "4016": "MegaMix-S1-13B",
        "4017": "Tess-XS-v1.0",
        "4018": "ChickaQ-V2-Large-Beta",
        "4019": "zephyr-2b-gemma-sft-qlora",
        "4020": "Senzu-7B-v0.1",
        "4021": "Tinybra_13B",
        "4022": "Mistral-v0.1-PeanutButter-v0.0.5-DPO-7B-QLoRA",
        "4023": "Mistral-7B-Instruct-v0.2-DARE",
        "4024": "mistral-7B-v0.1-hf",
        "4025": "airoboros-65b-gpt4-1.4",
        "4026": "airoboros-65b-gpt4-1.4-peft",
        "4027": "llama_allyarc",
        "4028": "WizardLM-70B-V1.0",
        "4029": "Llama-2-7b-chat-hf-afr-300step-flan-v2",
        "4030": "deepseek-coder-6.7b-base",
        "4031": "Mistral-7B-claude-instruct",
        "4032": "Cerberus-7B-slerp",
        "4033": "CollectiveCognition-v1-Mistral-7B",
        "4034": "digital-socrates-7b",
        "4035": "llama-30b-2048-instruct-PL-lora_unload",
        "4036": "Llama-2-7b-chat-hf-20-sparsity",
        "4037": "Llama-2-7b-chat-hf-afr-441step-flan-v2",
        "4038": "llama-30b-instruct-2048",
        "4039": "Code-290k-13B",
        "4040": "LLaMA-Pro-8B",
        "4041": "japanese-stablelm-base-gamma-7b",
        "4042": "Mistral-7B-Instruct-v0.1-gpt-4-80k-base_lora",
        "4043": "Llama-2-7b-chat-hf-20-attention-sparsity",
        "4044": "Synatra-11B-Testbench",
        "4045": "gaodrew-llama-30b-instruct-2048-Open-Platypus-100steps",
        "4046": "TinyLlama-Cinder-Tiny-Agent",
        "4047": "gemma-2b-lora3",
        "4048": "SynthIA-7B-v1.3",
        "4049": "Tess-10.7B-v2.0",
        "4050": "cinematika-7b-v0.1",
        "4051": "zephyr-beta-Nebula-v2-7B",
        "4052": "SynthIA-7B-v1.5",
        "4053": "airoboros-m-7b-3.1.2-dare-0.85",
        "4054": "Mistral-v0.1-PeanutButter-v0.0.2-7B",
        "4055": "stablelm-2-1_6b",
        "4056": "Mistral-7B-SFT",
        "4057": "v1",
        "4058": "Mistral-7B-openplatypus-1k",
        "4059": "Llama-2-7b-chat-hf-30-attention-sparsity",
        "4060": "mistral-7b-platypus-fp16",
        "4061": "mamba-gpt-7b-v1",
        "4062": "h2o-danube-1.8b-chat",
        "4063": "Elliott-Chinese-LLaMa-GPTQ-V1.0",
        "4064": "ToxicHermes-2.5-Mistral-7B",
        "4065": "speechless-coding-7b-16k-tora",
        "4066": "gemma-7b-lora-distilabel-intel-orca-dpo-pairs",
        "4067": "Mistral-7B-OpenOrca-lora",
        "4068": "Llama-2-13B-German-ORPO",
        "4069": "deepseek-moe-16b-base",
        "4070": "Obscura_32k_7B",
        "4071": "Mistral-7B-v0.1-Open-Platypus",
        "4072": "MixtralOrochi8x7B",
        "4073": "mamba-gpt-7b-v2",
        "4074": "deepseek-coder-6.7b-chat-and-function-calling",
        "4075": "Elliott-Chinese-LLaMa-GPTQ",
        "4076": "zephyrnotus-11b-alpha",
        "4077": "0.0001_withdpo_4iters_bs256_511lr_iter_3",
        "4078": "Mistral-v0.1-PeanutButter-v0.0.5-SFT-7B-QLoRA",
        "4079": "gemma-2b-lora16b2",
        "4080": "Llama-2-7b-chat-hf-30-sparsity",
        "4081": "0.001_zephyr_5551_4iters_bs256_iter_4",
        "4082": "tigerbot-13b-base",
        "4083": "Open-StaMis-stock",
        "4084": "0.0001_withdpo_4iters_bs256_5102lr_iter_4",
        "4085": "d-Qwen1.5-0.5B",
        "4086": "samantha-1.2-mistral-7b",
        "4087": "Zenith-7B-dpo-v1",
        "4088": "deepseek-coder-6.7b-chat",
        "4089": "Qwen1.5-MoE-A2.7B",
        "4090": "mistral_7b_2epoch_norobots",
        "4091": "Mistral-7B-attention-100000",
        "4092": "Medtulu-2x7b",
        "4093": "0.0_zephyr_withdpo_4iters_bs128_5551lr_iter_3",
        "4094": "Reyna-CoT-4B-v0.1",
        "4095": "hope_for",
        "4096": "gemma-2b",
        "4097": "mnsim-dpo-peftmerged-2-eos",
        "4098": "mpt-30b",
        "4099": "archangel_sft-kto_llama13b",
        "4100": "llama-30b-instruct-2048-PL-lora",
        "4101": "mistral-7b-v0.1-layla-v1",
        "4102": "Noromaid-Aeryth-7B",
        "4103": "vigostral-7b-chat",
        "4104": "Uncensored-Frank-33B",
        "4105": "mhm-7b-v1.3",
        "4106": "Zenith-7B-dpo",
        "4107": "gemma-2b-it-tamil-v0.1-alpha",
        "4108": "SOLAR-13B-Instruct-v1.0",
        "4109": "cymist2-v01-SFT",
        "4110": "phi-1_5_base",
        "4111": "traversaal-2.5-Mistral-7B",
        "4112": "hope_for_7b_1.0v",
        "4113": "tora-code-13b-v1.0",
        "4114": "TowerInstruct-7B-v0.1",
        "4115": "llama-2-alpacagpt4-1000step",
        "4116": "mistral-7b-platypus1k",
        "4117": "lora_llama2-13b_10e5_r2_a256",
        "4118": "Qwen1.5-0.5B",
        "4119": "Tess-XS-v1.1",
        "4120": "0.0_ablation_sample1_4iters_bs256_iter_3",
        "4121": "Enterredaas-33b",
        "4122": "fin-llama-33b-merged",
        "4123": "GEITje-7B-chat-v2",
        "4124": "Mistral-11B-TestBench9",
        "4125": "llama-2-7b-miniguanaco",
        "4126": "MentaLLaMA-chat-7B",
        "4127": "finetuned-llama2-chat-5000-v1.0-squad",
        "4128": "0ai-7B-v4",
        "4129": "Llama-2-7b-chat-hf-structured-responses",
        "4130": "gemma-2b-coder",
        "4131": "ultra0",
        "4132": "llama-13b-pretrained",
        "4133": "manticore-30b-chat-pyg-alpha",
        "4134": "Elliott-Chinese-LLaMa-GPTQ-V2.0",
        "4135": "vicuna-7b-v1.5-lora-mmlu-merged",
        "4136": "vicuna-7b-v1.5-lora-temporal-sharegpt",
        "4137": "gemma-2b-chat-ultra",
        "4138": "Mistral-7B-OpenOrca-Guanaco-accu16",
        "4139": "samantha-mistral-7b",
        "4140": "LosslessMegaCoder-llama2-13b-mini",
        "4141": "llama2-13b-megacode2_min100",
        "4142": "Yi-6B_Open-Platypus-v2",
        "4143": "firefly-llama-30b",
        "4144": "stack_codellama-7b-inst",
        "4145": "MultiLoRA-mmlu",
        "4146": "NewHope_HF_not_official",
        "4147": "0.0_withdpo_4iters_bs256_531lr_iter_3",
        "4148": "Alpacino30b",
        "4149": "finetuned-llama2-chat-5000-v2.0",
        "4150": "Dans-AdventurousWinds-7b",
        "4151": "recurrentgemma-2b",
        "4152": "Deita-1_8B",
        "4153": "Deita-Qwen-1_8B",
        "4154": "MiquMaid-v2-70B",
        "4155": "orca-open_hermes-llava-v1.5-7b-dpo",
        "4156": "Dans-PersonalityEngine-30b",
        "4157": "llama2-13b-megacode2-oasst",
        "4158": "gpt4-alpaca-lora-30b-HF",
        "4159": "Orca-2-13B-GPTQ",
        "4160": "qwen1.5-vortex",
        "4161": "Qwen1.5-0.5B-vortex",
        "4162": "0.0_zephyr_withdpo_4iters_bs128_5551lr_iter_4",
        "4163": "Qwen1.5-Wukong-0.5B",
        "4164": "shqiponja-59b-v1",
        "4165": "Qwen1.5-7B-Dutch-Chat",
        "4166": "Awanllm-Llama-3-8B-Dolfin-v0.3-DPO",
        "4167": "gemoy-4b-instruct-scientific",
        "4168": "openbuddy-qwen1.5-32b-v21.2-32k",
        "4169": "StrangeMerges_48-7B-dare_ties",
        "4170": "openbuddy-atom-13b-v9-bf16",
        "4171": "Vicuzard-30B-Uncensored",
        "4172": "llama-2-13b-FINETUNE4_addto15k_4.5w-r16-gate_up_down",
        "4173": "orca_mini_v3_7B-GPTQ",
        "4174": "Vicuzard-30B-Uncensored-instruct-PL-lora_unload",
        "4175": "llava-v1.5-7b-hf-vicuna",
        "4176": "Mixtral_AI_CyberCoder",
        "4177": "mpt-30b-instruct",
        "4178": "llava-v1.5-7b_vicuna",
        "4179": "athene-noctua-13b",
        "4180": "mhm-7b-v1.3-DPO-1",
        "4181": "stock-solar-10.7b-v1",
        "4182": "Airoboros-L2-70B-2.1-GPTQ",
        "4183": "CodeUp-Llama-2-13b-chat-hf",
        "4184": "Morningstar-13b-hf",
        "4185": "Llama-2-13b-chat-hf",
        "4186": "0.001_ablation_5iters_bs256_iter_5",
        "4187": "speechless-nl2sql-ds-6.7b",
        "4188": "h2o-danube-1.8b-sft",
        "4189": "Uncensored-Jordan-13B",
        "4190": "AISquare-Instruct-SOLAR-10.7b-v0.5.32",
        "4191": "OpenOrcaxOpenChat-Preview2-13B",
        "4192": "chinese-alpaca-2-7b-rlhf",
        "4193": "frankencria-llama2-11b-v1.3-m.1",
        "4194": "0.0005_withdpo_4iters_bs256_5551lr_iter_4",
        "4195": "chronoboros-33B",
        "4196": "BioMistral-7B-DARE",
        "4197": "Mistral-11B-TestBench11",
        "4198": "ANIMA-Phi-Neptune-Mistral-7B-v4",
        "4199": "odia_llama2_7B_base",
        "4200": "llama_sft_longer",
        "4201": "Dans-AdventurousWinds-Mk2-7b",
        "4202": "ANIMA-Phi-Neptune-Mistral-7B",
        "4203": "TinyLlama-Cinder-Agent-Rag",
        "4204": "llama3-passthrough",
        "4205": "finetuned-llama2-2048-v3.0",
        "4206": "Nebula-7B",
        "4207": "llama_ppo_1e6_new_tokenizerstep_8000",
        "4208": "llama-7b-ludwig-alpaca",
        "4209": "PsyMedRP-v1-20B",
        "4210": "llama-30B-hf-openassitant",
        "4211": "llama-30b",
        "4212": "QuantumLM-70B-hf",
        "4213": "Chat-Stheno-L2-13B",
        "4214": "speechless-codellama-dolphin-orca-platypus-34b",
        "4215": "Orca-2-7b",
        "4216": "llama-2-13b-mathgpt-v4",
        "4217": "openbuddy-mistral-7b-v13",
        "4218": "psyonic-cetacean-20B",
        "4219": "speechless-codellama-34b-v1.0",
        "4220": "Stellaris-internlm2-20b-r512",
        "4221": "VicUnlocked-alpaca-30b",
        "4222": "tyc_test1",
        "4223": "Qwen1.5-7B-Chat_llamafy",
        "4224": "Llama-2-7b-hf-gpt-3.5-80k",
        "4225": "base_7b",
        "4226": "llama2-13b-FINETUNE3_TEST",
        "4227": "Cypher-Mini-1.8B",
        "4228": "Llama-2-7b-hf",
        "4229": "Mixtral_13Bx2_MOE_22B",
        "4230": "Chinese-Llama-2-7b",
        "4231": "Orca-Nova-13B",
        "4232": "llama2-MultiLoRA-sharegpt-mmlu-drop-ffn-1.0general",
        "4233": "ELYZA-japanese-Llama-2-13b-instruct",
        "4234": "magpie-13b",
        "4235": "VicUnlocked-30B-LoRA-HF",
        "4236": "BELLE-Llama2-13B-chat-0.4M",
        "4237": "Platypus-30B",
        "4238": "llama_ppo_1e6step_4000",
        "4239": "llama-33B-instructed",
        "4240": "dolphin-llama-13b",
        "4241": "0.0_withdpo_4iters_bs256_5551lr_iter_4",
        "4242": "Magicoder-S-CL-7B",
        "4243": "FuseLLM-7B",
        "4244": "unraveled-7b-a1",
        "4245": "gemma-2b-chat",
        "4246": "Mistral-7B-Instruct-v0.1",
        "4247": "llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o",
        "4248": "tulu-13B-fp16",
        "4249": "llama-2-70B-LoRA-assemble-v2",
        "4250": "Wizard-Vicuna-30B-Uncensored",
        "4251": "vicuna-7b-v1.5-general-temporal-merged",
        "4252": "Wizard-Vicuna-30B-Uncensored-fp16",
        "4253": "zephyr-7b-beta-lora-mmlu-merged",
        "4254": "Myrrh_solar_10.7b_3.0",
        "4255": "hope_for_7b_1.1v",
        "4256": "WizardLM-13B-V1.0",
        "4257": "CAMEL-33B-Combined-Data",
        "4258": "doctorLLM5k",
        "4259": "llama-2-13b-FINETUNE5_4w-r8-q_k_v_o",
        "4260": "zephyr-7b-alpha",
        "4261": "llama-2-13b-huangyt_Fintune_1_17w-q_k_v_o_proj",
        "4262": "coven_tiny_1.1b_32k_orpo_alpha",
        "4263": "ReMM-v2.2-L2-13B",
        "4264": "llama-2-13b-FINETUNE1_17w-q_k_v_o_proj",
        "4265": "Llama-2-7b-hf-gpt-4-80k",
        "4266": "L2-7b-Hermes-Synthia",
        "4267": "zephyr-7b-dpo-full-ExPO",
        "4268": "chronolima-airo-grad-l2-13B",
        "4269": "LLaMA2-13B-Estopia",
        "4270": "YaYi-30b-EverythingLM",
        "4271": "Hermes-2-SOLAR-10.7B-Symbolic",
        "4272": "llama-13b-pretrained-sft-epoch-1",
        "4273": "airoboros-m-7b-3.1.2",
        "4274": "gemma-2b-orpo",
        "4275": "GPlatty-30B",
        "4276": "wizardLM-13B-1.0-fp16",
        "4277": "YuLan-Chat-2-13b-fp16",
        "4278": "llama-2-13b-FINETUNE5_4w-r16-q_k_v_o",
        "4279": "StableBeluga-13B",
        "4280": "openchat_v3.1",
        "4281": "vicuna-33b-v1.3",
        "4282": "UndiMix-v4-13B",
        "4283": "airochronos-33B",
        "4284": "chinese-alpaca-2-7b",
        "4285": "llama-2-13b-FINETUNE5_4w-r4-gate_up_down",
        "4286": "airolima-chronos-grad-l2-13B",
        "4287": "openchat_v3.2",
        "4288": "Llama-2-13b-chat-german",
        "4289": "airoboros-65b-gpt4-1.3",
        "4290": "doctorLLM",
        "4291": "llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o",
        "4292": "openchat_v3.2_super",
        "4293": "WizardLM-13B-V1.2",
        "4294": "Macaroni-v2-7b",
        "4295": "llama-2-13b-FINETUNE5_4w-r8-gate_up_down",
        "4296": "fietje-2b-instruct",
        "4297": "falcon-40b-openassistant-peft",
        "4298": "llama-2-13b-FINETUNE1_17w-r16",
        "4299": "Meta-Llama-3-13B-Instruct",
        "4300": "llama-2-13b-huangyt_Fintune_1_17w",
        "4301": "WizardLM-1.0-Uncensored-Llama2-13b",
        "4302": "Stheno-1.8-L2-13B",
        "4303": "openchat_v2_openorca_preview-GPTQ",
        "4304": "llama-2-13b-FINETUNE1_17w",
        "4305": "Llama3-ChatQA-1.5-8B",
        "4306": "mythalion-13b",
        "4307": "Fewshot-Metamath-OrcaVicuna-Mistral-10B",
        "4308": "vicuna-7b-v1.3-attention-sparsity-10",
        "4309": "Qwen1.5-7B-Chat",
        "4310": "llama-2-13b-FINETUNE1_17w-r4",
        "4311": "codellama-13b-oasst-sft-v10",
        "4312": "Yi-6B_Open-Orca",
        "4313": "Llama-2-13b-FINETUNE4_TEST",
        "4314": "Stheno-Inverted-L2-13B",
        "4315": "ReMM-v2-L2-13B",
        "4316": "Dans-TotSirocco-7b",
        "4317": "Llama-2-13b-FINETUNE4_TEST2",
        "4318": "vicuna-13b-v1.5-16k",
        "4319": "TowerBase-7B-v0.1",
        "4320": "llama2-13b-sharegpt4-test",
        "4321": "vicuna-7b-v1.3-sparsity-10",
        "4322": "speechless-llama2-hermes-orca-platypus-wizardlm-13b",
        "4323": "orca_mini_v3_13b",
        "4324": "minotaur-13b-fixed",
        "4325": "wizardllama-7b",
        "4326": "chronos-33b",
        "4327": "zephyr-7b-beta-128k",
        "4328": "airoboros-33b-gpt4-1.3",
        "4329": "13B-Legerdemain-L2",
        "4330": "lora_llama2-7b_10e4",
        "4331": "Mistral-7B-random-100000",
        "4332": "llama-2-13b-FINETUNE3_3.3w-r16-gate_up_down",
        "4333": "H4rmoniousAnthea",
        "4334": "llama-2-13b-huangyt_Fintune_1_17w-gate_up_down_proj",
        "4335": "llama-2-13b-FINETUNE1_17w-gate_up_down_proj",
        "4336": "WizardLM-30B-Uncensored",
        "4337": "gemma-2b-tamil",
        "4338": "vicuna-33b-coder",
        "4339": "OpenRP-13B",
        "4340": "llama-2-13b-FINETUNE4_3.8w-r8-gate_up_down",
        "4341": "Llama-2-13b-orca-v1",
        "4342": "Emerald-13B",
        "4343": "llama-2-13b-huangyt_FINETUNE2_3w-q_k_v_o_proj",
        "4344": "stack_llama_fil_ai",
        "4345": "llama-2-13b-FINETUNE4_3.8w-r4-gate_up_down",
        "4346": "stablelm-2-1_6b-sft-full",
        "4347": "trurl-2-13b",
        "4348": "llama-2-13b-FINETUNE2_3w-q_k_v_o_proj",
        "4349": "Stheno-v2-Delta-fp16",
        "4350": "Mistral-Hinglish-7B-Instruct-v0.2",
        "4351": "Yi-Ko-6B_Open-Platypus",
        "4352": "ReMM-v2.1-L2-13B",
        "4353": "Llama2-7B-guanaco-dolphin-500",
        "4354": "Qwen-1_8b-EverythingLM",
        "4355": "openthaigpt-1.0.0-13b-chat",
        "4356": "CodeLlama-13b-Instruct-hf",
        "4357": "Yi-6B",
        "4358": "llama-2-13b-OpenOrca_20w",
        "4359": "CodeLlama-13B-Instruct-fp16",
        "4360": "llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down-test1",
        "4361": "airoboros-33b-gpt4",
        "4362": "Llama2-Chinese-13b-Chat",
        "4363": "0.001_4iters_bs256_nodpo_only4w_iter_4",
        "4364": "llama2-13b-FINETUNE3_TEST2",
        "4365": "mistral-7b_open_platypus",
        "4366": "CalliopeDS-v2-L2-13B",
        "4367": "Kimiko-v2-13B-fp16",
        "4368": "Slerpeno",
        "4369": "llama3-8b-cqia",
        "4370": "Llama-2-13b-FINETUNE4",
        "4371": "Yi-Ko-6B",
        "4372": "minotaur-13b",
        "4373": "OpenOrcaxOpenChat-Preview2-13B-GPTQ",
        "4374": "LLaMA_2_13B_SFT_v0",
        "4375": "llama-2-13b-dolphin_20w",
        "4376": "phi-1_5",
        "4377": "Barcenas-13b",
        "4378": "Platypus2xOpenOrca-13B-IA3-v3",
        "4379": "llama-2-13b-chat-platypus",
        "4380": "Chat-AYB-Nova-13B",
        "4381": "vicuna-7b-v1.3-attention-sparsity-30",
        "4382": "recycled-wizardlm-7b-v2.0",
        "4383": "stack_llama-clang",
        "4384": "LewdEngine",
        "4385": "WizardMath-13B-V1.0",
        "4386": "SOLID-SFT-WoDPO-MixQV2-Zephyr-7b-beta",
        "4387": "vicuna-13b-v1.5-PL-lora_unload",
        "4388": "genz-13b-v2",
        "4389": "llama-2-13b-FINETUNE5_4w-r4-q_k_v_o",
        "4390": "Samantha-1.11-13b",
        "4391": "gemma-ko-7b-instruct-v0.50",
        "4392": "llama-2-13b-OpenOrca_5w",
        "4393": "llama-2-13b-FINETUNE5_4w-r4-q_k_v_o_gate_up_down",
        "4394": "LlongOrca-13B-16k",
        "4395": "manticore-13b",
        "4396": "trurl-2-13b-pl-instruct_unload",
        "4397": "StableBeluga-13B-instruct-PL-lora_unload",
        "4398": "llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down",
        "4399": "0.0_ablation_sample1_4iters_bs256_iter_4",
        "4400": "CodeLlama-13b-hf",
        "4401": "OpenHermes-Gemma-2B",
        "4402": "Llama-2-7b-hf-llama2-raw-80k",
        "4403": "llama-30b-instruct",
        "4404": "llama-13b-FINETUNE3",
        "4405": "SmartQwen1.5-1.8B-orpo-v1",
        "4406": "Llama-chat-AY-13B",
        "4407": "mpt-30b-chat",
        "4408": "llama-2-13b-FINETUNE2_3w-gate_up_down_proj",
        "4409": "tutor-model-13b-ep3",
        "4410": "Llama-2-7b-chat-hf-gpt-4-80k-base_lora",
        "4411": "vicuna-class-tutor-13b-ep3",
        "4412": "minotaur-llama2-13b-qlora",
        "4413": "llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o_gate_up_down",
        "4414": "Configurable-Mistral-22B",
        "4415": "llama-2-13b-huangyt_FINETUNE2_3w-gate_up_down_proj",
        "4416": "llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o",
        "4417": "Zenith-7B",
        "4418": "ReMM-Mistral-13B",
        "4419": "Uncensored-Frank-13B",
        "4420": "Mistral-7B-guanaco1k-ep2",
        "4421": "storytell",
        "4422": "llama-2-13b-huangyt_FINETUNE2_3w",
        "4423": "Llama-2-7b-hf-llama2-chat-80k",
        "4424": "llama-2-13b-FINETUNE2_3w",
        "4425": "gemma-ko-7b-instruct-v0.52",
        "4426": "Athena-v4",
        "4427": "Mistral-7B-OpenOrca-1k",
        "4428": "mamba-gpt-7b",
        "4429": "llama-2-13b-FINETUNE3_3.3w-r4-gate_up_down",
        "4430": "Stheno-L2-13B",
        "4431": "mistral-guanaco1k-ep2",
        "4432": "vicuna-7b-v1.5-lora-temporal-without-mctaco-1",
        "4433": "llama-2-13b-FINETUNE5_4w-r8-q_k_v_o_gate_up_down",
        "4434": "Mistral-11B-SynthIAirOmniMix",
        "4435": "llama-30b-supercot",
        "4436": "llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o",
        "4437": "Llama-2-13b-hf-instruct-pl-lora_unload",
        "4438": "llama-2-13b-code-alpaca",
        "4439": "Llama-2-13b-FINETUNE4_compare8k2",
        "4440": "llama-13b-pretrained-dropout",
        "4441": "Platypus2xOpenOrca-13B-IA3",
        "4442": "vigogne-13b-instruct",
        "4443": "llama-2-13b-dolphin_5w",
        "4444": "Metabird-7b-DPO",
        "4445": "llama2-13B-sharegpt4-orca-openplatypus-8w",
        "4446": "MythoLogic-L2-13b",
        "4447": "BerrySauce-L2-13b",
        "4448": "llama-2-13b-FINETUNE3_3.3w-r8-gate_up_down",
        "4449": "pygmalion-2-13b",
        "4450": "airoboros-33b-gpt4-1.4",
        "4451": "multimaster-7b",
        "4452": "MultiLoRA-llama2-mmlu",
        "4453": "stack_llama_full",
        "4454": "chronos-hermes-13b-v2",
        "4455": "llama2guanacotest",
        "4456": "firefly-llama2-13b-v1.2",
        "4457": "0.001_3iters_bs256_nodpo_only4w_iter_3",
        "4458": "Llama-2-7b-chat-hf-guanaco-freeze-embed-tokens-q-v-proj",
        "4459": "TarsChattyBasev0.0",
        "4460": "mistral-4.2B",
        "4461": "OpenHermes-13B",
        "4462": "Nusantara-4b-Indo-Chat",
        "4463": "Athena-v3",
        "4464": "airoboros-l2-13b-2.2.1",
        "4465": "Qwenchana-4B-restart-OH",
        "4466": "llama-2-13b-guanaco-fp16",
        "4467": "speechless-codellama-34b-v2.0",
        "4468": "llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o_gate_up_down",
        "4469": "llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o",
        "4470": "LongQLoRA-Llama2-7b-8k",
        "4471": "LLaMA2-13B-Holomax",
        "4472": "SwahiliInstruct-v0.2",
        "4473": "llama-2-13b-FINETUNE5_4w-r16-gate_up_down",
        "4474": "Yi-7b-dpo",
        "4475": "Yi-6b-200k-dpo",
        "4476": "qCammel-13",
        "4477": "30B-Lazarus-instruct-PL-lora_unload",
        "4478": "llama2-13b-Chinese-chat",
        "4479": "Samantha-Nebula-7B",
        "4480": "MLewd-L2-Chat-13B",
        "4481": "vitruv_1",
        "4482": "Mistral-7B-Instruct-v0.2-sparsity-20",
        "4483": "bimoGPT-llama2-13b",
        "4484": "oasst-llama-13b-1000-steps",
        "4485": "vicuna-13b-v1.5",
        "4486": "Llama-2-13B-GPTQ",
        "4487": "Platypus2-13B-IA3",
        "4488": "Llama2-chat-AYB-13B",
        "4489": "danube2-upscale-1.7",
        "4490": "Llama-2-7b-chat-hf-guanaco-freeze-embed-tokens-q-v-proj-lora",
        "4491": "chronos-13b-v2",
        "4492": "SthenoWriter-L2-13B",
        "4493": "llama2-22b-blocktriangular",
        "4494": "tulu-7B-fp16",
        "4495": "Llama-2-13b-FINETUNE4_TEST3",
        "4496": "mistral-instruct-frankenmerge",
        "4497": "firefly-llama2-13b",
        "4498": "Redmond-Puffin-13B",
        "4499": "FINETUNE3_TEST4",
        "4500": "vicuna-7b-v1.3-attention-sparsity-20",
        "4501": "AceGPT-7B",
        "4502": "OpenOrca-Platypus2-13B-QLoRA-0.80-epoch",
        "4503": "vigogne-33b-instruct",
        "4504": "WizardLM-13B-V1.2-PL-lora_unload",
        "4505": "Alpagasus-2-13b-QLoRA-merged",
        "4506": "llama2-22b-chat-wizard-uncensored",
        "4507": "Unholy-v1-12L-13B",
        "4508": "Qllama-.5B-Base-Wiki-Chat-RAG",
        "4509": "Redmond-Puffin-13B-instruct-PL-lora_unload",
        "4510": "SOLAR-Platypus-10.7B-v1",
        "4511": "Mistralic-7B-1",
        "4512": "selfrag_llama2_7b",
        "4513": "llama2-13b-math1.2",
        "4514": "CodeLlama13B-Finetune-v1",
        "4515": "Synthia-13B-v1.2",
        "4516": "llama2-13b-orca-8k-3319",
        "4517": "llama2_13b_instructed_version2",
        "4518": "MLewdBoros-L2-13B",
        "4519": "llama-2-13b-Guanaco-QLoRA",
        "4520": "Synthia-13B",
        "4521": "Platypus2xOpenOrca-13B-IA3-v2.1",
        "4522": "openllama-7b-icl",
        "4523": "Baichuan2-7B-Chat-LLaMAfied",
        "4524": "llama2-13b-fintune2-4E",
        "4525": "llama-2-13b-FINETUNE4_compare15k_4.5w-r16-gate_up_down",
        "4526": "Asimov-7B-v2",
        "4527": "trurl-2-13b-academic",
        "4528": "MXLewd-L2-20B",
        "4529": "Stheno-1.2-L2-13B",
        "4530": "MLewd-ReMM-L2-Chat-20B",
        "4531": "llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o_gate_up_down",
        "4532": "llama2-7b-hf-chat-lora-v2",
        "4533": "openbuddy-openllama-7b-v12-bf16",
        "4534": "Platypus2xOpenOrca-13B-IA3-v4",
        "4535": "tigerbot-7b-base",
        "4536": "Amethyst-13B-Mistral",
        "4537": "Synthia-7B-v1.2",
        "4538": "Llama-2-13B-fp16",
        "4539": "samantha-mistral-instruct-7b",
        "4540": "Flash-Llama-13B",
        "4541": "Starlight-13B",
        "4542": "gemma-pro-3.1b-ko-v0.1",
        "4543": "Amethyst-13B",
        "4544": "recycled-alpaca-7b-v2.0",
        "4545": "EnsembleV5-Nova-13B",
        "4546": "GZDX",
        "4547": "llama2-7b-hf-chat-lora",
        "4548": "vicuna-13b-v1.3",
        "4549": "CodeLLaMA-chat-13b-Chinese",
        "4550": "gemma-2b-dpo-v1",
        "4551": "airoboros-33b-gpt4-2.0",
        "4552": "belal-finetuned-llama2-v1.0",
        "4553": "dulia-13b-8k-alpha",
        "4554": "Llama-2-13b-chat-dutch",
        "4555": "13B-Chimera",
        "4556": "Gemmalpaca-2B",
        "4557": "UltraLM-13B-fp16",
        "4558": "llama2-13b-math1.1",
        "4559": "Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16_merged",
        "4560": "Dionysus-Mistral-n1-v1",
        "4561": "pythia-12b-sft-v8-7k-steps",
        "4562": "llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o",
        "4563": "Cypher-Laser-Mixtral-2x1.8B-v0.1",
        "4564": "nash-vicuna-13b-v1dot5-ep2-w-rag-w-simple",
        "4565": "lora_llama2-7b_10e5",
        "4566": "gemma-2b-translation-v0.103",
        "4567": "Mistral-7B-Instruct-v0.2-sparsity-30",
        "4568": "Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16",
        "4569": "belal-finetuned-llama2-1024-v2.2",
        "4570": "MiniChat-3B",
        "4571": "Llama-2-13b-hf_Open-Platypus-QLoRA-multigpu",
        "4572": "MLewd-Chat-v2-13B",
        "4573": "CodeMind-gemma",
        "4574": "Cypher-Mixtral-2x1.8B-v0.1",
        "4575": "llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o_gate_up_down",
        "4576": "Nous-Hermes-13B-Code",
        "4577": "deacon-13b",
        "4578": "13B-HyperMantis",
        "4579": "mistral-7b-sft-open-orca-flan-50k",
        "4580": "perry-7b",
        "4581": "llama2-13b-ft-mc4_nl_cleaned_tiny",
        "4582": "lora_llama2-7b_10e6",
        "4583": "2x-LoRA-Assemble-Nova-13B",
        "4584": "vicuna-mmlu-val-mcq-7b-ep2",
        "4585": "hippogriff-30b-chat",
        "4586": "TarsDolly",
        "4587": "Llama3-OpenBioLLM-8B",
        "4588": "doctorLLM10k",
        "4589": "OpenBioLLM-Llama3-8B",
        "4590": "Phi-5B-Test",
        "4591": "recurrentgemma-2b-it",
        "4592": "Gemma-Wukong-2b",
        "4593": "wizard-mega-13b",
        "4594": "starling-7B",
        "4595": "llama13B-quant8-testv1-openorca-customdataset",
        "4596": "CodeLlama-13B-Python-fp16",
        "4597": "Platypus-Nebula-v2-7B",
        "4598": "Nous-Hermes-Llama2-13b",
        "4599": "AppleSauce-L2-13b",
        "4600": "UndiMix-v1-13b",
        "4601": "Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16",
        "4602": "stack-llama-2",
        "4603": "Luban-Marcoroni-13B",
        "4604": "CalliopeDS-L2-13B",
        "4605": "gaodrew-gorgonzola-13b",
        "4606": "Luban-Marcoroni-13B-v2",
        "4607": "Mistral-Trismegistus-7B",
        "4608": "Mixtral-8x7B-MoE-RP-Story",
        "4609": "Zro1.5_3B",
        "4610": "Luban-Marcoroni-13B-v3",
        "4611": "llama2-22b",
        "4612": "Llama-2-7b-chat-hf-guanaco",
        "4613": "finetuned-llama-v2.0",
        "4614": "MythoMix-L2-13b",
        "4615": "canarim-7b",
        "4616": "Aurora-V2-DLEC",
        "4617": "Wizard-Vicuna-13B-Uncensored-GPTQ",
        "4618": "openbuddy-openllama-13b-v7-fp16",
        "4619": "QuantumLM",
        "4620": "pygmalion-instruct",
        "4621": "Luna-AI-Llama2-Uncensored",
        "4622": "speechless-hermes-coig-lite-13b",
        "4623": "firefly-llama2-13b-chat",
        "4624": "llama2-7b-hf-instruction-lora",
        "4625": "una-llama-7b",
        "4626": "MLewd-v2.4-13B",
        "4627": "airoboros-33b-gpt4-1.2",
        "4628": "chinese-llama-2-13b",
        "4629": "tau-0.5B",
        "4630": "Colossal-LLaMA-2-7b-base",
        "4631": "speechless-llama2-hermes-orca-platypus-13b",
        "4632": "Luban-13B",
        "4633": "llama-2-7b-alpaca-gpt4",
        "4634": "speechless-llama2-dolphin-orca-platypus-13b",
        "4635": "codellama_7b_DolphinCoder",
        "4636": "llama-op-v4",
        "4637": "airoboros-33b-gpt4-m2.0",
        "4638": "wizard-vicuna-13B-GPTQ",
        "4639": "SuperPlatty-30B",
        "4640": "test-help-steer-filtered-orig",
        "4641": "openllama-7b-base",
        "4642": "Xwin-LM-13B-V0.1",
        "4643": "llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o_gate_up_down",
        "4644": "pythia-12b-sft-v8-2.5k-steps",
        "4645": "llama-2-7b-small-model-new",
        "4646": "pythia-12b-sft-v8-rlhf-2k-steps",
        "4647": "CollectiveCognition-v1.1-Nebula-7B",
        "4648": "CreativityEngine",
        "4649": "Llama-2-13b-hf_Open-Platypus-8bit-att",
        "4650": "Python-Code-13B",
        "4651": "manticore-13b-chat-pyg",
        "4652": "Llama-7B-rollercoaster_v2",
        "4653": "LosslessMegaCoder-llama2-7b-mini",
        "4654": "GZDX-1.1B",
        "4655": "PrathameshLLM-7B",
        "4656": "vicuna-chinese-replication-v1.1",
        "4657": "mistral_v1",
        "4658": "WizardCoder-Python-34B-V1.0",
        "4659": "SOLID_SFT-WoDPO-WoMixQ",
        "4660": "SUS-Chat-72B",
        "4661": "Llama-2-13b-hf_Open-Platypus",
        "4662": "TarsChattyBasev0.1",
        "4663": "TekniumAiroboros-Nebula-7B",
        "4664": "OpenOrca-Platypus2-13B-GPTQ",
        "4665": "llama-2-13b-hf-platypus",
        "4666": "sitebunny-13b",
        "4667": "Aurora_22e_Test",
        "4668": "wizard-vicuna-13B-HF",
        "4669": "Dans-PersonalityEngine-13b",
        "4670": "Asimov-7B-v1",
        "4671": "Llama-2-13B-Instruct-v0.2",
        "4672": "llama-3-8b-DUS-initialized",
        "4673": "chinese-alpaca-2-7b-16k",
        "4674": "2x-LoRA-Assemble-13B",
        "4675": "gpt4all-j",
        "4676": "Alpagasus-2-13B-QLoRA-pipeline",
        "4677": "Nous-Hermes-13b-pl-lora_unload",
        "4678": "PrathameshLLM-2B",
        "4679": "llama-13b-pretrained-sft-do2",
        "4680": "Indic-gemma-2b-finetuned-sft-Navarasa-2.0",
        "4681": "ReMM-SLERP-L2-13B",
        "4682": "Brunhilde-13b",
        "4683": "Free_Sydney_13b_HF",
        "4684": "sheep-duck-llama-2-13b",
        "4685": "Huginn-13b-v1.2",
        "4686": "huginnv1.2",
        "4687": "meditron-7b-chat",
        "4688": "EstopianMaid-13B",
        "4689": "wizard-vicuna-13b",
        "4690": "starcoder",
        "4691": "Guanaco-13B-Uncensored",
        "4692": "gpt4-alpaca-lora-13B-HF",
        "4693": "openchat_v2",
        "4694": "Sailor-4B-Chat",
        "4695": "speechless-codellama-platypus-13b",
        "4696": "duplicitous-mammal-13b",
        "4697": "MLewd-ReMM-L2-Chat-20B-Inverted",
        "4698": "BrainDerp2",
        "4699": "OpenOrca-Platypus2-13B",
        "4700": "MythoMax-L2-13b",
        "4701": "vicuna-13b-v1.3-PL-lora_unload",
        "4702": "baize-v2-13b",
        "4703": "Qllama-.5B-RAG-1",
        "4704": "Deita-500m",
        "4705": "wizard-mega-13B-GPTQ",
        "4706": "btlm-v1-7b-base-v0.1",
        "4707": "Stheno-Inverted-1.2-L2-13B",
        "4708": "leo-hessianai-13b",
        "4709": "airoboros-l2-13b-3.0",
        "4710": "Mythical-Destroyer-L2-13B",
        "4711": "LWM-7B-1M-1000000ctx-AEZAKMI-3_1-1702",
        "4712": "LIMA-13b-hf",
        "4713": "webMistral-7B",
        "4714": "mcq-hal-vicuna-13b-v1.5",
        "4715": "ALMA-13B-Pretrain",
        "4716": "Llama2-chat-AYT-13B",
        "4717": "ChatAYT-Lora-Assamble-Marcoroni",
        "4718": "PuffedConvo13bLoraE4",
        "4719": "monika-ddlc-7b-v1",
        "4720": "GPT4-x-Alpasta-13b",
        "4721": "duplicitous-slurpbeast-13b",
        "4722": "Llama2-13b-sharegpt4",
        "4723": "Sailor-4B",
        "4724": "gpt-sw3-20b-instruct",
        "4725": "DaringFortitude",
        "4726": "Kimiko-13B-fp16",
        "4727": "Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16_merged",
        "4728": "openbuddy-mistral-7b-v13.1",
        "4729": "Mister",
        "4730": "PuffedLIMA13bQLORA",
        "4731": "guanaco-13B-HF",
        "4732": "Metharme-13b-Merged",
        "4733": "vicuna-13b-delta-v1.1",
        "4734": "llama-2-13b-FINETUNE2_TEST_2.2w",
        "4735": "MythoLogic-13b",
        "4736": "vicuna-13B-1.1-HF",
        "4737": "Wizard-Vicuna-13B-Uncensored-HF",
        "4738": "Llama-2-7b-chat-finetune-AUTOMATE",
        "4739": "MythoBoros-13b",
        "4740": "Vicuna-13B-CoT",
        "4741": "vicuna-13b-1.1",
        "4742": "minima-3b-layla-v2",
        "4743": "minima-3b-layla-v1",
        "4744": "youri-7b",
        "4745": "delta13b",
        "4746": "Wizard-Vicuna-13B-Uncensored",
        "4747": "Manticore-13b-Chat-Pyg-Guanaco",
        "4748": "airoboros-l2-13b-gpt4-m2.0",
        "4749": "vicuna-13b-v1.1",
        "4750": "vic_critT_20pr",
        "4751": "CodeLlama-13b-Python-hf",
        "4752": "Vicuna-13B-CoT-fp16",
        "4753": "zarafusionex-1.2-l2-7b",
        "4754": "Qwen-Orpo-v1",
        "4755": "airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
        "4756": "Llama-2-13b-ft-instruct-es",
        "4757": "SambaLingo-Thai-Chat",
        "4758": "OpenOrca-Platypus2-13B-thera-1250",
        "4759": "firefly-llama2-13b-pretrain",
        "4760": "llama-2-13b-Open-Platypus_2.5w",
        "4761": "llama2-7b-chat-hf-guanaco",
        "4762": "cria-llama2-7b-v1.3",
        "4763": "Dans-PileOfSets-Mk1-llama-13b-merged",
        "4764": "falcon-7B-case-5",
        "4765": "Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16",
        "4766": "manticore-13b-chat-pyg-GPTQ",
        "4767": "Llama-2-7b-chat-hf-afr-100step-v2",
        "4768": "llama2-7b-layla",
        "4769": "Emerhyst-20B",
        "4770": "speechless-codellama-dolphin-orca-platypus-13b",
        "4771": "Orca-2-13b-SFT_v5",
        "4772": "llama-2-13B-LoRA-assemble",
        "4773": "openchat_v2_w",
        "4774": "vicuna-13b-v1.3.0-GPTQ",
        "4775": "llama_13b_sharegpt94k_fastchat",
        "4776": "Mistral-v0.3-6B",
        "4777": "mpt-7b-8k",
        "4778": "ELYZA-japanese-Llama-2-7b",
        "4779": "airoboros-c34b-2.1",
        "4780": "storytime-13b",
        "4781": "airocoder-34b-2.1",
        "4782": "Nous-Hermes-13b",
        "4783": "vigogne-13b-chat",
        "4784": "falcon-7B-case-1",
        "4785": "falcon-7B-case-4",
        "4786": "oasst-llama-13b-2-epochs",
        "4787": "CodeMind-gemma-2b",
        "4788": "BrainDerp",
        "4789": "llama-2-13b-4bit-alpaca-gpt4",
        "4790": "Sina-Odin-7b-Merge",
        "4791": "speechless-code-mistral-orca-7b-v1.0",
        "4792": "vicuna-7b-v1.5",
        "4793": "chimera-inst-chat-13b-hf",
        "4794": "firefly-llama-13b",
        "4795": "Novocode7b-v2",
        "4796": "speechless-llama2-luban-orca-platypus-13b",
        "4797": "llama2-13B-eugeneparkthebest",
        "4798": "airoboros-13b-gpt4-1.1",
        "4799": "llama2_7b_code",
        "4800": "MiniMA-2-3B",
        "4801": "WizardLM-13B-V1.1",
        "4802": "gpt4-alpaca-lora-13b-decapoda-1024",
        "4803": "Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16_merged",
        "4804": "llama-2-16b-nastychat",
        "4805": "WizardLM-13B-V1.1-GPTQ",
        "4806": "chinese-alpaca-33b-merged",
        "4807": "starcoderplus",
        "4808": "BrainDerp3",
        "4809": "llama-7b",
        "4810": "firefly-llama-13b-v1.2",
        "4811": "WizardLM_13B_juniper",
        "4812": "mcq-vicuna-13b-v1.5",
        "4813": "llama-2-13B-instructed",
        "4814": "L2-7b-Orca-WVG-Test",
        "4815": "airophin-13b-pntk-16k-fp16",
        "4816": "Llama2-Chinese-7b-Chat",
        "4817": "Alpacino13b",
        "4818": "llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o_gate_up_down",
        "4819": "Guanaco-Vicuna-7B-L2",
        "4820": "falcon-7B-case-0",
        "4821": "CodeLlama-7b-Instruct-hf",
        "4822": "llama-2-7b-rockwell-final",
        "4823": "lima-test",
        "4824": "L2-7b-Guanaco-Uncensored",
        "4825": "Stheno-1.1-L2-13B",
        "4826": "saqr-7b-beta",
        "4827": "llama2_7b_mmlu",
        "4828": "starcoderbase",
        "4829": "ELYZA-japanese-Llama-2-7b-instruct",
        "4830": "Llama-2-7b-chat-hf-afr-200step-v2",
        "4831": "airoboros-13b-gpt4",
        "4832": "L2-7b-Beluga-WVG-Test",
        "4833": "Baichuan2-7B-Base-LLaMAfied",
        "4834": "GiftedConvo13bLoraNoEcons",
        "4835": "tableBeluga-7B-instruct-pl-lora_unload",
        "4836": "llama-2-7b-guanaco-instruct-sharded",
        "4837": "StableBeluga-7B",
        "4838": "llama-2-13b-chat-hf-phr_mental_therapy",
        "4839": "vicuna-7b-v1.5-lora-timedial-unit-080082",
        "4840": "Llama-2-7b-orca-v1",
        "4841": "13B-BlueMethod",
        "4842": "zarafusionex-1.1-l2-7b",
        "4843": "WizardCoder-Python-13B-LoRa",
        "4844": "GiftedConvo13bLoraNoEconsE4",
        "4845": "MM-ReMM-L2-20B",
        "4846": "GenAI-Nova-13B",
        "4847": "Llama-2-13b-longlora-32k-ft",
        "4848": "airoboros-13b-gpt4-1.4",
        "4849": "llama-2-7b-claude-chat",
        "4850": "airoboros-13b-gpt4-1.4-fp16",
        "4851": "30B-Lazarus",
        "4852": "vigogne-2-7b-chat",
        "4853": "airoboros-l2-13b-gpt4-2.0",
        "4854": "Qwen1.5-0.5B-Chat",
        "4855": "testmodel2",
        "4856": "TinyLlama-Cinder-Math-Train",
        "4857": "QuantumLM-7B",
        "4858": "vicuna-7b-v1.5-lora-timedial-unit-080091",
        "4859": "pythia-12b-pre-v8-12.5k-steps",
        "4860": "llama-13b",
        "4861": "testmodel-3",
        "4862": "vicuna-13b",
        "4863": "gpt4all-alpaca-oa-codealpaca-lora-13b",
        "4864": "vigogne-7b-chat",
        "4865": "zaraxe-l2-7b",
        "4866": "OpenLlama13B-Guanaco",
        "4867": "Llama2-7B-guanaco-1k",
        "4868": "saqr-7b-merged",
        "4869": "test-Qwen1.5-0.5B",
        "4870": "LlongOrca-7B-16k",
        "4871": "elm-test",
        "4872": "tamil-llama-13b-instruct-v0.1",
        "4873": "Platypus2-13B-LoRa",
        "4874": "llama2-to-mistral-diff",
        "4875": "Alpacino-SuperCOT-13B",
        "4876": "llama2-7b-chat-hf-v4",
        "4877": "speechless-tools-7b",
        "4878": "speechless-orca-platypus-coig-lite-2k-0.6e-13b",
        "4879": "llama-2-7b-hf-guanaco-1k",
        "4880": "open-llama-7b-v2-open-instruct",
        "4881": "trurl-2-7b-pl-instruct_unload",
        "4882": "zephyr-neural-chat-frankenmerge11b",
        "4883": "WizardVicuna2-13b-hf",
        "4884": "falcon-7B-case-c",
        "4885": "Qwen1.5-0.5B-Chat_llamafy",
        "4886": "llama_mirror_13b_v1.0",
        "4887": "CAMEL-13B-Role-Playing-Data",
        "4888": "Koss-7B-chat",
        "4889": "airophin-v2-13b-PI-8k-fp16",
        "4890": "MistralLite-summ-sft-e1",
        "4891": "llama2-7b-chat-hf-dpo",
        "4892": "openchat_8192",
        "4893": "Llama-2-7b-chat-hf",
        "4894": "L2-7b-Base-Guanaco-Uncensored",
        "4895": "llama-2-7b-claude-chat-rp",
        "4896": "vicuna-7b-v1.5-lora-timedial",
        "4897": "yehoon_llama2",
        "4898": "Wizard-Vicuna-13B-juniper",
        "4899": "zarafusionix-l2-7b",
        "4900": "vicuna-7b-v1.5-PL-lora_unload",
        "4901": "Samantha-1.11-7b",
        "4902": "LLaMa-2-PeanutButter_v18_A-7B",
        "4903": "llama-13b-supercot",
        "4904": "EMO-2B",
        "4905": "orca_mini_v3_7b",
        "4906": "airoboros-13B-HF",
        "4907": "Starlight-7B",
        "4908": "llama2-7b-chat-hf-v2",
        "4909": "araproje-llama2-7b-hf",
        "4910": "CAMEL-13B-Combined-Data",
        "4911": "test_llama2_7b",
        "4912": "SOLAR-10.7B-Instruct-v1.0-128k",
        "4913": "trurl-2-7b",
        "4914": "llama-2-coder-7b",
        "4915": "vicuna-7b-v1.5-lora-mixed-datasets",
        "4916": "Flash-Llama-7B",
        "4917": "test-llama2-7b",
        "4918": "vicuna-7b-v1.5-lora-mixed-datasets-time-unit",
        "4919": "Platypus2xOpenOrca-13B-LoRa",
        "4920": "llama-2-13b-Open_Platypus_and_ccp_2.6w-3_epoch",
        "4921": "Qwen1.5-32B-Chat",
        "4922": "L2-7b-Base-WVG-Uncensored",
        "4923": "Platypus2-13B",
        "4924": "minillm-7B-init-13B-sft",
        "4925": "Llama-2-7B-physics",
        "4926": "manatee-7b",
        "4927": "falcon-7B-case-8",
        "4928": "tau-0.5B-instruct-DPOP",
        "4929": "dpo-Qwen1.5-0.5B-Chat-alignment-handbook",
        "4930": "airoboros-13b",
        "4931": "airoboros-l2-13b-gpt4-1.4.1",
        "4932": "L2-7b-Base-test-WVG",
        "4933": "Nous-Capybara-7B",
        "4934": "LLaMarada-7B-v0.1-16bit",
        "4935": "Llama-2-7b-chat-hf-instruct-pl-lora_unload",
        "4936": "chronos-wizardlm-uc-scot-st-13B-GPTQ",
        "4937": "firefly-ziya-13b",
        "4938": "GPT-NeoXT-Chat-Base-20B",
        "4939": "elliott_Llama-2-7b-hf",
        "4940": "Capybara-7B",
        "4941": "spatial-vicuna-7b-v1.5-LoRA",
        "4942": "koala-13B-HF",
        "4943": "Mistral-Pygmalion-7b",
        "4944": "gemma-pro-3.1b-ko-v0.5",
        "4945": "llama-2-13b-Open_Platypus_and_ccp_2.6w",
        "4946": "EverythingLM-13b-V2-16k",
        "4947": "ToolLLaMA-7b-LoRA",
        "4948": "Medusa-13b",
        "4949": "FLAN-Llama-7B-2_Llama2-7B-Flash_868_full_model",
        "4950": "NeuralReyna-Mini-1.8B-v0.3",
        "4951": "cria-llama2-7b-v1.3_peft",
        "4952": "Nova-13B",
        "4953": "Uncensored-Jordan-7B",
        "4954": "yayi-7b-llama2",
        "4955": "PlatYi-34B-Llama-Q-v3",
        "4956": "Synthia-7B",
        "4957": "airoboros-33b-2.1",
        "4958": "llama-2-7b-hf_open-platypus",
        "4959": "nsfw-noromaid-mistral-instruct",
        "4960": "mistral-megamerge-dare-7b",
        "4961": "vic15-exp-syn-fight-cp3838",
        "4962": "platypus-2-22b-relora",
        "4963": "kollama2-7b-v2",
        "4964": "chinese-llama-2-13b-16k",
        "4965": "LLaMa-2-PeanutButter_v18_B-7B",
        "4966": "Mistral-22B-v0.1",
        "4967": "EverythingLM-13b-16k",
        "4968": "MultiLora-drop-sharegpt",
        "4969": "llama2_7b_zh",
        "4970": "Llama2-13B-no_robots-alpaca-lora",
        "4971": "gpt-sw3-6.7b-v2-instruct",
        "4972": "carl-33b",
        "4973": "vicuna-7b-v1.5-16k",
        "4974": "orca_mini_v2_13b",
        "4975": "llama-2-7b-hf-small-shards-Samantha-V1-SFT",
        "4976": "pygmalion-2-7b",
        "4977": "falcon-7B-case-2",
        "4978": "llama-2-7b-guanaco-fp16",
        "4979": "ELYZA-japanese-Llama-2-7b-fast",
        "4980": "Pygmalion-2-13b-SuperCOT",
        "4981": "platypus2-22b-relora",
        "4982": "ELYZA-japanese-Llama-2-7b-fast-instruct",
        "4983": "lacda-2-7B-chat-v0.1",
        "4984": "tigerbot-7b-sft",
        "4985": "goims",
        "4986": "Llama-2-7b-hf-instruct-pl-lora_unload",
        "4987": "Platypus2-mini-7B",
        "4988": "vicuna-7b-v1.3-instruct-pl-lora_unload",
        "4989": "llama-2-7b-int4-python-code-18k",
        "4990": "Pygmalion-Vicuna-1.1-7b",
        "4991": "Chinese-LLaMA-2-7B-hf",
        "4992": "falcon-7B-case-6",
        "4993": "falcon-7B-case-3",
        "4994": "Barcenas-7b",
        "4995": "airoboros-l2-7b-2.2.1",
        "4996": "DukunLM-7B-V1.0-Uncensored",
        "4997": "Limarp-Platypus2-13B-QLoRA-0.80-epoch",
        "4998": "PULI-LlumiX-32K",
        "4999": "LLama2-7B-Structural-Prune-1.25x",
        "5000": "starcoder-finetune-selfinstruct",
        "5001": "Mixtral-6x7B-Instruct-v0.1-bfloat16-Trimmed024567",
        "5002": "llama2-7b-hf-guanaco",
        "5003": "llama2-7b-chat-hf-v3",
        "5004": "speechless-codellama-orca-13b",
        "5005": "Airoboros-L2-13B-2.1-GPTQ",
        "5006": "llama-2-7b-instruct-peft",
        "5007": "kollama2-7b",
        "5008": "LLaMa-2-PeanutButter_v10-7B",
        "5009": "L2-7b-Synthia-WVG-Test",
        "5010": "llama-2-7b-chat-hf-phr_mental_health-2048",
        "5011": "gemma-2b-nlaf-v0",
        "5012": "OpenHathi-7B-Hi-v0.1-Base",
        "5013": "Qwen1.5-0.5B-vortex-v2",
        "5014": "speechless-orca-platypus-coig-lite-4k-0.5e-13b",
        "5015": "Gemma-2B-Samvaad",
        "5016": "L2-7b-Hermes-WVG-Test",
        "5017": "llama2_7b_chat_uncensored",
        "5018": "phi-gemma-nlaf-v1",
        "5019": "Buttocks-7B-v1.1",
        "5020": "pooled_gqa_mix_chatml_sft",
        "5021": "gemma-pro-2.8b-ko-v0",
        "5022": "guanaco-13b-llama-2",
        "5023": "Nous-Hermes-llama-2-7b",
        "5024": "SpeechlessV1-Nova-13B",
        "5025": "Buttocks-7B-v1.0",
        "5026": "LIMA2-13b-hf",
        "5027": "llama-13b-4bit-alpaca",
        "5028": "vicuna-7b-v1.3",
        "5029": "Llama-2-7b-ft-instruct-es",
        "5030": "SOLID-SFT-DPO-MixQV3-SOLIDRejected-SFTChosen-Zephyr-7b-beta",
        "5031": "llama-3-8b-slow-DUS-method-1",
        "5032": "dolphin-llama2-7b",
        "5033": "MelangeA-70b",
        "5034": "kunkun_dat",
        "5035": "gemma-2b-openhermes",
        "5036": "Llama-2-7b-hf-eli5-cleaned-wiki65k-1024_qlora_merged",
        "5037": "leo-hessianai-7b",
        "5038": "fietje-2b-chat",
        "5039": "openhermes-gemma-2b-it",
        "5040": "mistral-se-inst-ppo",
        "5041": "DeepCode-7B-Aurora-v12",
        "5042": "em_german_leo_mistral",
        "5043": "vicuna-7b-delta-v1.1",
        "5044": "EverythingLM-13b-V3-peft",
        "5045": "AmberChat",
        "5046": "vicuna-7b-1.1",
        "5047": "gemma-3b-002",
        "5048": "llama_7b_lora",
        "5049": "starcoder_mirror",
        "5050": "ANIMA-Nectar-v2",
        "5051": "tamil-llama-7b-instruct-v0.2",
        "5052": "bactrian-x-llama-13b-merged",
        "5053": "phi-gemma-nlaf-v0",
        "5054": "baichuan-vicuna-chinese-7b",
        "5055": "WizardLM-Uncensored-SuperCOT-StoryTelling-30b",
        "5056": "calm2-7b-chat-dpo-experimental",
        "5057": "vicuna_7B_vanilla_1.1",
        "5058": "gemma-2b-it",
        "5059": "gpt-neox-20b",
        "5060": "Reyna-Mini-1.8B-v0.1",
        "5061": "autotrain-xva0j-mixtral8x7b",
        "5062": "gemma-2b-it-nlai-p1",
        "5063": "LLongMA-2-13b-16k",
        "5064": "starcoderbase-7b",
        "5065": "EverythingLM-13B-16K-GPTQ",
        "5066": "cosmo-1b",
        "5067": "TinyLlama-1.1B-OpenHermes-2.5-Chat-v0.1-sft",
        "5068": "Llama2-7b-openorca-mc-v2",
        "5069": "Kan-Llama-SFT-v0.5",
        "5070": "DeepCode-7B-Aurora-v13",
        "5071": "ypotryll-22b-epoch2-qlora",
        "5072": "gemma-2b-it-nlai-v0",
        "5073": "gemma-nlaf-v1",
        "5074": "deepseek-math-7b-rl",
        "5075": "U-Amethyst-20B",
        "5076": "gemma-2b-it-sp-test",
        "5077": "Xwin-LM-7B-V0.1",
        "5078": "WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ",
        "5079": "gemma-2b-it-sp-test1",
        "5080": "gemma-2b-it-sp-test-openherms-step500",
        "5081": "csg-wukong-1B",
        "5082": "llama3",
        "5083": "glaive-coder-7b",
        "5084": "openthaigpt-1.0.0-7b-chat",
        "5085": "CodeLlama-7b-Python-hf",
        "5086": "CodeLlama-7b-hf",
        "5087": "leo-hessianai-7b-chat",
        "5088": "starchat-beta",
        "5089": "chatml-pyg-v1",
        "5090": "falcon_7b_DolphinCoder",
        "5091": "Moko-DARE",
        "5092": "llama-7b-SFT_ds_eli5_1024_r_64_alpha_16_merged",
        "5093": "Poro-34B-GPTQ",
        "5094": "Orca-2-13b-SFT-v6",
        "5095": "guanaco-7B-HF",
        "5096": "OpenHermes-7B",
        "5097": "Evaloric-1.1B-test",
        "5098": "Platypus2-13B-QLoRa",
        "5099": "Uncensored-Frank-7B",
        "5100": "Llama-2-7B-GPTQ",
        "5101": "metharme-7b",
        "5102": "tora-code-7b-v1.0",
        "5103": "MedicWizard-7B",
        "5104": "TinyLlama-QuantumQuill-chat",
        "5105": "OpenOrca-Preview1-13B",
        "5106": "Athena-v1",
        "5107": "calm2-7b-chat",
        "5108": "Tinyllama-Cinder-1.3B-Reason-Test",
        "5109": "spicyboros-7b-2.2",
        "5110": "Mist_LLaMA-2-7B-1024_V3",
        "5111": "komodo-7b-chat",
        "5112": "Qwen-LLaMAfied-7B-Chat",
        "5113": "ANIMA-Nectar-v3",
        "5114": "longchat-7b-v1.5-32k",
        "5115": "blossom-v2-llama2-7b",
        "5116": "yuj-v1",
        "5117": "Qwen-las-v0.1",
        "5118": "kuchiki-1.1-l2-7b",
        "5119": "mamba-7b-rw",
        "5120": "openbuddy-zephyr-7b-v14.1",
        "5121": "gpt-sw3-40b",
        "5122": "Ember-7B-v0.1",
        "5123": "bagel-8x7b-v0.2",
        "5124": "falcon-7b-instruct",
        "5125": "Llama-2-7b-hf-eli5-cleaned-1024_qlora_merged",
        "5126": "llama-7b-SFT_eli5_wiki65k_1024_r_64_alpha_16_merged",
        "5127": "WizardCoder-Python-7B-V1.0",
        "5128": "Llama-2-7B-32K-Instruct",
        "5129": "neural-chat-7b-v3-1-Nebula-v2-7B",
        "5130": "codegemma-2b",
        "5131": "Huginn-13b-V4",
        "5132": "opencoderplus",
        "5133": "Chronos-Beluga-v2-13bfp16",
        "5134": "pygmalion-7b",
        "5135": "llama-7b-SFT_ds_wiki65k_1024_r_64_alpha_16_merged",
        "5136": "Qwen-sft-la-v0.1",
        "5137": "Huginn-13b-v4.5",
        "5138": "dociproLLM-7B",
        "5139": "falcon-7b",
        "5140": "Huginn-v3-13b",
        "5141": "llama_7b_qlora",
        "5142": "zarablend-1.1-l2-7b",
        "5143": "Wizard-Vicuna-7B-Uncensored-HF",
        "5144": "AlpacaGPT4-7B-elina",
        "5145": "K2S3-Llama2-13b-v1.0",
        "5146": "Wizard-Vicuna-7B-Uncensored",
        "5147": "llama7b_alpaca_1gpu_bf16",
        "5148": "llama-7b-SFT-qlora-eli5-wiki_DPO_ds_RM_top_2_1024_r_64_alpha_16",
        "5149": "openbuddy-deepseek-10b-v17.1-4k",
        "5150": "Quark-464M-v0.2",
        "5151": "Llama2-7b-openorca-mc-v2-dpo",
        "5152": "kuchiki-l2-7b",
        "5153": "vicuna-7b-v1.5-lora-mctaco",
        "5154": "falcon_7b_norobots",
        "5155": "TinyLlama-1.1B-SlimOrca-Function-Calling-3T",
        "5156": "Llama-2-7b-hf-flan2022-1.2M",
        "5157": "GOAT-7B-Community",
        "5158": "mpt-7b-8k-chat",
        "5159": "zarablend-l2-7b",
        "5160": "Huginn-19b-prototype",
        "5161": "yi6",
        "5162": "baize-healthcare-lora-7B",
        "5163": "Nova-13B-50-step",
        "5164": "pygmalion-6b-vicuna-chatml",
        "5165": "llama7b-wizardlm-unfiltered",
        "5166": "llama_7b_sharegpt94k_fastchat",
        "5167": "amber_fine_tune_sgall",
        "5168": "Huginn-13b-FP16",
        "5169": "ex-llm-e1",
        "5170": "LLaMA-2-7B-32K",
        "5171": "Luminia-13B-v3",
        "5172": "gemma-3.5b-orpo-selfmerge",
        "5173": "speechless-orca-platypus-coig-lite-4k-0.6e-13b",
        "5174": "vicuna-7B-physics",
        "5175": "Guanaco-7B-Uncensored",
        "5176": "llama_7b_qlora_pds-eval",
        "5177": "orca_mini_v2_ger_7b",
        "5178": "baize-v2-7b",
        "5179": "longchat-13b-16k",
        "5180": "lloma_step200",
        "5181": "mpt-7b-chat",
        "5182": "llama_7b_qlora_cds",
        "5183": "Pythia-Chat-Base-7B",
        "5184": "Llama2-7b-openorca-mc-v1",
        "5185": "stable-vicuna-13B-HF",
        "5186": "airoboros-l2-7b-gpt4-m2.0",
        "5187": "yayi-13b-llama2",
        "5188": "samantha-1.1-llama-33b",
        "5189": "gemma-2b-sft-telugu",
        "5190": "Tinyllama-Cinder-1.3B-Reason-Test.2",
        "5191": "Airavata",
        "5192": "SOLAR-Platypus-10.7B-v2",
        "5193": "Delta-4B-notso-base",
        "5194": "oasst-pythia-12b-pretrained-sft",
        "5195": "mpt-7b",
        "5196": "test-custom-llama",
        "5197": "gowizardlm",
        "5198": "MultiLora-sharegpt",
        "5199": "WizardMath-70B-V1.0",
        "5200": "vitruv_2",
        "5201": "palmyra-20b-chat",
        "5202": "openthaigpt-1.0.0-alpha-7b-chat-ckpt-hf",
        "5203": "llama-v2-7b-32kC-Security",
        "5204": "GPT2-774M-CINDER-SHOW-MULTI-CHAT",
        "5205": "Chronorctypus-Limarobormes-13b",
        "5206": "LightGPT",
        "5207": "airoboros-13b-gpt4-1.2",
        "5208": "LIMA2-7b-hf",
        "5209": "vigogne-2-7b-instruct",
        "5210": "Quark-464M-v0.1.alpha",
        "5211": "chinese-llama-2-7b",
        "5212": "Llama-2-7b-chat-orcah",
        "5213": "amber_fine_tune_sg_part1",
        "5214": "OLMo-7B-hf",
        "5215": "llama2-22b-daydreamer-v3",
        "5216": "TinyLlama-3T-Cinder-v1.3",
        "5217": "open-llama-3b-v2-elmv3",
        "5218": "vicuna-class-tutor-7b-ep3",
        "5219": "mistral-7b-raw-sft",
        "5220": "llama2-7b-raw-sft",
        "5221": "airoboros-7b-gpt4-1.4",
        "5222": "ennodata-7b",
        "5223": "PuddleJumper-13b-V2",
        "5224": "amber_fine_tune_001",
        "5225": "koala-7B-HF",
        "5226": "mtor-2x7b",
        "5227": "airoboros-gpt-3.5-turbo-100k-7b",
        "5228": "llama-7b-4bit-alpaca",
        "5229": "nart-100k-7b",
        "5230": "llama-base-7b",
        "5231": "POLAR-14B-v0.2",
        "5232": "Sailor-1.8B-Chat",
        "5233": "Planner-7B-fp16",
        "5234": "airoboros-l2-13b-2.1",
        "5235": "Stable-Platypus2-13B-QLoRA-0.80-epoch",
        "5236": "EulerMath-Mistral-7B",
        "5237": "Galactica-6.7B-EssayWriter",
        "5238": "gemma-2b-ko-dev-pbmt192",
        "5239": "open_llama_7b_v2",
        "5240": "Code-290k-6.7B-Instruct",
        "5241": "WizardLM-30B-Uncensored-Guanaco-SuperCOT-30b",
        "5242": "OpenBezoar-HH-RLHF-DPO",
        "5243": "guanaco-unchained-llama-2-7b",
        "5244": "frankencria-llama2-12.5b-v1.3-m.2",
        "5245": "deepseek-coder-1.3b-chat-and-function-calling",
        "5246": "Newton-7B",
        "5247": "KoreanLM-hf",
        "5248": "palmyra-large",
        "5249": "falcon-rw-1b-instruct-openorca",
        "5250": "PuddleJumper-13b",
        "5251": "very-test",
        "5252": "stablelm-3b-4e1t",
        "5253": "MFANN3b",
        "5254": "Nusantara-2.7b-Indo-Chat",
        "5255": "vicuna-7B-chemical",
        "5256": "Nusantara-1.8b-Indo-Chat",
        "5257": "firefly-llama2-7b-pretrain",
        "5258": "WizardLM-7B-Uncensored",
        "5259": "PygmalionCoT-7b",
        "5260": "open_llama_13b",
        "5261": "GoLLIE-7B",
        "5262": "llama-2-13b-QLoRA",
        "5263": "airoboros-l2-7b-gpt4-2.0",
        "5264": "effi-7b",
        "5265": "h2ogpt-oasst1-512-20b",
        "5266": "deepseek-coder-1.3b-chat",
        "5267": "llama7b-qlora",
        "5268": "airoboros-7b-gpt4-1.1",
        "5269": "Falcon-7B-Fintued-Finance-Stock-E",
        "5270": "dolphin-2.2-yi-34b-200k",
        "5271": "galactica-6.7b-finetuned",
        "5272": "oasst-gpt-neox-20b-1000-steps",
        "5273": "RedPajama-INCITE-7B-Base",
        "5274": "WizardLM-13b-OpenAssistant-Uncensored",
        "5275": "oasst-sft-4-pythia-12b-epoch-3.5",
        "5276": "medalpaca-7b",
        "5277": "ReMM-L2-13B",
        "5278": "Chat-AYB-Platypus2-13B",
        "5279": "FLAMA-0.1-3B",
        "5280": "ReMM-L2-13B-PIPPA",
        "5281": "gpt-j-6b",
        "5282": "Platypus2-13B-QLoRA-0.80-epoch",
        "5283": "neu-sai-it1",
        "5284": "GPT-NeoX-20B-Skein",
        "5285": "oasst-gpt-neox-20b-3000-steps",
        "5286": "Mistral-4B-FT-2",
        "5287": "llama-2-26b-trenchcoat-stack",
        "5288": "Evaloric-1.1B-V.0.1",
        "5289": "orca_mini_v2_7b",
        "5290": "WizardCoder-Guanaco-15B-V1.1",
        "5291": "Code-Llama-3-8B",
        "5292": "gpt4-x-alpaca",
        "5293": "dpo-Qwen1.5-0.5B-Chat",
        "5294": "Baichuan-7B",
        "5295": "airoboros-2.1-llama-2-13B-QLoRa",
        "5296": "Amber",
        "5297": "galpaca-30b",
        "5298": "llama2-platypus-llama2-chat-13B-hf",
        "5299": "scarlett-33b",
        "5300": "Tinyllama-1.3B-Cinder-Reason-Test-2",
        "5301": "airoboros-l2-7b-gpt4-1.4.1",
        "5302": "Cinder-1.3B-Test",
        "5303": "GPT-J-Pyg_PPO-6B",
        "5304": "mpt-7b-instruct",
        "5305": "LLama2-7B-Structural-Prune-1.2x",
        "5306": "WizardMath-7B-V1.0",
        "5307": "Tulpar-7b-v0",
        "5308": "MiniMA-3B",
        "5309": "leo-hessianai-7b-chat-bilingual",
        "5310": "llama-2-7b-1-percent-open-orca-1000-steps-v0",
        "5311": "Sailor-1.8B",
        "5312": "vigogne-7b-instruct",
        "5313": "codegen-16B-nl",
        "5314": "PPO_Pygway-V8p4_Dev-6b",
        "5315": "gpt-neox-20b-full-precision",
        "5316": "Llama2-7b-sharegpt4",
        "5317": "Javalion-R",
        "5318": "giraffe-7b",
        "5319": "palmyra-med-20b",
        "5320": "TinyUltra-4x1.1B-Base-Alpha",
        "5321": "InstructPalmyra-20b",
        "5322": "TakeTwo",
        "5323": "xr_dat_test_part2",
        "5324": "llama2-ko-7B-model",
        "5325": "stablelm-base-alpha-7b-v2",
        "5326": "PPO_Shygmalion-V8p4_Dev-6b",
        "5327": "open-llama-3b-v2-chat",
        "5328": "chinese-llama-2-7b-16k",
        "5329": "zephyr-1b-olmo-sft-qlora",
        "5330": "Barcenas-3b",
        "5331": "CodeBarcenas-7b",
        "5332": "Qwen-LLaMAfied-HFTok-7B-Chat",
        "5333": "Kan-LLaMA-7B-SFT-v0.1-sharded",
        "5334": "tora-7b-v1.0",
        "5335": "Project-Baize-v2-7B-GPTQ",
        "5336": "OpenBezoar-SFT",
        "5337": "Tiny-Knight-1.1b-v0.1",
        "5338": "h2ogpt-gm-oasst1-en-1024-20b",
        "5339": "opt-iml-max-30b",
        "5340": "Qwen1.5-4B-Chat",
        "5341": "starchat-alpha",
        "5342": "Raiden-16x3.43B",
        "5343": "csg-wukong-1B-sft-bf16",
        "5344": "illuni-llama-2-ko-7b-test",
        "5345": "vicuna-class-shishya-all-hal-7b-ep3",
        "5346": "TinyNaughtyLlama-v1.0",
        "5347": "airoboros-13b-gpt4-1.3",
        "5348": "HelpingAI-Lite-2x1B",
        "5349": "TinyLlama-1.1B-Chat-v1.0",
        "5350": "OpenOrcaPlatypus2-Platypus2-13B-QLora-0.80-epoch",
        "5351": "speechless-coder-ds-1.3b",
        "5352": "pythia-1b-spin-iter1",
        "5353": "Tinyllama-1.3B-Cinder-Reason-Test",
        "5354": "carl-7b",
        "5355": "Huginn-22b-Prototype",
        "5356": "airoboros-7b-gpt4-1.4.1-qlora",
        "5357": "lamatama",
        "5358": "TinyLlama-1.1B-orca-v1.0",
        "5359": "TinyLlama-MoE-Chat-0.1",
        "5360": "OrcaMini-Platypus2-13B-QLoRA-0.80-epoch",
        "5361": "Janin-R",
        "5362": "GPT-NeoX-20B-Erebus",
        "5363": "RedTulu-Uncensored-3B-0719",
        "5364": "TinyLlama-1.1B-Chat-v1.0-x2-MoE",
        "5365": "tinyllama-chat",
        "5366": "instruct-13b",
        "5367": "gogpt2-7b",
        "5368": "TinyLlama-QuantumQuill-chat-08-05-24-2",
        "5369": "tinyllama-1.1b-layla-v4",
        "5370": "llama2-13b-chinese-v2",
        "5371": "d-Qwen1.5-1.8B",
        "5372": "open-llama-3b-claude-30k",
        "5373": "Palworld-SME-13b",
        "5374": "codegen-6B-nl",
        "5375": "airoboros-l2-7b-2.1",
        "5376": "h2ogpt-gm-oasst1-multilang-1024-20b",
        "5377": "merge_dolly-v2-3b_dpo_test",
        "5378": "2xbagel-dpo-34b-v0.2",
        "5379": "csg-wukong-1B-sft-dpo-bf16",
        "5380": "airoboros-7b",
        "5381": "rwkv-raven-14b",
        "5382": "mommygpt-3B",
        "5383": "Dolly_Shygmalion-6b",
        "5384": "pythia-13b-deduped-green_devil",
        "5385": "zephyr-tiny-dpo-qlora",
        "5386": "GPT-2-SlimOrcaDeduped-airoboros-3.1-MetaMathQA-SFT-124M",
        "5387": "TinyLlama-Cinder-1.3B-Test.2",
        "5388": "internlm2-math-20b-llama",
        "5389": "TinyLlama-1.1B-Chat-v0.6",
        "5390": "dpo-qlora-Qwen1.5-0.5B-Chat-xtuner",
        "5391": "shearedplats-2.7b-v2-instruct-v0.1",
        "5392": "chinese-alpaca-plus-13b-hf",
        "5393": "pooled_gqa_mix",
        "5394": "WizardCoder-15B-V1.0",
        "5395": "PsyOrca2-13b-DARE",
        "5396": "airoboros-7b-gpt4-1.2",
        "5397": "blockchainlabs_tinyllama_fusion_LHK_yunkong",
        "5398": "Barcenas-Tiny-1.1b-DPO",
        "5399": "BigMaid-20B-v1.0",
        "5400": "WoolyHermes-1.1B",
        "5401": "pygmalion-6b",
        "5402": "Ferret-7B",
        "5403": "vortex-3b-v2",
        "5404": "WizardLM-13B-Uncensored",
        "5405": "TinyWand-SFT",
        "5406": "zephyr-danube-sft-qlora",
        "5407": "open_llama_7b_v2_med_instruct",
        "5408": "vigogne-2-13b-instruct",
        "5409": "gogpt2-13b",
        "5410": "fusedyi",
        "5411": "dolly-v2-3b",
        "5412": "Ferret_7B",
        "5413": "Dolly_Shygmalion-6b-Dev_V8P2",
        "5414": "EverythingLM-13b-V3-16k",
        "5415": "palmer-002.5",
        "5416": "pythia-1b-dpo-full",
        "5417": "pythia-1.4b-sft-full",
        "5418": "open_llama_3b_glaive_assistant_v0.1",
        "5419": "Janin-GPTJ",
        "5420": "pythia-1b-sft-full",
        "5421": "GPT-J-6B-Shinen",
        "5422": "TinyLlama-1.1B-Chat-v1.0-intel-dpo",
        "5423": "OpenHermes-Symbolic-Mistral-7B",
        "5424": "open_llama_3b_glaive_v0.1",
        "5425": "Qwenchana-0.5B-restart",
        "5426": "TinyMix",
        "5427": "TinyWombat-1.8b-Chat-v.1",
        "5428": "open_llama_3b_glaive_code_v0.1",
        "5429": "open_llama_13b_600bt_preview",
        "5430": "tinyllama-coder-py-v13",
        "5431": "llama-2-ko-7b",
        "5432": "smolphin-test-stack-sorted",
        "5433": "Ambari-7B-Instruct-v0.1-sharded",
        "5434": "KobbleTiny",
        "5435": "MiniLlama-1.8b-Chat-v0.1",
        "5436": "OLMo-1B-hf",
        "5437": "Ensemble5-Platypus2-13B-QLora-0.80-epoch",
        "5438": "TinyWand-DPO",
        "5439": "HelpingAI-Lite-4x1b",
        "5440": "GPT-J-Pyg_PPO-6B-Dev-V8p4",
        "5441": "gogpt-7b",
        "5442": "open-llama-3b-v2-wizard-evol-instuct-v2-196k",
        "5443": "tinyllama-coder-py-v14",
        "5444": "tinyllama_merged_test",
        "5445": "pooled_gqa_mix_chatml",
        "5446": "open_llama_3b_code_instruct_0.1",
        "5447": "weblab-10b-instruction-sft",
        "5448": "Javelin-GPTJ",
        "5449": "Medusa-7B-bf16",
        "5450": "DopeyTinyLlama-1.1B-v1",
        "5451": "pythia-1b-self-kto-iter0",
        "5452": "Stable-Platypus2-13B",
        "5453": "lloma_step400",
        "5454": "Galpaca-30b-MiniOrca",
        "5455": "speechless-codellama-airoboros-orca-platypus-13b",
        "5456": "PPO_Shygmalion-6b",
        "5457": "tamil-llama-7b-instruct-v0.1",
        "5458": "Orca-2-13B-16k",
        "5459": "Qllama-tiny-.5B-test-1",
        "5460": "Sailor-0.5B-Chat",
        "5461": "Hippolyta-7B-bf16",
        "5462": "Platypus2-7B",
        "5463": "TinyLlama-1.1B-2.5T-chat-and-function-calling",
        "5464": "manovyadh-1.1B-v1-chat",
        "5465": "starcoderbase-3b",
        "5466": "opt-13b",
        "5467": "gpt-sw3-356m-instruct",
        "5468": "pythia-1b-sft-50k",
        "5469": "airoboros-7b-gpt4",
        "5470": "airoboros-7b-gpt4-fp16",
        "5471": "Tiny-Cowboy-1.1b-v0.1",
        "5472": "Tiny-Pirate-1.1b-v0.1",
        "5473": "firefly-bloom-2b6-v2",
        "5474": "zephyr-tinyllama-sft-qlora",
        "5475": "Dolly_Malion-6b",
        "5476": "TinyLlama-repeat",
        "5477": "zararp-l2-7b",
        "5478": "pythia-12b",
        "5479": "DeciCoder-1b",
        "5480": "DistiLabelOrca-TinyLLama-1.1B",
        "5481": "Javelin-R",
        "5482": "PPO_Pygway-6b-Mix",
        "5483": "TinyLlama-1.1B-1T-OpenOrca",
        "5484": "KobbleTinyV2-1.1B",
        "5485": "dopeyplats-1.1b-2T-v1",
        "5486": "pythia-1b-dpo",
        "5487": "tinyllama-dare",
        "5488": "falcon-rw-1b-chat",
        "5489": "SOLID-SFT-DPO-MixQV2-SOLIDChosen-SFTRejected-Zephyr-7b-beta",
        "5490": "opt-66b",
        "5491": "TakeThree",
        "5492": "Javalion-GPTJ",
        "5493": "Bio-Saul-Dolphin-Beagle-Breadcrumbs",
        "5494": "TinyLamma-SFT",
        "5495": "ChanMalion",
        "5496": "h2ogpt-oasst1-512-12b",
        "5497": "gemma-7B-alpaca-case-1-2",
        "5498": "pythia-6.9b-deduped",
        "5499": "open-llama-3b-everything-v2",
        "5500": "RedPajama-INCITE-7B-Instruct",
        "5501": "zephyr-tiny-sft-qlora-quantized-2",
        "5502": "pyg-instruct-wizardlm",
        "5503": "gpt-sw3-1.3b-instruct",
        "5504": "tinyllama_frankenmerge",
        "5505": "h2ogpt-oig-oasst1-256-6_9b",
        "5506": "open_llama_3b_instruct_v_0.2",
        "5507": "babyllama-v0.6",
        "5508": "FinanceConnect-13B",
        "5509": "RedPajama-INCITE-Instruct-7B-v0.1",
        "5510": "posi_13b",
        "5511": "ZySec-1B",
        "5512": "HelpingAI-Lite-1.5T",
        "5513": "open_llama_7b",
        "5514": "Adventien-GPTJ",
        "5515": "smartyplats-3b-v2",
        "5516": "RedPajama-INCITE-Base-7B-v0.1",
        "5517": "csg-wukong-1B-orpo-bf16",
        "5518": "MediKAI",
        "5519": "landmark-attention-llama7b-fp16",
        "5520": "Ambari-7B-base-v0.1-sharded",
        "5521": "TinyLlama-1.1B-step-2T-lr-5-5ep-oasst1-top1-instruct-V1",
        "5522": "pythia-1b-kto-iter0",
        "5523": "GPT-R",
        "5524": "Orca-2-7B-16k",
        "5525": "CodeEngine",
        "5526": "h2ogpt-gm-oasst1-en-1024-open-llama-7b-preview-400bt",
        "5527": "falcon_7b_3epoch_norobots",
        "5528": "Skegma-GPTJ",
        "5529": "cosmo-3b-test-v0.2",
        "5530": "bloom-3b",
        "5531": "FinguAI-Chat-v1",
        "5532": "Llama-2-7b-chat-hf-flan2022-1.2M",
        "5533": "fialka-7B-v3",
        "5534": "pythia-1.4b",
        "5535": "Tiny-Vicuna-1B",
        "5536": "AIRIC-The-Intern",
        "5537": "open-llama-3b-everythingLM-2048",
        "5538": "ablation-model-fineweb-v1",
        "5539": "shearedplats-2.7b-v2",
        "5540": "MistralInstructLongish",
        "5541": "TinyDolphin-2.8-1.1b",
        "5542": "llama2-7b-hf-chat-lora-v3",
        "5543": "Mia-1B",
        "5544": "ennodata-13b-8bit-raw-15epoch",
        "5545": "TinyLlama-1.1B-miniguanaco",
        "5546": "TinyLlama-chat-SFT",
        "5547": "h2o-danube-1.8b-base",
        "5548": "GPT-J-6B-Skein",
        "5549": "Medusa-1.1-L2-7B",
        "5550": "TinyLlama-1.1B-intermediate-step-1431k-3T",
        "5551": "alpaca-native",
        "5552": "TinyLlamax2-1.1b",
        "5553": "SOLID-SFT-DPO-MixQV3-SOLIDChosen-SFTRejected-Zephyr-7b-beta",
        "5554": "zyte-1B",
        "5555": "TinyLlama-1.1B-intermediate-step-1195k-token-2.5T",
        "5556": "LLaMA2-13B-Psyfighter2",
        "5557": "Nusantara-0.8b-Indo-Chat",
        "5558": "cisco-iNAM-1.1B",
        "5559": "Brunhilde-13b-v3",
        "5560": "WizardCoder-Guanaco-15B-V1.0",
        "5561": "weblab-10b",
        "5562": "tinyllama-coder-py-v12",
        "5563": "pythia-12b-deduped",
        "5564": "Nous-Hermes-Platypus2-13B-QLoRA-0.80-epoch",
        "5565": "csg-wukong-1B-chat-v0.1",
        "5566": "TinyLlama-1.1B-intermediate-step-955k-token-2T",
        "5567": "Nous-Hermes-2-SOLAR-10.7B-v1.1",
        "5568": "Tukan-1.1B-Chat-reasoning-sft-COLA",
        "5569": "llama2-13b-ft-openllm-leaderboard-v1",
        "5570": "RedPajama-INCITE-Instruct-3B-v1",
        "5571": "cosmo-3b-test",
        "5572": "zyte-v1-1.1B",
        "5573": "youri-7b-chat",
        "5574": "TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-3epochs-oasst1-top1-instruct-V1",
        "5575": "GPT-J-6B-Janeway",
        "5576": "lora_opt13b_10e5",
        "5577": "CAlign-alpaca-7b",
        "5578": "model_007_13b_v2",
        "5579": "pooled_gqa_chat",
        "5580": "dpo-test-hermes-open-llama-3b",
        "5581": "bloom-7b1",
        "5582": "zyte-1.1b",
        "5583": "K2S3-SOLAR-11b-v1.0",
        "5584": "openhermes-danube2-sft-qlora",
        "5585": "openthaigpt-1.0.0-beta-7b-chat-ckpt-hf",
        "5586": "MiniMerlin-3b-v0.1",
        "5587": "mc_model_v1",
        "5588": "stablelm-4e1t-2b-v0.1",
        "5589": "ToRoLaMa-7b-v1.0",
        "5590": "BioTATA-7B",
        "5591": "fbopt-350m-8bit",
        "5592": "kunkun_dat_llama_13b_alpaca",
        "5593": "gpt-neo-2.7B",
        "5594": "ennodata-raw-pankajmathur-13b-peft",
        "5595": "TinyDolphin-2.8.2-1.1b-laser",
        "5596": "Moderator-Chan_GPT-JT-6b",
        "5597": "tinyllama-1.1B-intermediate-step-715k-1.5T-dpo-lora-merged",
        "5598": "MLewd-L2-13B",
        "5599": "K2S3-SOLAR-11b-v2.0",
        "5600": "TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-4epochs-oasst1-top1-instruct-V1",
        "5601": "vicuna-7b-v1.5-lora-mctaco-modified1",
        "5602": "fialka-13B-v3",
        "5603": "phoenix-inst-chat-7b",
        "5604": "Marx-3B",
        "5605": "llama-2-13b-Beluga-QLoRA",
        "5606": "TacoBeLLM",
        "5607": "pythia-410m-sft-full",
        "5608": "smolphin-test-bottomheavy",
        "5609": "tinyllama_eng_long",
        "5610": "phi-2-ko-v0.1",
        "5611": "amber_fine_tune_ori",
        "5612": "Llama-2-ko-7b-Chat",
        "5613": "RedPajama-INCITE-Base-3B-v1",
        "5614": "Cerebras-GPT-13B",
        "5615": "GPT-JT-6B-v0",
        "5616": "tinyllama-1.1b-layla-v1",
        "5617": "oasst-pythia-12b-reference",
        "5618": "tinyllama_eng_short1",
        "5619": "gpt-sw3-6.7b-v2",
        "5620": "Marx-3B-V2",
        "5621": "Nous-Hermes-13B-SuperHOT-8K-fp16",
        "5622": "ShortKing-3b-v0.3",
        "5623": "palmer-002",
        "5624": "dolly-v2-12b",
        "5625": "TinyLlama-1.1B-intermediate-step-1431k-3T-laser-dpo",
        "5626": "Stellaris-internlm2-20b-r256",
        "5627": "GPT-JT-6B-v1",
        "5628": "Test-7B-pthrough",
        "5629": "Sailor-0.5B",
        "5630": "openbuddy-mistral-7b-v13-base",
        "5631": "Pygmalion_AlpacaLora-7b",
        "5632": "mamba-gpt-3b-v3",
        "5633": "neural-chat-7b-v3",
        "5634": "tinyllama_eng_short",
        "5635": "gpt-neox-20b-4bit-alpaca",
        "5636": "Qwen-sft-ls-v0.1",
        "5637": "koishi-instruct-3b",
        "5638": "LLama2-7B-Structural-Prune-1.5x",
        "5639": "dolly-v2-7b",
        "5640": "cloudymixtral7Bx2-nectar-0.2",
        "5641": "OpenLlama-Platypus-3B",
        "5642": "JARVIS",
        "5643": "WizardVicuna-Uncensored-3B-0719",
        "5644": "TinyLlama-1.1B-2.5T-chat",
        "5645": "zararp-1.1-l2-7b",
        "5646": "22-Neuro_Model",
        "5647": "DiffMerge_Pygmalion_Main-onto-V8P4",
        "5648": "pygmalion-6b-roleplay",
        "5649": "Evaloric-1.1B",
        "5650": "Llama-3-pruned-45B-Drobeta-Turnu-Severin",
        "5651": "SmolLlama-1.5B",
        "5652": "opt-30b",
        "5653": "pythia-1b-deduped",
        "5654": "MobileLLaMA-1.4B-Base",
        "5655": "LLmRA-3B-v0.1",
        "5656": "OPT-6.7B-Erebus",
        "5657": "pythia-2.7b",
        "5658": "tinyllama-coder-py-4bit-v4",
        "5659": "Med_GPT2",
        "5660": "open-llama-3b-v2-layla",
        "5661": "Nanbeige-16B-Base-32K-llama",
        "5662": "bloom-3b-conversational",
        "5663": "pythia-6.7b",
        "5664": "smartyplats-3b-v1",
        "5665": "localmentor_25K_3epochs_tinyllama",
        "5666": "wizard-orca-3b",
        "5667": "SmolPlatypus-1.5B-Sorted",
        "5668": "MistralLite",
        "5669": "Sheared-LLaMA-2.7B",
        "5670": "h2ogpt-gm-oasst1-en-1024-12b",
        "5671": "gpt2_137m_DolphinCoder",
        "5672": "deepseek-coder-1.3b-instruct",
        "5673": "TinyllamaMix-1.1B",
        "5674": "tmm-1b",
        "5675": "Covasna-0.1",
        "5676": "gpt-sw3-126m-instruct",
        "5677": "codegen-6B-multi",
        "5678": "megachat",
        "5679": "SmolPlatypus-1.5B",
        "5680": "TinyLlama-MoE-Chat",
        "5681": "airoboros-7b-gpt4-1.3",
        "5682": "openbuddy-openllama-3b-v10-bf16",
        "5683": "Griffin-3B",
        "5684": "tiny_starcoder_py",
        "5685": "GPT-JT-Moderation-6B",
        "5686": "SRBOSGPT-7B-slerp",
        "5687": "oasst-pythia-12b-flash-attn-5000-steps",
        "5688": "tinyllama",
        "5689": "Tinypus-1.5B",
        "5690": "pythia-1.3b",
        "5691": "WizardVicuna-open-llama-3b-v2",
        "5692": "Medical-ChatBot",
        "5693": "phi2-mmlu-lora",
        "5694": "SuperChat-7B",
        "5695": "h2ogpt-oig-oasst1-512-6_9b",
        "5696": "gpt-sw3-20b",
        "5697": "nucleus-22B-token-500B",
        "5698": "palmyra-base",
        "5699": "opt-6.7b",
        "5700": "MT7Bi-wizard-3-alpha-dpo",
        "5701": "open-cabrita3b",
        "5702": "smolphin-test1",
        "5703": "gemma-2b-ko-v0",
        "5704": "Walter-SOLAR-11B",
        "5705": "gpt2-xl_lima",
        "5706": "NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "5707": "13B-Thorns-l2",
        "5708": "speechless-tora-code-7b-v1.0",
        "5709": "starcoderbase-1b",
        "5710": "2x-LoRA-Assemble-Platypus2-13B",
        "5711": "Gaja-v1.00",
        "5712": "Flash-Llama-3B",
        "5713": "RedPajama-INCITE-Chat-Instruct-3B-V1",
        "5714": "TinyLlama-1.1B-Remix-V.2",
        "5715": "yayi-7b",
        "5716": "openllama_3b_EvolInstruct_lora_merged",
        "5717": "qd-phi-1_5",
        "5718": "Luban-Platypus2-13B-QLora-0.80-epoch",
        "5719": "llama-2-13b-platypus-vicuna-wizard",
        "5720": "boomer-1b",
        "5721": "elysa_model",
        "5722": "PandaLM-Alpaca-7B-v1",
        "5723": "llama-2-13b-vicuna-wizard",
        "5724": "open_llama_3b_v2",
        "5725": "vortex-3b",
        "5726": "MythoMix-Platypus2-13B-QLoRA-0.80-epoch",
        "5727": "gpt-j-6B-Dolly",
        "5728": "CroissantLLMBase",
        "5729": "pythia-2.8b-deduped",
        "5730": "GPT-J-6B-Adventure",
        "5731": "Gaja-vv1",
        "5732": "bloom-1b7",
        "5733": "openthaigpt-1.0.0-beta-13b-chat-hf",
        "5734": "TinyLlama-748M-Reason-With-Cinder-Test-2",
        "5735": "QwenSailorMerge",
        "5736": "Alpaca-tuned-gpt2",
        "5737": "pythia-1.4b-deduped-sharegpt",
        "5738": "stablelm-tuned-alpha-7b",
        "5739": "cherry_5_7B",
        "5740": "crow-1b",
        "5741": "MindLLM",
        "5742": "FLAMA-0.5-3B",
        "5743": "mptk-1b",
        "5744": "gpt2-large",
        "5745": "pythia-1.4b-deduped",
        "5746": "rwkv-4-7b-pile",
        "5747": "xglm-1.7B",
        "5748": "smol_llama-101M-GQA",
        "5749": "llama-pile-350b",
        "5750": "7B-redpajama-conditional-alpha",
        "5751": "Healix-3B",
        "5752": "OPT-6.7B-Nerybus-Mix",
        "5753": "I-Code-NousLlama7B-slerp",
        "5754": "metharme-1.3b",
        "5755": "dopeyshearedplats-1.3b-v1",
        "5756": "phi-2-upscaled-4B-instruct-v0.1",
        "5757": "WizardVicuna-3B-0719",
        "5758": "Instruct_GPT_v1",
        "5759": "FLOR-1.3B-xat",
        "5760": "16b-experiment-llama-2",
        "5761": "TinyLlama-Mistral",
        "5762": "gpt2-xl-sft",
        "5763": "ko-en-llama2-13b",
        "5764": "PULI-GPTrio",
        "5765": "OPT-13B-Erebus",
        "5766": "blockchainlabs_tinyllama_fusion_LHK_yunkong_v2",
        "5767": "pragna-1b",
        "5768": "QuantumQuill-chat-v1",
        "5769": "Puma-3B",
        "5770": "Alpaca_refine_tuned_gpt2_large",
        "5771": "42dot_LLM-PLM-1.3B",
        "5772": "WizardLM-13B-V1-1-SuperHOT-8K-fp16",
        "5773": "smolphin-test-stack",
        "5774": "Algae-550M-base",
        "5775": "open-llama-0.7T-7B-open-instruct-v1.1",
        "5776": "smol_llama-220M-GQA",
        "5777": "llama-3-8b-slow-DUS-random-method2",
        "5778": "rwkv-4-3b-pile",
        "5779": "LLaMA2-13B-Tiefighter",
        "5780": "42dot_LLM-SFT-1.3B",
        "5781": "Anima-7B-100K",
        "5782": "firefly-bloom-7b1",
        "5783": "phi2",
        "5784": "TinyLlama-1.1B-Chat-v0.3",
        "5785": "My_GPT2",
        "5786": "galactica-6.7b-ReFT-GSM8k",
        "5787": "Kaori-34b-v2",
        "5788": "OPT-350M-Nerys-v2",
        "5789": "TinyDolphin-2.8.1-1.1b",
        "5790": "OPT-6B-nerys-v2",
        "5791": "vicuna-7b-v1.5-lora-mctaco-modified2",
        "5792": "Alpaca_refine_gpt2_e0_se1",
        "5793": "math_gpt2_sft",
        "5794": "pythia-410m",
        "5795": "WizardLM-13B-V1-1-SuperHOT-8K-GPTQ",
        "5796": "Tulpar-7b-v1",
        "5797": "RedPajama-INCITE-Chat-3B-Instruction-Tuning-with-GPT-4",
        "5798": "mamba-gpt-3b-v4",
        "5799": "WizardVicuna-Uncensored-3B-instruct-PL-lora_unload",
        "5800": "gpt2",
        "5801": "black_goo_recipe_c",
        "5802": "chinese-alpaca-plus-7b-hf",
        "5803": "Deacon-1b",
        "5804": "Mistral-7B-AEZAKMI-v1",
        "5805": "zephyr-smol_llama-100m-dpo-full",
        "5806": "kaori-34b-v4",
        "5807": "calypso-3b-alpha-v2",
        "5808": "tinyllama-coder-py-4bit-v3",
        "5809": "TinyLlama-1.1B-1.5T-OpenOrca-Alpha",
        "5810": "smol_llama-220M-openhermes",
        "5811": "SmolLlama-1.5B-Sorted",
        "5812": "stablelm-base-alpha-7b",
        "5813": "SmolLlamix-8x101M",
        "5814": "LL7M",
        "5815": "b1ade-1b",
        "5816": "SmolLlama-1.5B-Bottomheavy",
        "5817": "open_llama_3b_600bt_preview",
        "5818": "10k_v1_lora_qkvo_rank28_v2",
        "5819": "FusedKuno",
        "5820": "llama-r",
        "5821": "oasst-sft-1-pythia-12b",
        "5822": "3B-redpajama-conditional-alpha",
        "5823": "llama3-8b-ultrafeedback-dpo",
        "5824": "pythia-2.8b-4bit-alpaca",
        "5825": "Aquila2-34B",
        "5826": "Mistral_solar-slerp",
        "5827": "latent_gpt2_medium_alpaca_e4",
        "5828": "ChickaQ",
        "5829": "Alpaca_spin_tuned_gpt2_large",
        "5830": "CrimsonPajama",
        "5831": "ReasonixPajama-3B-HF",
        "5832": "RedPajama-INCITE-Chat-3B-v1",
        "5833": "orca_mini_3b_juniper",
        "5834": "zephyr-220m-dpo-full",
        "5835": "Cerebras-GPT-6.7B",
        "5836": "stablelm-tuned-alpha-3b",
        "5837": "tinyllama-coder-py-4bit-v10",
        "5838": "TinyExperts-v0-4x1B",
        "5839": "SmolLlamix-8x101M-take2",
        "5840": "gpt_bigcode-santacoder",
        "5841": "open-llama-7b-open-instruct",
        "5842": "hf_checkpoint2_01052024",
        "5843": "TinyLlama-1.1B-step-50K-105b",
        "5844": "tinyllama-1.1b-chat-v0.3_platypus",
        "5845": "oasst-pythia-12b-6000-steps",
        "5846": "wangchanglm-7.5B-sft-enth",
        "5847": "shearedplats-1.3b-v1",
        "5848": "pile-7b-250b-tokens",
        "5849": "gpt-sw3-6.7b",
        "5850": "Guanaco-3B-Uncensored",
        "5851": "blossom-v2-3b",
        "5852": "Bean-3B",
        "5853": "black_goo_recipe_a",
        "5854": "fialka-13B-v3.1",
        "5855": "oasst-pythia-6.9b-4000-steps",
        "5856": "pygmalion-350m",
        "5857": "Cerebras-GPT-2.7B-Alpaca-SP",
        "5858": "bloomz-7b1-sa-v0.1",
        "5859": "Silver-Sun-11B",
        "5860": "TinyLlama-1.1B-Chat-v0.1",
        "5861": "bloomz-7b1-mt-sft-chat",
        "5862": "numfalm-3b",
        "5863": "chinese-llama-plus-13b-hf",
        "5864": "Mistral-offspring-1-3",
        "5865": "TinyLlama-1.1B-intermediate-step-480k-1T",
        "5866": "opt-iml-max-1.3b",
        "5867": "falcon-rw-1b",
        "5868": "Yousei-22B",
        "5869": "PT_GPTNEO350_ATG",
        "5870": "numfa_v2-1b",
        "5871": "RedPajama-INCITE-7B-Chat",
        "5872": "bloom-zh-3b-chat",
        "5873": "ShortKingv0.1",
        "5874": "platypus-1_8b",
        "5875": "llama-2-4b",
        "5876": "opt-1.3b-rlhf",
        "5877": "Sheared-LLaMA-1.3B",
        "5878": "stablelm-base-alpha-3b",
        "5879": "13B-Ouroboros",
        "5880": "Cerebras-GPT-2.7B",
        "5881": "Cerebras-GPT-590M",
        "5882": "LlamaCorn-1.1B",
        "5883": "TinyLlama-3T-1.1bee",
        "5884": "numfalm_v2-1b",
        "5885": "open_llama_3b",
        "5886": "rwkv-raven-3b",
        "5887": "rwkv-4-169m-pile",
        "5888": "tinyllama-oasst1-top1-instruct-full-lr1-5-v0.1",
        "5889": "RedPajama-INCITE-Chat-7B-v0.1",
        "5890": "gpt-neo-1.3B",
        "5891": "fialka-13B-v4",
        "5892": "GodziLLa-30B",
        "5893": "bloomz-3b-sft-chat",
        "5894": "radintloom-mistral-7b-fusion-dpo",
        "5895": "rwkv-4-430m-pile",
        "5896": "Minueza-32M-Base",
        "5897": "black_goo_recipe_d",
        "5898": "pythia-160m-deduped-step92k-193bt",
        "5899": "lora_opt6.7b_10e5",
        "5900": "orca_mini_7b",
        "5901": "Sheared-Pythia-160m",
        "5902": "Athena-8B",
        "5903": "Cerebras_1.3b_Quantized",
        "5904": "MistralLite-11B",
        "5905": "OPT-13B-Nerybus-Mix",
        "5906": "camel-5b-hf",
        "5907": "TinyLlama-1.1B-FFT-Test2",
        "5908": "galactica-6.7b-evol-instruct-70k",
        "5909": "megatron-GPT-2-345m-EvolInstruct",
        "5910": "latent_gpt2_medium_alpaca_e2",
        "5911": "RWKV-4-PilePlus-169M-20230520-done-ctx4096",
        "5912": "deacon-3b",
        "5913": "zephyr-220m-sft-full",
        "5914": "test-22B",
        "5915": "Quokka_2.7b",
        "5916": "Llama-3-7b",
        "5917": "dopeyshearedplats-2.7b-v1",
        "5918": "blossom-v1-3b",
        "5919": "Silver-Sun-v2-11B",
        "5920": "Dorflan",
        "5921": "Tiny-Llama-3-7b",
        "5922": "mc_data_30k_from_platpus_orca_7b_10k_v1_lora_qkvo_rank14_v2",
        "5923": "stablelm-7b-sft-v7-epoch-3",
        "5924": "rwkv-4-14b-pile",
        "5925": "774M-03_09_2024",
        "5926": "bloom-560m",
        "5927": "falcon-1b-t-sft",
        "5928": "RedPajama-INCITE-Chat-3B-ShareGPT-11K",
        "5929": "based-30b",
        "5930": "pythia-70m",
        "5931": "Guanaco-3B-Uncensored-v2",
        "5932": "OPT-350M-Erebus",
        "5933": "gpt2-alpaca-gpt4",
        "5934": "OPT-2.7B-Nerys-v2",
        "5935": "opt-350m",
        "5936": "Mixnueza-6x32M-MoE",
        "5937": "Shiki-v2-m7",
        "5938": "finetuned-gpt2-tiny",
        "5939": "pythia-410m-deduped",
        "5940": "model-a-48.5m",
        "5941": "gpt-neo-125m",
        "5942": "scarlett-7b",
        "5943": "RedPajama-INCITE-Chat-3B-v1-RL-LoRA-8bit-test1",
        "5944": "LLmRa-2.7B",
        "5945": "SSH_300M",
        "5946": "Asclepius-Llama2-7B",
        "5947": "rwkv-raven-7b",
        "5948": "rugpt3large_based_on_gpt2",
        "5949": "galactica-6.7b-ReFT-Rerank-GSM8k",
        "5950": "gpt2_test",
        "5951": "GPTNeo350M-Instruct-SFT",
        "5952": "Deer-3b",
        "5953": "zephyr_0.2_a2.5",
        "5954": "OPT-2.7B-Erebus",
        "5955": "opt125m_10e5_lr2e-7",
        "5956": "verysmol_llama-v11-KIx2",
        "5957": "gpt3-finnish-13B",
        "5958": "bloom-560m-RLHF",
        "5959": "gpt2023",
        "5960": "Instruct_GPT",
        "5961": "TinyLlama-1.1B-intermediate-step-240k-503b",
        "5962": "test-3b",
        "5963": "vicuna-tutor-shishya-model-7b-ep3",
        "5964": "NEBULA-XB-v1.0_SFT_2_epoch",
        "5965": "LLongMA-3b-LIMA",
        "5966": "ShearedLlama-1.3b-FFT-Test1",
        "5967": "gpt-sw3-356m",
        "5968": "pythia-31m",
        "5969": "dolphin-2.6-mistral-7b-dpo-5.93B",
        "5970": "xglm-4.5B",
        "5971": "new-turn-2",
        "5972": "instruct-12b",
        "5973": "bloom-1b1",
        "5974": "Gaja-v2.00",
        "5975": "Minueza-32M-Deita",
        "5976": "xglm-7.5B",
        "5977": "zaraxls-l2-7b",
        "5978": "Gaja-v2.00-dpo",
        "5979": "megatron-gpt2-345m",
        "5980": "pythia-160m-deduped",
        "5981": "256_5epoch",
        "5982": "h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
        "5983": "Cerebras-GPT-1.3B",
        "5984": "RWKV-4-PilePlus-430M-20230520-6162-1018Gtokens-ctx4098",
        "5985": "ScarletPajama-3B-HF",
        "5986": "gpt-neo-1.3B-4bit-alpaca",
        "5987": "opt-2.7b",
        "5988": "smol_llama-81M-tied",
        "5989": "TinyNewsLlama-1.1B",
        "5990": "opt-125m",
        "5991": "OmegLLaMA-3B",
        "5992": "xglm-564M",
        "5993": "dlite-v2-1_5b",
        "5994": "pythia-160m",
        "5995": "mamba-gpt-3b",
        "5996": "distillgpt2Cinder",
        "5997": "Narumashi-11B",
        "5998": "openbuddy-mixtral-8x7b-v16.2-32k",
        "5999": "TinyLlama-QuantumQuill-chat-08-05-24-3",
        "6000": "TinyLlama-1.1bee",
        "6001": "open-calm-7b",
        "6002": "OPT-30B-Erebus",
        "6003": "sappha-2b-v3",
        "6004": "Stheno-1.3-L2-13B",
        "6005": "BioMistral-7B-TIES",
        "6006": "OPT-13B-Nerys-v2",
        "6007": "Minueza-32M-UltraChat",
        "6008": "tinyllama_PY-CODER-4bit-lora_4k-v5",
        "6009": "math_gpt2",
        "6010": "Mixsmol-4x400M-v0.1-epoch2",
        "6011": "wangchanglm-7.5B-sft-en-sharded",
        "6012": "codeparrot",
        "6013": "OEvortex",
        "6014": "neuralfalcon-1b-v1",
        "6015": "gemma-2b-data-std",
        "6016": "Guanaco-3B-Uncensored-v2-GPTQ",
        "6017": "gpt2_open-platypus",
        "6018": "Tinyllama-616M-Cinder-DPO-With-GGUF",
        "6019": "Bloom_1b_Quantized",
        "6020": "mistral-orpo-alpha",
        "6021": "OPT-2.7B-Nerybus-Mix",
        "6022": "Mixsmol-4x400M-v0.1-epoch1",
        "6023": "opt125m_10e2",
        "6024": "opt125m_10e5_lr2e-6",
        "6025": "llama2-ppo",
        "6026": "gpt-2-xl-EvolInstruct",
        "6027": "gpt-2-xl_camel-ai-physics",
        "6028": "Bio-Mistralv2-Squared",
        "6029": "vigogne2-enno-13b-sft-lora-4bit",
        "6030": "pruned_mistral",
        "6031": "T3Q-ko-solar-dpo-v6.0",
        "6032": "Facebook_opt_1.3b_Quantized",
        "6033": "lamini-neo-1.3b",
        "6034": "1.3b",
        "6035": "mixtral_stack_llama",
        "6036": "bloom-560m-4bit-alpaca",
        "6037": "opt-1.3b",
        "6038": "gpt2-dolly",
        "6039": "Asclepius-Llama2-13B",
        "6040": "Alpaca-7B-v1",
        "6041": "smol_llama-4x220M-MoE",
        "6042": "lamini-cerebras-590m",
        "6043": "gogpt-3b-bloom",
        "6044": "EastAsia-4x7B-Moe-experiment",
        "6045": "polyglot-ko-12.8b",
        "6046": "Llama3merge5",
        "6047": "Stellaris-internlm2-20b-r128",
        "6048": "Manticore-13B-Chat-Pyg-Guanaco-SuperHOT-8K-GPTQ",
        "6049": "phi-2-audio-super",
        "6050": "DolphinMini-Mistral-7B",
        "6051": "aqua-smaug-hermes-8B",
        "6052": "A.I.Kant-Test_Llama-3-8B-Instruct_v0.1.1",
        "6053": "spin_gpt2_medium_alpaca_e2",
        "6054": "Sparse0.5_OPT-1.3",
        "6055": "GALAXY_v03_slimorca_1_epoch_50k_DPO_1_epoch_30k",
        "6056": "OpenMath-Mistral-7B-v0.1-hf",
        "6057": "orca_mini_13B-GPTQ",
        "6058": "pruned-yi-3b-prerelease-ckpt01",
        "6059": "590m",
        "6060": "Merge-Mayhem-L3-V2",
        "6061": "TinyLlama-Remix",
        "6062": "black_goo_recipe_b",
        "6063": "Sheared-LLaMA-1.3B-ShareGPT",
        "6064": "vicuna-mmlu-val-only-correct-mcq-7b-ep2",
        "6065": "Smol-Llama-101M-Chat-v1",
        "6066": "TinyLlama-3T-Cinder-v1.2",
        "6067": "gpt-sw3-1.3b",
        "6068": "Alpaca_spin_gpt2_e0_se1",
        "6069": "Psydestroyer-20B",
        "6070": "Libra-19B",
        "6071": "Camel-Platypus2-13B",
        "6072": "open-calm-large",
        "6073": "Mixtral-GQA-400m-v2",
        "6074": "bloomz-7b1",
        "6075": "gpt-neo-125m-neurallinguisticpioneers",
        "6076": "Pygmalion-13b-Merged",
        "6077": "TinyOpenHermes-1.1B-4k",
        "6078": "Llama-2-7b-WikiChat-fused",
        "6079": "Stheno-Mix-L2-20B",
        "6080": "LLmRa-1.3B",
        "6081": "open_llm_leaderboard_demo2",
        "6082": "bloom-560m-RLHF-v2",
        "6083": "RedPajama-INCITE-Chat-3B-v1-FT-LoRA-8bit-test1",
        "6084": "vicuna-7b-v1.5-lora-mctaco-modified4",
        "6085": "Platypus2xOpenOrca-13B-LoRa-v2",
        "6086": "Nape-0",
        "6087": "Narumashi-RT-11B-test",
        "6088": "Athena-Platypus2-13B-QLora-0.80-epoch",
        "6089": "gpt2-conversational-or-qa",
        "6090": "GPT-2-Large-115k-steps",
        "6091": "gpt-sw3-126m",
        "6092": "Confluence-Renegade-7B",
        "6093": "BioMistralMerged",
        "6094": "dlite-v1-1_5b",
        "6095": "llama-160m",
        "6096": "orca_mini_3b",
        "6097": "gpt2-large-conversational",
        "6098": "proofGPT-v0.1",
        "6099": "DARE-Merging",
        "6100": "KoAlpaca-Polyglot-5.8B",
        "6101": "SparseOPT-1.3B",
        "6102": "Walter-Mistral-7B"
    }
}